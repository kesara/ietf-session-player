[
  {
    "startTime": "00:00:03",
    "text": "You I think you can start on time. I can go see if there's anybody in the hallway. Yeah. Hi, everyone. Lunch will be slightly delayed, but it will be here around 12:15. obviously, if there's anybody outside that wants to come in and maybe start -- Yeah. -- a couple minutes late. We'll about of maybe we suppose more. I guess there's a little bit of noise. We will start shortly. And subsidiary in front of his the technical problem Yes. Should we be starting?"
  },
  {
    "startTime": "00:02:09",
    "text": "So I would propose that we start. Right? because just to be on time because I would like to go have some time for questions if possible. So my name is Wim Hendrix. I work for Nokia. So I worked for Vatch status yesterday on on the plenary. The goal of this Talk is to give you some insights what we are doing with respect to cloud native automation. So my goal of this session is to give you an actually an overview of Nephew. So Nephew is an open source project. that we are doing where all of this is being developed. Right? So And my goal of this talk is to give you some insights what we are doing. how it works and so on and so forth to get to share some knowledge and so on and so forth. But before I start, how many people here have been or have heard about nephew, Okay. so it's quite a few. And How many people are familiar with Kubernetes and that ecosystem. Because Yeah. I didn't know, so I prepared a few so quite a bit. I prepared a few slides to give you some context because all of this happens within the So of Kubernetes. So I wanted to I didn't know what to expect, so I give In the presentation, there is a little bit of information on on that as well. just to give you some comp. Now so As a start, what we are trying to do in Nephew is actually so this is actually screenshots from the website. So what we are trying to do is to deliver but but we call a clouds get a great cloud native automation solution. The use case that we are focused upon right now is actually"
  },
  {
    "startTime": "00:04:00",
    "text": "network function deployments of 5g and so on and so forth at scale. Now what you will see or what I will trying to do during this presentation, a number of the things that we are doing with respect to the automation tool chain is not constrained to the use case. Right? So keep that in mind, but I will use that use case to illustrate the primitive that we are using with the nephew to do that automation. But use case as such out so the the the the solution as such is not constrained to that use case. Right? And I'll try to explain that in probably a little bit more detail when we go to the examples and so on and so forth. But we so what is important here, what we see is that we are actually extending Kubernetes Right? with a number of primitives to achieve that. And so the use case is important because what we don't want to do inside of Nephew is reinvent everything that has happened within that ecosystem, we are trying to augment things that are not yet available there. Right? And as such, we are trying to augment capabilities and give you capabilities to ease that automation within that environment. Right? Now one of the primitive that we have is we have to do that at a pretty large scale. So in other words, for us, the units that we work with is not just a single cluster, but it's actually a fleet of clusters. Right? and you will see that that in a bit first of all, this project is not a Nokia project, so it's it actually got instant initiated by Google, and it actually sponsored by Google, there is a number of let's say vendors system integrators as well as service providers involved because What is important is that this is actually an area that is important I or that all these parties need to be involved and Right? Because we can come up with a great automation framework, but unless vendors adopted, and secondly, the service providers implemented, it has no use. the Right? So when as such,"
  },
  {
    "startTime": "00:06:01",
    "text": "it's critical to have that landscape of people that are involved in this in this space to get insights on how they are using, or what they are using. And secondly, trying to identify the gaps that we have and and try to improve those as we go along. Right. Right. Right. Also, this is, yeah, I forgot to mention. So all of this happens in LF Networking. So there's a Linux foundation context. Right? And so everything that I'm talking about is is actually open source. Right? Now in order to achieve that, and I mentioned that we are using use cases and user stories. Right? and we are using we are doing reference implementation. Right? So all of what I'm talking about here, you actually see in quotes. right. Right. and you can actually experiment yourself with within that environment. And in order to prove that we are using reference implementation, and one of those reference implementation is Free 5GC. So Free 5GC is an implementation off. a 5g core. So you have a u I for those familiar with the terminology that you have a UPI, an the 11 and AMF, and you have an NRF. And I see you have the whole framework there. and we are using that to approve that that use case. We also started to provision infrastructure, so we are provisioning clusters and so on and so forth. So there is an implementation of cluster API, which is a Kubernetes project. And so we are using that to actually illustrate how clusters could be provisioned during that framework that we will talk The second piece of Nephew is a set of what I call machinery that enables those use case and enables that cloud native automation who as such, So nephew has actually 2 phases, if you will. 1 phase is the use case. Right? The 2nd phase is actually the machinery to accomplish that use case And as I mentioned in the beginning, the machinery is not constrained to the use case. there are specific pieces that are specific to"
  },
  {
    "startTime": "00:08:00",
    "text": "that's 35 DC, but there are a lot of parameter that we are building that have that can be used, for example, to deploy a database. Right? Or primitive that is completely not limited to network functions. Right? And you will see already, I'm using some terminology here, so we're using in that I what I call CRM. So KLM is the It stands for kubernetes resource model, Right? So we're using the Kubernetes API, machinery, as is, and we are extending debts with a set of parameters. So, for example, You see here the mention of packages, right, so I'll explain that in more detail. So a construct that natively at the moment is not existing inside of Kubernetes. So that's a primitive that we have been extending kubernetes with to be able to accomplish this. Right? You see controllers that is a native primitive but we also consume CRM functions. Right? Get that can be run as a serverless function. Right? to accomplish something. and those can run either in a container, but can also run as a web assembly element that just execute something and achieve a certain task. Okay? So 2 things, Nephew, is use cases, 2nd is machinery. Right? So keep that in mind. I'm using the 35 DC, so network functions, to illustrate the machinery, but you will see that you can actually leverage that in other environment. Okay? Okay? Okay? Okay? Okay? Okay? Okay. Okay? Okay? Okay? Okay? Okay? Okay. Okay? Okay? Okay? Okay? Okay? Okay? Okay. Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay. Okay? Okay? Okay? Okay? Okay? Okay. Okay? Okay? Okay? Okay. Okay? Okay. Okay? Okay? Okay. Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay? Okay Now to give you some context of of the environment, familiar ISO, most of the are familiar with telco landscape, I'm assuming or not. because If you look to Nephew We are looking at fleet of elements. So I mentioned already, we have multiple clusters. So we operate on an environment that have multiple clusters. for example, if you look to the radio,"
  },
  {
    "startTime": "00:10:01",
    "text": "in a 5 g, you can have, like, 10,000 sites or depend ISO. is a huge amount of sites on which that get deployed or can be deployed. Right? So you see that that scale that automation framework has to support those type of environments. Right? So it can be small but can be fairly large. Right? And so that's gets a set of challenges that we have to accomplish, and that's what we are addressing with with the nephew. The second thing that you see and One of the reason Nephew exists. This is an important element. I mean, as a vendor, We have been used to develop platforms that completely, what I call a black box. Right? So everything, hardware, software, everything was packaged together. and was actually used to deliver those applications. Right? And why did we do that? Because we had fairly high performance. There was a lot of scale. There was a lot of let's say, performance and availability request to to make that scalable and high highly performing. But what you see is we are coming into a world of desegregation. So these days, these environments will be built on a genetic cloud computing environment and you'll see that there is a complete decoupling between the app and the infra. Now you come from a world where you have been in control over everything, if on the planet, and now you have to move to an environment where Some of these information is delivered by someone else, right, and you don't have full control over it. How do you do that? So what you see And and one of the challenge that you see is that every vendor has its own way to do that. And so one of the things that we are trying to do also in Nephew is try to standardize the decoupling between that infra piece and the application. Because what you see is that in order to develop and deploy it at scale,"
  },
  {
    "startTime": "00:12:02",
    "text": "There is a number of various roles and responsibility and organization that are involved to deliver them. bright, So as such, a network function or that application developed or is delivered or is by a certain group of people that own and that are responsible for that application. but the infrastructure is done by a completely different team. rights. Right? So we could build an automation framework that's doesn't care about that, but but the reality is that people consume us in that in an environment where you have different roles and responsibility to achieve that deployment. Right? And another element where you see that we are doing a lot of effort That's with respect to the APIs, with respect to the ARBEC controls and stuff like that, who is able to do what in that journey of automation. Right? The third thing is that's i. that's related to the the bullet that I mentioned before is that every vendor, including ourselves, we have our own specific view of that world. Right? And I call it the the eye. I made the annotation towards the houses, because everyone believed that he builds his own house and the house is the best. Right? But in reality, what you see is that operators they consume not everything from a single vendor. Right? So that means that if everybody comes with its own house and with its own thing, and and you have to integrate. You have to you see that you have to stack all of these houses together. and that's very complicated. Right? So what we are trying to do is actually inside of Nephew, is giving you a unified environment on which all of these things run. Right? to illustrate it differently is we are trying to use Kubernetes And so this is the link towards Kubernetes. As a debt operating system, on which those apps are delivered. So instead of building our own house, with our own Kubernetes environment, with our own specific set tools, tools,"
  },
  {
    "startTime": "00:14:00",
    "text": "No. We are trying to build a generic Kubernetes framework, and then there's a set of apps think the apps are similar to the network functions, that are going to be run on that environment. Right? So so we are going to use Kubernetes as a native operating system on which all of this runs. and different vendors will use that same Kubernetes framework. Right? And we are not going to have a specific one for Ericsson's for Nokia and so on and so forth. Right? Right? Right? So that's the other important aspect. And I make the l annotation similar to our Android words or or I also you have a set of apps that are being developed over there that delivered that automation environment. Okay? Now then we come to Kubernetes. So given that there is quite knowledge in the room so I'm I'm not gonna to go into a lot of detail. But Kubernetes, at the end of the day, at its core, Whats is actually a container orchestration system. Right? And so what it actually does is use you have a set of applications, You deploy that, and it actually orchestrates that cross dedicated environment, and you could say Kubernetes is a cloud by itself, 4 containers. In the meantime, you have solutions that also allow it to be used for VMs and so on and so forth, but, basically, in its core, that's what it Right? And that's where it was born at at Now and in Kubernetes, we have a concept of So a note which is a a host on which something gets scheduled. Right? So a bot I so container is scheduled in the in a framework of a pod. Right? So a pod can have multiple containers. and there is an API server that makes that happen and a scheduler and so on forth. So there's a bunch of primitives inside of Kubernetes that that make that happen. Okay? Now Then you see I mean, this is a"
  },
  {
    "startTime": "00:16:02",
    "text": "slide that is being used by many people, but you see that it's that Kubernetes has been extended It every direction possible. Right? So As such today, you can use Kubernetes to, for example, to set up a VPC or to set up Kubernetes inside of Google or inside of AWS. So in other words, It's no longer constrained. to container orchestration. So it's being used by various projects to do anything. I mean, if you look here, I don't know how many icons are on the charts. but it's probably more than 2, 300 icons that are on this job that are doing something. Right? For example, in this context, can I mean, this was one of You the experiments that we used before we we jumped on this bandwagon. We tried to see can we leverage that Kubernetes system for example, to reach out to physical elements. Right? Like, we we in in this context, we have a lot of devices which have Yang support. Right? can we leverage Kubernetes to interact with a yang based API? The answer is yes. Right? And so what you see is that because of we have all of these primitives, and we have that huge ecosystem It makes sense to leverage that for that whole automation framework that's basically why we leverage in Kubernetes because you can leverage a lot of activities or a lot of project that are enabling certain use cases. you don't have to develop it yourself. You just have to interact with that with that API. because we are all using And TRM, which is the language, if you will, on how that API system works inside of Kubernetes. that whole integration becomes way easier. Or at least that's our perspective. Okay? Now at its core, What is and how does Kubernetes work? Actually, that is a controller. Right?"
  },
  {
    "startTime": "00:18:02",
    "text": "and it's a very simple building block. So you have a controller that has a sensor So you get an event and that's controllable do something with that event. And at its core Kubernetes is an intent based system, So it basically gets a request from an API, I want This desired state, It looks at the actual states of what's happening for that particular environment, and it ensures that it tries to align them. Right? So it tries to align the desive state to the actual state of that system And if you look to inside of Kubernetes natively without any extension, you'll see a tons of these controllers happening. But if you look at it from an automation framework, It's a very nice primitive to leverage for automation because you get a complete event driven and declarative system with us. Right. Right. and we want to leverage that 4 the use case that I was talking about in the beginning. Okay? The second thing, just to give some context, what is krm. Right? I have a better example actually later into the the the examples. But It's a predefined, you could say, there is a header Right? So there is a a header that is a fairly standard, and then you have basically a spec on which you can define your own API attributes and you have the status which are also customizable, but the spec itself I saw the map of data in the header, if you will. is a predefined format, and that's the thing that we are leveraging and that's what we are calling KLM based system is basically there is a predefined cheema, that we are leveraging in order to do a number of things. And why is that important? For example, by having that predefined schema, and that all these application leverage the same schema Integration of the API system becomes way more simpler."
  },
  {
    "startTime": "00:20:00",
    "text": "because we are all somehow talking the same language, but then you can customize it within a set of parameters. Right? And and what you see is why is that ecosystem so big Kubernetes has a concept of CRDs, Right? And CRDs are a way to extend the API with your own schema. you can take any So schema that you want. So for example, one of the experiments that I did was I took a young file of IDF or any device. And you basically build a schema with that Yung. schema. So as a result, you now have a mapping of that young device inside of KRM, and then you have to ensure that you can interact with it in a declarative way. And as a result, you enable a bunch of use cases. Right? So that is the basic primitives that we are talking about. 2nd, very nice attribute of KLM is it's completely event driven. Right? So that means if your state changes or if you get a trigger from something, You can actually See whether this the desired state is still in line with actual state and so on and so forth. So you get a very a nice set of primitives, which are I I In my view, fantastic for when you are looking at automation. Because what you typically see in automation frameworks today is They focus on configuration. but they are not focused on this event driven system that actually take into account real estate, that is changing dynamically during that environment. Okay? So these are the base venitas principles that we rely upon to, let's say, develop or the the deploy nephew Now you can ask yourself what is missing. white. because You see on one hand, CNCF, which has this ecosystem. I don't know how many people probably 500 different solutions. and then I what this nephew trying trying to do. So, for example, 4,"
  },
  {
    "startTime": "00:22:02",
    "text": "the thing that I was mentioning, the young based interaction. Today, we don't have something in CNCF that does that, for example. Right? So interacting with the yang based device. is actually something that we would like to have in order to accomplish let's say, interacting with devices that have that API. right. And that's not constrained. to ISO that can be BNGs that can be a 5gsystem that can be physical switches that can be basically anything. like like like like And as such, what we did in Nephew, We try to structure the space into 3 swimblanes, if you will. Right? On the left hand side, We have what we call the infra swimling, which is about infrastructure, configuration. So I think of clusters in that space. Think of network inter connectivity and so on and so forth. So these are actually infrastructure that you need to deploy those network functions. The second swim lane in the middle is actually the life cycle management, which are not focusing on the configuration change. So for example, if you have an app and you want to deploy it So take, for example, a database You want to deploy it and you want 10 flavors of it or you want to upgrade it, that's what is in what we call the swim lane 2, which is the middle swim lane where we actually do genetic life cycle operations. on such a function Right? And then the 3rd swim lane, which is on the right, is actually the configuration changes, onto a running system As for example, you want to add a VLOM You want to change the VPN or you want to ISO in in networking space or you want to add slice, things like that. on the running system, That's what basically swim Laying 3 is. is where you can do that dynamic change. So we basically separated that into various buckets"
  },
  {
    "startTime": "00:24:03",
    "text": "And as such, that's how we reason and look at those use cases to see what is missing in all in one of in each of these 3 swimlays, and what do we have to do to actually extend that. And you will see in the next set of slides, what are the things or the primitives that we have been adding in order to make that automation journey easier. Okay? Now, Before I go into more details, what is important, I mentioned it in the beginning, is that whole concept of roles and responsibilities. Right? Because you deploy an app, and you need something from the infra. Let's say you need a VLOM on a switch, to work to ensure that that app runs Typically, that VLOM or that IP address that is configured on that switch, is typically done by a different team. So it's typically not the people that develop that app. It's typically done by the info. Right? So you need to ensure that that whole ecosystem takes in account these primitives and the way that people consume you. Right? And that has reported effect on how we build that API system, and how we package those system into a decomposeable infrastructure, that is flexible to accommodate different environments because also it is like this that not every operator is the same. Right? So we also see that depending on how people are organized, you can see different roles and different responsibility. to achieve and accomplish something. Right? So The first thing that we saw inside of of that whole journey is that There was something missing with respect to the way that that whole automation system work, and A configuration as data is a concept that we are using inside of Nephew, and to summarize it what it means, is"
  },
  {
    "startTime": "00:26:02",
    "text": "the first thing if you look native Kubernetes, it doesn't have a version backup. So Right? Well, it means that if you at an API or a or a a YAML file it's doesn't keep track of the the various versions. Right? So that means if you change something, The latest version is what is in the i API system. So it doesn't track the the changes necessarily, and it doesn't keep track of of the different flavors that you have inside. So there is a version back end that we are using. second thing that we use in configuration is data is package, management system, So what is the package? a package is a set of KLM resources. And why is that important? Because that set is achieving something. Right? So if you build a package you basically build a set of resources in that packets together that accomplish something. So example just to I think in the next slide is an example. I don't know whether very visible. But you see right hand side, You see That is a package. So a package, for example, in this case, This is an example of a network function Right? So you see that you have interfaces. So that is I need this network function needs 3 interfaces. It needs a IDNN which is very specific to 5 g. So it needs a PLM NID. Right? It needs a pool for UV IP addresses. So what the package does is actually, it's a set of individual resources But together in the packets, they are binded together. Right? Right? But the nice attribute of that is We do not have to build an API system for each of these functions. We can actually say, So that interface resource, if you see here, Whether it's a 5g system. or whether it's a network device or whether it's a PNG or whether it's whatever thing that needs an interface, We just reuse that same"
  },
  {
    "startTime": "00:28:01",
    "text": "building blocks. So that CRM resource that you see inside, we can just reuse for anything. rather than building a new API to And aggregates it and tries to do it. We just say this package contains a set of resources. And the the fact that they are together in the package means that they are bind somehow together. And that also allows us to go very quickly because That means we don't have to have various conversations on how that API system and how the best truck the future is to accomplish these things together. We just need to ensure that the basic building blocks that we need we have to define, and then we just consume that system Right? And the second or the third thing that actually configuration as data does. Is it allows us to have a set of functions or controllers that act on that package. Right? Because what you see is that sometimes you need to change I so that parameter is an input and needs to be used, for example, I need an interface that interface needs a VLOM. Right? I need to allocate a VLOM Right? So what that I what that pipeline does within the package it gives you a set of functions or controls that actually use that data that is inside and then mutates, or generate or validate the data that you receive within that package. So as a result, I what is nice now? You can actually mutate data. So for example, you say I get this VLOM. I need it from this interface. You can actually mutate during that package and because you have all these CRM resources, you can actually builds a completely new resource from the input that you get. Right? And these are things that you don't have natively inside of Kubernetes. and we are heavily using that. because you get this whole deco so this decomposable piece of software, that you can compose together the way you want. Right? And we what we are trying to do in Nephew. is try to build those functions,"
  },
  {
    "startTime": "00:30:04",
    "text": "as generically as possible so that we can use it into various use cases. That's why I said from the beginning, the use case as such is focused on Free FireGC, for example, the interface function, We have already tried it to use it, for example, inside of a cluster. Right? or inside of a switch or inside of a network function. So we can use those things in various resources And then if we have a library of all of these functions, we can basically scale to do many use cases. So that's basically how you have to look at at Nephew. And what you see here in this example is The left hand side is how the packets look like when it started. And when you go through a whole pipeline, it changes mutates, validates, and changes the resources of generate new resources that are relevant through that pipeline. Right? And I also I have a better examples on how that works in reality. But That's basically configuration as data. So it's a concept that allows us to mutate, extend use resources within a package and and and change it. And the other nice attribute of it is that During ISO, when you when you have a package as an input, and you generate new inputs You keep track of all the changes. that means let's say So i. i. what we call inside of Nephew. We have something what we call a blueprint package. So it's the social where everything starts from. Now let's say that for whatever reason, we have a new software or we see that there is a security vulnerability. and we have to update that package. for a a secondary vision to accommodate for that change. What happens actually is that we just changed a new revision, and that whole hydration, if you will, is exactly the same. So we always keep track of that whole chain how each of the steps that have happened, during that pipeline at"
  },
  {
    "startTime": "00:32:01",
    "text": "to keep track of of of the changes and and be able to to changes at scale. and that works across the whole fleets of the environment that I was So Now How does nephew look as an architecture? Right? Because so far, I've been mainly talking about the the the the pieces of the puzzle, If you look to Nephew as a system, how we architected as to how we put pieces together is we have a concept of what we call a management cluster. Right? Right? And we have what we call workloads Right? So think of those 10,000 sides of the radio. Right? So each of them represents a bubble in this. and that also can be what we sometimes call a runtime. Right? So we have, like, a management play, which we do stuff, on then we have runtime or workload environments which gets then the actual running application, that is going to accomplish some Right? Now also to make a bit of an analogy towards Kubernetes back So in Kubernetes, what you typically have, you have a cluster. Right? So Kubernetes natively works within a cluster, And as I mentioned before, there is notes. So notes are can be delivered in bare metal or VMs and stuff like that. So a node is a unit on which you can schedule containers. Right? or pots in the case of of Kubernetes. So they they schedule pots. And then we have what we call the deployments or statefulsets. So depending whether you have a stateless or state full application, You basically schedule that unit across that fleet. Right? So you basically have and that's what i. i. essence what Kubernetes was born wit. Okay? If you make the analogy to Nephew, replace node with cluster. Right? So you have a cluster which is the unit on which you schedule."
  },
  {
    "startTime": "00:34:01",
    "text": "You have network functions, so the application, so because of network function can consist of multiple pots Right? and we schedule them across those clusters. Right? So that's kind of a little bit how the use case for Free FireGC or for is is working right now. We have package from the beginning, and we schedule that across the fleet of cluster. So, for example, we can say schedule it only here or schedule it there. depending on the parameters that you give it as the input for your automation frame. Right? So So that is a lot of analogy that you see here on how Kubernetes works as a base system. but it doesn't have this concept of fleets Management. Right? So that's something that we have added into it. then if you put that together, right, so you basically have that management plus And of and that those run times on that management cluster We have a set of controllers and functions that are running to accomplish that automation jump. Right? And so what are those things. So typically what we try to do is we try start from what we call a blueprint package. Right? As you saw before, A blueprint package consists of a set of CRM resources like the interface, I need an IP address. I need a VLOM. I need so those type of things. And then what you see is that We schedule that package towards a certain environment, right, that can just be I need 1, or I need it everywhere, or I need it almost I I need it regionalized. Right? So you basically say, I want to fan out based on a set of criteria. So what actually then happens is we replicate that package. But what you see is during automation, that environment on which that gets scheduled, has potentially specific parameters. So what we are doing during that process we are I so we are actually, propagating values,"
  },
  {
    "startTime": "00:36:05",
    "text": "towards from that specific environments inside of that package dynamically and then we mutate it further to accomplish that automation job. Right? So that's kind of a little bit how Matthew works. And then We also try to And that was the feedback from a lot of customers and service providers. We try to give them the hooks, to validate and tests this output before they actually go to the runtime. Right? So in other words, you can people talk about digital twins and stuff like that. So you could actually say, I get a new, let's say, outputs, outputs but I want to validate that that configuration that I'm going to apply to that environment actually works. Right? So you can actually build a hook to say, okay. I scheduled this to a system run it through a CICD pipeline. and then you can actually validate before you go to the runtime. So all of these components are actually inside of the system to achieve that. So Now What are those primitives that we use to accomplish that. So the first one what we call a package variance. So believe you start from a package, And because everything is versions, Right? We clone that package, but you potentially can change parameters. Right? So, for example, I want to deploy onto this region. So you get the regionalized parameters so that package will Alright. So some of these parameters, and you can control how you do it. you can actually mutates or that parameters that are locally or giving you the context on where it gets scheduled. gets then added into the package based on that function, that you set up within that package itself. Right? So you basically you can see you can build very decomposeable constructs, fairly easily to to achieve that."
  },
  {
    "startTime": "00:38:03",
    "text": "And we, for example, when we started nephew of the use cases, we started looking at 35 DC, and then we said, okay, but we also need clusters. can we use the same primitives to basically deploy clusters. and we used exactly the same constructs just to prove that the machinery that we are building can be reused for different use Right? The 2nd primitive that we built is what we call a package variant set The way I would describe it, it's a four loop. with some input, with some context, And so basically have a scheduler that takes that package with that parameter, you act so you do that by that fan out that I was showing to basically deploy this across a fleet of of environments. So that's whole thing. So that's what the package variant sets actually does. So you take a package as the input, you schedule it, towards various environments, and then each of these parameters that are let's say, localized for that environment gets added or mutated within within that packets. The third thing that we that we do is is is when we go to that whole process and and that also comes to the factor of that roles and responsibility, You see that typically, for example, that interface Right? So that network function says I need that specific interface but then the infrastructure person needs to allocate a set of resources that are needed for for for that interface. So what's that's choreography does, It actually allows you to to achieve those type of tasks, independently, but together, they achieve a a certain outcome. So that is actually nice because you actually have like the"
  },
  {
    "startTime": "00:40:00",
    "text": "independent function that have no clue that they are working together inside of a package but they together because of the composition that we have or the choreography that we have, actually achieve that. And so the way we do that is we leverage, leverage, let's say, the primitives that are within the Kubernetes ecosystem of conditions. So for example, if a function run You can actually say that's I need more work from you, and you can actually request work to another function that is then going to act so that whole pipeline gets automatically triggered and figures out all the dependency automatically without you having to figure out, okay, how does each of these things work together. So it gives you a very nice way to accomplish a set of tasks independently without creating a lot of logic on how it all works together. Right? So that's I how you have to look at it. You probably have to look at this in more details on how it looks like, it's nice is you don't have to build by ourselves that hold dependency 3 on on which thing is dependent or what, it sorts itself out. right? Similarly, on how Kubernetes work, you have a set of independent controllers that tell you I have a want an IP address. and the person that needs that allocates IP addresses is going to act and it's going to allocate that thing, and he's going to then make it known and then something else will trigger. So that whole pipeline as you see is is something that basically happens automatically. So to, yeah, give you some context, so what did we deliver in r one. So r one is a release of nephew that just was done. Right? So all of the primitives that I was showing you here are actually delivered. Right? So all of these functions are available. in open source. And the use cases that we are able to accomplish with that is deploying"
  },
  {
    "startTime": "00:42:01",
    "text": "a a 35 DC across that whole fleet of that environment. Right? we are able to do changes to those configurations. So, basically, those packages when you say, I have a new revision. I have new changes inside of them. they will auto automatically hydrate and stuff like that. You can do changes, upgrades, and stuff like that. plus you, we also have provisioning of all the networking and clusters and stuff like that. So So there is a whole bunch of use cases that we enable within the r one release in order to accomplish some of that task. until the point that you can actually make a call. Right? Because it all comes down to making it work and and basically achieving a call or a data play packet across that whole infrastructure. So with that, I think yeah. So lunch is coming in, so it's right on time. So I hope you get a little bit of a better understanding of you're trying to accomplish with Nephew. So here, there's a bunch of links if you want to go into more details. And given that we have still some time, I think if there are questions, I'm happy to take some questions. Thank you. chaos, Okay. Yeah. Charles Eckel. First of all, you know, thanks for a great talk. really enjoyed it. And one of the things we were just talking about earlier today, which I'd like to get your insights on where we do a lot with certificate and certificate management here, and they're that he asked me working group and was just wondering within this environment, if Nephew like, how does Nephew deal with containers and with renewing certificates, especially perhaps short lived certificates Is it kind of like the"
  },
  {
    "startTime": "00:44:03",
    "text": "and maybe this is a deployment option, but whether to tie the life of the container to the life of the certificate, or does Nexeo handle renewing certificates whenever necessary and keep the container running across This renewal. So first of all, I mean, I that's something that is natively inside of Kubernetes, so there search manager, which actually interact with Acme, So to actually generate certificates automatically. Right? and that whole renewal process is there. So the way that Kubernetes works basically with certificates, you actually mount that certificate inside of your box And if you renew it, You actually so that volume get changed. and then the application takes that new certificate into account and and leverage it. So the new session so the ongoing session still use the old, right, because the session has been set up. But every you session that is being set up is going to leverage And when you say new session, is that, like, a new container that gets spun up or does the -- Okay. -- the container stay up the whole time? The container stays up. Right? So you have a volume that so that certificate gets injected inside of the bot. Right? And then the application, uses or depending on how it's written, you can also I depend. Right? But there are let's say, basic primitives inside of Kubernetes that allow you to reuse that certificate on the fly. Okay. Great. Great. Thank you. Hi. Nacho from Telefonica. I was wondering, if you consider using Helm for managing packages. Okay. That's so So that's an a a hot topic inside of Nephew. And I did not yeah. I did not go to the into that detail so far. But if you look configuration as data -- Mhmm. is a little bit so they are competing with Helm a little bit. So or let's say, attacking Helm if you will. Mhmm."
  },
  {
    "startTime": "00:46:02",
    "text": "And what is let me explain the reasons behind. Right? If you look to help, for those familiar helm is actually as high. is a is a mechanism which You have, like, a values of your mobile file. Right? So So they basically deliver a new API, And then through a set of templating and rendering systems, you actually generate a of resources. Right? So if you compare that with configuration as data, with the package system, The difference is that you don't have to build a new API which is the values of YAML file. Right? So so it's the same API, and you have a set of functions and new data to basically accomplish what helped us. Mhmm. But So Why? are the configurations, data people doing that is because you get Nate KLM, you don't have to build a new system to mutate something. Right? So you don't have to build a new API, that is not native Kubernetes. Not native KLM. And now you have to manage that's All life cycle, you have to have a system that does that and so on and so forth. Right? that's the reason. If you look to So confirmation data for this album. It's not that they say it's bad. They say that's a different behavior. Now What you see in the industry is that configuration as data is brand new and Helm has been used or around for. I don't know how because it was even there from the opens like this. Right? So What you see is that Helm is used a lot by Actually, every vendor today has a helm chart one way or another to accomplish. So we are looking as we speak to integrate Helm within the whole ecosystem. Now But I I can tell you the latest discussion that we had on the topic We are at the main use case or the main requirement that we get is the ability to reuse help charts that the vendor already has in that whole ecosystem. Right? Now"
  },
  {
    "startTime": "00:48:00",
    "text": "what it means is actually that it's needed at the end because the vendors don't want to change those helm charts either in order to leverage the benefits of the system that I showed here. Right? What it means actually is that that help job will be used at the later stage. And so what we will do or what we plan to do inside of Nephew is to render that whole specialization, that package towards the value of the YAML file, that is what the vendor delivered. You see? And so we don't have to change anything. We just have to ensure that we can render that whole thing So that whole system that you saw before will not change. We just need to make a plug in at the end, and and Typically, those plug ins already exist. We just have to use some of these things. to leverage that values of YAMO construct. and ensure that we, let's say, hydrate those parameters towards it and then deploy it as this as this as this And that's how we are looking at supporting help. within the Nephew framework. Okay. Okay. Thank you. okay. Okay. Thanks. Any other question, Yeah. Hi. My name is Ted Kuo from National Yang Min. Chadong University U. S. is the the home of Free Fire GC. Okay. Perfect. Thank you. Nice to meet you. Yeah. So it's very nice to see that have been used chosen as one of the use case. question is, we are also working on manual how to deploy application to MEC area. Yes. wonder that if nephew or Haps similar discussion before, so that would maybe we we can join today. Work together is on that one. So if you look if you look to the pros that we are using in Nephew, a bit of an alternative to the mono frameworks. and because we have we leverage the full let's say benefits that Kubernetes gives us."
  },
  {
    "startTime": "00:50:02",
    "text": "because it has a whole life. I we don't need to have a life cycle manager because the controller that I was showing before is a life cycle manager on its own. Yeah. And so what you see is that actually the nephew approach is basically a different way to achieve what Menno tries to achieve. Yeah. Right? So what we are trying to prove right now with Nephew, I think, is to try to show you that it will be faster and quicker to leverage that approach, plus you can leverage that whole ecosystem that I was mentioning before. Yes. I think that's in line with what we thought about. we start from the old exam because the it was a tool over there already. Yeah. So But once the nephew comes up, we are thinking about this some possibility of how to deploy it this application in a more efficient way toward the MEC distributed MEC environment. Right? Yeah. Yeah. Say yeah. So so we will work. So that's one of the use case that we are going to focus on next most likely, is Mac and and radio and stuff like that. Okay. That's great. So and anything we can do to help Yeah. Let's let's talk offline. Yeah. Thank you. Any other questions? If not, Thank you for your time. and I hope you look because this Okay. Yeah. positive. understandable?"
  },
  {
    "startTime": "00:52:04",
    "text": "Thanks. Okay. Okay. Perfect. Don't have to be the sometimes, either No. No. I don't. Yeah. I don't know. I didn't know."
  }
]
