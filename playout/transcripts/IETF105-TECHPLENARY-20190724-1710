[
  {
    "startTime": "00:00:28",
    "text": "Goswami diminish your good evening ladies and gentlemen Bienvenue or IETF welcome to the IETF we have an announcement to make you know for and I\u0027ll say kefka\u0027s shows we\u0027re having a bit of a technical problem up front with the projectors these lovely people are working on it but we want to let you know that the download all of the presentations from the from the website now this is a stress test for the network because we may have to go forward with the rest of the program with those in your laptop\u0027s as opposed to on these nice big screens so if you would like to find your way to the agenda page now and start at downloading the next step will be Brian Trammell who will introduce our speakers and provide backing interpretive dance I\u0027ve been joking about that but there\u0027s an actual separate stage for it normally we would let this debugging go on a little bit longer but we have a quite a tough schedule tonight and a lot of people would be upset if we ran late so we\u0027re going to try it this way please do download them and please do give your attention to the speakers even if there aren\u0027t any pretty lights many thanks right so I have the slides here on the monitor in front of me so if everyone could please come to the front hi I\u0027m Brian Trammell I be the emcee for the technical portion of tonight\u0027s whoo or you can hang out on me Tyco which will also be a stress test for me deco also a stress test so as a beginning note were you\u0027ll notice on the agendas that we\u0027re trying out something new this time we\u0027re more explicitly splitting the tech and tech and admin plenaries um you know wait way way back in the past these were on separate evenings and then they sort of came together and then they sort of came even farther together into a single session we are splitting these out explicitly to make sure that we have enough time for the tech plenary as well as enough time for the admin plenary this part of the session is one hour long which is why we were going ahead and getting started even though we don\u0027t have video yet um we\u0027re going to be holding pretty strictly to time there will be time for questions and discussion at the end "
  },
  {
    "startTime": "00:03:28",
    "text": "um so um you know clarifying questions only but please know clarifying questions um with that privacy question mark what\u0027s the delay on okay all right yes next slide please as some of you may be aware the IB and the IETF at least we hope many in the IETF is deeply interested in confidentiality on the Internet this is a conversation that we\u0027ve had ongoing for a while we\u0027re interested in this in large part for reasons of privacy um we spend a lot of time in the working groups these days hmm that is the most applause I thought I would ever get for privacy with a question mark and an IETF meeting post Vancouver I\u0027ll go ahead and it gets better um uh we\u0027ve been talking a lot about in the in the the working groups and in the hallways and you know around the working groups and um the press and sort of everywhere it\u0027s been a while since we\u0027ve addressed it in plenary so we\u0027d like to change that tonight we have a program where we\u0027d like to talk about current issues and eternal issues in Internet privacy with Arvind or Ivan and Ryan I worked so hard to get your name right and Steve elleven Arvin Ryan is an associate professor of computer science at Princeton he leads the Princeton web transparency and accountability project he\u0027s also the recipient of the presidential Early Career Award for scientists and engineers if there\u0027s a award ceremony for this that he\u0027s missing to be with us tonight so we\u0027re very very honored to have him here he\u0027ll be talking about some of the implications and current trends and communicate on communications privacy in large current trends on communication parts the internet sort of in the large so he\u0027s sort of a contextual look at this Steve Delavan needs no introduction in this room but I\u0027m gonna try to do so anyway um he is a former member of the IAB a former security Area Director he was instrumental in the creation of Usenet um some of you may have heard of that he\u0027s currently professor of computer science at Columbia and affiliate at Columbia law he will be showing us tonight that an Internet privacy everything old is new again so thank you both Arvind come on so I\u0027d like to share with you what I\u0027ve learned from a decade of doing privacy measurement is kind of a boring sounding term but what it really means is trying to find privacy vulnerabilities ideally on a large scale I\u0027m talking millions of endpoints and an "
  },
  {
    "startTime": "00:06:28",
    "text": "automated or mostly automated way and before I do that I\u0027ll start with a couple of caveats one is I\u0027m going to be really upfront that most of my work has been in the web space and my prior engagement with standards agencies spend with the w3c and that\u0027s what a lot of this is going to be informed by but that\u0027s what I\u0027m going to try really hard to do is extract some principles that are much more broadly applicable and that\u0027s what I\u0027d like to share with you today and another thing that\u0027s going to be a common theme of the presentation is that I\u0027m going to be talking about issues beyond encryption I\u0027m going to assume that we\u0027re in a world with pervasive encryption and in fact some of the things that I\u0027ll touch upon are perhaps some downsides of encryption or privacy and how we can try to mitigate them so that already sounds surprising to some of you so I hope this will be an interesting discussion I should also say that that as you\u0027ve heard from the intro I\u0027m an academic so my job is to think you know idealistic lucify thoughts there are going to be points where you\u0027re going to feel oh this will never work in the real world and you\u0027re welcome to come say that I\u0027m Q\u0026A that\u0027s totally our game and I appreciate that okay so with those caveats here are three things that I want to share with you the first thing is an issue that very options up when we\u0027re talking about privacy beyond approaching especially when we\u0027re talking about more subtle privacy threats such as device fingerprinting an argument that often comes up is oh forget about fingerprinting that ship has sailed the horses left the barn it\u0027s too late for fingerprinting defenses there are too many fingerprinting vectors too easy to do tracking so we should just forget about that and accept that we\u0027re going to be in a world where it\u0027s really easy to track profile people that\u0027s the first thing I tell you about and specifically this this has come up a lot in the web context [Music] [Music] [Music] "
  },
  {
    "startTime": "00:09:59",
    "text": "and ironically you can see on the list privacy features like do not track also contribute to fingerprinting because do you have do not track and able do not have it enable so that\u0027s a small amount of function entropy etc so one thing you might conclude from this is you know the horses left the barn fingerprinting is devastatingly effective we shouldn\u0027t even try to minimize the fingerprint ability of new features that we put into the standard now the w3c to their credit there were a lot of people who still try to minimize the fingerprint ability of new features and I don\u0027t want to present this as a criticism of other people this was absolutely me up until about a year ago so this is what I believed and here\u0027s why I changed my mind so those studies that I present it they were really you know excellent studies but there was something wrong with the way that a lot of people interpreted them one weird thing about those studies is that the users who participated were self selected so does that mean that the results could be non representative in some way what could be different about self selected users one possibility is that all the users who had self select into a study like that are actually really tech-savvy people the kind of people who are likely to make a lot of modifications in their browsers that would make them more unique and more fingerprint so that was one interesting kind of bias that some researchers suspected could be in those studies including some of the researchers at INRIA who were responsible for one of those studies and then what they did was they partnered with a major french website and fingerprinted all of the users of the of that website without really telling them so by doing this lightly ethically questionable thing they did a statistically much more rigorous thing and they published that study which found in fact contrary to some of the previous findings only a third of the users were unique and as more and more activity shifts to mobile less than a fifth of mobile users were unique because those devices are less customizable and further has flash and Java and other old plugins are phased-out that number is actually going down and if you look at for me when I looked at the findings of this study the conclusion was very different even little things that browsers can do in order to minimize the fingerprint ability of features are going to have a big impact and so I came away with this with a very different point of view then a lot of people have had before before this study which is let\u0027s not even bother let\u0027s not cripple features for the sake of privacy but instead after the study what I concluded was quite the opposite so I think this is a much more general principle in a lot of contexts we hear the ship has sailed the horses left the bar in kind of argument and if you were at Pete Snyder\u0027s talk at PRG earlier today you heard a lot of similar points from him as well you know the the same kind of thing that that I\u0027m saying here so that\u0027s the first kind of insight that I want to that I want to give you the ship has not sailed and one of the reasons that people will say that the ship has sailed is that if you don\u0027t have a perfect defense even if you try to mitigate fingerprint ability oh "
  },
  {
    "startTime": "00:13:00",
    "text": "here\u0027s a clever way that somebody can get around that well I have an imperfect defense at all is it is it not better to you know to not give people a false sense of security so that is a point on which I will disagree I think that imperfect defenses are still very useful and one reason I believe that is because technology doesn\u0027t have to bear the full burden of privacy protection what do I mean by this here\u0027s an interesting example Safari has third-party cookie blocking as you might know and it\u0027s not a perfect defense it can be circumvented in fact Google decided to do exactly that Google decided to circumvent it and once they did something interesting happened in the US the Federal Trade Commission got involved they said hey you can\u0027t do that you can\u0027t circumvent a privacy measure that\u0027s actually a violation of the law and they went after Google and they find Google so that\u0027s an interesting phenomenon where the technology itself was not bulletproof but it turns out that circumventing even a weak privacy protection measure can actually get companies into trouble with the law it can also be a reputational harm so when we\u0027re talking about the privacy adversaries here we\u0027re talking about the Facebook\u0027s and googles of the world where talking about somebody you know from a poorly regulated jurisdiction somewhere out there in the world and therefore technology doesn\u0027t have to bear the full burden and perfect defenses can still be useful even if all that it does is raise the cost of some of these fingerprinting and privacy invasive features and it takes a couple more years for those kind of tracking technologies to become very widespread that is still useful because it gives a couple of years for new defenses to be developed whether they may be technical or legal or something like that so that was point number one point number two that I want to talk about is we\u0027re in a world where what privacy means to people changes very quickly whether or not something is a privacy breach changes very quickly so both privacy attitudes and privacy infringing technologies change pretty quickly how can standards cope in this world given that standards are intended to be pretty long-lasting documents and so how do you resolve the tension between these two so one good example of this is one of my favorite examples of how privacy attitudes evolved quickly is that if you thought about privacy 10 years ago most users would have been concerned with what are the individual harms that can accrue to me out of all of those data collection out of all of the databases owned by companies that have my personal information is it identity theft is the data breaches is it perhaps targeted price discrimination what should I be worried about those were the kinds of privacy questions that people were asking people are still worried about those privacy issues but now people are increasingly worried about a very different kind of privacy issue which is what are the threats to society overall and perhaps to democracy from all of these massive collections of personal information especially after a recent recent stories like Cambridge analytic apeople are very concerned about what is the potential of hyper personalized targeting to affect you know the overall "
  },
  {
    "startTime": "00:16:01",
    "text": "society that we live in so I want to say that there has been a shift from these very individualized concerns about privacy to more collective societal concerns about privacy among privacy scholars and privacy advocates that shift has been pretty stark and even among the general public I think there has been a substantial shift and so what this means is that a certain type of data collide that might have seen pretty innocuous ten years ago begins to look very different today so that was one example I have a couple of other examples that I\u0027ll skip but the result of this is that it\u0027s very hard in a standard document to write down and fixed privacy definition and then say that I\u0027ve analyzed this protocol with respect to this privacy definition and I\u0027m confident that this is going to be a privacy respecting protocol now and for all time to come and so going back to that example of individual versus collective harms let me show you very quickly that paper by Cambridge researchers this was in 2013 this was the paper that realised that you could take people\u0027s Facebook Likes which is a very innocuous sounding type of information and use that to predict their so-called Big Five personality traits and those are things like emotional stability agreeableness extraversion and so on the stuff that you see in green over there if you can even greet that text sorry about that the font size is a little small and this is exactly the research that was allegedly weaponized by Cambridge analytic ofor psychographic targeting so this was not necessarily anticipated a few years ago there are many other examples of this of improvements in machine learning training innocuous data into something that can be used for something much more problematic this was a headline from a few years ago statisticians at Target had figured out how to use a person\u0027s shopping records to figure out whether they were pregnant or not and so a one concrete threat along these lines is well stated by Paul ohm who\u0027s a legal scholar who calls this the database of Rouen he asks us to imagine the consequences of a single massive database containing secrets about every individual formed by linking different companies data stores and I think one of the technologies that is enabling something like this today is cross device tracking techniques that enable the linking of our activities between different devices even if we\u0027re not identifying ourselves using explicit identifiers that allow such linkage just using statistical patterns to link these different devices together and I think these types of concerns should perhaps be at the forefront of some of our privacy efforts including in standards efforts but these are not things that we really recognized as privacy concerns maybe ten years ago as much as we do today so that\u0027s kind of what by the landscape of privacy is shifting pretty quickly and this is a challenge for our standards document in a standards process which needs to be really long-lived so we thought about this in a paper recently where we looked at specifically the battery status API in the web context and this was an API that turned out to have much more serious fingerprint ability privacy consequences then was realized and therefore was taken out of a number of browsers after it had shipped and after "
  },
  {
    "startTime": "00:19:02",
    "text": "people had started using it that was kind of unprecedented so we looked at how did this go wrong and how can we be more aware of these potential and misuses during the standards process and so here\u0027s a paper citation at the bottom and what we proposed in this paper at a high level what we called for is a much tighter loop between standards agencies as well as researchers and developers and by developers I mean both implementers and also developers in a much more general sense people who are using the api\u0027s that are you know implemented by by the browser vendors for example and as part of this we think that it would be really useful to incentivize academics to do two things one is to get involved in the standards process and do privacy reviews of standards and the other one this is perhaps still quite missing which is once an API is out in the wild and once people are using it to do regular privacy audits of how it\u0027s being used and abused I\u0027ve talked about this a few times and one question that I get is sure this sounds good in theory but it\u0027s hard to convince researchers to do this how do we do that now one good thing I\u0027ll say about this this actually sounds like a horrible thing but I\u0027ll claim it\u0027s a good thing is that it\u0027s fairly easy to influence academic researchers influenced influenced them not in the sense of what they\u0027ll say but it influenced them in the sense of what they want to work on by funding certain work or by making it more prestigious by creating awards for example for certain types of work such as privacy reviews of standards I think it\u0027s there\u0027s a there\u0027s a fairly straightforward path to incentivizing much more academic work as part of the standards process which I think will be a good thing another thing that I think would be useful is as part of the standard process to be explicit about assumptions because privacy changes so quickly because we can\u0027t anticipate what new privacy infringing technologies will be out there in five years it helps to be explicit about assumptions as part of the standards process and that is to be able to explicitly say we have created the standard assuming that this API will not be highly susceptible to fingerprint ability but if it turns out that that\u0027s the case if it turns out that this is being exploited in the wild here are some things that implementers could do to mitigate that risk so that\u0027s the second point okay the third and final point that I want to talk about is that this idea of measurement which is finding these privacy violations on a large scale I\u0027m claiming that it\u0027s been really useful for privacy but unfortunately it\u0027s going away and I want to talk about whether there is a way to preserve it I don\u0027t want to make the sound like a sky is falling kind of claim but in my little corner of the research world the sky has already fallen and a lot of us that have moved on to other research areas so let me tell you why that is and why that should worry us from a privacy perspective and to see whether there\u0027s a way to preserve it so I\u0027m claiming that at least in the web context measurement has played a very key role in keeping the worst of the privacy abuses in check "
  },
  {
    "startTime": "00:22:02",
    "text": "many teams around the world have been working on web privacy measurement I\u0027ll tell you a tiny bit about my own team\u0027s work something that we built is a tool called open wpm this is a the github page if you want to check it out as you can see it\u0027s an actively developed open-source project it was developed at Princeton and now the main developer Steve Englehart has moved to Mozilla it\u0027s maintained by Mozilla now so what it is I don\u0027t mean for any of the details on this page to be important this it\u0027s just the URL if you want to look at it or the name open wpm now what it is is an instrumented version of Firefox it\u0027s basically a bot that visits the web\u0027s top 1 million websites every month and looks at what kind of privacy violation violating techniques are out there it even does things like put in fake PII into various forms and tries to see where they go and it saves all that data we have half a terabyte of data per month and then we run various scripts on that data to try to find privacy violations and publicize them and get people to change their practices we\u0027ve written a number of papers based on this data this is one example it\u0027s called online tracking of 1 million site measurement analysis and as you can see one of the key things here is to be able to do this on a large scale in a mostly automated way it\u0027s had a number of positive impacts on privacy one of them is enhancing block lists for example if you use adblock plus or you block origin those tools use filter lists and the developers of those filter lists often look to research like hours to try to figure out what are some of the new privacy violating endpoints in the URLs in order to add them to their block lists various other things for example in some cases there\u0027s there\u0027s been an enforcement action by data protection authorities by the federal agency and things like that so I\u0027m claiming that the the this kind of research that\u0027s been done by many groups around the world is one of the main reasons why web privacy has been you know kind of at an equilibrium hasn\u0027t been even worse than it already is now the important point though is that five years ago a lot of fuss that we were going to do this very same kind of work for IOT because we were hearing that a lot of the IOT devices in our homes have occasionally have surreptitious data collection that consumers did not know about and so we want to do this kind of work but we very quickly realized that we can\u0027t actually do this work because of one very simple reason which is that most devices are end-to-end encrypted which to be very clear is a great thing it\u0027s great for privacy they should be into an encrypted unfortunately the downside of that is that the two ends of course off into an encryption are the device in the server it doesn\u0027t involve the user it doesn\u0027t involve a researcher a researcher can Smitham these devices a researcher can\u0027t figure out what data is being collected and where it\u0027s being sent and we think this is you know kind of a crisis for this kind of research it makes meaningful privacy measurements basically infeasible the public is very interested in these questions for example there was this article called the house that spied on me that just looked at what are the endpoints of communication of various IOT devices including sex toys why is that "
  },
  {
    "startTime": "00:25:03",
    "text": "contacting 13 different servers you know people want to know what data is going out there and this is important not just from a privacy advocate point of view if you\u0027re a company and you\u0027re a reputable company and you want to able to show your users that your data collection is completely you know according to your specified privacy policies there\u0027s no good way to do that today because researchers can\u0027t examine the plaintext of these communications and I think this is a serious issue for example if we wanted to know if the smart light bulbs in our homes are transmitting conversations because they actually have microphones we really don\u0027t have a good way to check that today and this is not a totally paranoid scenario something somewhat similar has happened for example this interesting thing happened a few months ago where Google sent an email to all of the owners of nest thermostats and said hey your nest thermostat is also a Google Voice assistant now and people like what how is that possible it doesn\u0027t have a microphone and Google said no it does have a microphone and if people said what we didn\u0027t know it had a microphone and Google said yes it does check the privacy policy and people said what privacy policy nobody reads the privacy policy also when they read the privacy policy it was actually not in there and then Google said oh we meant to disclose that in the privacy policy sorry that was an oversight so of course in this case I\u0027m willing to believe that it was an oversight on the part of Google but if there was a malicious you know vendor who put microphones and devices that are in millions of people homes we literally don\u0027t have a good way to know about it this measurement research has been in the past one way to know about it but it doesn\u0027t work for IMT so with that I\u0027ll just end by saying that what it likes a call for is some kind of debug mode for IOT devices I think this is a critical need the idea being that when you enable this kind of debug mode the user or more likely a researcher you know the details and user experience will depend on the device but some way to be able to intercept the plane tax in order to be able to audit what\u0027s going on out there there\u0027s a Stanford project related to this called TLS TLS what does it called TLS replays something and so what I\u0027m proposing is slightly different I\u0027m happy to hash out the details later this is not necessarily the time for that but I think some way of being able to examine the communications of IOT devices is critical and I think there\u0027s a role for Standardization here with that I\u0027ll just put the summary back up thank you for your time thanks okay so I\u0027m going to talk about some modern issues in privacy today and you know privacy is not a new issue when I started doing the research that led to this talk and by the way these slides were already on my webpage is the reference link to references a technical "
  },
  {
    "startTime": "00:28:04",
    "text": "class legal document is also on my webpage a lot of this stuff goes back to the 1960s you know the New York City Bar Association started studying computers in privacy in 1962 Alan Weston prepared basically a report of that committee in 67 been very influential the US Congress held hearings on this legal academics for writing papers on this all the 1960s it actually goes back the right to privacy is mentioned in Jewish literature about eighteen hundred years ago it\u0027s not a new issue and the privacy that we work used today the privacy paradigm called notice and consent goes back to Westen\u0027s 1967 book which is the report of this Bar Association the city of New York Committee that users individuals can determine for themselves what they want to share and what they\u0027re willing to reveal in this statement from 1967 has been the basis for virtually all privacy regulation since then and you look at the timeline he published this book in 67 six years later a US government committee came up with what became known as the Fair Information practice principles of consent of security of openness of use specification and so on in 1974 a year later the US government actually enacted this into law but only is applied to the US government didn\u0027t apply to private corporations not the American Way a few years later the OECD suggested more or less the same thing but applying to the private sector in 94 the EU and active data privacy director seven years ago the gdpr was enacted when it to affect a couple of years ago but from 10,000 meters all of these are substantially as India tremendous difference in details but fundamentally if you consent the data that you have data about you can and will be collected and notice and consent and so notice and consent is sites tell you what they\u0027re going to collect and what they\u0027re going to do with it and by using the website by using the device you are deemed to have consented to this policy and some of the risks were known back in the 1960s academics law professors wrote people are just going to go along with the request because they want the service 1960s we didn\u0027t have Google we didn\u0027t have Facebook they realized people are going to go along to get the benefits they realized they told "
  },
  {
    "startTime": "00:31:06",
    "text": "the US Congress people are going to share passwords maybe we need multi-factor authentication 1967 folks how many sites you log in to adjust a password today they worried about hackers they even cited MIT the MIT students breaking into systems for fun insider threats why are tapping the need for encryption the importance of metadata and the inferences you can draw from metadata in again 1967-1969 the danger of large searchable aggregate able databases all of this was known and largely forgotten so we haven\u0027t solved the technical problems of north for more than 50 years ago we still have noticed in consent though does it work nope not even close to working there\u0027s a tremendous amount of data is collected and we don\u0027t know who is collecting it we have privacy policies we have location data and of course there are the governments of the world there\u0027s a tremendous amount of over collection apart from all the folks whom you give consent there are the data brokers outside parties who business is to collect data about people and sell it they collect it they buy it and they sell it sometimes from public records sometimes from private transactions that you know nothing about last year I sold the car I found out that my odometer readings had been sold by my mechanic well yeah did I could send to it no that was a private deal between the mechanic and some data collection company the ads that you see on the web they\u0027re not generally not coming from the website you\u0027re visiting they\u0027re coming from ad brokers often multiple levels of ad brokers who do HTTP redirects each warrant is a separate website can collect and set cookies so lots of folks are gathering data about you and you don\u0027t even know who they are and the third party like buttons like Facebook and Twitter and the third party authentication Facebook and Google tells these collection sites what sites on the web you\u0027re visiting these analytic platforms are used to build up profiles on people and their companies in calling out rubicon simply because they\u0027re cited in New York Times article they take what they know about you from the tracking cookies they combine that with information from third-party data aggregators and estimate based your age your gender your income and use that to say how valuable a customer are you and therefore what ad is appropriate to show you and you don\u0027t see any of this but we "
  },
  {
    "startTime": "00:34:08",
    "text": "have privacy policies nope curiosity who in this room reads every privacy policy they encounter I\u0027m impressed I am seriously impressed security these hands down there are lori crater and her colleagues at the carnegie mellon estimated the opportunity cost for reading all the privacy policies you encounter would be about thirty five hundred US dollars per year and they\u0027re deliberately vague deliberately expansive because at least in the US regulators will come down on you not for what they collect but where you collect but from when you break your promise that\u0027s an unfair and deceptive trade practice according to US law so if you say you might do everything then you don\u0027t lie when you do everything you know we may collect personal information and other information about you remember the date of Roker\u0027s remember the analytic platforms from business partners contractors and other third parties in other words the world in quota Advisory Committee report to President Obama about five years ago only in some fantasy world the users actually read these notices and understand their implications before clicking to indicate their consent by and large that\u0027s true and remember because of all these third and fourth and fifth and sixth parties on the web you don\u0027t even know what websites you\u0027re consenting to you go to a news site a sports like what have you and you you\u0027re careful you read it and you look at the fine print says by the way read our advertising partners privacy policies to who are they good luck finding out location data is a huge issue for mobile devices lots of apps are collecting and analyzing this kind of data and even if the app is not doing the collection and transmission IP geolocation very mature technology reveals a lot is it perfect no is it very very good yes and this stuff doesn\u0027t have to be perfect if data exists it\u0027s available to governments sometimes in some government you\u0027ve got a complex restricted and somewhat painful process to gain access to your data I said the US government at this is this 45 year old privacy law you can under certain circumstances gain access to certain information about the held about you other governments don\u0027t really care about the nice ease of privacy policies and access yeah it is your data we wanted we haven\u0027t go away and of course that\u0027s even ignoring what you know 193 nations in the in the UN I think about 192 of them have espionage agency is "
  },
  {
    "startTime": "00:37:08",
    "text": "they collect data via technical means and other means and this you don\u0027t get to look at it all the privacy laws that we have are largely based on what\u0027s called PII personally identifiable information your name your email address a government ID number of some sort the definition varies the EU considers IP addresses PII much of the United States government does not I\u0027m someplace to be I think they\u0027re both rights under depending on the circumstances but it turns out you don\u0027t need PII to invade somebody\u0027s privacy Hamazon doesn\u0027t need your name and address to recommend products oh they might like it oh you live in a well-to-do neighborhood we\u0027re going to recommend more expensive products you have an ethnic surname family name let me go recommend products that appeals to that ethnic group so can help but they don\u0027t really need that you know people who bought this also bought that Netflix doesn\u0027t need to know who you are to recommend movies TiVo doesn\u0027t need to know who you are to recommend TV shows it\u0027s a great essay out there you can find search for it called my TiVo thinks I\u0027m gay somebody overreacted when he started getting recommendations from TiVo forgetting movies so we started this line to overcorrect by watching nanri he-man movies war movies and so on at that point you started showing him Nazi propaganda movies in [Applause] PII is actually just a database key but the database records exist on their own can be used for lots of things even without the key to look it up and to merge it if you\u0027re worried about PII some people try to anonymize the data what will strip off the identifying information it doesn\u0027t work first of all for most kinds of anonymization the real worlds are shown is easy to re identify or Earvin you\u0027ve done some of that as I recall haven\u0027t you and if you do too good a job of anonymization you may actually destroy the utility of the date of a certain very important things for example some medical dosage calculations done based on machine learning on a large database of patient information very successful to calculating the proper dose of warfarin there which have been a very tricky problem but some academics showed that if you anonymize the data well enough to really hide the patient\u0027s identity the calculations wouldn\u0027t work you\u0027ve hidden too much of the subtle details about the patient\u0027s medical condition so take your choice identification utility even for things that we all agree are useful like medical research to benefit everybody "
  },
  {
    "startTime": "00:40:11",
    "text": "PII is focusing on PII also misses the importance today of machine learning and the inferences that it can make you can tell someone\u0027s sexual orientation from the kinds of things they do I will ignore them my Tivo thinks I\u0027m gay but you can infer this is this good as event its private information to a lot of people whether or not it should be it\u0027s much much harder to control because it\u0027s not based on data directly collected you can say you cannot collect information say from my doctor on my sexual orientation but maybe there are proxy variables that tend to indicate it the foods that I buy might indicate my ethnicity proxy variables are a very powerful thing there was a study done by the Federal Trade US Federal Trade Commission about 10 years ago they discovered that auto insurance companies were using credit scores to set rapes what is your ability or willingness to pay a debt have to do with whether or not you\u0027re going to get into an auto mode or a mobile accident and the FTC staff came to three conclusions one it was a valid predictor why what machine learning doesn\u0027t tell us why it just says there\u0027s a correlation this is a good predictor and insurance is about prediction and statistics not about causation two it was also a correlation with that with ethnicity the higher rates were going to certain ethnic groups based on credit scores well that\u0027s bad social policy so the FTC staff said we\u0027re going to solve this we\u0027re going to try to build a model that\u0027s just as predictive but not discriminatory and guess what they couldn\u0027t do it there was something deep in the data that said yes there is this true correlation that\u0027s going to discriminate if we don\u0027t do something regular in a regulatory fashion against certain ethnic groups in setting rates it\u0027s very hard to find and eliminate all of this and got nothing to do with PII so to me notice and consent is dead no one knows who collects the data no one knows what they\u0027ll do with it no one knows where it\u0027s stored and some of the most sensitive stuff like location is dual use it\u0027s used for your benefit you know how do I get from point A to point B in a map program and as part of what\u0027s called your data shadow you know even the US Supreme Court has noted how sensitive location data can be in the aggregate so if we don\u0027t have "
  },
  {
    "startTime": "00:43:12",
    "text": "notice and consent what should we do what should we replace it with one answer is use control it\u0027s controversial but give up on data collection restriction it doesn\u0027t work better in the EU but still doesn\u0027t work that well instead let people specify how their data can be used not what can be collected but what it can be used for targeted advertising statistical analysis medical research what-have-you it sounds like a great idea it\u0027s not that easy how do you define your use categories how do you give people a really usable interface to specify here\u0027s a kind of data we\u0027re collecting and here\u0027s a kind of use that you may or may not want to permit for this kind of data usability of privacy settings is a fiendishly difficult problem very few of anyone has gotten that right you\u0027ve got to give consent across long time intervals you know I have been posting stuff on the net for about 40 years now Brian mentions one of the people created net News which went live in January of 1980 I was one of the founders so I was out there from the very beginning do I have the same preferences today as I had 40 years ago I was lucky my first boss at Bell Labs when I walked into his office a few years after that said I\u0027ve seen your flames on net news Steve yeah okay upper management reads these things yeah okay data that exists can be abused by hackers scofflaws governments were simply through a change in the law and it turns out that under US law it may be impossible to mandate use restrictions for companies they could adopt it but you may not be able to mandate it but a US law so how do we implement these control you could start with a privacy-preserving credential scheme tag all the data that you create with a privacy-preserving sub identity and a data type and you can publish tuple saying data type anonymous identity allowed uses and all digitally signed with your anonymous credential supermoms credential and where we put it well gee do we put it in the blockchain no no tomatoes please and if if you change your mind about something you just push out something at your newest it\u0027s your new a statement that wins enforcement well it\u0027s often pointed out governments have a role if you break a legally binding promise if you break a law governments can come down on you difficult but might be doable might being worth examining as a research "
  },
  {
    "startTime": "00:46:12",
    "text": "project what we really need is a new privacy paradigm he\u0027s got a scales are very many data collectors known and unknown in the future it has to scale across time it\u0027s got to be comprehensible by individuals it\u0027s got to account for inferences it\u0027s got to trade-off the harms and benefits of different kinds of data use and I have no idea what such a paradigm would look like or is that for me as an academic that\u0027s great if we knew the answer it wouldn\u0027t be research but yeah this is the real challenge how do we do this so what should the IETF do obviously encrypt as much as possible the ITF has been moving in that direction for more than 20 years and that\u0027s great avoid creating unnecessary third party metadata one place this really shows up in protocol definitions is stuff that\u0027s left to the implementation because that becomes finger printable how about to pick one random example if the HTTP header headers could only be in a certain specified order and even if they know you like to specify it and didn\u0027t and how you know just a semicolon or something design privacy protocols do a privacy analysis of protocols similar to what is done for security considerations today you know some years ago there was the Geo Kirov working group geo locations and okay we this is dangerous stuff from a privacy perspective let\u0027s look at it first tagging might help create some more metadata so here are the references most of the quotes are from my comments on privacy again written for us legal context I apologize quoted assorted academics from 50 years ago thank you [Applause] thank you very much week that we open the floor to questions I have Eliot Steve Arvind thanks very much for your presentations two comments first of all related to Arbenz work I\u0027m very pleased to find a colleague of yours sir gentleman at Berkeley who\u0027s done a lot of work in this space particularly around linkages on cellphones and the idea that you have about TLS and privacy of IOT is something that I that I am deeply involved in and one of the things that it raises the question of privacy brokerage we release this information some often times we release information for a purpose and the notion of contextual privacy is something that I think is a relatively nation if I understand in terms of research and I\u0027d be very interested to see us continue that discussion here at the IDF or at "
  },
  {
    "startTime": "00:49:13",
    "text": "least at the IRT F as to how as to what that means and this goes to the tagging that you mentioned Steve so thanks for your research and if people haven\u0027t looked at surges work to he\u0027s done a lot of work particularly around the Amazon echo recently that\u0027s very useful Thanks Thank You Barry hi this is very this is a very live Mike hi this is Barry Lieberstein how does notice in consent and GDP our work with being trapped by Facebook and Twitter icons in the one that\u0027s another reason notice that consent doesn\u0027t work you\u0027re being tracked by lots of people with whom you don\u0027t have a direct relationship and how can you consent I don\u0027t consume can I say I don\u0027t consent to seeing a facebook like button on a webpage I want to visit do you do you have any idea how they have not been attacked by the GDP RP I\u0027m not a lawyer I will let the lawyers answer that one so this is actually I\u0027m interested in responses from both of you that there\u0027s been a lot of interest in the IHF in privacy issues around the DNS and so I\u0027m wondering what you think of the risks privacy risks around that and whether it dot and doe provide useful solutions privacy like any of the security problem has to be done in the context of a threat model who is trying to collect this data what are they going to do with it you know with DNS over HTTP over TLS you know you might get a central aggregation point and do you trust them to be honest secure against governments secure against governments who come armed with legal process and you don\u0027t necessarily have a business relationship it\u0027s not clear to me that guarding against the NSA your GCHQ or the FSB or GRU the Mossad or whomever is the best threat model versus the commercial threat model that one might actually be best dealt with with laws saying your ISP can\u0027t use collect or use this data in any way rather than this technical mechanism and to Voyage the central point of collection which is a greater threat for against certain threat miles watch the threat model mary hi Malory knodel article 19 and so my questions for Arvind I really liked your example of how a limited technical mitigation was encouraged a strong policy that then filled that gap for user privacy this was like about a third true your presentation and I think that pair like paralleling that example with your conclusion is also interesting so I guess my question would be and then I can explain a bit more if that\u0027s helpful is I mean I think there\u0027s there is a "
  },
  {
    "startTime": "00:52:15",
    "text": "role that that measurement and research can still play even if it\u0027s limited now because of the privacy enhanced protocols that were using how can we instead pivot instead of trying to bargain like in the stages of grief or in the bargaining stage like how can we do both of these things when there\u0027s an actual inherent technical paradox between the two and rather go into pivot into a more complicated relationship between policy incentives policy sticks and then you know so I I wonder how academic researchers can help for example human right or not Human Rights but like impact assessments or getting companies to take more responsibility for doing privacy audits security audience and it\u0027s a slower approach it\u0027s not as fast as scanning a million websites every month but I think that where we\u0027re at now and the way that we\u0027ve advanced privacy for end-users to get the higher hanging fruit we actually have to have more complicated approaches that\u0027s great thank you the way in which I think measurement research has helped at a very high level is in economic terms closing the information asymmetry and what I mean by that is when a product doesn\u0027t live up to its privacy claims oftentimes the buyers users consumers of that products don\u0027t know and have no way of knowing and this parallels in in the United States one of the critical situations that we had with respect to used car sales 40 years ago and the matter became so critical that buyers of used cars would not know if the car had a critical defect whereas the seller would know and would not tell them and it was exactly the same kind of problem that was faced economists call this an information age symmetry and that particular information asymmetry was closed by lemon laws that mandated certain information exclosure disclosure pardon me that\u0027s guaranteed the right for buyers of cars to first take it to mechanics to be inspected and so on so broadly to your question as long as we have some way of closing this information asymmetry that exists between the sellers of products and services and the people who use them I think we\u0027re in good shape and one of the ways we\u0027ve been doing that is with academic research that\u0027s been you know scanning a million endpoints at once but it doesn\u0027t have to be the only way another critical way to do that has been journalists have been you know individually examining these products in a lot of detail and holding companies feet to the fire so as long as we have some oversight mechanism whether that comes from moi whether that comes from academia whether that comes from journalism or whether it simply comes from a more informed public that helps close this information asymmetry then I think we\u0027ll be in better shape thank you so Peter file Deutsche Telekom so from "
  },
  {
    "startTime": "00:55:18",
    "text": "my point of view that was an excellent presentation that it was very technology oriented so we have and also very North American oriented so in in Europe especially in Germany we have very severe laws regarding privacy so you mentioned the gdpr which is in effect since last year basically and I don\u0027t think that we can solve this issue from a technical point of view it\u0027s a legal issue so in in Europe I don\u0027t know if you were at the news but Facebook will probably have to pay some billions because they did not follow the rules of this law and in Europe the any data I give to any any company is owned by me and not by the company who gets this so this is something that has to be changed worldwide so especially in the US and again I just wanted to find out that it\u0027s not a technical issue it\u0027s an Eevee issue I agree I agree completely the document that that I wrote to it my truck was derived from was a submission to a US government process on privacy because I agree completely there\u0027s a very important legal role for the legalities here and governments around the world but I think that trying to base your privacy on notice and consent from a technical perspective is not going to work and I want what I just what my paper said is we need to find a different paradigm for regulators and legislators to mandate so thank you for your comment I completely take your point that the role of regulation in the law is very critical here thank you for bringing up the gdpr one thing I want to slightly push back on is that I wouldn\u0027t see it as a technical or legal issue I don\u0027t think it\u0027s a dichotomy in fact a lot of the investigations that have come about under the gdpr and the fines that have resulted from that those privacy issues only came to be known because of the kind of research that I described whether it was done by academics journalists or some other third parties so that\u0027s technical work in a sense and and for me the real success stories involve the collaboration between technical teams and legal measures thank you we\u0027re gonna head and close the mic line so we\u0027ll drain the cues please be brief carlos winning a seat books thank you very much for your thoughts they both first even though harvest I want to actually follow up on this discussion because in fact that\u0027s precisely what I wanted to say in this world where we leave privacy is getting harder the battle is lost I very much appreciate the message of no it\u0027s not lost we can keep improving things and also just following up from the previous speaker that we are going all the way from the extremes of regulations towards the purely technical and I think they both "
  },
  {
    "startTime": "00:58:19",
    "text": "have to now at some point in time it\u0027s true we don\u0027t have the answers to all the questions but and it\u0027s true that for instance I was regulatory discussion where they were just discussing okay in a world where the watch is checking your vital signs and then it\u0027s sending it to your phone and then that\u0027s anything to an app and that\u0027s sending it to our cloud provider and who do you regulate it\u0027s nothing more the world of one piece does one thing so it\u0027s important I agree with Arvind and message that we can help their regulatory bodies understand that is the service provider probably the most accountable one that will make sure that the information flows down and also on our side as a technical writers we do have indeed the the role of writing the right standard but also educating people as much as we can regulatory it could be a section Steven you mentioned the privacy considerations I think that\u0027s a great way to communicate what the standard should do what what are the issues what should be looked after and then follow up and make sure that we do improve because definitely the the battle is not lost and there\u0027s a lot of things we can keep you high riad Wahby Arvind you mentioned at the very end of your talk a more project of Stanford TLS are AR rotate and release I was one of the authors on that so I think you\u0027re absolutely right that there are some technical measures like that but just to provide a little background in kind of a counterpoint while we were working on that we actually spoke with some of the people in the TLS working group and said hey look it might be the case that like a small change to TLS would actually make this easier and be very rightly got pushback them from the TLS working group who said yeah but we don\u0027t want to make this easier because yeah you might want to use it for watching your own devices but anything that we make easier for you is can also be easier for somebody who\u0027s spying on you so while it\u0027s true that we want to look at our devices it seems like technical measures at the level of you know the encryption standards maybe not the right way to go we may be in some sense at the mercy of the people who are building the devices almost no matter what we do because you know we shouldn\u0027t insert back doors into TLS for our own good they hurt us more than they look so just yeah thank you for your comment and somewhat aware of the debates that have gone on in the in the tls working group my main goal is to call attention to the severity of the problem I\u0027m not claiming that I know what the right solution is but I think the current situation is perhaps not optimal I would like to ask you a question following the the gentleman from German Telecom about ownership of the data this is a very big difference in the US and Europe for example where ownership of the data is always about me when I\u0027m in Europe and once is collected in the u.s. is "
  },
  {
    "startTime": "01:01:20",
    "text": "property of who collected the data and as I think is the biggest issue in when privacy instead of giving out your data you can borrow my data but I can always ask you to remove your my data from your system whenever I want to you know I don\u0027t want to have this very issue with us etc and and if you can elaborate on that if you think that this might be a tool that enhance privacy from a legal standpoint of unit since that give me give me as a user a possible recourse of action in case you\u0027re you\u0027re failing to protect my privacy and the second point is about the measurement you say that you know this type of privacy issue came out because of measurements maybe it\u0027s time to talk about having measurements as part of the legal framework so that it\u0027s not left to academic to expose this but with what is it actually have authority to and to follow up on that data ownership is a really complicated question there\u0027s been a fair amount of legal writing lately legal academic writing on why trying to treat data as property can have bad side effects one of the interesting things from US law is that a lot of these transactions there are two different parties that have ownership so I mentioned about the my mechanics uploading it was selling my odometer readings oh yes my ODOT my mic is recording the odometer reading to go let me know when I should change my oil again and that\u0027s perfectly that becomes a business record of the mechanic and that\u0027s the property the data belonged to the mechanic and therefore the mechanic can sell it as well as me and my privacy problem is that it gets aggregated and attributed to me as well so there are very complicated questions with trying to treat this as as property even apart from the international issues and different philosophies there\u0027s a lot of data that businesses very legitimately have to collect and medical personnel utterly rely on it they need this to keep you healthy they have to have this data and then who owns it so it\u0027s an it\u0027s not an easy question so which is why I like the notion of use control instead I just want to say a couple sentences about the measurement issue that you raised I agree to hundred percent that measurement should be a standard part of the regulatory process and just to tell you how much I agree with that at Princeton and part of the Center for Information Technology Policy and it was started 15 years ago with precisely the notion that there need to be more technologists in government exactly because we can do more of the sort of things you\u0027re calling for because today the main limitation is just the technical expertise that exists in regulatory agencies yeah if you\u0027re a technical person get involved with your own government make sure the lawyers judges legislators "
  },
  {
    "startTime": "01:04:21",
    "text": "regulations on understand the technology I\u0027ve done that I\u0027ve done this twice I highly recommend it and never the last word Phil you have negative four minutes so please be extremely brief I\u0027m sorry back Mike we cut the mic lines or I would okay name withheld actually so Steve said we had the wrong trust model you know we got thinking beyond the CIA etc attacking I think goes beyond that these third-party databases they are a national security threat and we saw them weaponized in 2016 and it isn\u0027t just personal data I know of an insurance company that is operated by an individual who is widely believed to be operating on behalf of an intelligence agency a hostile one this insurance agency specializes in commercial vehicles if you think about what such an insurance agency would be doing it is collecting data on all the trucks that are moving in that country and they managed to get 70% of the market in a markedly short time because businesses are very price sensitive so when we\u0027re thinking about this thing it is no longer just us as individuals having concerned about our personal privacy it is also a matter of national security and patriotism two major data breaches of multinational US firms are frequently thought to have been perpetrated by a foreign intelligence agency equi fact the Equifax and the Marriott breach have been attributed to foreign intelligence agencies in fact the someone Fairfax said justice just yesterday this is zero evidence that any of the stolen data has been used commercially for identity theft or anything else which kind of goes along pretty well with the notion that it was an intelligence agency that took it so yeah this is very plausible so thank you very much we now have a four minute break I think before the administrative plenary I\u0027d like to thank again very much both Steve and Arvind this is an excellent evening I had I learned a lot i specially appreciate the challenges to the IETF from both of you and we hope to live up to them so thank you very much we\u0027ll see you in 180 seconds yes "
  }
]