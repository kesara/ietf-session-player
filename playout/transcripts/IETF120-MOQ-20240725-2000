[
  {
    "startTime": "00:00:09",
    "text": "All right, everyone, welcome to media over quick Second session. The first one was not perfect, so we're going to do it again Today's local sports mascot is Spike the Kingfix who is attached to the local soccer team or football for those of you who are not for North America Vancouver White Caps The session is being recorded This is the note well if somehow this week you've you're still unaware of the intellectual property implications of you attending this and the Code of Conduct and other aspects of being an IETF participant. Please point in your favorite search engine at IETF note well and you will be able to beat about this to your heart's content We have been asked to note really well a little bit about the code of conduct. Please speak to each other professionally and ideally and maybe a friendly manner. As I said, yesterday, speak as if you are having dinner with that person rather than you were on a Twitter thread with that person And if you harassment is a serious issue, we do have some strong personality with that person rather than you were on a Twitter thread with that person. And if you harassment is a serious issue, serious issue. We do have some strong personnel in this working group. So if you fuel your are being harassed or witness any harassment, you can kind of the IETF on Bud's team And if you would like a more immediate nominal source of authority of course we as chairs are happy to facilitate any corrective action. And we have our area director here. Zahead Sarker, raise your hand please, Zahead him. He's the ultimate authority in this room, so you can appeal to him if you are not otherwise getting sacked satisfaction You are probably familiar with how to participate in a meeting at this point, but this is"
  },
  {
    "startTime": "00:02:01",
    "text": "a good reminder to, if you have not already, to scan that QR code up on the screen and register your attendance to this meeting, which is useful for it well, this is important for us to know how many people showed up so we get the right size room It is also important if you actually want to enter the queue to have any comments. And of course, those you who are doing this remotely are almost certainly already on You got to go remain muted. Well, okay if you are here and you're on the full client, be sure to mute your computer as I failed to do it first and in general, turn off your video and microphone feeds unless you are speaking Okay, this is the gender for today. We have Will's warp talk fell off the edge of session one, so we're going to start off with that. And then we have some other talks like yesterday, most of the emphasis for this IETF is some maybe bigger picture stuff and exploring some new avenues of inquiries um as most of you know we have virtual interms on a weekly or biweekly basis that cover M of QT issues and like low small scale GitHub issues. And of course, everyone's invited to those, and so we have a relatively small amount of time for that today I also uploaded a set of slides about issue 480 which if there's time permitting, we'll tack on after Ian's a deck of issues unless somebody objects to it. All right, certainly follows under the, um, rubric of a mukiti issues, but great. Okay, um, does would anyone like to bash the agenda And actually, Ian, would you rather? we do 484 before your your gauntlet or i mean whatever you think is high priority, I'm willing to defer to the editor there No, I'd say I'd let you in go first"
  },
  {
    "startTime": "00:04:01",
    "text": "okay all right then ian will go, and then Alan will talk about 484, if time permits. And then the closer mark should be relative to spicy. We're going to talk about upcoming meetings, including our following interim in-person interim as well as virtual interms When you describe you've been warned, we're going to just sit here uncomfortably until someone agrees to enter the note-taking app there and record our major decisions and other important points of public comment. You do not have to you definitely do not have to, to, to, um, dictation on what the presenter is doing. That's what the slides are for and just reference the slides but somebody to make a note of what is happening now would be the time to raise your hand, please. And there is chocolate for whoever volunteers I think so of the remote people might not be getting audio based on the Zulip chat. I'm offering those as a Zulip Relay Thank you, Colin Colin Okay, it might be a Lucas problem Yeah, so Will was saying he can see and here, so if you can't see in here and you are remote, that might be a you problem Is Jordy, there's actually a good opportunity to point out that we have an alternate street and that is Jordy's MOQ version of this meeting And the link is in the chat. So if, troubleshooting immediate echoes beyond your immediate capabilities I invite you to use this technology called"
  },
  {
    "startTime": "00:06:01",
    "text": "MLQT And so all this stalling has now given a little more opportunity for someone to decide they want to do good by the community and be ascribed today Do we have any volunteers? Someone may be about to be volunteer if we don't have any progress thank you Ian. Can we? Yes Luke volunteered also. Lovely. So Luke, when Ian wonderful, we have three people covering Ian, Ian, Ian will be talking to some extent. Colin will be talking to some extent. Colin and Ian may have a conversation. So even Luke as a second fallback. So thank all three of you for agreeing to you scribe Okay, that concludes the administrative portion of our talk and we are still ahead of schedule so that's lovely. And next up, we will, to talk about warp warp Oops, that's not the one. Uh-oh This is the right right night, well I think so I didn't put the version on the title Excellent. I believe it is. Okay It's close enough. So thank you So good evening. This, will law from Akamai this is going to be a very quick update of war. If you can go to next slide What I want to cover again is an overview because there were a bunch of questions yesterday on our compartmentalization and how it we're splitting things up. So I thought a picture or two might help there And then I just have time to cover two PRs, one on lockdown packaging adding lock and the other on timeline tracks which is a new introduction and then a summary of a lot of"
  },
  {
    "startTime": "00:08:01",
    "text": "work that we still need to do on Warp. Next slide, please So as a reminder, the bulk of the work done in this group is on mock transport, which is the layer you see there It rides on web transport, it's on War Creek And it's a service, essentially, that'll be provided by some like a CDN or a network provider. And it's like agnostic to the streaming applications or what we're calling streaming formats that might write on top of it demonstrated in the app layer so what I'm talking about today is one of those which is war lock is another one that's being presented. We have a chat format and there can be many others. So we do need to keep this separation. And we do need that we have a strong focus in this group on media at the moment but at the back of our heads, we do need to keep in mind, especially for things like catalog, then it might need to apply to non- we have a strong focus in this group on media at the moment but at the back of our heads we do need to keep in mind especially for things like catalog then it might need to apply to non-media applications and we already have comments on the list to that effect next slide So warp itself is a collection is a spectator refers to other drafts. So it refers to the catalog draft. The catalog draft is intended and there was a good description yesterday, to be like a better class that you extend, right? It's a generic base catalog that can be used for any application, media-centric or otherwise, that might be using mock transport. You can then extend it and add in application-specific information in your draft, but we're referencing catalog draft CMAC over mock transport is another draft I put together how to take the most common media format for non-real time and bar tracts and apply it to mock then we have lock over Mock Transport, which is both a packaging format description and a streaming format itself which is referenced by Warp. And then Warp has some specific logic, which is how to tie these things together"
  },
  {
    "startTime": "00:10:01",
    "text": "next slide So PR 27 is up there right now. This is adding in lock packaging. So when warp started out it was CMF only if you look at all the demos being run, including the one coming from oxygen right now, and as well as quick dot video they're using lock so the notion here is that Warp should use both CMAP and Lock Pack one coming from Oxygen right now, and as well as quick dot video, they're using lock. So the notion here is that warp should use both CMAP and lock packaged bitstreams, at least for now. Maybe we had more later. But those seem to be the dominant ones that get us the most bang for the buck allow real time but also allow near-real-time interactive levels of latency So within Warp, we have a table and we define the packaging field value yesterday there's another PR for catalog to rename this to format so ignore that I'm just going against the ID draft, which will cause it packaging And we define three values. These values are in fact inherited from the CMAF packaging it's it's basically are you putting all your putting a whole gop inside an object and inside a group, in which case it's CMAF fragment the group or are you putting your frames which works, well, chunks, because it might be a frame, might be a collection of frames inside an object, and then having multiple objects in, having your whole gop in a group. And that's called CMAF chunk for object, and then lock at the moment and correct me if I'm wrong, or mo having your whole Gop in a group and that's called CMAPTumper object and then lock at the moment and correct me if I'm wrong Suhast or Mo it has one mode you basically put your coded audio chunk and coded video chunk sample in a separate mock object if there are more modes there we'll need to extend this table. So this is a simple PR, check it out. Here's a go. Thank you next slide. Here's an example, catalog, just to show we got two tracks. The first one is referencing CMAP break per group, and the second one is referencing lock. And you can use both together. A lot of people want to use Opus, for example say with H.264 video packaged in an iso-based media file format"
  },
  {
    "startTime": "00:12:01",
    "text": "contained. Okay, the next PR is the timeline proposal so this was mentioned that at prior sessions, but I've actually put forward a candidate here on a PR, quote, comment, and improvement. So the timeline track provides data about previously published group their relationship to objects and also their relationship to war clock time and any associated timed metadata that makes sense for that application This allows players to seek backwards behind live into a broadcast or for random access in a few future hard asset. You can also use it to link in events at times which do not correlate with objects boundaries, but that's important. Things don't necessary happen at object boundaries, especially if you've got one object for your whole goal. And timeline tracks are often but that's important. Things don't necessarily happen at object boundaries, especially if you've got one object for your whole copy. And timeline tracks are optional, and you might have multiple timeline tracks and you describe them in your catalogue and you can use the new type to say this is the timeline track. Next slide So here's a proposal I've done it with CSV you might say why in 2024 are we doing that well it's low overhead it's easy to read and parse. It follows much of the same philosophy there as using Jason for our catalog It's simple to concatenate. We use media time, which is the first column as the ordering key it's easy to debug it without a parser and we can easily convert this to see more if we care about size in the future So it's got a header, media PTS, group ID, object, ID, war clock, and metadata you see some examples there so a player wanting to see that future so it's got a header of media PTS group ID object ID war clock and metadata you see some examples there so a player wanting to seek back to a certain time simply looks up in this table go media, PTS, group ID, object, ID, war clock, and metadata. You see some examples there. So a player wanting to seek back to a certain time, simply looks up in this table, goes and finds the preceding group and loads from and fetches if we want to use I think our decision from yesterday fetches back in the past and can plan that content next slide So, Will, I just want to give about four minutes left, and if there's going to be a discussion time, we need to get through these. Yeah, I'm okay, super quick So here's an example. I added some metadata, scores, if you have this happens to be a soccer game. You notice the second one"
  },
  {
    "startTime": "00:14:01",
    "text": "it's occurring. It's the these are all its an example I added some metadata scores if you have this happens to be a soccer game you notice the second one it's occurring it's the these are all that sort of group starts are the ones that an object within a group Next slide uh here's one with XML aligned metadata just to so we can take a scuddy marker study is going to become important when we're that an object within a group. Next slide. Here's one with XML-aligned metadata, just as so we can take a Scuddy marker. Scuddy is going to become important when we try to do advertising insertion, and we've inserted it as metadata. And also at a time that is not aligned with any group boundary. So it's an example of that next slide and here's a reference in the catalog you can take a track you say i'm a timeline track that's my type and then we use the Depends attribute to describe which video, which tracks within the catalog that this timeline applies to. And these would necessary need to be sing Next slide And here's a diagram, which I wanted to animate but we don't have time. The blue objects is just group ID comma object ID it's a group with three objects This shows how you can incrementally update the timeline track. So you're guaranteed if you ask for groups zero object zero that you will get the complete timeline up to that point. After that, within the same group, you just get incremental delta updates so you can catch up and as a player if you just want to know where you are in the past, you could subscribe only to group anything object zero. You'll get where you are and then from that point on you can keep your own a record of what but i think this would work reasonably well i suggest a maximum 30 seconds between updates so we don't get you know too large but that's really bachshedable Next slide and these are some of the core issues remaining which i won't get in now, and I'll save the last two minutes for any comment on timeline tracks other than yes I had Spain winning when I wrote that it tells you when I was making this one There's a little bit of feedback"
  },
  {
    "startTime": "00:16:00",
    "text": "in the chat about CSV and strings being some annoying, so I'm not sure if anybody wants to... So they are if you go, I show an example, so Jonathan, you do need to, any anything you put, anything with quotes has to be quoted itself, and the quotes need to be double quoted to escape them so yeah And then it's, Jonathan Maddox, yeah, it was coming back and also, I think I seem to recall that embedded new lines in CS values are all strings are also problematic. Yes but I think they're escapable. So as long as we have a we're, and as long as we like and as long as we like swiftly say this version of CSV as defined by I think there's a IETF CSV spec and not just loosey Googley as defined by some software somewhere. That's probably okay, but we need to be very specific about the CSV yeah in the in the in the PR I reference an RFC that tells us how to parse CSP. Moe. Mosinati, I generally support the timelines, but I think they would be better stand-alone if there's a separate draft and a separate maybe even the bindings could be separate, how you bind this time track to other things, including including you know a warp um maybe a better way to go. Okay. Okay it independent yeah So, Will um do you feel like you're close to asking for adoption on this draft or not? No we have, look at all the things remaining We, this ultimately, warp should be what George, using to stream and anyone with a warp compliance player should be able to connect to that stream and it all works i think we're up ultimately, warp should be what Jordy's using to stream. And anyone with a warp compliant player should be able to connect to that stream and it all works. I think we're far from that point. So I think first we, we aren't a warp-compliant player should be able to connect to that stream and it all works. I think we are far from that point. So I think first we are in our catalogue, we make that robust and then the next step after that is we need to homogenize look at common attributes of all the various solutions today and distill them down into something that warp at least can be the basis for and then"
  },
  {
    "startTime": "00:18:01",
    "text": "address the issues remaining here and then I think maybe before we get to some of these you can call for adoption to at least bring it into the work group but i think it's a little premature right now Colin Jenks. Look, I agree with your statement at the where we are on this draft that makes sense to me But I think that I would lean towards bringing it into the working group early on this. We don't, it's not like people are proposing alternatives to it. It's not like we have three competing drafts so we need to figure out which one we want to choose a starting point I think this is a great starting point. In fact, I think it's very close to done in many ways. Like, yeah, there's a lot of details that need be figured out in PRs and stuff, but this seems very much along the way And right now, it's at a state where it's like it's, it's, it's, a great starting point. In fact, I think it's very close to done in many ways. Like, yeah, there's a lot of details that need to be figured out in PRs and stuff. But this seems very much along the way. And right now, it's at a state where it's like, it's, you know, unknown whether it represents consensus or anything else. It's harder to put things in a little hard to work with. So I'd rather see it brought into the structure and adopted sooner That said, whether it's working group draft or non-working group or after going to be the same people doing the same work on it, so it's not the end of the world But I guess what I'm saying is, at the point that it's fairly clear, this is a piece of paper that's sort of got a shape of a solution that people can live with, which it clearly is at this point. I think that that's a good point for us to be adopting it. Thank you I defer to the gentleman from Cisco thank you hello Geraldiz Sincano. Just a clarification, so are you proposing the as an independent draft or part of catalog? Not part of catalog definitely independent. This refers to catalog and this is an example of a streaming format catalog is not catalog is designed to be used by other streaming formats. It's a base class for describing other tracks within mock transport Okay, then I really like the, I really like the idea be used by other streaming formats. It's a base class for describing other tracks within mock transport. Okay, then I really like the idea, so too. And we could also implement this without having catalogs just make the publisher also publish this track for every video or audio track or group of synchronization"
  },
  {
    "startTime": "00:20:01",
    "text": "audio and video tracks. So basically we don't have catalog dependence and I think this is extremely needed in a real world So I really like the idea. Thank you Again, before we leave this topic, does anyone believe that we are not on a glide path to adopt this at our next? in-person meeting in October? No one like to articulate this is just going in the wrong direction for that? Okay so Will, I mean, obviously it's up to you when you ask for adoption, but if you would like to kind of land some issues and like move for adoption prior to the interim, like let's move that. No, I'm going to ask for adoption prior to the interim. I think I heard enough here today We'll take it forward there. That'll be good. Lovely thank you very much our next presentation is on... Martin, can I say one quick thing? Oh, go ahead, Mo zanaty. I think this uh this is a good basis for the working grip disorder but my one caution is that in all things describing the media format, I think we have a very small number of people actually looking at that you know, even smaller actually writing that And I can't imagine that we're covering everything properly for everyone and this is an important part This is the actual media formats that Mock is going to carry and I think it would it would be the chairs can somehow get some more people involved in this work at least just for review, but hopefully also to contribute some Well, if we have a, I mean, forecast, that we'll do a call for adoption uh the first question will be have you read the draft? So, like, ideally there will be an email to the mailing list like a couple weeks before the interim and, like, inviting people to read the drafts. We get an intelligent discussion about it prior to an actual adoption call. I think to get people to understand what this really is this is basically the SDP of Mock This is the mime types of mock. This is all the stuff that describes media"
  },
  {
    "startTime": "00:22:01",
    "text": "How we do it in Mock is very different from everything else that's been done in the IETF Everything else has been done in ISO and ITU and everybody else. So we need those people that care about that to come here and, you know, make their points about it So are you saying we need people from outside? the working group? I think so, yeah i mean it's only the same three people that have been working on it for can you say that can you send an email what communities you think should be included Sure. Thank you you All right, let's go. Okay Sounds good this is a really small, Cullen and my self-wrote up a really small, okay, color and myself wrote up a really small drafts that talks about how do you send something related to diagnostics like metrics and logging or mock and why do we think mock might be a good transport of certain use cases that came through our experiments Next slide, please This is very typical that in any kind of real-time media applications all in general applications that would want to report a lot of diagnostic information like things that are being logged or the metrics This is very true in WebEx kind of infrastructure where we do that the clients report quite a bit of metrics and also media servers reports quite a bit of metrics and logging and our backend diagnostic tool they analyze the call quality and should be able to in near real-time fashion, figure out if there are any quality issues and go to do take some collective actions And the clients and servers have few choices they can do today. One is that they have an option to report this information near real time or in real time. But the problem with that is that that the diagnostic information competes with the media the actual applications media and that there's the a good for user experience or other option is that you know"
  },
  {
    "startTime": "00:24:01",
    "text": "they do collect a matrix towards the end but the problem with that is, and collect towards end and report, but the problem with that is that either is too late to do any collective actions while the call or session is going on or many times the end users would not even wait to report those metrics. So you basically lose most of those metrics Or other option is that some combination of both where they collect metrics every five minutes or every ten minutes in a round-robin kind of in a circular buffer kind of fashion once that gets filled up they keep publishing the metrics to the backend systems the problem with that is that it brings in the problems of both either it's the time it gets published if it the backend systems. The problem with that is that it brings in the problems of both. Either the time it gets published, it's at the exact same time where you're generating an eye frame you mess up the media experience or the time you're publishing is like five minutes delayed to figure out what's going on, you miss on doing any corrective action or doing the media quality analysis. Next slide, please So going on step deeper into the kind of problems that happens with this is that if you think about today most of the metrics that we report uses some kind of an inflection client that's using HTTP to report metrics or something like a prometheus that's asking this server and the clients to pull the metrics which they store Both of those things, they're happening in a different connection context between your media and the metrics reporting or the logging reporting. When that happens, this a bandwidth computation that would happen. And because you don't have a shared congestion context between both kind of data, sometimes they fight against each other and you lose both this is very typically observed in the cases where the call is undergoing lossy experiences and at the same time that coincides with your medical in some form or the other with all those losses adding up with streams, HTTP streams and the TCP streams and quick streams, it just makes everything bad. And by the time you realize and take corrective action"
  },
  {
    "startTime": "00:26:01",
    "text": "on your client, it's already too late And people just give up on the calls. Another thing is that in either metrics and logging, even though there are many granular levels like some metrics are more important than the other, some logs are more serious than others. But when you report this kind of metrics, they are all treated exactly the same. They are just a blob of things i want to report at a particular point in time and i just publish it. There's no easy way typically done in today systems that would help with some of these things. Next slide So our proposal is we have beautiful transport that we're building that supports Pupsub model that supports priorities and it's is we have beautiful transport that we're building that supports Pupsub model, that supports priorities, and quick supports nice Dmultip supports pupsub model that supports supports priorities and and quick supports nice demultiplexing features why not we use metrics and logging as mock tracks Instead of using software to HTTP, client application or server application, use mock tracks that's shared with your real media. And we see observed some benefits, and I think that would be something that we think who are thinking about diagnostic information reporting should think about as in the next slide please. The benefits you can think about is that you have a fine grain control on what to report some metrics are more important than the media or some logging is more important than media some are not. So when that needs to happen, you're priority, that we use matthew quick priorities for when we use mock for tracks that can be used in a fine can control to say, at this point in time, I'm going to report this metric at higher priority compared to the thing other things the same way are kind of video confidence conferencing system or streaming system, the media is inherently bursty You have huge set of eye frames that consumes most of your peak bandwidth and then at the periods where you don't have that pattern. So something like this can be used to say, when media wants to take a"
  },
  {
    "startTime": "00:28:01",
    "text": "peak bandwidth, and then there are periods where you don't have that pattern. So something like this can be used to say, when media wants to take up the peak bandwidth, consume the bandwidth, it can use it, but in all off period, you can always start sending the metrics and logging kind of data And because of the shared context, this basically allows us to say when things are really congested, you don't want to blast a lot of logs and metrics And priorities along with that makes sure that in the most important things which is the application we'll go through and if there's something really important for diagnostic in those things can go through and this pattern is happening even in the way the back-end systems are building the logs and other things. A lot of these servers, they collect a lot of logs locally, and you have a server that collected collection service that basically pull these locks off the services. But if you really think about it, mocks in a way, the architecture for the mock in a way provide distributed relay and caches and that can be used in for our benefit where you can report the logs to your local relay or your cloud server and that can be stored in those caches there, and the collection service whenever they want to do some advanced analytics on top of that they can pull the information at water gran alert they need so we think using mock as a substrate for sending a metrics and logging kind of information is beneficial We'd like to collect feedback. Go ahead, Mark Yeah, Martin, do Google, no hats So the, I guess I'm 100% sure I understand the communication model. So the idea here is that a subscriber is also publishing data upstream to on the same MOQ session that it is oh, whether it's a relay or I guess I'll original publisher, and then it is being cached there, yes, potentially, or maybe being passed up. Okay. All right, thank you OK, there's a little bit of a queue, so I'm probably going to close it Get in now if you want to comment on stats and log in uh go ahead and john jem i and got to"
  },
  {
    "startTime": "00:30:01",
    "text": "Angar Fastly, thanks for the presentation So as I first of all say that, you know, I've been thinking about doing metrics and log comment on stats and logging. Go ahead and John. John Angar Fastly. Thanks for the presentation. So as I first of all, I'll say that I've been thinking about doing metrics and logging with Mock, ever since I've heard about Mock because I think it's a very promising use case for it Especially with live logging, it's actually extremely useful You have multiple consumers of the same log that's coming out of one place super useful I think the narrative here is not clear though. And what I'll say is that my feedback perhaps here is that there's two different things happening here You got the media streams, there's a tree, right, like a distribution tree of publishing and subscription for the media stream but your log stream doesn't need to follow that same tree It could be following very different things. And as a result, your subscription context is likely to be different which to me tells me that the shared congestion context is not necessarily a win I don't think that's necessary for your proposal, but I think it's confusing it a little bit. That may be where Martin was also heading with this and I had the same confusion that if I'm yeah, that's all I'll say for now I can say that when I say shared congestion context, I was thinking about, is as a media client I'm publishing my media right and today I published my metrics or HTTP Yeah, yeah. I understand. Both are not shared. Yeah, but just because their mock doesn't mean that they will be shared because they could be on two different connections because they're fundamentally two rooms of subscriptions that's what I want to do. Yeah, totally Yeah. Okay, Zahad. Zahed with no hat also so i try to understand this this things like what you're doing like so you have a mock session going on you're sending live media, and you like to do the same mock connection to use live logging. Right is that the thing or it's like we have a separate kind of connection to separate kind of kind of logging center, but you use MOC as a transfer protocol? So the thing here is that you have a mock session going on, let's say one quick connection, and in that few tracks are used to send your media the audio and media media that's been captured. And few tracks are used to report your metrics for the media that's been happening right now"
  },
  {
    "startTime": "00:32:01",
    "text": "So in that case, those tracks will have prior and control different compared to your actual media that's being sent So in that, from that perspective, it's the same kind of being happening right now. So in that case, those tracks will have priority and control different compared to your actual media that's being sent. So in that, from that perspective, it's the same connection context. Yeah. So if this, this is kind of like same, so, so it's interesting to say like, I would like to understand a bit better, like, how the logging could be important for media, like you talked about iFrame and all this things. So, I mean, in some cases, I could see like how logging could be important in India, but sometimes media is important and you like to do all those things right so you like to have some sort of like prioritization or consideration those kind of thing and if it is a single context your connection context, I could understand less here at Condition Control thing uh given that you understand there's a little shared bottleneck from other mock transport that's happening. That's one thing, but also you can use like like what you use in a screen protocol condition rate control for web vertices basically you have a shared condition control control control one thing but also you can use like like what you use in screen protocol condition or rate control from the web vertices basically you have a shared condition control context but you have a prioritized skill you actually application decide what to put given that you have a certain amount of bits to send you decide what to send so you don't need like you know you can you can distribute your current available bandwidth to your logging and monkeys and do all this kind of prioritize things so I don't know like how we are getting into that just I can give some context to that right we had two implementations of this one where the same media application was using HTTP connection to say the metrics and logging and mock session to send the media. When things go bad, both went bad because they're all trying to say the same connections, the bandwidth that's available there. So what we did was we tried to report metrics and logging over mock transport as well so that we now the same congestion controller is basically telling I have X-Nine number of bytes and you know the priority of media is more higher because you're sending high frame and you want that to take over. So that gets the first way to go and go out And then on the off period times metrics because"
  },
  {
    "startTime": "00:34:01",
    "text": "it's all each track you map to stream or you have priorities so they get a chance when they get go get okay so so then then my understanding is more like like a prioritization point of issue from your like sending point of what you want to do. But I understand like here you're you're also trying to collect logging from the other side. So yes I think, yes, yeah, okay, both sides of thanks We have three minutes, so please be brief okay uh hello jordi i see uh i really like the idea of using MOQ to send metrics and I think the idea behind that to share the priority and the connection context to prioritize media over metrics, I think it's great. But I do think that this proposal needs more detail exactly what Jana said needs more detail because you usually your metrics will be in another connection connected to another server than your media. And then what would happen there? so just I think I like the idea just this clarification would be great. Yeah, definitely we can we can think about like how is your topology set up, right? And the thing with nice, thing that mox gives is that you have a next hop relay that would be our intermediate next hop way set up, right? And the thing with nice thing that Mox gives is that you have a next hop relay. That would be our intermediate next hop where things can go and from there it can get gone to like metric server or the logging server or the uh the relay as a few cons some kind of things or it can go to two different things from the client itself. I agree with both options You're right. I think Martin already pointed at that in chat, but a blog diagram would help tremendously here I think two points on this. I'm a big fan of it. I really like it from a large-scale point of view one problem though our prioritization from the last interim is within a connection, right? So if you have separate connections, it's been said already. We're going to fair share between them. So, in fact, you could start competing with some of your media traffic So that's an issue, but it would be no different if we're using HGDG And the second one is I'd like us to standardize the internet for relates so that you you can ask a relay server if it can act always as a publisher of its logs stream as long as you supply appropriate auth credentials"
  },
  {
    "startTime": "00:36:01",
    "text": "then you can get a standard log stream out of that relay. I think that would be nice feature to build in all our relays from the beginning Makes sense. Thanks, Will. Hi, good day. It's from a Apple. Good day from Apple. So yesterday we started talking about like secure objects so it'll be interesting how this kind of goes into that because there we said that's going to be encrypted using M like secure objects so it'll be interesting how this kind of goes into that because there we said that's going to be encrypted using MLS keys clearly this is between reporting server and the client so this has to be in encrypted during using a different key so maybe the draft will eventually also talk about that possibly. Yes, we didn't think about in the draft as just today but it's not something to think about. Yeah, thank you Okay, there's quite a bit of interesting this so let's continue discussion on the list sounds good thank you thank you Okay, to be crystal clear, I'm presenting this with no hats on. I've had a bunch of conversations on, well, in person with a number of people in this working group, and that inspired me to kind of synthesize a lot of it advice and a lot of ideas into one presentation And it is an addition to the object model that I am going to call peeps I'll talk about why in a minute The so as I understand it, peeps are only distributed North America, so those you are not, from here, this is, as you can see, this is a shape artificially colored marshmallow candy that resemble little baby chicks. The package there says they're gluten and fat fat-free. So I think that means they're good for you yes entirely sugar. And the reason the calling it peeps is because I think I'll do, my observation is that a lot of the words we use in our object model have other meanings"
  },
  {
    "startTime": "00:38:01",
    "text": "people have application like oh for instance group I think people have applications. They use the term group and a lot of back of the words we use in our object model have other meanings, people have application, like, for instance, group. I think people have applications, they use the term group, and a lot of baggage is coming along. So I'm predicted term there's no baggage in any use case no one uses peeps in their use case so it means exactly what we say it means and later we can bike shed what the name is, and I'm going to find her places it to be whatever we decide is an appropriate name. Next slide Okay, so, I've been of you know, I'm approaching MOQ as a transport person who is here to learn about use cases, and I'm always trying to think how are all these things mapping the transport concept? Groups are, of course well groups are the one thing we have between tracks and objects And like, there are a bunch one might have a bunch of questions but what the properties of groups are. And in fact, for a lot of those for a lot of those questions, the answer is it depends on the use case. Like, are those objects that? of questions about what the properties of groups are and in fact for a lot of those for a lot of those questions those the answer is it depends on the use case like are those objects depend on each other can you have multiple groups of independent? Could you have multiple? subgroups that are independent they're dependent with each other, but the subgroups themselves are independent? you know, can you skip objects, are they in order, and it's all sort of ambiguous in the general case. And if you're writing a general purpose, MOQT stack and you're trying to map this to transport, concepts, in particular quick streams, it is really hard to do that. Like what can I, what can I, assign semantic meaning to a reset stream? in an easy way can I like the fact that streams give you in order delivery does that is that useful is that a useful MOQ capability? Does a stream? thin give you a useful signal? And uh next slide and this ties in with forwarding preference which is that we have four different meanings for to stream is delivering. It can be an entire track. It can be a good it can be a single object, or it could be a data with forwarding preference, which is that we have four different meanings for what a stream is delivering. It can be an entire track. It can be a group. It can be a single object or it could be a datagram, as many of you know. And"
  },
  {
    "startTime": "00:40:01",
    "text": "you know, there are a lot of use cases out there and so this does not give you full flexibility to map streams to wherever they need to be mapped to, but it gives you a lot of flexibility flexibility And this forwarding preference is also a track level thing So if you have a more, if you have subscriber concerns, if subscribers need different forms forwarding preferences or if, or if like things vary over time in a track, you really can't do anything about it. So these end of group markers, end of stream markers, or stream resets, fins, etc. Like as an implementer and as a person who you know has worked a lot with quick i find it very hard to reason about those in all these different foreign preference content Next slide. OK Okay. Let me try to be a little more concrete here. So use case example Thank you, Mo. So let's take a certain group with eight objects in it um And my beautiful ASCII art there is trying to indicate dependencies. So you have objects. So again, object IDs are in decode order but seven is dependent on five, which is dependent on three, just dependent on one You can think of those as progressive frames in common use case. And then 2468, you could think of as an enhancement frame which depend on each other, and also depend on the progressive frames. So there are a couple ways to accomplish that to model this in the current spec wants to put each object on its own stream and declare a relative priorities behind all those streams. That totally works for some values it works. I think most people would accept that that is kind of gross in terms of just consuming stream IDs and just a lot of having a lot of overhead and like duplicative messages etc. You could do it as separate tracks which again will work, but uh i think also people might think is a little bit gross to have to subscribe separately to enhancement and grab aggressive frames. And then these objects are going to be delivered and if you put them all in the same group um"
  },
  {
    "startTime": "00:42:01",
    "text": "sorry, if you put the group on one stream, then they will be ordered, they will be delivered in object ID order. If you can you get one, two, three, four five six seven eight which is not really reflect the process of these things. And if you reset the stream, you might lose things you might lose things you might want to get. Like, if you don't want 8 because you just don't have the capacity for it, like you can't you can't, if you don't want six, but you want seven, because that's all the, time you have left, you can't, there's no way to signal that Next slide. Colin, do you want to ask a question now? I just want to apply a question you have left, you can't, there's no way to signal that. Next slide. Colin, do you want to ask a question now? I just want to apply a comment. I don't think it's really very relevant where you're going here, but I mean, like, I don't really agree with either delivered it ID order, as you know. I don't think that is what the spec says And I also think that the basic problem, you're suggesting this is all a problem about how to map groups to streams but we don't. We map objects to streams. That's the data that goes over. And we have very clear ways to map objects to screen We have, you know, we can map one object or a bunch of objects called a group to a stream, or all the objects that attract to a stream. And it's the objects that represent the bite. And, you know, no we were very clear about, you know, you can't move bytes out of the middle of an object, you can't have a gap in the middle of it, all of those things, right? so i like i'll carry on where you're going here, but I just want to sort of flag that, yeah, I don't quite agree with this. Okay, maybe in a way that doesn't matter All right, fair enough. I mean, every time I try to like, staple down, where a group is, I get like, oh, well, not always as a response I don't want to re-litigate that now The point is, is a group in mock not in warp, but in mock, is yeah, is, is a set of objects that is set up to have the proper whatever the application using it wants it to be. And you're trying to get at those properties, but they don't matter to the real That's why they're not specified here. So the things that you view as ambiguous don't matter to the relay right because we don't map group systems, we map objects systems they don't matter to the relay. That's why they're not specified here. So the things that you view as ambiguities don't matter to the relay, right? Because we don't map groups to streams, we map objects to streams. Do you want to keep to clarifying questions? What's that? Do you want to keep to clarifying questions? That's okay Well, I mean, I do want to say that, like, I think there's a lot of conditions"
  },
  {
    "startTime": "00:44:02",
    "text": "about the object ID thing, and having had a few conversations in the last 24 hours So the spec, and thank you's pointers to the experts in the room who pointed this out to me, so if you use group per stream, there's a single priority, like the actual encoding is a single priority for that group slash stream So it is not possible to force a re- and it says within a priority you have to deliver an object ID order within a group and so it's impossible to reorder objects on a stream per group mapping That may be wrong but that's what is in the spec Is it? Okay, hold on I disagree with that. We can bring up the text of the spec right now if you want, but I don't think it's relevant to where you're going for the conversation. So I'm certainly willing to 100% table it All right, thank you So as given that Colin, is it like a super quick clarifying question? We want to make sure we get through the slides here and not face plan. I'll wait doesn't matter okay thanks thank you Okay, so what is Peep? So Peep is a new layer of a hierarchy between groups and objects And like the TLVR with all this stuff is that the idea here is the application identifies objects that would be benefit from being in the same quick stream That is that in order delivery is in no way a detriment to them, that like that the later order, the later objects of the stream are useless without the earlier objects which implies some sort of dependency relationship, but not every dependency relationship is like that for a bunch of reasons and all this stuff is negotiable I do want to say this is, the intent of this talk is very much like, Victor's talk which is kind of said a general direction and if the fee feedback is that direction is a positive one, then we can then bike shed the detail in a PR later but it would be a big PR so like I want to spend the effort until we're, we're"
  },
  {
    "startTime": "00:46:01",
    "text": "interested in something like this and the idea is that this is, this is, instead of having 40 preferences, this is the way you map streams it is it is an application to find things actually more flexible than the forwarding preference model because you can essentially do anything within a group but it does illuminate some other things Apps are always able to put internal structure in objects if they won't it will ruin sort of the atomic if you do too much of that, like you can't really ensure atomic delivery in a sense in a sensible way but that is what it is. That's not, that's no change from the current spec. And like subscribers don't actually need to know about this except as relays because all it affects the stream map mapping. As a receiver, you don't have to care about that Let's see, what else is important here? i think those are probably the main things but just i want to be clear this there's not a rule that all dependent objects need to be in the same peep because next slide Applying the use case example you had here, even though there is depend there are dependency relationships between all of these objects the the op I think I think most people can see the optimal way to map this step to peeps Where like peep one is higher priority than peep two and so you will get those objects first and you will get those objects for the objects in peep two do people have questions about how this why this is the right way to do it? in a perfect world Johnna Jona So the slide that he had just before this, why is a people not just a stream, I guess I'm confused again Because I am of one using any term that has any other meaning in networking or in media applications but it has a meaning in quick yes i And what you have there to me is a stream is it not? If there is consensus that I should just find replace peep with stream and everyone is fine with that with no ambiguity, I am not asking because I'm going to understand"
  },
  {
    "startTime": "00:48:01",
    "text": "if it's something, I, I'm, I'm, I'm, I'm, replace PEEP with stream and everyone is fine with that with no ambiguity, I'm not asking because I'm trying to understand if it's something, yeah, I'm thank you for putting this together first because I'm finally seeing it all on one slide in one one place right so it helps and as a as a work through it it seems to me that basically it is literally a stream, not anymore, not any less Right So if a peep is delivered over two connections, for reasons, then they will, they will arrive on two logically distinct streams, but ups connections for reasons, then they will arrive on two logically distinct streams, but when re-delivered, they should be consolidated on a single stream I see. So it's an abstraction that the application is using from Mocti. What Mocti does with it underneath is a different problem because Mocti is also a quick connection, isn't it? Well, web transport potentially but yes. Right, but then you don't go across connections with Makti anyway because you're going to expect that up to the application to deal with it's an error the connection closes it's an error so i mean connections are not so if for some reason a subscription fails or a connection fails and your relay and you're getting your going to another connection or another subscription and get data from the same peep, then they will come in on on different streams obviously and you need to know somehow to send those downstream, ideally you would know to send those downstream on the same stream which is why I don't want to stream because upstream downstream, but I think this can function without peep by bees but i think it does have that useful property and also it allows you to express priority with them but that's maybe a second order discussion to have Yeah, I'll stop in a second, but I think the last thing I want to say is that I think without expressing this on the wire, it becomes if you're not expressing on the wire it's it's it's really across kind of connections, I don't know how you can establish state, but I'll lead that at that for now. Okay. Thank you. Before we go"
  },
  {
    "startTime": "00:50:01",
    "text": "you were on your next to last slide. You want to just cover your last slide and then we can open wide up? I think people want to discuss this and I want to leave a lot of time for discussion. Let me blow through these other things. I think you were there Yeah, keep going right so i mean i think what would appear these other things. I think you were there. Yeah, keep going. Right, so I mean, I think what would a PR look like? I think you add some things to the API to allow the application who assign objects to peeps for Foreign preferences go away. We were just having to talk about peep ID. I'm not going to die on that hill. I think it's useful but we could not have it. Next slide And like the higher order question is like would people interest is this enough of a right direction that people like to CPRs? And like there's sort of a total solution that like does peeps more or less what are presented here where like you can have unlimited flexibility to to assign objects to streams within a group and then like a corollary of this that we're eliminating stream portray and is that a hill that people is that a feature that people really need and if so we would have to rework that but and or we could not do peeps and just eliminate stream per track which I think solves some problems that I've articulated. So at this point, like that's all the slides let's let's talk about it and i'll trust my chair to like stop us of running off the rails here okay we have 11 minutes There's five people in queue and it's not just clarifying. So feel free to like it's wide open Rip into it. mo zanaty so to answer John's question, I think, uh, the way that the way that i interpreted this was that at the uh object at the object model level people are basically subgroups at the transport level, they're basically quick streams with the exception of datagrams And they're quick outbound streams, unrelated to how you receive them in on relay, but they're, you're your egress streams when you write out on a quick collection they're the in intended outbound streams Again, with the caveat that there's also support for datagrams, that's the way"
  },
  {
    "startTime": "00:52:01",
    "text": "I see it. The one thing that I've been struck with in mock is to figure out how to official convey temporal scalability, and I don't see a good way to do it in the current object model or in the current wire format There was a there's potentially a hacky way to do it Suas and I had a long conversation about how it could pop possibly be done with group or stream and Singleton streams at the same time on the same group I don't believe people are going to be happy with that either. So peeps does allow potentially away to cleanly signal something like that So I'm not totally opposed to having something in object metal that does that but um i'd like people to think about the temporal scalability case and figure out how would you solve it with the current mock object? and how would you solve it with peeps and which way it could be better. So are you interested in the PR? on this? I don't see another way to do it in the current object model. Okay, thank you Okay, Sue Haas. A couple of things on the platform clarification point is that today we allow groups to have multiple priorities There's nothing in the draft that says you cannot a group cannot have objects of multiple priorities. There's nothing in any anywhere in the draft. They cannot be included if they're in their same stream it is impossible again we are talking about object model and transport and keeping it separate right? You can construct a group with objects with different priorities Now, when you're picking up the next object and sending it, that's where you make the choice saying that if you will I send this object all the objects on the same stream, if they're of same priority, if there are different priorities, you can create more streams and send. So today we do allow a group to have multiple streams Only thing the PIPS adds values that the way we allow today, from my interpretation of reading the spec is that you can send a stream header group with like for your example of temporal scalability, where you had, you had, you stream header group for one set of priorities which is like"
  },
  {
    "startTime": "00:54:01",
    "text": "the one three and five and then you had to create single stream per object for the same group and you can send it that's again it's totally how you want to transport it but the spec does not stop you from having a group with multiple objects No other than the spec that's defined anywhere. But there are use cases where, like let's some of the use cases where you want to send all the objects of same priority, they are in the group on all the objects of our same priority then you can map it to stream as it is, then obviously by the reason, by by by had your objects in the group and they're all being of the same priority, it also has them one-to-one mapping to the stream That's why group per stream has that confusion. When you take the group and send at the stream, everyone assumes that, you know, every object should be of the same priority in a group no you don't have to be the nice thing about peeps is that it will make it very explicit. Now, today the draft is implied. Hence, the problem for the confusion, which is totally possible but what peep does is that it makes it very clear a group can have multiple priorities in it and uh as most said for me peep is a subgroup a subgroup size can be the entire group if all the objects are for the same priority a subgroup can be a small size of the group a given group in that case you have multiple streams of each priority, like the use case you had Or a subgroup of size one in a group In that case, it will be stream per object. So in a way, we have stream per group with all the priorities say of object same stream per object also supported with peep and people's will be stream per object. So in a way, we have stream per group with all the practice of objects same. Stream per object is also supported with PIP, and PIP also supports something in between, which is I have multiple streams. So in that way, I think we can, we should consider making PR out of it. On stream per track, I'm not going to okay either way for me Okay, thank you. So yeah, so I apologize since it's unclear but yes absolutely you could do that use case I should at stream per object. If that is, with a fair amount of noise, you can do it but it's totally possible. And yes, if"
  },
  {
    "startTime": "00:56:01",
    "text": "is a generalization of stream per group and stream per object and everything in between that is the point of peeps okay so there are six people in queue six and a half minutes so A, please be brief, B, hop in the queue right now if you think you want to get in. Otherwise, I'm going to lock it in about 30 seconds all right I'm next so um completely agree with Moe that this all comes down to temporal scalability And at the end of the day, we really added the object for stream mode for temporal scalability The idea is that you could have a group, you have different parts within the group like the base layer and the enhancement layer of a dim priority I think that as I, you know, as I think about it more and more, this works if you're watching a single track, right? You're watching a single track and you can prioritize the base layer with the enhancement layer It really just doesn't work when you're trying to watch multiple broadcasts multiple different namespaces. And subscribe to your part as we added. So I really think that the object per stream, like all these different ways of mapping to quick has done us like us amazing amount of harm And it doesn't actually address the end use case, which is 10 temporal scalability. So my requirement for Peeps is that you can subscribe to Alice and Bob's base enhancement base layer and then separately, little priority, subscribe to their enhancement layer. And that's kind of what Peeps works to some degree, but I end up just consolidating into a stream for through because of temporal scalability so I really want to like approach this from my how do we do temporal scalability when there's more multiple broadcasters, like as a use case requirement? And I think PEEPS needs a little bit of rethink just to handle that use case because it gets complicated So would you like to see PR in this space? if I wrote something like what I presented, can we get it to where you could be? Absolutely. Anything that gets rid of the stream modes is 100% Like, we can't have separate APIs for"
  },
  {
    "startTime": "00:58:01",
    "text": "separate modes like that. It doesn't work Thank you. Okay, four and a half minutes in five people in queue. So it's, please be brief Please hustle to the mic. And, um half minutes and five people in queue. So it's, please be brief. Please hustle to the mic and try to focus on, would you, do you want to CPR or this is? a distraction? We shouldn't be working on this or it's the wrong direction I would like to see a PR that I think is a long way that the people saying you're you're doing here of the actual ID. So I'd like to see something where we could include an identifier that when you were doing effectively the stream per group mode that uh if this identifier the two objects with a different value of this identifier didn't end up in the same stream okay we still have reconnection cases in things where they could be in different streams, but basically, it identifies the stream and you'll never put two things with different values in the same stream, right? I think that's the better way of phrasing pretty much what you've got there. Now, that's one part of it The other part of it, though, of removing stream per track, we haven't just discussed that at all. It's completely an independent question from this This is a totally different thing. I think I don't want to see a PR that does that what's not some separate discussion on that. That's an independent issue. None of your slides addressed it I'm probably in favor of removing stream for track but I don't think we've motivated doing that right now, and I'm really against us going and exploding old consensus i don't view that it makes it harder to reason about these things or harder to implement Like, you know, if somebody can show me the PR that produced 1,000 lines of code out of their existing code base when we remove the stream per track mode, I might be motivated, but you know I'm not going to see that. So, you know that's, so I want to separate those two separate issues okay uh Thanks, Ian, then Christian, Mike, and Jonah Ian, but yes, I'd like to see a PR about that. In the stream per track question, I think that only is useful for Fetch anyway. And so I'm hoping that like whenever Victor writes a fetch-ish PR thing, we just say like if you're asking for stuff"
  },
  {
    "startTime": "01:00:01",
    "text": "in the past you're gonna get it at line rate the only way to do flow control at line rate is to put it in a stream. And that's the answer and that will naturally kill it and also keep it around for the case that we actually won't kind of want it in the first place, but we, I think, didn't, weren't fully able to express yeah I see this as a generalization of what we have and just kind of a loosening of the rules actually when i originally we added forwarding preference, I thought you could do a bunch of this stuff but then we added more and more roles about what you couldn't do and then we kind of got into the software space word. Yeah So, anyway, this seems like a net simple to get And thinking about the three modes as an editor is annoying because like you're constantly thinking about like edge cases in different modes Yeah. So, given the feedback, you portray stream per track, I think I'll just make reasonable preference to an enum of stream per peep and stream per track and then we can fight out web whether stream per track is valuable separately Christian. Christian Reitomo, I kind of like what you're proposing because what I really believe that the tension is that the model of groups and sequence number and tracks does not capture the temporal way of the two dimensions of the graph that you're making. They might be more accurate may be three dimensions in some cases but living like that. So effectively what you get, is something like you have a stream per group and per priority level And that's the magic. Yes I kind of like that. What I struggle with is that your encoding of the temporal dependency between the different levels seem to be implicit And I'd like to make it explicit so that we can understand. Well, I mean, so this is a little bit of a spelling issue, I guess. But one reason that I would like to have explicit peep IDs is we could use that as the low order bits of priority, of our priority in industry So that the peep ID, so peep ID unique to a group right it's in the group scope"
  },
  {
    "startTime": "01:02:01",
    "text": "and the lowest peep ID is the highest priority for instance i mean it's many ways to spell this but that's the most straightforward thing I can think of I think that if we can use that to that so that we don't have to have multiple tracks for the same video then that will be a game. Great thank you. Okay, Mike, and then John has the last word and we're a little bit over time so please continue being here Yeah, I like this. Thank you for writing it up. I do think that this helps us move towards simplifying forwarding preference And, yeah, I'd be happy to help with PR text or anything like that. Thanks. Thank you Thanks. All right, thanks, Johnna Johnna Very quickly, first thing is everybody loves a new level of industry So it's always fun to see that percolate, except that if you don't define it well there'll be lots of questions and more problems So I think a couple of things. First, I have a lot of thoughts and questions which I don't want to ask at the mic, but I'm going to offer to work with you on clarifying those and maybe help you with clarifying them in whatever it is that you're writing. Because I think it's really important to make sure that the absence is written in the context of the abstraction we already have so you know it's a thing more like this. We know in quick there's this that the abstraction is written in the context of the abstractions we already have. So, you know, it's a thing about like, there's, there's, we know in Quick, there's, there's bits, bytes, streams, and connection and peace have to fall somewhere in there. Otherwise, it doesn't make sense. Similarly, we've got tracks, groups, and all objects and peeps have to fall somewhere in there for it to make sense So I think if we are articulated well, we can actually find a better name than P peeps. I think until then keeping peeps is better. Yes the articulation of what the abstraction actually is should help us with that. But thank you. Thank you, John OK, I have a strong signal, I think, to do a PR, which I guess guarantees nothing, but like I will be away way on one. Thank you for your offer of help, Jana, and we'll see what people"
  },
  {
    "startTime": "01:04:01",
    "text": "think and and i just want to make clear that i'm not married to any particular detail of this proposal, and so I'm very very malleable on like almost every one of those details thanks i think zoffer is next all right Thanks, Martin. Zoffer, do you want me to share slides for you? Yes, yes, please. Hi Or do you want you, Martin? Okay, we don't trust me Okay, before starting, let me introduce myself. I'm Zafar from Ozi University, from Istanbul I'm a PhD student and my supervisor is ali begen. Today, we're will present our draft about track switching and major quick transport There's a proposal that we propose. Next slide please So actually now we are implementing, we implement Lux and Maxcode, MOCRS and MOC propose. Next slide, please. So actually, now we are implementing, we implemented Lux and Maxcode, MochRES and MoCOP, for our testbed. So we started to develop a test pet to compare the performances of DashJS and the mock player And we implemented ABR and track switching but we face some problems in switching actually under congested scenarios So when the switch, two tracks between two tracks so we face this problem So there wasn't a seamless trend tracking switching between them. So the problem is that the relays are unaware when two tracks are ultraments and we needed to send two consecutive subscribe messages to the relay"
  },
  {
    "startTime": "01:06:01",
    "text": "sorry, a subscribe message and then when we get data from the relay last minute relay we send an unsubscribe message to the relay. But that resulted in two parallel tracks being transferred from the relay and that caused it betrayed spike in the congested network Next slide, please So our solution is very easy So the end subscriber hints to the last minor day about its intent to switch to a new track so that the relay can know that it can cancel the current track which is hinted by the end subscriber in a subscribe message. So whenever the new track is ready in the cache, it can send subscribe OK to the unsubscribe so that the client receives this okay message and then it can it can switch seamlessly next slide please So there are two different variations about our solution the first solution is using Altrucrupy group identifier in the subscribe message So it's the identifier for a group of alternative tracks within scope of a track namespace Next slide, please Second solution is a little bit easier It's switch track Alice. Switch track is easy an optional parameter. Again, it's the track alice of the active subscription. So let it run in received by the relay the track that has this alias is cancelled and then subscribe okay message sent to the unsubscribe. So we have some preliminary results. It seems that it's working so now we will we are continuing our tests so that's all Thank you. All right"
  },
  {
    "startTime": "01:08:01",
    "text": "time for a few questions. Kota Hello, Ms. Golda. So we've already had a go away control message, right? And when it happened, subscriber, just unsubscribe from the old trucks and create the new trucks So I don't really come up with the cases where the relays are unaware that the subscriber and subscriber so there's a duplication of subscribers and duplication of trucks. I don't come up with the cases Whenever you, so, so actually, for instance, for a video player, so you have one active, you know, track for instance, for a low resolution, and you want to switch the new track. So these are two different subscriptions right? So you need to send two different independent subscribe messages to relay. So these are individuals you want to switch the new track so these are two different subscriptions right where you need to send two different independent subscribe messages to the relay so these are in the view of the relay these are two different subscribe messages. So there's, you can, you can get parallel tracks There's no, nothing that prevents you from the proposal. But if you want, just one active subscription at one time, like a video track so you need to hint to the relay so that relay can know and can end the other tracks. So that's the idea okay i get it thank the cue is feeling fast so I'm going to close it soon. Oh, thank you So Zoh Zaffer, I just want to make the same comment I made an email thread I think our existing APIs can do this for us efficiently by using a subscribe update. So if you're in track A and you need to switch and you have an open support I made in the email thread. I think our existing APIs can do this for us efficiently by using a subscribe update. So if you're in track A and you need to switch and you have an open subscription on track A, you can do a subscribe update to terminate it at say the next group which you know what it is, say group 73. And then you do a subscription for track b and starting at group 74"
  },
  {
    "startTime": "01:10:01",
    "text": "So that will stop you transmitting duplicate data on the wire and the existing APIs allow us to do this we don't need uh new extension to allow them Yeah, it seems possible but as I applied in my email that if the if the track that the new track is not in the cache, and you cannot know if it's in the cache or not so that the unsubscriber will signal the group ID, as you said but if that group is not in the cache then what will you do So you need to you need to continue this stream the other track so that there can seem switching if it's not in the cash, we have a problem. That's why we wanted to give the control to the relay to cancel the stream whenever it wants, whenever it's ready to stream the deep track, when it's in cash Okay. Thank you You're welcome. So, how, Cisco? Jafford, thanks for the presentation. At a high level, I agree this is a problem needs to be solved but on the other hand, I have a few concerns about the thinking around it I'm, I don't think so as a more clear we should have put some out on the tracks for the relays to understand the relationship between the tracks like some tracks might be out alternate sometimes dependent we don't like to we ask for us as much as we put less baggage on market relays to understand how the tracks are related is good that keeps the independent and gives the application innovation to do it on the other hand like a while back we this I think there's still open PR which I think Alan also suggested some improvements on top of that wherein for the to solve the problem of warming your caches with all the qualities that you need there was a proposal wherein you can do subs caches with all the qualities that you need there was a proposal wherein you can do subscribe for all the qualities that you need at one go like like"
  },
  {
    "startTime": "01:12:01",
    "text": "send multiple subscribes with saying, I want to freeze everything except the lowest quality or highest quality water it is at any point in time you want to switch, you send the update thing, I want to understand unfreeze the other one. So some, some, some, that will basically keep the track idea for the relay independent of each other. It's not burdened with semantics. And we do use that in the cases where we want our local relay that's running in our house to have multiple tracks all that data coming from the cache of from the original publisher and we are in a bad Wi-Fi network and we don't want all the three tracks or three qualities to come from everyone. In that case, what we do is that we freeze everything other than the low quality, and when you get better, we ask for the okay, I'm good to get to the other things So that would give as an experience for the end user, it will give an immediate switch to the highest quality so i think something on those lines, or some form of the design we can come But on higher level, this problem is, I think, good. We should think about it. Thank you. Thank you. Thank you for it feedback Colin Jayes I was just going to basically ask whether you think that. So first of all I'd like to solve this problem you're trying to solve for sure Right. Makes sense. I think so, of course, the use case But the next question was, do you think, I don't know how familiar looked at that freeze, unfreeze model where you can freeze a subscription. I mean, would that, would that meet? your needs or is there any reason that that wouldn't, where? that wouldn't be an optimal solution? That's my question No, I didn't look at this. Okay OK, that's totally fair. Well, we can discuss it more than later thank you you're welcome thanks Hello, Jordi. So thanks for working on this. I think of us, the rest of the people, I think this we need to solve this, especially if we want that we want to solve AVR. But it seems that the only thing that you would need to do a clean switch is an atomic and subscribe, subscribe yes to the relay and say when you"
  },
  {
    "startTime": "01:14:01",
    "text": "only thing that you would need to do a clean switch is an atomic and subscribe, subscribe. Yes. So send a message to the relay and say, when you are at the new group boundary, do that switch, and then the relay could answer when the switch is done so basically we could put that logic in the subscribe update or create a new message for that Any message? Sorry Yeah, so we could describe that behavior in the current subscribe update message that I think it needs perhaps few more data. Or we could design a new message to basically implement exactly that behavior. Yes, sure a new message also can be added or as you mentioned in your email to me we can put this fields into subscribe parameters or the custom parameter section But there's a problem here. So this are proposals, but I think we need to solve this because it's a problem lying there. So yeah it can be. Thanks. Thank you All right, a slight agenda back rather than estimate how much the administrative review will take, I'm just going to do it and then give Ian the balance of our time So the administrative announcement just involves upcoming interim So as many of you know, we've been doing virtual interns on a more or less weekly basis. Alan and I have decided that we're going to use the August holiday to basically go to a bi-weekly rhythm. And then once you come to September or go back to weekly, does anyone have a problem with that? Okay and those have been typically Wednesday mornings at 9 o'clock PST, Pacific time, whatever daylight or not, whatever that is at UTC I don't know, varies, I guess. And we always invite comments to send to M&PT chairs if you think something we're doing with virtual interms is bad The other subject is an in-person interim We have, like, settled the dates of october 1st the 3rd and we have 10 do not so put that on your calendars. We we"
  },
  {
    "startTime": "01:16:01",
    "text": "identified New York City as the target location Do not buy plane tickets because we not yet have a venue in Seattle we several people decided, said they were going to look into potentially hosting New York City. I know Zahed was one of those people. We don't have notes on who else said If you agreed in Seattle to look into it, can you? raise your hand right now or virtually raise your hand? as the case may be? Okay, so I know it was more than just Zahed um i had volunteered and i have looked into it and it's suboptical so I know it was more than just Zahad. I had volunteered and I have looked into it. Okay, right. So if we can't find a good venue, we know we can get Cambridge, Massachusetts. So that is our fallback. So your punishment for not finding New York City venue is having to go to Boston Boston Okay. There are worse cities in the West world, but yes. All right. Well, so with that, we hand the balance of the time to do real work, so Ian it's off to you Oh, 30 minutes. Okay, perfect Lightning round. Oh, yeah, no, I will attempt to be fast So we've discussed a number of things in the last two days. I tried to pick out items that haven't changed dramatically as a result of this conversation because a number of things I wanted to talk about have changed dramatically And I think they don't need to be discussed right now. One thing is, should miss objects be required? So a while back, we added the ability to specify that objects work currently not available, and it's not just that they weren't delivered due to congestion or some other reason, but that they were not available, but we did actually say you had to use them. We just kind of like put them there and said they exist This does create, not requiring them does create some problems caching is a pretty obvious one so if you have the Victor's use case from yesterday where, you know, every other object is"
  },
  {
    "startTime": "01:18:01",
    "text": "missing, if you can cache the fact that every other object is missing, that's fairly efficient. If you have no idea if I every other object is missing, I guess in the worst case, you would have to go through and do like thousands of little subscribes, which is quite wasteful I mean, negative also as a result, you could infer that any gaps that don't have explicit indicators are due to congestion So when we add delivery time out, then, you know, you can basically say, well, I didn't get it, so it must have been dropped due to congestion and the delivery time out hit Consum spite's in the wire Anyway, comments, I guess is Sue us first? I think I'll break a question go back to the fetch versus subscribe a bit here because fetch is a promise that if there's a gap because of something was dropped on the cash and if you're aware of it will make an attempt to go to the origin and fill if possible. On Subscribe, at the point of time, if you're sending the data and you don't have the data, you don't have the data, that's it, because subscribe is supposed to be live is even telling the other end that you know you missed an object in between, it's not going to help. They have to handle the loss anyways uh they have to work around it but for the fetch it might be useful for, if cash has the value that's saying that this object is not it's not it's missing but I for whatever reason it can go at least try to fill the gap and come back Uh, Jonathan lennox, I wanted to clarify, is this mean, does this the original publisher said? this object does not exist, will never exist? No, I matter how hard you try, I'm not going to give it to you, or is it something that a relay could make up if didn't get something? is something either the original publisher would put in originally or for some reason, say the content timed out and when you back, back to the original publisher later, it no longer existed at that point. So all it's really saying is it doesn't exist now, it might have existed in the past, I have no idea, but"
  },
  {
    "startTime": "01:20:01",
    "text": "you're not going to get it no matter how hard you try. Okay, so it's it's at that point. So all it's really saying is it doesn't exist now, it might have existed in the past, I have no idea, but you're not going to get it no matter how hard you try. Okay, so it's either, it's gone in some sense, don't try to get, you're never going to get it. It's very much a negative cash indicator as much as anything, but yes, you're not going to get it martin duke, no hats. I am in favor of explicit signals and less like ambiguity, but what should come next at all times. I don't remember what object status codes we have If we don't have them, I'd be happy to add I don't have it yet, and I'm not going to send it to you later and I don't have it yet, I am going to send it to you later to eliminate any ambiguity of whether or 90,000 subscribers a thousand subscribers or not. I'm not sure what I would do and I'm going to send it to you later. Would you send it to them later? When it arrived as a relay So say like I don't have four, but I'm expecting it because it's object per- stream or something. That like oh there's a gap here but you'll get it later versus like I'm never going to send this to you unless you ask me for it. Okay Thanks as how this is expected to work with ranges, because we allow us false objects. So you ask for zero to one thousand and there might only be three groups in there. So are you expected to signal any? with ranges because we allow fast objects. So you ask for zero to 1,000 and there might only be three groups in there. So are you expected to signal anything that's missing? It's not, it's fine if you ask for an explicit object, but as soon as you ask for a rage with sparseness, what is expected to be communicated? in terms of missing object? So the I think there's two different cases. One is you, for some reason, have a really sparse space and you have a thousand someone asked for a thousand groups, and for some reason, there's only three in that space. So yes, in that case you'd have to send 997 missing groups now thousand groups and for some reason there's only three in that space so yes in that case you'd have to send nine nine nine nine hundred nine seven missing groups now i don't know what why there's only three in that space. So yes, in that case you'd have to send 997 missing groups. Now, I don't know why. Just stop, why? Like nothing says they have to be incremental and ordinal. They're not missing. They would just never make and never given numbers so they're not missing right I think sending nine or 99 99,000 things saying stuff that was never made in the first places is not there. We need to, we need to re-architect that"
  },
  {
    "startTime": "01:22:01",
    "text": "Sure, but yeah, I mean, you can use numbers in whatever way you want. I mean, you could use the full UN-62 space if you wanted, but I mean, at some point, wouldn't you want? your numbers to be moderately compact, only so the varut? would be reasonable? I don't know. Like we can make the gap encoding more efficient if we really want to I don't know. Like we can make the we can make the gap encoding more efficient if we really wanted to. I guess why don't we separate that out if we want to make the gap? I think it's in various solutions to that. This is a solution for explicit missing object. Yes, this is a solution for the explicit case of, like, this doesn't exist either because it doesn't exist, never did, or or at least at this point it will not Luke Yeah, I think for low latency, this doesn't matter because effectively there's ambiguity if this object is in flight or if it's not even being transmitted at all and it will never be transmitted And I think for Reliable Live, like HLS data, use cases, you want to know if the object is not coming so you can just keep playback, like, you know, continue playback Adding a timer, like forcing the client to add a timer based on some arbitrary amount of time is, it's just going to increase latency so i think we definitely should have a signal saying you asked for you know, group eight, and I'm not going to send it to you Like, it's not in cash or it your delivery timeout has expired. Just tell me that, you know, and I'm not going to send it to you. Like, it's not in cash, or your delivery timeout has expired. Just tell me that you're not sending eight so I can move on to nine. Otherwise, my client is going to sit there waiting for eight eight Go on So I mean the lot so I'm sort of three different things. I have to keep them straight in my mind here So, I mean, sort of agree with Luke said. And I believe that last time we had this conversation, what we came to was there's"
  },
  {
    "startTime": "01:24:01",
    "text": "some applications and uses where, like the one, Luke was just describing, where you explicitly know your numbers are compact and they're moving along a certain way and you can put in a marker for this has never come. We can discuss what that marker looks like, but you put in an explicit marker There's other cases where and the application doing the publishing knows what type of application it is and the application receiving the data knows what type of application it is that's receiving this publishing, so they can deal with that Now there's other types of applications where you're objects might be very sparse because you're trying to use random numbers that don't collide in a certain way because there might be multiple subscribers on a various things, like the chat application used that in some ways it was groups not objects but it's fairly similar so maybe we could say we'll never have those ones but i don't think we can't i think we have some applications where you very much do have some large gaps because you're using hashed things in some form or another random numbers. Deliberately large gaps for the application to avoid collisions And for those types of applications, they know that they probably should be publishing these marker things because they'd have to publish a billion markers in between things So I think that that's where we got last time was like, oh, this should be punted up to, you know, different applications we'll use it in different ways and we should have a way of communicating this mechanism. Now, note, I don't think the relay ever needs this information. And this is the sort of showstopper problem with this, is if you say you have to publish these the people that don't want to publish them simply won't publish them. And you can't tell the difference between, I'm saying, waiting for it as a relay. And not things. So I think that if you start writing, as soon as you start requiring these in some ways, every you look at, you end up creating these huge sort of DOS attack type things where a miss misbehaving client can accidentally or deliberately cause the relay to have to do a bunch of work, far more work than the client has to do And once you start ruling those out, you're just being like,"
  },
  {
    "startTime": "01:26:01",
    "text": "oh, we're back to where we are today, which is basically you can put in these objects if you have them, the relay will explicitly deliver them If you're in a track that doesn't use them, then you can tell the difference between it hasn't been created yet and it will never be created. So make it you have them, the relay will explicitly deliver them. If you're in a track that doesn't use them, then you can't tell the difference between it hasn't been created yet and it will never be created. Does that make sense? Yes, that does make sense The hash collision use of IDs is a little mind bending for me, but I'll like process that offline I have a question, would it be useful if we made a property of a subscribe okay? Maybe an optional one that indicated whether these were going to come? So that I have a specific thing that like, so really today, assuming we get something that looks like fetch if you make a request for a big range and it has a bunch of gaps in its cache presumably it is going to go upstream to try to fill all those gaps in the use case you just said where you may have, you know, a hundred group IDs being used or something out of a billion I mean, it's going to have to make like 100 upstream fetches It's kind of annoying. Maybe you won't care Well, if you had a million objects in that 62-bit space, it's going to have to make a million upstream, like, however many objects you already have in the space It's the number of gaps. So yeah, it's going to make a it. And like, that sounds terrifying to me. I can send a single request to your relay that causes your relay to make a million requests. It does not sound like that many objects you already have in the space it's it's the number of gaps so yeah it's going to make it and like that sounds terrifying to me i can send a single request to your relay that causes your relay to make a million requests does not sound like a hot idea sure but if i can cache that something's missing that I don't have to make those, I guess for sure So I look, putting the this putting the, this type of track will always have this or not have that marking that in the subscribe somehow or maybe, I, guess the relays need to know it, so it'd need to be in the subscribe. Subscribe, okay yeah. That makes total sense, like, something like that. Okay I mean, I think that could be helpful. Okay. I think we'd have to look exactly what we're going to use that information for but as long as there was a use for it, I think the clients that are doing the scribes would know it from the catalog. It would be easy. Like, I think it's perfectly reasonable to add that information if there's something useful to do with it Yeah, it'd be mostly for the relays, cashability, and so such. Okay. Thank you. That was perfect. You're going to help"
  },
  {
    "startTime": "01:28:01",
    "text": "have like two or three minutes I know pick whichever one you think you can get through that fast. I like this one. Sure Currently subscribe is sent on, Subscribes are sent on a single control stream, so there's no limit on how many we have we know we need to put a limit on them at some point. There are two ways forward to potentially fix us now, or we can punch it for the future. The first way is to do matthew quick style max subscriptions and, you know, out of frame, add a setup for them fairly straightforward adds an extra frame but otherwise is is fairly clear machinery the other suggestion I've heard is to open a new bi-directional stream for each subscription and as well as putting all the control messages for that subscription on that stream As a benefit, this avoids me having to write over and over again when the subscribe ID is a scribe ID that you've never seen before slash doesn't exist anymore close the connection. So it does remove a ton of like inane error cases but you basically are reusing the bidirectional street MacStream's feature of quick slash what transport to implement the exact same feature as max distributions. I don't have a super strong reference as an individual. I think both will work fine fine I can see pros and cons. Luke Yeah, so I implemented a stream per subscribe as part of Transfork. It's a lot easier because of Rust otherwise it doesn't make too much of a difference Relying on quicks flow control gets a little bit messy when you start getting with work that is a different sizes and different amounts Like, you know, if, if different bidirectional streams have different workloads, like subscribe is a lot heavier than an ounce is an equivalent just having one fixed flow control limit is kind of a problem. So I think at some point we do need max subscribes, unfortunately, some sort of"
  },
  {
    "startTime": "01:30:00",
    "text": "flow control to say the maximum subscriptions is N, and that should be lower than quick bi-directional flow control regardless of if we make a stream per subscribe I do like, I just to say that Alan's point, I really like the stream per subscribe. It makes the statement machine a lot easier. All right. So you've implemented screen per subscribe before and you like it, but you're not sure and you think we might need the other thing eventually Yeah, I think using quick flow control is just it's not a good enough match I don't think you can just use it blindly. I think we, mark thomas more semantics than Quick does. Okay, thanks subscribe is more expensive than announce. Colin Mark and Mo we're over time. You're between us and cookies Cookies are overrated. Okay, very quickly We might need to ban you What? Google loves cookies? No The was inappropriate. I'm sorry. I apologize What I actually stood up here to say quickly was, I think, I suspect we're going to have more than just the limit, and that we're not going to want to, that the limit you might want to set format subscriptions and more importantly Max announces is probably going to be different than your stream limit. And so we probably need to separate those and i'd also like to however we do this make sure we never end up with some sort of messed up priority thing where the priority of our data is causing us not to be able to send our control messages to say, stop flooding me with all that data. So those are the, like, this all sounds good I designed that meant those requirements. The latter is our already in the text that you should put control messages a higher burden than yep martin duke, don't care what you do, but if you do number one, please max subscribe ID, not max subscriptions Melsenady, I agree that we probably need to allow put control messages a higher barrier than yep uh martin duke don't care what you do but if you do number one please max subscribe id not max subscriptions those and i agree that we probably need a limit i disagree with two i think uh the earlier decisions about"
  },
  {
    "startTime": "01:32:01",
    "text": "having a control stream in the first place one of the main reasons was to serialize all of the control messages So you'd lose that if you shard them out to different streams So I think there's more determinism in the way that we have things set up right now Thank you. You have given me what I need. That's exactly what I want okay that concludes this meeting thank you, everyone. Our next virtual interim is August 7th, so we'll see, we'll do the rest of this slide deck then probably, unless something magic happens and we will see you in person either in new york city or in by Boston, or if you choose Dublin Have a good week It was one very good long That was information"
  }
]
