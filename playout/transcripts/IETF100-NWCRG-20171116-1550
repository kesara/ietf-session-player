[
  {
    "startTime": "00:00:36",
    "text": "okay um so welcome everybody um this is the IETF and it\u0027s my first one as a co-chair so that\u0027s I and I are very happy to have you here and we have a very very full agenda actually and maybe you\u0027re going to put it know you want to put the okay so this is actually a very important thing you probably do not know but there was a meeting yesterday of all the chairs for the research group and actually the idea the actually the new rules for IPR was discussed so I think it\u0027s very important if anybody presents something today that has IPR issues please make sure that you are compliant with the rules okay so oh I miss trivia we have updated the charge of the group and I\u0027m going to continue I\u0027m going to mention what we did the wiki is available for uploading documents and things that evening are valuable for the group I intend also to use it to upload documentation and background papers that have been published both in industry in academia in this field that people have a good image of what is happening in the field this is the right URL or the white guy story we will fix it but you need time to write meaning this is their dislikes above these are the ones that we have I\u0027ve already been uploaded if there are presenters who did not send us their slides please do it now and there is presentation so what I said is that I don\u0027t intend to go on with a lot of this um the the agenda is very very full I think we were very happy that we could get that presentation so we\u0027re going to go to coding use cases where the coding can be beneficial and the research projects updates and things that are ongoing this reflects all these presentations reflect a little bit of the new directions of the group and that\u0027s the next one so we have one draft that is actually in awaiting the end of the review this is a taxonomy the one that has been essentially being worked on for many years in the individual ideas we have something on going on that were coding in satellite which is also going to be presented here we have a network coding for ICN based on is going to "
  },
  {
    "startTime": "00:03:38",
    "text": "present the API and I know that there\u0027s a bad name for the quick one but we have the presentation from Google on FEC for four quick so what\u0027s new I want admit something with colorful ones so it\u0027s news because we change the name and the reason that we change a name is nice nothing to do that we change them the fact that we\u0027re talking about network coding but a lot of people didn\u0027t really know what networking was used for so we changed the name so that people would know that when we do network coding it\u0027s actually to have more efficient network communication and it is part of a toolkit for improving the performance of communication and this is the goal of this group is to look at coding as part of this toolkit for improvement we have a new charter why do we have a neutral because the old charter was about five years old and since then there\u0027s been a lot of development and I think it was also to reflect the fact that we wanted to move a little bit from just codes and things that go directly on codes on more into how our codes being used or could be used since we are research group and what are the research area that should be investigated in order for codes to be better better used or better applied in again to improve the efficiency of networks we have a new one new milestones what\u0027s on the next page so what we did in the meantime is we had a meeting an interim meeting in Boston on September 19th which happened to be my daughter\u0027s birthday sirs fantastic we had way more participants than we thought we would have actually we were extremely pleased by the number of participants there were 10 to 12 people local depending on the time there was more than 10 online apologize to the online we were using a WebEx version that did not work very well so a lot of time the WebEx was going up and down and I guess next time we\u0027re going to be better but the goals was essentially we had started working on the Charter at that time and we wanted to have the the feeling of the group to define the major groups the major goals that we want to achieve and again this focus on the research on how to use codes as a toolkit for as part of the toolkit for improving efficiency also look at common issues what are the big elephants in the room why aren\u0027t the coding solutions be more used or be more applied in the industry and in the research also and the challenges that we need to address if we want these things to go better so essentially it was a great outcome so we had a proposal for a new charter a new milestone that we spent to the list for approval and actually we had some discussion and add-ons and we can actually identify the number of activities and the first volunteers for "
  },
  {
    "startTime": "00:06:39",
    "text": "doing these activities which I think them are here so it was a very successful meeting and it made us think that we\u0027re going to redo that and by the way we felt that Boston was a good place to do it seems that there\u0027s quite a good proportion of researchers in the field that are in the Boston area so the milestone that we identified and are now uploaded we want to look at a document talking about the existing solutions again this is something that although this group has been chartered for quite a long time there\u0027s never been a document saying what is are these things and what are they used for and why would we want to look at them we were going to look again at this idea of network coding and quick-quick had had FEC from the beginning if we make it better there is a NCN satellite news case to look at an overview and the research challenges when using that we\u0027re going over sad like networks and we have Angeles here we have Nicholas Kuhn and we have Emmanuel who have all looked into these things we want to look at a some kind of a common coding API the reason for this is that you know that there are current their codes the codes that people are using the code that people may use they may be music new codes and what we want to be is future proof so that coding solutions that exist now to want to use them but something better happens later than we have actually some way however being able to change the code without changing the whole code again but in the sense of software code that supported some adoption challenges what is why isn\u0027t this not being used a big elephant in the room that has been there since the beginning of network coding and the IRT F is the that\u0027s where coding and congestion control there\u0027s been more emails and stuff on this that I can just think about and is there a way to finally get this behind us and actually this is also Michael well sir is not there heat now but this is something that could be done also in collaboration with the ice crg the ICN news case again we\u0027re going to have a draft on this this is something that has been going on for quite a while and we have also the people from the Xen orgy and we had talked about doing maybe common meetings at one point and there is the last one for the moment doesn\u0027t have a draft but there was this idea of having NC and robust tunneling and I can tell you that after attending the tax meeting yesterday they could be some reuse of some of the work that\u0027s been done in taps to do this Allisyn Mankin as the iron chef chair so i took the word use case out of all your milestones because I think it\u0027s important to not do a here\u0027s an exemplary thing but to do a "
  },
  {
    "startTime": "00:09:41",
    "text": "here\u0027s a hard problem that we solve for these people right and it might be that in the end you\u0027ll consolidate these documents because you\u0027ve solved some hard problems for multiple types of use so it\u0027s and it\u0027s quite important not to not to publish their little ephemeral use cases right because there are exemplary they don\u0027t actually necessarily last for very long and also I now have some fuel for this so we\u0027re going to work this in the whole IRS G they cost the the documents are quite expensive in the RFC editor so they really want us to use our RFC as well so so I see it all there and a night since I\u0027d taken them all out of all the milestones I thought I\u0027d take this moment to explain the kind of goal we\u0027re looking for which is solve a hard problem and then see what how they make it to the road yeah you don\u0027t have to say yeah right and then and then it may turn out that several of those things turn into you know one one document and I think all this is very explorable by your group especially since you\u0027re now having so much more energy so another something that has been an issue for quite a long time so as people come here and they are new in the group and actually have no clue what we\u0027re talking about so what is a network code yeah so we prepared a very brief tutorial on this topic just going through the ideas or main ideas and not into the details okay so so the other cat so this is an extract from the current taxonomy documents which explains what we are what we mean by so scoring network owning channel coding physical coding what we\u0027re talking about in this research group so it\u0027s quite usual but network coding is the thing in the middle on the top you are potentially source coding so schooling typically is well multi media encoding multimedia decoding all these so specific stuff which depends on the application of course and at the bottom at the bottom you of course those physical layer FEC codes that\u0027s one way to have network currying in this protocol stack the other way is putting this networking stuff bill within the communication layers so below UDP below IP below TCP depends on what who we want to address to us they\u0027ve always clue that but just to make it clear then "
  },
  {
    "startTime": "00:12:41",
    "text": "there are a few things we want to do and a few things we do not want to do more particularly we never will never consider a physical layer of physical layer codes bit error correction bit error detection all of this is physical layer specific and not and will not be addressed within this research group on the opposite we want to deal with packet losses so packet means many different things independently context it can be a UDP Datagram it can be a UDP Datagram payload it can be a unique IP Datagram itself TCP segment whatever you want an application message and so and so forth so it really depends on the context yeah just quick clarification is that just another way of saying you only do a ratio coding or a ratio yeah and so I\u0027m trying to figure if you got a packet yeah and the packet CRC is wrong yeah all right it removes that treated as an erasure or do you actually try to correct that packet we don\u0027t try to correct it so your terms the way I would say erasure codes okay we decided to keep it simple so we removed with a ratio and we use loss but there are okay fine yeah packet loss or packet erasure but you\u0027re right maybe we should also remind that erasure and loss is the same in our context yeah for this for the sake of this presentation we decided to limit it to like they most often used thank you okay so the vocabulary is a little bit more complex I don\u0027t want to make it complex so I skip the details so I want to speak about symbols for instance so next next slide is about coding basics very easily well you can have packets sauce packets repair packets and the typical way of doing that of doing encoding consists in computing a linear combination of for instance sauce packets in to repair packets so you in the first case the first prepare packet you just do the exhaust some of these sauce packets this is one way to do that another example just below consisting multiplying each sauce packet by a certain coefficient and Windex or some of all of these well it\u0027s pretty simple of course you can also and in some use cases you will also compute repair packets from auto repair packets that you have received is no way to do that and in this bottom example you can see that we multiply the first repair decade by coefficient 57 and second repair "
  },
  {
    "startTime": "00:15:43",
    "text": "packet by another coefficient you do the Sun exhaustion of the two results and we produce your additional repair packets that cancel it it\u0027s very basic it\u0027s not rocket science for sure you basically have two math mathematical operations XO you have two data trunks you want to show them and you have also this multiplication by o coefficients you multiply a certain data chunk by a coefficients over a certain finite field but there\u0027s nothing complex in this operation as well so that\u0027s almost what all you need to know in order to be able to understand at least the main FEC techniques used in this domain now we have two kinds basically roughly speaking where two kinds of FEC codes or network cards one of them being block codes Yas over being window based codes so block codes are traditional codes in some way you probably know some of them by name radicals rato Cukor\u0027s richlum encodes a little sister guess all those are block codes and here the idea is quite simple you have discontinuous packet rule and you do you segment discontinuous that I flew into blocks of a certain size most of the time of the same fixed size and you do efficient cunning of this of those Achatz in this block and produce one or more reaper packet for to protect this block and you continue like that so that\u0027s the basic lucien the one that has been addressed by the IMT and fig frame IDF working group for instance in the past and then you have this second approach which consists in considering a sliding and killing window we know that we slide over the set of sauce packets or repair packets depends on the example I\u0027m considering sauce packets only you have this and coming window that slides over this sauce packet continue sauce packets and whenever you need to reduce one or more repair packets it\u0027s pretty simple you consider all the packets in the end coming window you computer linear combination you produce one you produce one we package if you want more than you consider another combination linear combination and you produce additional repair kits as many as you want all of them from this for the currents and cutting window that\u0027s pretty simple no like a typical example raw well the well-known iron see cut well when she cuts the ones that I\u0027m working on in the context of TS vwg I will come back on this later on Falcone but there are additional examples but those are examples of gods that typically work in this manner then there are additional names for those window based codes so "
  },
  {
    "startTime": "00:18:45",
    "text": "it\u0027s more as the same sliding window cuts is morrison animals in the case where this lining window is not a fixed size but can evolve over the time depending on for instance feedback that may be from the destination this is not shown not always the case but if you have something back you can adjust this window size and in that case you will talk about an elastic window size code on the fly codes are more assessing so main benefits compared to block codes is first of all it\u0027s much more flexible and then it\u0027s also very benefit in terms of reduced latency so when you have very time constraints flows real time flows then it makes sense to use this kind of of course next and that\u0027s more or less all I wanted to say for this toriel introduction part we have this taxonomy document that explains or defines additional terms and single for encoding multiflo encoding all those are defined in these documents you can have a look at it if you if you need we can also talk after the meeting no problem thanks so now I have two additional slides to give you a gross panorama of what has been discussed presented in the past within this research group so the first slide is about the Kurds themselves so we talked a lot on about RL and C which is the old story cold cuts for this this use case for networking yeah I forgot to mention that so random linear network codes so the equations are produced from Tom Lee in that case and they also transmitted within the packets itself in order to be able to do what I mentioned after in order to be able to do Rhian coding within the network so that\u0027s more or less than that ready to do that i simplified a little bit but there is no specification for the moments for those curves ohms this is probably something that is missing next is the network cuts from home network cuts was proposed and introduced by Stein wolf fuel ITF meetings ago at Hawaii yes so you had the slide in this URL bats was also introduced and proposed some time ago it was in London for another correctly by professor Raymond young so you also other slides can refer to that there is no specification for those codes and you have this work-in-progress about our LC codes from Dom linear codes it\u0027s in fact more less the same name but it\u0027s different the main difference with respect to iron C is the fact that there are only four end-to-end communications so you do not carry the current coefficient for instance within the packet itself just Korea 95 acid for PNG "
  },
  {
    "startTime": "00:21:49",
    "text": "it\u0027s working progress and while he\u0027s progressing when in fact looking so next slide this one is about the protocols so the code stem cells are not sufficient you need to have a full solution that is to say you have to specify also the mechanisms that will be used to make all of this work together so basically you have three proposals that have been discussed in the past the first one being Tetris from Israel there is no specification there is this internet draft that is now expired but maybe oh I hope they could be resubmitted updated it\u0027s up to you okay so most probably it will be updated soon then we have this Dragon cast cedric at the end of this meeting will say a few words about it\u0027s another way to do to apply network coding and this this time with Riaan coding within the network so seroquel talk about it with a specific use case and there is a also an expired internet draft that describes what it is and finally there is this fixed frame extension so fixed frame is already specified and standardised she\u0027s IFC 6363 it was four or five years ago now the idea is to extend it in order to be able to use sliding window cuts it was restricted to block codes so we extended it for slanging window cuts the specification is more or less ready for working group last call so it will soon be move forward next I think this is all I need to I wanted to say just to conclude well there are many research outcomes in the domains in the field very interesting outcomes here in this group it\u0027s time to work to transition to application and protocol research and this is the the main goal of this group and of course doing that in collaboration with a close collaboration to other research group or IGF groups whenever it\u0027s it makes sense so we\u0027ll see examples today afternoon of collaborations that\u0027s all questions comments no okay so I will continue with so second presentation for this generic API now so the idea is to have you so this is joint work with many people with unit on that shot for mr. Shapiro with a civic IG from INRIA as well as me just like me but we are not in the same team with Yan sweat from girl and with modern medicine from the sign off this is working "
  },
  {
    "startTime": "00:24:51",
    "text": "progress so the idea of this work is to specify a common API for the coding part and only the coding part so this is this bottom right box so typically this code is this generic API will make it possible to interact with the codec itself by doing session management initialization in visualization shutdown office colleague instance for instance you will also be able to interact with the correct in order to specify and manage the encoding and decoding windows in order to specify and manage the coding coefficients so it depends on what code you are considering sometimes the kurds are generated by the correct itself sometimes they\u0027re generated by the application top of the correct so that several ways to do that you also typically have functions to do efficient cooling and functions to do recurring by submitting new repair packets or new sauce packets that you may receive from the network so that\u0027s basically the the goal of this API and this is I will insist really low level API for low level component of a much larger software so not in this API are all those functions that are typically on the protocol side so congestion control memory management transmission reception packets either creation and processing all those are things that will be managed outside of this codec so they are not in the API so we are talking about the generic API so why is it generic what is generating this API well we want to have something that can be useful with many different codes from not just one code not just specific to one code but generic with and usable with different codes we also want to be able well initially I had in mind being able to have a an API that is common to block codes and sliding-window codes it turns out that it would make the API bit awkward so I think it\u0027s preferable to remove this block code support and only focus on sliding window codes but still this is something we can discuss if you have no beyond this we can talk about it then yes makes no sense in this context we want to be able to produce as many repair packets and manage has many repair targets as we want so this is what we mean by red lace we have this feature typically we also want to be and this is very important with both codes that can do Rhian coding within the network or codes that are limited to end-to-end coding and it makes a few differences in the API we have to to "
  },
  {
    "startTime": "00:27:52",
    "text": "manage this the goal is to is to simplify a product development on one side and also simplified protocol and application development and the other side by having this already standardized and specified API so it makes correct development simpler because typically designing an API you can believe me is something complex it\u0027s not obvious at first so that\u0027s one pot and of course if you have this community if you want to test new another type of codec then it\u0027s it will make things much simpler from a software development point of view so that\u0027s very important so we also want to is benchmarking facilitate benchmarking you can fast is mostly swap between several codecs and test which one is the best appropriate is most appropriate for your use case with this API you want we also want to simplify the development of future open source correct I will talk about it at the end of this presentation also because it\u0027s visible which is also a good reason to do that so the internet draft yes question they this may be a little too detailed here but because I did some work in this area I\u0027m just curious are your thoughts are um what if the core of the codec is in an FPGA and that and you need the data to stay in the gates of the fpga for example because the next thing you\u0027re going to do is is crip crypto okay good question this is typically something we\u0027ll have to discuss but outside this because I know any experience may be getting the actual Bears in and out across the API and you may not want to do that now that\u0027s a good point that\u0027s a good point but I have no experience so we we can discuss this if you have an idea of the requirements and specificities for this use case and I would be interesting a good point okay so for the moment if you look at the internet drug there will be you will see that there are two API specified well just released well we just leased the function we didn\u0027t try to do anything more intelligent eyes of third one that is available at this URL from citric and of course we expect something else from Norton and I don\u0027t know for young but you we will talk about it later and the next step typically is to identify what is common identifier which is different but work on this in order to find the best solution I would say for this January campaign so that will be next step and finally and finally yes I mentioned the idea of "
  },
  {
    "startTime": "00:30:54",
    "text": "adding and developing a new point source and the free reference codec so once we have the API we can continue with this codec this is this will be next step while typically in C C++ we\u0027ll see for the FPGA that\u0027s a good point we are looking for candidates codec that may exist we know that Cedric as one proposal this garden net project which provides already the functionalities that we are looking for it is more a little bit specific to embedded platforms but it can be as well a good a good starting point for this development so if you know if you are aware of correct open source codecs that may be the basis for this work then do not hesitate to tell us and that\u0027s my last slide yes Ian - at Google it is suggested that our next steps possibly it would be certainly very useful to actually try using multiple of these in a in a certain environment I mean given that you have three already that appear to have the same API actually try them in an in a real-world use case and make sure that the the API is like not overly cumbersome to use before you you know implement not I\u0027ve attended that I mean obviously Nestle what that is but I mean that definitely it\u0027s always good to make sure your API is like you use and there was a major problem with them and this is a totally different area but like the TFO api and linux turned out to be like stupidly difficult to use in v1 and it caused a lot of people not to use it for like five years until they fixed it and then the Apple folks like did the right thing yeah the experiment yeah we typically need experimental developers to do this watch but if I mention those free api sheets it is because behind them that is actually running code and we have we all have some experience we know that some features are maybe could be improved within those API so we want to benefit from this expense this common experience in order to make something that is useful and efficient yeah one further suggestion having tried to benchmark things like this is that it\u0027d be really good to have a null codec so you can measure separately the effects and the inefficiencies of the API compared with the effects in the inefficiencies of the codec itself yeah sure sure typically memory management is always an important aspect from a performance point of views if you can avoid cookies it\u0027s much better more question no okay thank you "
  },
  {
    "startTime": "00:34:07",
    "text": "hello everyone so I would prevent an update on the drafts on network coding and satellite I don\u0027t know if everyone is aware of the goal and the scope of this draft but I think that with what Ranson said we have good insight basically we want we have lots of we have had lots of activities in networking in satellite over the past lots of research activities going on and the main idea is to try to identify what is actually deployed at the moment and if there are any interest for research different different research axes to further make research on that but also having in mind that we have to make that into products to mobile so basically you notify challenges where we can actually have marketing when it makes sense that we deploy these techniques and what are the challenges in deploying them so as opposed to what we had in the first draft we have improved representation of the notation and what we can have at the generic satellite multi gateway satellite network because I mean problem in the satellite industry that we don\u0027t have reference architecture for mutti gateway systems like you may have in buy provided like like may be provided by the 3gpp or broadband forum or this kind of thing so there are some standards but it\u0027s not enough to make things on Tara payable so we just here propose some notations because sometimes the words we would use in the following at the draft may not be clear for everyone and for the moment we have just gathered some of the key words we are using and but depending on then how the use cases and the needs of the description in the use cases we will describe use cases and then depending on what we actually need in the description we will remove and update also that is some note for myself and for you is that radically one of the main use cases we want to focus on is when we have mobile user when the channel capacity is highly varying and in these cases is very difficult for physical area codes actually cut from the AOS and in this case if we think that is very important to deploy it from networking schemes in actual deployment systems to better match this document with what is done in the working group we have tried to take the taxonomy draft and make some kind of matrix because basically what van stomm presented earlier was two different layers at which the network coding can be applied either physical packet Network false coding and then the different way of doing it either end-to-end network coding or inter flow into a flow single path multiple paths to better see to try to make for each example of what is deployed today to see if there are any gaps and opportunities for more network coding and that is that table would be further fulfilled by the "
  },
  {
    "startTime": "00:37:08",
    "text": "use cases so idea is to see if we can actually use the taxonomy to to be the base for our organization of our use cases and you notification of the need for further use case so for example here the problem is that maybe it\u0027s because I didn\u0027t understand that correctly when we have for example video streaming like YouTube was quick we have some I thought it was resource notes but now I understand that the source node is actually the video encoding the thing not the transport layer but in quickly somehow mixed at the moment but but if it\u0027s more basically we have seeing that are done end to end per flow and single path and what is done at the moment in satellite industry is to introduce coding as a physical layer so this is what we have the quickest physical by your friends and for which we have we have only coding and the physical layer and what with there are probably from points that are missing here so the idea is to if anyone know think that we are meeting please tell us but we think that there\u0027s nothing much on the multipath the network coding in the interflow coding at the moment and not much at the packet and UDP level in either so that is such ill astray to opportunities and next please and what is day to stop me if the time think basically for the moment we have for research axes so we have proposed them if anyone wants to collaborate on that we are open to discussions and share the work on describing these use cases this is what some of them we are more believed in for the moment we just list it to see if there is interest for other people we have our own preference which I will hide at the moment but basically we have that is something that has been demonstrated all the way already the true way with a channel when we have two terminals satellite terminals wanting to speak to each other we have hey wanted to speak with B and the fat light gateway would make saw with a and B and so we only have to send one one packet one flow to the two terminals so we say satellite bandwidth the other use case is that one of the main one of big conventions issue we have in the satellite industry at the moment is the conversions between the broadcast and the bought born networks which are totally separate at the moment and with all bond networks we can provide medical services and satellite has huge potential in using more because of its coverage and but the main problem is how you make actually something reliable and we think that with natural coding we can actually implement some more reliable multicast services another one is there\u0027s been lots of work on the FEC in the for the random access links where basically users don\u0027t have to ask for capacity wait for that capacity to actually send packets they can actually "
  },
  {
    "startTime": "00:40:08",
    "text": "send back it directly this is fashion at the moment with all these IOT deployment and the problem is the thing is this is actually improved but we see there\u0027s still more room for research because at the moment system actually do one or the other we don\u0027t know I mean we are not aware of this I\u0027m doing actually both of them like while we could imagine very interesting things that could be deployed because sometimes the free capacity and that could be used by sending redundancy packets on this free capacity and another one but I didn\u0027t know you would speak about bad but that\u0027s not the same bats this bats is fp7 project where basically the idea was to try to breed the different technologies for example today you\u0027d upset when you deploy when it deploys the satellite service it may use 45 kilo forties 56 kilobytes link you have to send some acknowledgment on some things on the link and for you you don\u0027t have a busy directional access on the satellite link but you actually use satellites on network so they\u0027d hear an opportunity to use network coding to actually better to add some more reliability on the service and this is more following up on that because they have done some load sharing schemes more cloud close to what has been - - is different to what is done by MP TCP but it\u0027s close and next slide please what we need to do next we need to provide some more details on the SATCOM system and also i think they something that we hadn\u0027t mentioned and we want to add is to insist on when we will have huge variations in the satellite capacity because when you because some of the use cases we have at the moment are the the plains for example or all the trends of the satellite constellations for which they are used by ability and feeling we have my users so that\u0027s what we want to work on to further detail the architecture to better clarify these use cases afterwards we think that we still need some work to better match what is done in the taxonomy draft and how we use this taxonomy draft in in the description of our use cases there\u0027s still more use cases may be wherever maybe the some that are actually interesting we really want to focus on making it happen in the networks we don\u0027t want to make just axes of research that to do many things because there\u0027s already been lots of activity on that topic so we want to to be sure about what can be deployed and speaking about deployment within the link with what\u0027s happening in the network function virtualization working group because the trends at the moment is that we have all these crude round activities where we have data centers hosting virtualized function this is some trends we see and we believe that this is the usual portunity for deployment of network "
  },
  {
    "startTime": "00:43:08",
    "text": "coding schemes on both I mean we\u0027re told Caminos and data centers this is still forecast but that is something we want to look at and and for that around actually at the moment how it will happen but we think there\u0027s lots of things and it but we think I think we need to further work on this document and then feel their energy possible with the ICN document and with what is happening in the network functionality group and then we have to see what we remove first we add use cases and then depending on what is relevant we may add or remove things this is it okay I have a question manish oza more pussy I think I could I told you I could help on the state of the art and also I think what would be interesting in your if your graph if you would define what you think is that the limits of the satellite network where does it start does it start at the satellite gateway to the other side like Gateway does it start in the networks that are connected to them because in my experience there\u0027s different type of losses that are experienced by packets obviously the satellite link itself is usually ultra optimized so there\u0027s very little losses there but your bosses that happen somewhere else and I think figuring out the scope of your network is would be really really important so that we know exactly what where you put the coding and what type of code I think I think that\u0027s very important because for the moment we have tried to start a description of what is because nowadays for broadband access we have multiple gateways in the network and the problem basically we try to match with what the broadband forum is doing in terms of architecture where basically will have a PNG and then access more access related parts in the Gateway so we don\u0027t have one access gateway that satellite and Jen door to the Internet we have some network and independent then depending on what Internet manufacturer getaway manufacturers are doing and loss may happen in the gateway or and also we want to describe that and that\u0027s why we want we we want to detail the mobility use case because we think that this is the cases where we will have physical layer losses because the physical layer codes will not be able to come from these huge valuations because if we have fixed broadband network there\u0027s more loss on Wi-Fi than on satellites question between what you are doing here and NFV or G it is just that we think that the problem depending on the use case and where we put the coding do we want to put that in the part of the Gateway that it\u0027s actually "
  },
  {
    "startTime": "00:46:08",
    "text": "managing the QoS and the IP packets or formatting the physical layer packets medically we have different parts on which we can apply network coding and depending on the architecture we can we have lots of functions in these two components and we want to we are currently working on how we can actually visualize these components and then how we think that just that the network what is doing in what is it\u0027s both basically network coding if the use case for the NFV and and if so al is some of those components exactly we want these functions to be virtualized to Eve the deployment scenes in our networks so if all the Roman search can I have your name please Simon Romano University on Napoli first of all thank you for this document because I think this is something that is really needed because as far as I know there are a number of current projects that are working on this and trying to find a taxonomy and putting the use cases together is a very welcomed effort I also think that one son who is sitting here knows about the NFB effort because I think a look at the draft we are covering a draft together with Professor angle s baskets Castro here which is exactly about what he was saying so trying to associate the network coding function with the standard network function virtualization architectures and just to complete as a further comment I\u0027m personally leading a European Space Agency project that is about the use of network coding for content delivery networks in hybrid scenarios involving satellite and terrestrial trunks and in that case we are also I think the nice thing is that you are also trying to sell the network coding part as a means for improving security of the communication which is perhaps said a nice face it to look at so in case you want to share some information I would be really glad to do that I think thank you I\u0027ve now got two perhaps and yeah I think we can also involve the other produce just for the for the police I\u0027m very interested because we could we were lots of caching as well and I think it\u0027s part of the architecture and where you put your data but for the link for the Navy our point is not to explain how you get your eyes donate for the function because I think it\u0027s more with copper than every working group but here is just that we we want to focus on how we can actually deploy that in satellite networks today exactly eternity that may be just a pointer in the document totally agree that we want varying force yeah to speak about our project is about a test but so we\u0027re implementing that this is a nice thing to do so it\u0027s really deploying the thing and it\u0027s tough thank you very quickly they invoke the Norwich are you aware of the delayed disruptive network working group yes "
  },
  {
    "startTime": "00:49:10",
    "text": "because you know some of especially this work that you\u0027re doing it would be very applicable for them we we are working with them but on other because of these or the history call because of the CSDs validation so we have a lot of interaction with them for other issue that DTN network is where you could actually apply a net recording to actually improve the reliability and because they are right now working on some of the data models you know to define for it you know essentially to define the communication I had a meeting with them today and if you\u0027re trying to define the api\u0027s for the encoding while their work on the data model assume you might you know then have input how they will define it and you know take this into the account we thank you thank you I saw myself wrong when ITT I made the same presentation in icy energy walking group meeting for thanks for chairs so I\u0027d like to introduce the calling for I she she she Anna and na I didn\u0027t and at the end of the use case for Network coding for Shion so we imitated just we need eighty to making a draft so let me introduce a context and a content of this draft briefly okay so you know a little coding has been attractive attractive and research topic so there are several interesting papers already present it and so so actually our last last I I am eating the truth presentation-wise introduced overview of network only for Sheehan and it includes a context content of the infocomm paper and also present its network calling for Sheehan a use case for providing the for role entity streaming and so we thought we we think we need to clarify and specify the requirements and the potential item position will be such item for for this topic and they agree on that so we initiate to making this draft so actually I say now documents describes our network holding related to stuff but it is just simply it\u0027s a benefit so the purpose of this draft is to provide a sufficient information and "
  },
  {
    "startTime": "00:52:10",
    "text": "qualifications requirement and challenges in order to establish common under studying this topic and probably useful insight to develop but we want to apply a network coding in decision so here\u0027s a proposal structure with this table now so we introduce a current research out out out currently such outcomes otherwise the Oh Bobby and or the over B over the coding and decision architecture and the we idea we specify the ultimate scope this torta is not is not to provider from the specific solution but maybe we want to provide a rough solution okay so after defining of the definition of the post she she an and network holding terminology we briefly introduce GG background and we do really describe given by network coding and she she landed in it and then in the fiction fall will consider how network coding can be applied in decision engine and its requirement and after clarifying the requirement we we want to provide the research challenge and potential research item to to make makes the communication better by using an equal coding technology are the world\u0027s oxygen and in an architecture program and the protocol so so you know net recording bring some benefits such as a throughput soup the under capacity improvement and the robust robust not enhancement so so these benefits are not radically different from the session and energy and benefit so accordingly just focusing on just focusing on what what data to be encoded rather than its data property such as where it is generated so it\u0027s very in line with she she she she met core networking Reyes so both they are very compatible and so it\u0027s natural to combine them to enhance keep a hormone system and promote promote promote a case full city and so yes and this trust we we want to consider how net recording can be apprised sittina and the energy and network architecture and then we want to qualify the researcher energy to enhance to further enhance she can and any gain with benefits so here are so let me let me get into the naming new request naming requirement so we have a two type surname one is a coded data has a unique "
  },
  {
    "startTime": "00:55:11",
    "text": "name or code you data ways quality coded data does it have a unigram so in the case of the coded data has a unique name called that account which could could could have a unique name by adding some information some coding information some coding information such as a encoding vector and generational ID like this and in this case consumer need to know the exact renaming structure to deliver it by using a specific name resolution system and in this case also or instead of content producer content to request determines encoding vector it means that the just indicated how how to create a colles packet so other case indicates that the coded that has no has no unique name in this case our coded data that the name of code editor has doesn\u0027t have a coding information in this in the name so this data may specify the coding information into a meta filter and the payload or under in the inglis pondok to the interest without either without a unique name for coded data in this case note you need a period according for generating and the providing innovation calling packets so I didn\u0027t want to bring this up in the IC energy meeting but it\u0027s it\u0027s relevant here because specific decoding the third bullet the reason the content requester determines the encoding vector to be used oh yes it isn\u0027t that kind of a separate design decision too because you could statically decide what the coding vector to be used is by the producer right and then and and then you only have one possible you know coding vector for all the possible consumers the trade-off however is that if it\u0027s the content requester that determines the coding vector it says the coded packets can\u0027t be produced ahead of time you have to wait until the interest message arrives from the consumer to for the producer to actually generate the correct coded packet so there\u0027s some there\u0027s some latency and delay implications to having the the consumer do that I would yeah I would maybe look at that as a separate two separate design answer in the in the design space because you could do it either way oh okay if we need we need to support it you mean in the case of the producer and "
  },
  {
    "startTime": "00:58:12",
    "text": "the another case is the encoding is it right so concerning transport requirement we need to we need to we need to discuss net recording scope it means that it should be discussed no no nodes can update data packets that are being received in transit so because of you know she she and the engineer has a mechanism to to verify the data integrity so in this case we encoding we do require some integration mechanism or another another case another execute network coding only when the receiver the interest for the colleague data can be satisfied it\u0027s like end-to-end Amana in this case it would require making it to ensure food exactly execute execute and net recording and we will we also clarifies the basic operation at consumer water and the opening publisher considering the how how nodes can provide innovative data packets especially especially in the case that called it that does have a unique name in this case consumer who do need issue issues interest with with some coding information for getting exactly innovative innovative datapack coded packet and Luther would need maintain maintain theory of interest for spec and generation and oh and uh and the aggregation should be avoided for getting a forgetting a multiple call these data packets okay so so in addition to important naming and the transport requirement we describe requirements regarding in neutral caching and security and policy and routing and following and how to single seamless mobility and it\u0027s their requirements so as I mentioned that network coding definitely impacts shishi and energy and security mechanisms so I think we we need to we need to clarify which aspects in more detail in the future so under after clarifying the requirements are we we qualify the Z challenge and in my opinion I am very interested in designing how we can reach an adopting triangles reading elastic "
  },
  {
    "startTime": "01:01:14",
    "text": "encoding window into sushi Anna because so the current research paper adopts just only Brooke Brooke Corning mana so it\u0027s very interesting topic so that\u0027s why I\u0027m now I\u0027m trying to design and implement and paint and the operational disturbing so I think the next next step is to improve the distort from this effect and we we are going to clarify the requirements and potential charrids in more detail the Givens thank you so can you when it seemed like it might be that you\u0027ll develop a draft here the draft in icy NRG that covers the two kind of interlocking parts of this because that would allow I mean I was think about the web RTC RTC web case but doesn\u0027t have to be quite as complex as that no I mean it certainly have to be complex but I think that getting the right getting enough people to look at both things meet and discuss both things may require splitting the content a little bit I just throw that out there I have to unfortunately leave for another RFC it a related thing so yes exactly actual implementation yeah absolutely they\u0027re meant to be they\u0027re meant to be to two halves of the same thing I just think it would be convenient to identify which things go in which and also yes yes so it\u0027s you have all the chairs here but I invite that discussion by I see NRG co-chair hat on which is I think the longer we can wait to split this up the better because we need cross fertilization in the community so the ICN folks need to learn more about coding and the coding people need to learn a little more about ICN and at some point when we go to sort of like move things you know really forward it may be necessary to to split it up so we get the appropriate reviews from you know the experts in the individual communities but for now for now I think it\u0027s it you know it\u0027s it\u0027s going to foster a lot of collaboration to to try not not split it up until we have to yeah so my name is Ian I\u0027m one of the "
  },
  {
    "startTime": "01:04:35",
    "text": "quick editors I\u0027m going to be talking about a border correction or no we\u0027re coding in quick and coming some so last time I talked a little bit about some previous experiments and a little bit of data we had this time it\u0027s more gonna be forward-looking and saying like what what might be experiments that are worth trying now and what you know what approaches architectural II might make sense and quick so for next slide here\u0027s an intro into the quick header in case some of you are not that familiar the quick header is pretty small but it does include a single byte to indicate what type of packet is a eight byte connection ID and one or two board for one two or four byte packet number and the packet numbers are actually truncated so really the packet numbers are technically 64-bit packet numbers in terms of space or 62 bit now I guess to do it like work but uh next slide oh and backward backwards weren\u0027t actually sorry and the rest of the payload is encrypted that\u0027s all you really need to know so from the network\u0027s perspective it\u0027s completely opaque f-fine so wife order it correction in quick numbers number one is we can unlike TCP certainly real-time communications tunnels may be multicast someday as I mentioned at a previous talk you know they\u0027re still interest in a more efficient tell us probe because that\u0027s kind of a proactive loss recovery scheme where you don\u0027t necessarily have much information and just have to send something and you\u0027re pretty much always wrong when you send something random that sounds dimming so next slide some quick features that may kind of make this mapping a little bit easier and a little bit more tractable from an implementation perspective at least I hope one is a quick monotonically increasing packet number that increases by one every time I guess I\u0027m hoping that somehow we can utilize this in how we map the coding and describe like which packets are protected by the decoding multiple flows can share the same 5-tuple if they need to or you can potentially brow it like over different 5/2 poles but back to the same host using connection ID so there are a variety of ways basically just a take like two flows and potentially one of them could be a forward error correction flow and one of them could be at the actual base flow as another example and put them together and quick provides multiple extremes which do not head of line blocking streams so a single stream is kind of an inorder sequence of bytes but we can have up to to the 62 individual stream so there\u0027s not a practical limit on the number of streams and so option number one is to put FEC kind of outside the crypto I guess the way I\u0027m thinking about this option is essentially is like a separate flow probably and it goes alongside and possibly you know the packet number of "
  },
  {
    "startTime": "01:07:35",
    "text": "the for Direction correction scheme lines up sort of with the original flow and then so there\u0027s some metadata inside to try to figure out like how to decode but this would be somewhat visible from the network\u0027s perspective I mean you would actually like presumably for better and for worse you know the network could you know potentially decode the without having any knowledge of the the quick crypto right so like there would be no cryptographic knowledge as I said you can use packet numbers another probe potentially is the this order goes on the side so the standard quick packetization process would not be modified so like in some sense this is like a bolt-on approach opposed to actually like getting inside the core quick packetization code yeah a con is it is visible in the network so I mean if you care that could may or may not be a major issue if you if you aren\u0027t doing this end-to-end obviously you would need like you know some middle boxes for lack of a better word to like terminate it in the middle in some environments that may be very compelling particularly since quick does not um it\u0027s not practical to terminate quick at a performance enhancing proxy so you know there might be cases where instead of running a performance enhancing proxy in a network your performance enhancing proxy for quic is you know one of these like FEC tunnels essentially or FEC side ones so I mean there are kid I think there are use cases it\u0027s it\u0027s practical it is fairly difficult to integrate into quicks congestion control in some cases it may be actually impossible which is kind of unfortunate from intellectually like we\u0027d really like to consider all the bytes that were sending as part of the congestion control from bed with estimation perspective and like loss detection and all these things this is a completely separate yeah next slide the next option is to do forward error correction within the encrypted payload so a pro is that there\u0027s no visibility into it another Pro I should have put is that essentially you can negotiate this you know as a you know you know laterally so you can say it like I have this new quick option that like you might know about and the other side says I know about that too and you know you can negotiate say a new frame so you know you could experiment with this but I would actually minting a whole new version of quick there\u0027s some CPU cost on the con side to coding as well as doing encryption because you\u0027d be doing the coding inside the encryption and it consumes an extra byte of payload because you actually have to burn a quick frame type inside the the palin yeah one-word question multipath yes what about it it would seem that there\u0027s delicate intertwining with how you add FEC and how you do multipath given the attention to multipath today eventually sorry given what given the quick doesn\u0027t do multipath oh that\u0027s certainly true I mean I think multipath and forward error "
  },
  {
    "startTime": "01:10:37",
    "text": "correction both this point kind of fall in the category of things that people are starting to experiment with and understand best like how to deploy for a post v1 world okay so my sense is the value of this kind of coding is enhanced significantly in a multipath environment and sort of trying to put FEC in and then redesign it all over again if well if it\u0027s done before multipath is put in might lead to either an undesirable situation or complexities that I wouldn\u0027t want to consider I just yeah I think we need to think about multipath at the same time we\u0027re thinking about coding this kind of coding okay thanks Space Agency projects doing Network coding and I fully agree with what he says and in the other draft we are dealing with Network coding neutralization we take Network coding as a network function you know then you have to think in advance about all day like all the purple all the objectives you want in advance so it\u0027s per floor multi flow per path multi path so this is to define a network function before the coding just for some one specific protocol so this is what we are doing just shirk Harriet I just want an Akula screen speaking I just wanted to point out the fact that indeed there is an interaction between the FEC in the congestion control and this is an open question that we mentioned before but I think that the link between quick and FEC and the impact on the causation control in totally different from the considerations of multipath for which the in quick multipath let\u0027s say you will have all these couple codes can control these issues which are not the same scope so it hasn\u0027t impacted the congestion control but not the same level in my opinion so I think yeah so [Music] the same moment when you speak about what impact on collision controlling quick in my opinion in zones the same level because the constraints and the problem you are trying to deal with are not the same so I think I think we\u0027re agreeing but let me check once if you do multipath it makes large changes to the way quick does congestion control independent of whether you\u0027re going to do coding as well is that what you\u0027re saying yeah I agree entirely with that yes if you\u0027re going to do multipath you need multipath the congestion control yes I would agree but you but you can do fake with quick and it has an impact on the congestion control but you may not have you can have a quick v1 with that I do not need to do that need to consider "
  },
  {
    "startTime": "01:13:37",
    "text": "the v2 as one that\u0027s also true I think the point I was making is if you look at previous protocol integrations of coding they provide modest improvements in the single path environment but dramatically better improvements in a multipath environment so from a you know barrier to adoption and how people will view the value of this kind of work right I think people will view the value much higher to bother to do all this work if it\u0027s done multipath so I think we\u0027re basically agree I actually have a follow up on that is do you have any like references to literature of kind of considerations that they they went through and and other things that might be relevant because you know obviously since we haven\u0027t done quick multi path yet and you know we\u0027re just starting to talk about this it might be a good time just to have the those concepts in the back of my mind if it folks would be willing to share I mean it you can email me later if you want as well several works on the PCP type so you can see the differences of applying the network all in per flow TCP or multipath TCP and so they the constraints and the trade-offs are different so if you know that you should consider that thing advances so yeah I still agree with him you know so there is this pre work on multiple TCP that can give you they you\u0027re talking about yeah no it\u0027d be interesting to read it thanks neck side another option that\u0027s yeah yeah yeah I can oh how did you I\u0027ll blow through the rest I\u0027ll go through the rest and then whatever remaining time we have for questions believes four questions a third option that\u0027s been suggested is to actually create one or more streams that are forward error correction themselves and have those protect other streams so this may work well for existing applications I know some existing applications actually have mappings that are sort of of this form that already exist you can implement this without any transport changes whatsoever which is extremely nice actually people even talked about implement this in JavaScript which seems a little bit crazy but it possibly is plausible cons is it\u0027s it\u0027s fairly application specific and it may end up increasing the overhead versus kind of on a packet layer just because you\u0027re doing it out on a stream layer and yeah there\u0027s no like benefit to things like packet number sequencing because you\u0027re now dealing with like many streams each of which that have their own like byte space so next slide my opinion on this so far is that option two seems like the most promising and the most straightforward thing to experiment with it\u0027s not clear it\u0027s ideal for all circumstances but it seems fairly flexible and you know it\u0027s relatively "
  },
  {
    "startTime": "01:16:38",
    "text": "easy to negotiate a new frame type it should work well with a variety of codes Kryptos cheap so that negative is really not very interesting and you know from the network\u0027s perspective it looks like exactly like any other quick flow which has a nice benefit from making sure that like middle boxes don\u0027t do terrible things to you so next slide I was kind of like thought through some of the considerations of how this would interact with you know something like an API one of the critical things that we encountered before when we did XOR is that you know there\u0027s always some amount of overhead from the forward direction and from the code not just from the code itself but also from kind of the interaction with the transport and how you do the reconstruction so it\u0027s key to know how much that is so quick and kind of leave that amount amount of extra quick does not fragment it\u0027s UDP packets so if it needs to leave 24 bytes and needs to leave 24 bytes that you can\u0027t just increase you know the coded packets by 24 bytes and have them all dropped on the floor so it\u0027s a practical consideration that definitely needs to be exposed obviously we need to know if it\u0027s you know the coding rate is dynamic can I change it you know this is curry bytes this is more of a non sliding-window case number three is probably not that relevant but we might be able to change the code and great you know the link lender link and their runtime obviously want to you know it to add data to be protected and request coded by its B Center or you know produced for transmission pretty basic stuff the challenges and questions are probably more interesting the first one is the one I sort of went over which is what do you do about the fact that the coding actually adds overhead and you need to make sure you actually like don\u0027t go over your MTU size and have all of your coded packets dropped another one is you need to ensure that the gener the code will actually protect them sing back as you\u0027re trying to protect so for example if you were to use this for at a loss probe and two packets turned out to be lost ideally you would want to generate another coded packet and then you could you know recover both of them but if for some reason it wasn\u0027t a sliding window code and you know the window like ended then that wouldn\u0027t work and so there would be no point in trying to generate more coded packets it would just be trash so there needs to be some interaction with the loss recovery and the congestion control to say like you know if I generate more code is this actually going to do anything um definitely an interesting point and oh yeah I guess the last you oh yes and the other question is like does the API need to understand packet numbers or is there a quick specific shim or like can we use FEC frame or like kind of how how is this actually like what\u0027s the glue with the transport so like given we have a Ford error correction API you know what there\u0027s got to be some kind of shim here of how we\u0027re gonna map this on and everything so I added one slide about implementations there are now I think "
  },
  {
    "startTime": "01:19:38",
    "text": "something at least five open implementations and probably ten total implementations of quick that largely interoperate with each other with TLS one three so if folks ever want to play around with an implementation they\u0027re certainly welcome to try chromium but honestly some of the other ones are a little bit easier to get up to speed with particularly the go implementations tend to be pretty easy to look at if you\u0027re familiar with go so you know I would encourage you to play around to things if you have any interest in this space yeah and I did send out a new slides with the link to the implementations but it\u0027s also on the go sorry in the quick so my name is emmanuel Lucia I\u0027m working at Israel France you need to lose University so my toe two days is about the joint use of TCP TCP and the network coding layer so next so basically you already presented some part of his work so I I could go a bit faster or so basically what said Vincent at the beginning of this talk is to say that when we are using a network coding layer we can use it at different level of Duty architecture so for instance above UDP below UDP whatever below IP this is not a problem however when you use it with TCP you have no choice you have to be below TCP and in the meantime you have to do a kind of costly or with it otherwise you have to replace the again again again replace the network coding layer question so on the pendant parts that you mentioned a section IPR disclosure yes okay yeah so you can surprise the replace the transport layer by a network coating layer TCP and obviously there is next there is no point to put it above the TCP because there is no point to put it above TCP next so basically there are already a solution to replace the transport coded layer transport protocol layer TCP which is coded TCP and the main problem of this implementation is that first there is one implementation that can be used for instance Linux system if I well remember well but there is no implementation for all vendors so you are quite limited and you have to "
  },
  {
    "startTime": "01:22:39",
    "text": "use a proxy like system or something like that to be able to implement such solution so next the ID it\u0027s simply to use the ecn signal and they sing signal is congruently used with the NC code a layer network adding layer and is going to signal to TCP that for instance some packet has been mask by the networking layer but revealed and to give the information to TCP that there are some loss packet in the network and you have to react to an on it okay otherwise all the losses are mask and TCP way will never get out from the slow start and you can have some problems because you began to be opportunistic and there is no no point to using this protocol anymore the main advantage is that you seen is implemented in any kind of Oasis and they all follows the AGC any error see I\u0027ve checked the main difference is that between them is only on Windows you have to activate it by and it\u0027s not activated by default next so if I represent how this principle is applied simply if I consider a network adding layer a bureau IP layer and you week you you want to treat strictly bill I behave like TCP simply each time you get a decoded packet and this packet has been is a rebuild lost packet you just have to mark the IP CN bit and transmit it to the upper layer next but for instance if you want don\u0027t want to be as bad as TCP over a random losses in that case you can do whatever you want if I can say you can apply a loss discrimination algorithm machine learning algorithm any kind of I go even allowing you to choose to filter some ecn bits and to prevent TCP to react to all losses next no problem above obviously IP layer the only difference is that in that case you have to mark another field the the TCP field corresponding tcp field next so just to illustrate what we obtained i did a simple experiment simple experiment showing here so it\u0027s a link capacity of 10 megabits there is energy of fourteen iskcon\u0027s and two percent of london random losses so basically if i applied on famis matches formula i shoot up that something like two megabits that\u0027s what I obtain next if I use a net recording layer so in this example I use tetris implementation and I do not cross layer any information to TCP in that case TCP "
  },
  {
    "startTime": "01:25:40",
    "text": "is becoming opportunistic and although all all information of mask so you is going to fetch all the bandwidth available and this is a problem for my view over TCP sharing the same link next on the contrary if I signal to the upper layer thanks to easy end that each time a packet has been rebuilt I provide a Sen bit to the upper layer in that case hi other fair share between both low it\u0027s not a fair share because it\u0027s random losses but they obtain the same amount of throughput however for my TCP 10 that so the one implement in the ecn bit using the ICN bit the good boot is enhance as there is no retransmission of packet so all packet are delivered there is a delivery ratio which is superior to the standard TCP next and if I use a loss discrimination algorithm or machine learning algorithm I can have a certain degree of freedom are going to get more interesting throughput even over random lattices next so to conclude using us here with a receiver and silly error so just at the receiver side allows to simply simply interact with TCP there is no modification of of existing TCP implementation and it was the goal to use thunder TCP layer without doing a new PC P again coded and we we prevent to check whether we affair with our over TCP layer and this is compliant with all TCP stack today thank you which is a fruit put I didn\u0027t represent it the fruit good put here another support of Brandon Williams it\u0027s actually we didn\u0027t really know pardon me yeah I\u0027m close now I should lower it I guess I don\u0027t know how these things work I\u0027m an engineer okay "
  },
  {
    "startTime": "01:28:41",
    "text": "so yes I we didn\u0027t really know at the time what manual was going to present but I guess that we are not in really in conflict because what is in this presentation is basically some of the requirements and I mentioned the interim meeting that we had in September one of the main topic that was identified in that meeting as something that we needed to address was this interaction or lack of lack thereof between network coding and congestion control next so what we have and what actually Akamai has measured and what we all know is that you know most of the Internet is fairly reliable but when it\u0027s not we know that the the packet loss can be significant and while there\u0027s been some kind of FEC X or FEC in terms of repetition code that have been used many year they actually failed to recover lost packets especially when these packages lost packet are not random but arrived in clusters so you have a series of lost packets so hence you don\u0027t get any good usage of doing these codes so this is actually as a almost a requirement for this whole working group but a research group but so we need more structured codes and we\u0027ve done that and the especially with long RTT which is the satellite people almost the conclusion to this whole meeting the FEC has been shown to shorten the recovery time and I think this is something that I will send to the satellite people next so what\u0027s the problem statement we do not have to know or do not have to we have to recognize that the use of FEC a lot of times hi is the congestion control information that TCP uses because obviously we correct things so the packet was lost we correct it we send it to the other end TCP has no idea what had happened the middle and there are instances and actually this is something that\u0027s going to be slightly different from what you have said there are instances where a reduction of bandwidth the reduction the bandwidth for the Akamai people means that we added some overhead to protect against the losses and there are some some times where this is not necessary what do we need that by that it\u0027s very short term or spiky events that by the time we get the feedback that this thing has happened it\u0027s it\u0027s too late in any case there\u0027s nothing we can do so you could actually kind of say we\u0027re going always going to protect against these things but then the losses will end up being "
  },
  {
    "startTime": "01:31:42",
    "text": "maybe worse than what you would have done without we\u0027re just living with the spike yes the window will below but lower but and you would but your retransmission is going to be very low because there\u0027s just a few packets that we\u0027re lost so maybe it\u0027s not worth it but we all know and actually this coming back from your presentation that there are instances where you have more chronic things that happened on almost a regular basis they\u0027re very long term and again in the measures that Akamai are very clustered together they\u0027re not you know chronic and spiky but actually obviously there\u0027s times where both are necessary and actually this goes into this ID that maybe we need more than one approach to deal with these different elements in terms of congestion control next so the project the potential approaches that basically has been done already is that instead of just doing the standard lost congestion control has actually moved to something like PDR which is delay or RT t based and this actually has given some good results at least in some of the stuff that\u0027s been done at Akamai and it\u0027s under investigation there was this idea of also sending the last information from the FEC in the congestion to monitor so here\u0027s Dave\u0027s question this may make no sense at all and it just occurred to me so just tell me I\u0027m crazy which is thank you um in a delay based um congestion control scheme inaccuracies in measuring delay throw the algorithm off as opposed to inaccuracies in detecting loss throw the algorithm off is it your assumption that the computational cost of reconstruction in a coded system does not increase delay to the point where you\u0027re actually um biasing the the delay is seen by the layer above okay actually I we assume that the delay that one that\u0027s exactly the exact Li what what is being but it\u0027s been assumed here that the delay in reconstructing packet assumption is that assumption valid yes okay thank you the assumption it\u0027s actually especially when you start using systematic codes that the cost of reconstructing a packet is very very low and and it\u0027s and will not greatly modify your estimation of the delay okay so the other idea was that sending loss information from the FEC to a congestion control algorithm like estimate the loss instead of estimating the delay and then that\u0027s has "
  },
  {
    "startTime": "01:34:42",
    "text": "been the subject of thousands of papers well do we the design which one is the congestion loss or everything but we think that this may add a lot of complexity and potential non-standard solution but again it\u0027s been tried the other well now we know that zcn that\u0027s been informed that has been looked at presented the same segment the work that was done trying to change to distinguish between congestion losses and others that also has been this is actually background and also the work that also emmanuel presented of MIT and the Hamilton Institute on the TCP and C and the NC TCP which are like the creation of a completely different way of doing TCP with coding I think point there\u0027s no this is not really like a solution presentation it\u0027s actually basically establishing with the problems and where some of the avenues could be obviously a manual presented something that is probably more like a solution this is like more like an investigation of what could work I know that Briscoe is not here but he\u0027s not a big fan of bbr but we were like we actually thought that actually the delay based stuff was actually pretty cool for what we wanted to do so and the question yeah just I think VBR is not actually debated such as the gas could be it\u0027s more that you estimate the channel rate so it\u0027s more a rate based protocol than property based it\u0027s the lace laughs but it\u0027s not because the rate is a function of delay but yeah it\u0027s not the same thing well it\u0027s well anyway so III yes I agree with your comment but what I\u0027m saying is that we think that this first approach of a non loss based congestion is something that we would like to really look into next so the status again we know there\u0027s a lot of patents at work we know there\u0027s going to be a lot of ongoing work that we would like to report to this group and the interaction of congestion control and network coding has been the elephant in the room ever since this research group was funded founded there was early results that were actually presented in the past which essentially had ignored the issues of congestion control and essentially we\u0027re biasing the results incredibly so that actually is not what we would like to continue we would like to start looking at new ideas and we would like to have a draft to be produced either for London or Montreal to start putting "
  },
  {
    "startTime": "01:37:42",
    "text": "ideas and potential solutions and potential architectures into a valid document and of course collaborator welcome you guys are already working on this I don\u0027t know if you want your own draft if you want to do something in collaboration there\u0027s probably other people who may have ideas that we would welcome and what I understand is that William will continue working on these things and who will be obviously the main collaborator to the draft so this was like just a small presentation again at the interim meeting congestion control was identified as a major issue that the group had to to address more questions Oh inspect go go I had a fairly strong opinion on this so my fairly strong opinion is that poor air correction should always be considered as bites in flight as it\u0027s usually called in TCP and quick when you send it and you should whether using bbr or any other congestion control algorithm you know any packets that are lost or delivered should be treated just like any other packets that are lost in delivered and so you know basically you should be doing congestion control and doing forward error correction but they ideally should not have any like in my mind the goal should be they should have no actual interaction like that for Derek Russian are now we\u0027re coding is is faster loss recovery it is not substitute for congestion control like if it\u0027s substitute for did congestion control I I think so I don\u0027t know I have a fairly strong opinion that like if that that should be a principle of whatever document but I mean that\u0027s just a personal opinion so someone could disagree if you look back into the history of network coding in general especially and networks that are tcp-based people were sending a UDP tunnel for the example in the middle of a bunch of TCP sessions and then everybody backs off except that tunnel and then you say wow it works really well yeah I totally agree that people in the past have like abused this idea of like hopelessly and that\u0027s why I was trying to like put forward that principle yeah I think and for me I agree is that if you you should be able to show that your solution is not killing the Internet I definitely agree with your point here I think this is something very important and I believe that we have also to consider if one day or another we are going to spread a lot of TCP NC or any kind of whether or not redundancy packet we per packet must be congestion control or not because if we decrease the the TCP flows without considering that we inject a lot of reaper bracket it could be a problem but "
  },
  {
    "startTime": "01:40:43",
    "text": "I definitely agree with this point I think this is something useful to discuss yeah makkya versa I my general view on this matter is kind of similar to ian\u0027s and I at first thought I\u0027m not gonna stand up because I I don\u0027t have any interesting thing to say because I don\u0027t think this is an interesting mix but I just had an idea I want to share that idea one of the benefits of of ECM one of the benefits is that you cannot you can be basically lossless right and you have this signal so in the absence of routers being able to do easy an that could be a possibility of doing essentially you know normal loss oriented congestion control and just using coding to master loss like not half the loss right but you will figure out that it happened so you could signal back just like easy and what you know that there would have been lost and then you could be in lossless more than figure out when loss would have happened and when you have when you had to use and see to compensate for it actually looked you know when Faison was talking about the sliding windows and the windows that can grow well the minute this you start seeing your window growing you know something\u0027s happening and you could start signaling back so there\u0027s a number of these signals that are intrinsically part of what\u0027s happening in YouTube oh you could even use this you could even use the ecnv panel to just singer back on the TCP layer you signal back Cee even though there wasn\u0027t an easy on mark that just was you know that were coding having to do what it does so I so that\u0027s why that\u0027s why I know that\u0027s why we think that it\u0027s important to have a some kind of a document where we can actually capture all these ideas and at least have you know like an element to answer to people say okay every time you do network coding you\u0027re killing the TCP congestion control or you\u0027re doing things that are bad for the network would say well by the way look here and here a number of things that can be done and will probably be done to actually do that yes so a plea let\u0027s not go over again the 30 years of mistakes of not telling the difference between congestive loss and other loss processes we have networks that have other loss processes and if we simply build something that can\u0027t tell the difference between congestive loss and other types of loss like errors on wireless links and you know rain fade or any number of other things we\u0027re gonna wind up in the same bad place the TCP was for 30 years and we have it we may have an opportunity by when we put congestion control into network coding there may be ways to actually tell the difference that we didn\u0027t have for TCP and okay and "
  },
  {
    "startTime": "01:43:45",
    "text": "I this is actually has been my Holy Grail and I think this is why this is why I think it\u0027s important for this group to address that problem so that we do not repeat the errors of the past and that we can actually come up with I would say a solution but maybe many solutions but things that will actually work for what we\u0027re doing okay Cedric I think it\u0027s worse I know there\u0027s some new people who arrive would you please sign the blue sheet okay so this presentation is about some use case of network coding specifically on multi up wireless network so I will present one use case I will present some example of what I think a key feature or constraint but maybe not found in over settings and also I will present some example of solution and team our goal of this presentation is maybe to give some feedback on what is developed in this course our group like module of a generic app IPIN so one motivation one really timely use case is update of IOT devices so imagine that you have a large deployment of IOT devices like Wallace on sock type of smart city deployment and imagine that now you use medium of shot short-range radio technology and that you want to update with your devices when you will have basically to take off your image and sound it over over via to entire network and because it\u0027s a multi up network you have to do mutual broadcast and the thing is also your female image is likely to be rather big so it can be hundred or thousand of packet and if you want to do in which a broadcast with lot of packet then it\u0027s a very use a very fitted use case for for networking and also I want to mention that our there are many use cases in over in general in multi openness network that\u0027s why in the different or working group they have been protocol that have been proposed to the broadcast and multicast like in raro and money so now one specific thing think in in the virtual "
  },
  {
    "startTime": "01:46:46",
    "text": "network is you really want when you do want to do broadcast is that you will really want to use the multicast the wireless media\u0027s advantage it will fact that when you transmit one packet you have many receiver and most of the protocol did do optimization in one way or another on the fact that you can have some kind of subset of a note like represented on the figure on the left but the black node only them will transmit the packet and if you select properly each subset and if everything goes well you have an efficient wireless broadcast now this is works well when something in open loop the problem is now if you want to have some feedback so for instance you cannot do a acknowledgement on every receive packet because you will use the wireless Makuta Utica Center so you don\u0027t want to do that and then you have a real problem it\u0027s not straight forward design efficient control plane where you are able to say that your broadcast is working well so to address this problem of efficient control plane so some protocol have been designed so that\u0027s dragon cast dragon head there is a draft there is some implementation and this protocol have been proposed by those people Ratan area and they are based on two principle the first one is network coding used we are you doing broadcast and then every node in the network sounds kool-aid packets which participate in the network coding process and also the what goes with this is the fact that the state of the node is piggybacked on each coded packet and this is a way to have knowledge actually over of a state of a neighbor so it\u0027s a it\u0027s a kind of local control plane responsible and the second one is that the protocols act locally and by acting locally the VC still sufficient in most ways to ensure that the broadcast is working well globally and locally in what in this way is each node tried to helps the neighbors so it\u0027s uncrazy trait if a neighbor is falling behind so that\u0027s who dragged on module and also it generates a proper packet but with your modem so this is a more detailed view of a protocol but basically on the left you have one transmitter which has some decoding buffer with some coded packet and what is important is to state the state is it has decoded two packets he has around three in the cotton before and as a window which include the converter which I include sauce packet free too and when "
  },
  {
    "startTime": "01:49:47",
    "text": "it\u0027s on the packet as I emotion it will add in a heater along with recorded packet it will add the state and which is received by the neighbor and we store in a neighbor information\u0027 set and now oh it is used is described on next slide it\u0027s sliding on coding window module and what the note do is take the neighbor affirmation state look at all many packet each neighbor has decoded and when the node helped on note which is the most behind in the decoding process on the video you have not B which has declared only up to sauce packet 9 and then the generate couldn\u0027t that start with sauce packet and this starting from 10 so that\u0027s that\u0027s the principal of the protocol and now if we want to connect this to the general KPI decision so it\u0027s on the next slide we if we want to see where generally KPI model will be it will be the Nostalgia encoding window all right good it\u0027s really it\u0027s not clear on tele where it would be but there is at least this which is a decoding buffer which is the livery that also Vance emotion which does basically in a coding operation and maintain a decoding buffer and so the decoding is easy every time a packet is received it is added in the buffer and potentially one step of Gaussian elimination is run and potentially went like when they coded packet it on that back to your application and then the next slide we can see that the the coding part is more complex because in part is more complex because you need the name of state information which is a sort of or ever dependent of the protocol and you need to use the state information to extract how to generate a proper packet to help your neighbor and this is where maybe there is a that should be could be a description for a general KPI phone because you have a constraint our minimum antics and maximum index that we could do works and I want to see some effect that yeah when they both state information is not even in coding module because it\u0027s depending on the protocol which depend on the use case if you are doing the networking point-to-point it will be more easy to to get the state because it\u0027s a state of a site but here this information is not necessary even accurate because you can use packet but it\u0027s what and then on the next slide on much yes this is what I was discussing so maybe but generate flag API will be "
  },
  {
    "startTime": "01:52:48",
    "text": "something around this module if for for we use K so if there is a genetic model which is designed good it would be power and with the use case we\u0027ll use this in this kind of way and the last slide is just to mention that if you charge slightly way but it is like if you alone know to be decentralized then probably you need different lining and more general coding strategy for management so you some flexibility there is a discussion in an expired draft but it\u0027s just to say that things are not always straightforward maybe not always pass and resolution and yes but with my presentation and if there is some comment or question I will be happy I just have a question on how you select the repeaters it does it follow a stochastic process something like that it\u0027s a random work packet it\u0027s just that every node waits for a random time and so this is the packet rate basically and the packet rate is adjusted the dynamically depending on the state of the neighbors so if you have a lot of neighborhood but are late in the decoding process use on more packets okay thank you small cups questions due out how far do you think you leave LC is specific to you use case or generic I have in mind you future on so how much is specific I don\u0027t think it\u0027s really specific it just the fact that it assume Gaussian elimination which is an online but on the other hand it\u0027s not the world protocol it\u0027s just one specific part doing decoding and only offering future to do coding like adding packet so so it\u0027s very little generate but some pie some things are missing to do a complete protocol of course and the next question on this walk what is the future so this is data so just compiled so yes at least continue I "
  },
  {
    "startTime": "01:56:43",
    "text": "think there\u0027s great stuff we can do with this link they\u0027ve said you know we can actually start doing something "
  }
]