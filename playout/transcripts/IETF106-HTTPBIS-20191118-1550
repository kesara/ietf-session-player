[
  {
    "startTime": "00:00:06",
    "text": "okay folks just turn 350 this is HTTP if you\u0027re not here for HTTP you don\u0027t have to go home but you probably shouldn\u0027t stay here if if someone coming in or going out could close the doors back there that\u0027ll be immensely helpful in sweat thank you or or ekor yeah and what if we could keep the doors closed that would be even better okay all right so this is the HTTP working group oops we for those who didn\u0027t catch it we had a we now have a logo for the work that we do here we also have some badges and stickers to handouts if folks are interested there\u0027s a couple there\u0027s a couple on the blue sheet we have more in the background I will be handing those out afterwards if folks are interested if you\u0027re having a side conversation it\u0027d probably better to do that out in the hallway if you\u0027re having a side conversation I\u0027d probably better thank you so and and by the way these are these logos are open the source is freely available on the github repo so this is the note well hopefully you\u0027re familiar with this if you\u0027re not these are the terms under which we participate in the ITF this is important not only for things like intellectual property and copyright but also things like the anti harassment procedures the code of conduct how we treat each other which we do take seriously if you have any issues around this or any questions you\u0027re more than welcome to talk to Tommy or myself we also have other folks the idea for a designated to help out with these issues so please do inquire if you have any questions and you can always find this by going to your favorite web search engine and searching for ia TF note well so blue sheets are circulating please fill is that when they come around scribes do we have any volunteers for scribes in the room Lucas party was even standing up to signify that he\u0027s going to know okay he submarines do we have any volunteers describe the session ah thank you very much uh anyone willing to help out um so if you could either do that on the etherpad that\u0027s in the minutes or on a Google Doc and share it with folks in the room that\u0027d be great thank you agenda bashing so we have two sessions this week today we\u0027re going to take a brief a couple minute straight of items to go over we\u0027re gonna have hopefully a pretty significant discussion of a "
  },
  {
    "startTime": "00:03:06",
    "text": "proposal for priorities in http/2 with the idea that that would also be useful for the htv-3 efforts hopefully them come to some sort of a sense of the room for that then we\u0027re gonna spend a good amount of time on core the core specs as we\u0027ve done for a number of meetings we\u0027re gonna go over some of the issues that the editors would like some feedback on and then finally uh we have 10 minutes reserved for discussion of a proposal for rate limiting headers and that\u0027s remote presentation then on Thursday we\u0027ll talk about the extension draft for foremost the meeting then we have a discussion of compression dictionaries a proposal for a new draft there did that signify something or is it just a okay any agenda bashing no bashing of the agenda okay so let\u0027s go ahead so first of all a few related meetings since we\u0027re early in the week that folks might be interested in sorry that would be lovely thank you unless one closer the doors would like to close the doors that\u0027d be great thank you so as you might might know the quick working group is working on HTTP three once they finish that they\u0027re going to hand it off to us for maintenance and further development but that\u0027s on Tuesday and Thursday SEC dispatch there is a proposal being discussed or something that\u0027s been actually on our radar for quite some time being discussed around HTTP requests signing that was mentioned in the dispatch this morning but the the media discussion that\u0027s going to happen on sexist insect dispatch on Tuesday there\u0027s also discussion of securing proxy to back in communications why do those doors stay up and Wow okay Martin well that\u0027s not great either really is it it was turned off Martin Thompson just a question why is the request signing stuff not happening here is this is that\u0027s a great question and I brought that up certainly like I said it\u0027s been on a radar it\u0027s been our list of drafts we\u0027re tracking the proponents for whatever reason took it to dispatch and then they had a discussion with SEC dispatch that doesn\u0027t mean it\u0027s not happening here it just means that the initial discussion has happens to be happening over there we equally could have had the initial discussion I think ya know just that\u0027s how the corner work because we have had that discussion here I think I know and that\u0027s I want to make sure that that\u0027s one of the reasons we have this slide is to make sure folks here understand that going to sex check dispatch this time around is probably a good idea so you know to my mind there are three communities involved in that discussion there\u0027s HTTP implementers and the HTTP folks in this room there\u0027s the people who actually want to use it for their applications and then there\u0027s the security community at the ITF as well and so we need we need input from all three microchip I\u0027ll add one more to this list that DNS ARP has adopted the it should be s service draft so please plan to come to that thank you thank you "
  },
  {
    "startTime": "00:06:06",
    "text": "for the reminder there\u0027s also web or trans the first session because the second one conflicts with the other extreme s session okay actually if you could send a reminder to the list that\u0027d be ideal web trans is on Wednesday and that\u0027s discussing something that kind of looks like WebSockets over quicken HTTP 3 I know that a lot of folks there are more inches from WebSockets W pack is also on Wednesday that\u0027s web packaging which has been discussed a little bit here from time to time and finally mops is a new working group on Thursday morning and that\u0027s media operations and that means video and these days video often means HTTP so encourage people to pop into that and see what it looks like any other related meetings that people want to note for HTTP folks okay so one more administrative item some of you may have noticed that there are only two of us up here at the table Pat Patrick McManus has achieved escape velocity and no longer is chairing the HDTV working group so we congratulate him on that thank thank him for his service take take take that however you like and as a to denote our appreciation of the service we\u0027ve gotten a small gift that we hope you\u0027ll enjoy Patrick you want to come on up or yes well we\u0027ll meet you halfway so this is a apparently a glass and the only glass that is specifically designed for drinking Irish whisky yes we hope so gifts can be donations too okay so that leaves us let\u0027s just get that off the screen that leaves us with our discussion of the priorities proposals so just to catch folks up there was a discussion starting in the quick working group about the design of the priorities mechanism they then came to us the HTTP working group and some of us wearing different hats and said do we really you know the Charter of quick says that hb3 will have everything that HTTP - hasn\u0027t it we really mean that for priorities and we came to an agreement between the working groups that no we\u0027re not going to force your hand on that you can ship htv-3 without compatible HTTP - priorities and so the immediate discussion afterwards was well what would a replacement mechanism for signaling priorities from the client to the server look like we formed a design team and these folks are now reporting back to us with what their recommendation is yes thanks I mean this is Robin Marx Robin has some nice simulation slides towards I\u0027m gonna have him talk through but next slide so these are the design team goals at least that I wrote down when I emailed folks on the design team I don\u0027t actually know that these are exactly the "
  },
  {
    "startTime": "00:09:06",
    "text": "correct goals but I summarized these from the chairs at the time hopefully I synthesized them sufficiently correctly and so I just kind of pulled this up for my email the other day but determine a solution for HP three to have some client-to-server mechanism priority hinting mechanism that it can ship with so other things that we can work on a mechanism for each two priorities obviously a mechanism to indicate what type of priority hinting is being used so for example a negotiation mechanism something that is non minimal so at you know has to have this feature set that we think we need and of course we want to be able to back port it to takes you and ideally we want to not ship something that we kind of are not sure of we don\u0027t want something that\u0027s unproven and introduces too much risk I don\u0027t want to do kind of what we did with h2 all over again next slide yeah so what why do we need something new it\u0027s basically because hb20 is a bit too flexible for its own good so you can build this whole complex dependency tree that you see in the top right side and depending on the shape of the tree the bandwidth gets distributed if you have a flexible system nobody is going to agree on how to actually use it you can see that very nicely to implement is they they do it quite differently only Firefox initially using the full complexity of the system at least when in the browsers there\u0027s another point is that all browsers just use one scheme for all the web pages so it\u0027s one size fits all this is going to work really well for some pages but really badly for others as well next slide so given this this flexibility and these different approaches we were interested in which actually works best in practice next slide these are results from a paper from two years ago on HP 2 and we found priorities mainly impact larger pages in our use case that was over one megabyte we found that Chrome\u0027s approach is actually quite good this is the the black line on the slide chromed us everything sequentially so it downloads a resource in full before going to the next one in most cases so that\u0027s quite good for the web browsing his case the opposite end affair round-robin where you injure leaf bandwidth between everything fairly is the worst case this is kind of ironic because that\u0027s also the default in HTTP 2 so for example the the old edge browser did not specify priorities and always fell back to the default always getting the worst case we also found some other implementation bugs related to the complexity of the hb2 system in that so next slide please so now for a quick and sp3 there were a lot of people that said maybe we can simplify this over several proposals proposed on how to do that there was a question from the quick working group is how well are these proposals gonna function in practice before we decide to adopt him so we decided to revisit that these are results from earlier this year we implemented all of this again but this "
  },
  {
    "startTime": "00:12:06",
    "text": "time it\u0027s free and quick we did all the browser schemes and then also the new proposals down towards the bottom and you can see in this visualization it\u0027s it\u0027s a simple concept but it can get quite complex and all the flexibility and variants that you get in this kind of a system so the results from that are on the next slide we again confirmed round robin is absolutely worst so we took that as a baseline here so all the numbers here are actually the multiplicative improvement on the round robin that you can get you see on there on the left that chrome is the best performing if you look at the whole webpage so all the resources but now if you look at subsections what we\u0027ve called you the above-the-fold resources or more aptly actually the critical resources that the things that you really need to load to get a first page view for example like that you can actually do better than chrome with even simpler schemes the ones towards the bottom another important result was that if you the server-side reprioritization is very powerful so again if you have the same scheme for all pages some pages are going to have miss prioritize resources it\u0027s very useful if you on the server side can say this resource is actually more important than the browser thinks it is the problem with h2 is if you have all these different trees it\u0027s difficult to know how to adjust a priority in that tree for each browser you could do some kind of user agent sniffing but that\u0027s hacky at best in practice what companies as CloudFlare I\u0027ve been doing is simply ignoring what the browser tells them and overriding everything in the server side which kind of announced the whole use for the prioritization system so the new thing we need to come up with really needs to support service re prioritization the final thing is that again use we can go to a very simple ski some people have been floating simple FIFO and and called quits but I still think we need a lot of flexibility there again you will have some web sites that really function quite badly on a very simple scheme and then there\u0027s also the issue from head-of-line blocking removal and quick so if you do everything fully sequentially you will always still have just one stream on the wire and then the head of one walking isn\u0027t gonna do any benefits so you get a really weird situation where for lossy networks round-robin actually becomes better than than FIFO which is the opposite of what you get on normal networks better networks so you need some flexibility in the system to adapt to those use cases those are the main results and Ian and his team and did some actual tests in wild recently to confirm or deny this and he\u0027s gonna propose then that thanks Robin alright next slide yes so we\u0027ve been ever since this design team started one of the first things I started doing was asking other people to write code because really I don\u0027t write that much code anymore it\u0027s sad but true and I convinced a co-worker to both fix our existing h2 scheme on our server side it turns out I had variety of those which caused it to not actually perform "
  },
  {
    "startTime": "00:15:06",
    "text": "as intended for Chrome Luc\u0027s implement FIFO and LIFO actually it turns out LIFO was already implemented don\u0027t ask why it just was yeah yeah yeah it\u0027s just a pre-existing condition that sort of thing we also added round-robin we did not have support for that but since you know people want to understand like exactly what the h2 default looked like in real-world pages we wanted to get some data on that and to go back gee quick currently uses speedy it always has and never bothered to move over to 82 priorities because it never really was worth the hassle and speedy seem to perform fine so that\u0027s kind of the default in most these tests although a few of them you\u0027ll see we actually compared as the baseline versus h2 and the baseline versus speedy separately just to kind of give you better statistics on the metrics oh yes and FIFO is lowest stream ID first not the first request is received so it\u0027s it\u0027s a request order not receipt order so in case there\u0027s a redirect on the on the request next slide great so for YouTube quality of experience really only one scheme was statistically significantly worse than the default of speedy and that was LIFO and that\u0027s not that surprising because when you start getting behind on a video playback you get more and more behind because the newer requests could put in front of the older requests and nothing ever finishes the degradation is quite significant I kind of put a 3% in two points six percent is is huge we wouldn\u0027t launch an experiment that made something like 0.3 percent worse so this is like not quite catastrophic but very bad like this is completely unacceptable bad so just to give you an idea you can really mess this up if you get things really really sideways obviously like those fairly sideways but nonetheless it\u0027s worth playing up next time actually some of the most interesting data comes from the flywheel data compression proxy and chrome one of the reasons it\u0027s interesting is there\u0027s actually a high degree of request multiplexing and they\u0027re commonly a large number of requests that are simultaneously active on the same connection which is not always true for all of our use cases it\u0027s only for HTTP unfortunately it\u0027s not for HTTP so that obviously limits the use cases a lot and the summary of the results essentially are Chrome\u0027s use of h2 is better than speedy which is better than all the other schemes and if we go to the next slide the improvements range from 0.4% to 1.7 so green means each 2 is faster so just just as a metric so basically each to on is faster than every other scheme here even speedy which is it\u0027s only slightly faster then and it\u0027s statistically significantly faster than any 5th percentile for all of these so that\u0027s good because this is Chrome\u0027s default scheme so someone at Chrome got something right at least "
  },
  {
    "startTime": "00:18:09",
    "text": "relative to the obvious options you know I I think that\u0027s that\u0027s that\u0027s great to hear and this is actually good enough that you know we we would actually consider switching over our default from the current speedy approach the h2 ones even you know temporarily as we transition because it it appears that this is pretty good evidence and they actually turns out that we have some other metrics research and such that kind of back out that this is a slightly better direction to move in all the other options but like next slide so if you compare relative to speedy as the baseline which is kind of how I originally set up these experiments the results are less statistically significant but as you can see you know there\u0027s still kind of an indication that h2 is is better these are the same metrics it\u0027s just the statistical analysis was done two different ways to make it a little bit more interesting it\u0027ll kind of give you some understanding next slide amp or accelerated mobile pages everyone loves this I know so this actually has slightly different performance properties as you\u0027ll see and in this case speedy which is round robin within bucket is better than chrome h2 FIFO LIFO around Rothman and the reason for that my understanding is that amp actually has a lot less like kind of dependency like this resource depends on this resource depends on this resource it\u0027s much more designed to be non end of line blocking and kind of inherently so there\u0027s a much simpler resource to fancy tree next slide even so yeah the the parameter improvement is is quite large at least by our standards you know you\u0027re getting close to two one percent a performance improvement versus priority of the other schemes so one thing that is also worth noting here is many vanilla suits that suggested just using like FIFO is fine I think this data at least presents that you can do a lot better than five without something overly complex and so you know my intuition is we should try to do something because you know this is not really that hard to to get better than 500 excellent so the new design needs to be simpler than h2 it needs to work for both HP - an HTTP 3 ideally would allow for expressing both the chrome h2 scheme and the speedy schemes in some way shape or form those are relatively simple schemes that seem plausible for different use cases should allow for server-side reprioritization as marvin mentioned the existing h2 tree system makes that quite challenging and it should not use round robin as the default so the there\u0027s a current draft at they are called that is under Kazuo his name and is written else if I\u0027d Lucas and it includes a scheme like this but I\u0027m also going to go over some updated design details that we have - one the design team met on Saturday or Sunday Mike Mike Bishop I think it might also "
  },
  {
    "startTime": "00:21:10",
    "text": "be worth calling people\u0027s attention to when we say the chrome h2 scheme that isn\u0027t the full tree it is a linked list ordered first by priority bucket and second by a request order yes is equivalent to essentially a speedy parties but we\u0027re quite not round-robin but instead in request order we\u0027re extremely idea orders that\u0027s exactly right thanks next slide so this is an update to the draft an updated version of the draft that\u0027s around a few weeks ago a lot of the details here are actually extraordinarily similar just copy pasted from the draft because a lot of the concepts are the same but the one major design detail is kind of changed which is a move from an indent header to one that\u0027s more focused on the two use cases that we think we we care about so when we try to talk through that and other working your sorry design team members can help me if there\u0027s confusion next slide so one of the goals here is to have a somewhat extensible scheme we want to have a core functionality that\u0027s actually useful and we can prove as useful but if we want to add another feature to this scheme we don\u0027t want to have to ship an entirely new scheme and then then we want to have a way of like expressing this new thing so the idea here is to use key value pairs currently that\u0027s specified using structured headers there might be other ways to do it but you know it seems like a perfectly plausible approach there\u0027s two fields urgency and progressive sir agency is a number between minus 1 and 6 right now it\u0027s basically 8 urgency levels to indicate these are like the equivalent of the speedy buckets and progressive is a you know 0 or 1 basically a boolean to say either I want this approximately round-robin or I want this you know sequentially in order and that that helps you indicate that a resource is indicated it\u0027s only useful why call or nothing so there are a lot of resources that just can\u0027t be rendered progressively and that\u0027s why it\u0027s called progressive although other people have said maybe you should be called concurrency and other things that\u0027s another time next slide there\u0027s a lot of interesting semantics here part of the reason for kind of describing so amount of semantics to associate with these priority levels is to say ok if you see a request that\u0027s party 3 or something that that means something and that means the browser you know has some meaning attached to this and ideally that would allow different browsers to come closer in how they\u0027re using the parties and avoid the situation we have with HTTP 2 priorities where as Robin presented all the roses are using things totally differently and you can\u0027t really derive any meaning from a given priority level it\u0027s just completely arbitrary so this ideally will allow servers to effectively prepare those things because if everything\u0027s just as I said if it\u0027s all relative then there are a lot of different ways of using the tree as well as gifts people some advice on like what these things mean and how to use them so "
  },
  {
    "startTime": "00:24:11",
    "text": "it\u0027s a little bit easier for application developers next slide so we talked a little bit about two key use cases before but I want to outline them a little bit more detail one is the client to server over a multiplex to HTTP connection so that\u0027s HP 2 or HP 3 so it\u0027s pretty clear that we understand that use case this is exactly what h2 parties did and this is this is something we have a lot of data for and I think we we know how to ship and we know how what the performance properties of it are the other one is I think Roberto described it as within the server where the server is kind of the entire serving infrastructure and that\u0027s the situation where an origin or an application front-end wants to change the the party as it when it arrives with the proxy or maybe the proxy does itself woman change the party but somewhere inside the like serving infrastructure you\u0027ve decided ah the clients beside that this is the party but I think like it should be slightly higher than the other images are slightly lower and so I\u0027m going to adjust it slightly the whole goal though here is in both cases we\u0027re trying to provide hints to the thing that scheduling resources to allow it to schedule those resources more effectively and more effectively like usually did the amount of bandwidth or the resource ordering or the in you know in the case of HTTP 1.1 it might even be the available connections because we have six connections available next slide so the proposal here is to actually use headers and as an API because they\u0027re the standard are the universal API for HTTP applications could also have a specific API you know it I know a lot of native applications like to actually like Burnett for example has a way to expose parties but that\u0027s a little bit out of scope for the design team that\u0027s kind of per application however there are a lot of challenges with headers and end and it\u0027s not really clear that the the working group wants to deal with those right now at this moment and we also need a frame for reprioritization anyway so the proposed solution is to have the client basically consume the header convert it into a frame on the wire and then on the other end if it needs to it can convert it back into a kind of whatever representation at once so this is fairly flexible but it also allows existing API is to sorry okay I\u0027ll just keep going okay so there\u0027s some open questions here one is should this what type of Heather should this be should this be a pseudo header and can and should this be exposed to the Web API so this is actually a question I was gonna look at mark Nottingham for there\u0027s some question as to whether this is kind of more in the purview of the w3c or is this is in the purview of the IETF but it\u0027s something worth thinking about next slide "
  },
  {
    "startTime": "00:27:15",
    "text": "so the wiring coding goals the initial priority frame needs to be delivered prior to the headers frame so it\u0027s key that there is actually an initial priority and we know what it is the client should send the first request with the initial priorities so we shouldn\u0027t have to wait for the settings there\u0027s definitely a possibility that it does not have settings when it first sends its first request and we need to allow reprioritization everyone in the working group kind of agreed that that was a use case that need to be allowed and it was it was some way used today and that hopefully browsers and other applications would use it more in the future next slide so the new proposed frame and this is actually taken out of the existing draft is essentially that it\u0027s a stream ID and a priority field which is a string it\u0027s only saying the control stream because of HTTP two extensions it seems like we have some reason it results from greasing that kind of confirmed that probably only on stream zero can we really send this dream this for a new frame and have it have it work effectively it must be sent immediately preceding the corresponding headers to make the parsing machinery a little bit easier and reprioritization is also on the control screen so that\u0027s pretty straightforward so there\u0027s one awkwardness here which is this situation where I\u0027m making a request on the request dream and right before it I have to serialize this new frame it\u0027s unfortunate that just due to how hb2 is specified we don\u0027t think we can get away with doing it any other way I mean if other people have especially deployment data that shows otherwise I\u0027m sure we could we could decide to change this design next slide okay so this is a little bit more straightforward this is fairly you know there\u0027s an ID to indicate whether it\u0027s the push ID or the stream ID at least when it\u0027s not on the request stream sorry when it\u0027s on the control stream when it\u0027s on the request stream obviously that indicates what stream ID it is and you know in this case we actually send the party frame on the request stream first and then on the control stream later and I had little brackets around there just and kind of indicate that that\u0027s optional this next plane so let\u0027s talk to about the proxy to origin case or the kind of within server case a little bit the tenant proposal is that a priority header can be sent to the proxy indicates the birdie on the previous hop so whatever the client indicated the priority was in the in the frame and it can also be sent as a response to say actually I would like to override the party that the client originally specified we have an example deployment that\u0027s written up by CloudFlare there\u0027s also a shin number 57 where Mike and others kind of discuss how this this might work and in the properties of it next slide negotiation with settings this is also in the draft currently so the key use cases we definitely want to capture are the client saying I do not support HP to parties so if you know don\u0027t don\u0027t use "
  },
  {
    "startTime": "00:30:17",
    "text": "the default ordering don\u0027t don\u0027t use round robin so on and so forth so that\u0027s a critical use case and that was in a previous draft that Lucas and Brad put out I think at the last idea the other thing we\u0027d like is the server couldn\u0027t express what information it wants from the client so the obvious thing right now and the thing two things that are in the raft right now or HT tree and urgency which might be renamed to extensible and it\u0027s basically a way of saying you know I would actually like HP to peruse style priorities if you can give them to me or I would actually like this new frame that\u0027s defined in an extension so we\u0027re actually kind of doing a somewhat odd negotiation scheme it turned out that negotiating anything with settings is is a little bit awkward because you\u0027re not really sure whose settings are going to be received first and you can\u0027t rely on ordering and so we ended up having a neat bit value which indicates the priority scheme and the server expresses kind of the order of priority schemes it\u0027s it prefers and you know the client basically chooses the first one that it supports there\u0027s a few other ways of of making this work but I think something with that shape is probably where we\u0027ll end up with next slide keep going some small issues are still to be decided should urgently start at one this might be kind of confusing to developers there\u0027s also the question of should the lowest priority actually be the most urgent or should the highest priority be the most urgent again this is one of those like developer API sort of things if we actually think we\u0027re going to expose this to people we probably should expose them be like easiest surface possible or did the encoding next slide Roberto is painting a bike shed all right awesome I like sheds as much as anyone all right so if we review the the core goals and at least the bullet points you know when I went back through and this is sort of unintentional it seems like we hit kind of the core goals that were outlined at the beginning and covered the core use cases and I don\u0027t think I think we are quite confident at least based on the experimental and simulation data that the scheme that we\u0027re outlining here actually will work and actually will perform well so next slide I think we\u0027re done okay yeah so clarifying question comment where were you at I was waiting for directions so okay go ahead um if you go back to slide I\u0027m gonna be jumping all over the place here I\u0027m good yep I think there\u0027s only three here because back porting and indicating that you\u0027re not using HTTP or --\u0027tis kind of imply the same thing right yeah I thought I\u0027d like this a whole lot more than I did in the end unfortunately I\u0027m having real "
  },
  {
    "startTime": "00:33:17",
    "text": "trouble sort of reconciling this this notion that you you had which I quite like the idea that you using the API of header fields to express priorities and then you start talking about frames and the ordering of those frames relative to the request center and um you lost me Zoe um I had some of the same thoughts and I personally I think I\u0027d like us to focus today on the general approach in terms of the expressiveness of the priority is knowing that the bits on the wire are probably gonna need some iteration sure but I wanted to go back to the requirements that led to those conclusions more than anything else and you had a slide there that basically said that you have to have the priorities before the first bits of the headers frame lands on the wire yes I think to make phones back I\u0027m not convinced that\u0027s true particularly if you start if you accept the fact that the that a header a an urgency header field whatever you want to call it I forget what it was is the API in which you expressed that piece you think about those cases where people are streaming header fields in to the stack in a stream in the important stuff the the pseudo header fields and then a block of the other ones and those might go out on the wire before you actually have access to the information that allows you to prioritize these things so do we have any information that supports I can tell you exactly why we that stipulation is in there and you can decide whether that\u0027s a good way and the reason why is because if you want to allow several different priorities and you\u0027re sending it back to an origin application front end or whatever you need to be able to put that somewhere in the original indication or don\u0027t need to but it makes it a lot easier if you\u0027re able to put it in a header in the original request back to the origin and if you can\u0027t then you need another piece of metadata that says like this is the party information that that was on that request and so having it before you\u0027re forwarding it back just makes the process a lot simpler so it\u0027s less a local scheduling decision and more of a if you want to inform the backend of what the client said it makes life a lot easier and that\u0027s why that was I\u0027m not sure I\u0027m finding that particularly convincing but I\u0027ll so Martin before you go and and for you and everyone else in the line you know my understanding where we\u0027re at is is that the design team is trying to make a recommendation the next step the working groups decide whether or not wants to do a call for adoption on the draft knowing that we don\u0027t we\u0027re not going to rubber stamp it we need to talk about it do you think that it\u0027s ready for that or do you think the design team needs more time I I wanted to work through some of these issues before we talked about that but I think based on my reading of it before and that was I admit superficial because when presented it I realized a number of mismatches between my understanding of what was written down and oh it\u0027s also "
  },
  {
    "startTime": "00:36:17",
    "text": "changed apparently it\u0027s I mean this is yeah it\u0027s an this is an updated version some of the things they\u0027re taking directly from the draft some of the things are notably changed but once with oh that\u0027s fun once we\u0027ve chased a few of these things to ground I don\u0027t see us doing anything other than what these fine folks have produced because it\u0027s I think it is approximately the right thing to do it\u0027s just that I want to make sure that what we what we\u0027re taking is reason properly we\u0027ve got 60 minutes so it may be that we adopt something then immediately spool for design team that works just for the worst issues yeah yeah I think that\u0027s the right way to do it yeah Mike Bishop I will note that when you\u0027re discussing hetero versus frame if you want to allow reprioritization you have to have a frame you could also have okay martin says that\u0027s not true okay martin can come back to that but assuming with the premise that you have to have a frame anyway then we started talking about if you want to use a header to set the initial one is that in to end is it hop-by-hop can priorities change hop-by-hop and given that h2 and currently h3 no longer have the concept of hop-by-hop headers then expressing what you want on this hop versus what the client asked for in the last hop gets kind of dicey if you an end-to-end header and trying to mix semantics of different connections in there so what we wound up with in our discussion yesterday was we use headers anywhere that we are talking about a different hop and we use the frame to talk about this hop of the whole progestin but not just sit so it\u0027s basically the client sending a frame to indicate how that should be prioritized while using a header to communicate that information from the proxy to origin and from the origin to the proxy to the powers in signal how it should prioritize based on the information that\u0027s the server has such gentle I really enjoyed the data that you collected it seems like you got seven different priority levels from understanding it correctly you\u0027ve run it a bunch but against a bunch of different websites there\u0027s kind of a couple percentage difference between different approaches I guess like as a website developer I would want to be like well for websites that have these particular characteristics we use this priority scheme and these other websites we use this particular card scheme I\u0027m curious if you\u0027ve got any recommendation so knowing you that or if you plan on doing anything like that actually I think the some of the text in the draft is actually like not a bad recommendation because you guys talked about some of the issues about like whether resources can be loaded progressively and whether they depend on each other and so on and so forth I don\u0027t think that\u0027s the "
  },
  {
    "startTime": "00:39:17",
    "text": "end-all be-all and actually I think some of the the the post link by a cloud flare is actually good about that as well but I think I think the answer is either as a browser a browser needs to be slightly more intelligent about exactly understanding what fancy structure it\u0027s trying to load is or the website needs to help the browser and say like I think you\u0027re missing firing the dependency tree I know that\u0027s a hard answer yeah I guess I\u0027m imagining like if my website has a lots and lots of resources if I should be using priorities system 6 for example then if that could be automatic then that would make the whole thing feel simpler to me but yeah yeah thanks Roy fielding I in your presentation I didn\u0027t see any reference to those messages that I sent earlier about using ditches just a header field and I feel at this point that while I appreciate a lot of the the work that\u0027s gone into it we\u0027re really on the cusp of a changing document and not not something that\u0027s ready for any sort of notion of consensus even amongst the the design group so I think that the work should continue and and find the right path I\u0027m not really interested in a lot of the complexity that\u0027s inherent in in the in the scheme right now in the sense that you\u0027ve got a lot of talk about frames and prioritizations and using different things which you know from my perspective I don\u0027t need any of that I just need a header field so I would like to get us back to the point where we\u0027re you know we have discussions in in the design group or whatever or we shift out of the design group we should actually be thinking about all of the complexity of HTTP not just Chrome\u0027s interests not just one browsers interest or a different browsers interests I mean the idea here is that we have to adapt the complex the the rate at which the protocol is processing the requests to all of the different applications that might use HTTP the one size all doesn\u0027t work in that perspective doesn\u0027t work and so I would prefer that we spend more time introducing flexibility to the priorities as opposed to trying to shift them into the simple simple repetition of age toothed browsers monotone Tsin I find myself agreeing with Roy for other reasons that I think equally valid when I ask the question about the the ordering of these things I didn\u0027t realize that that was masking the bigger issue of how this meant and how this managers hop by hop or end-to-end in this this whole thing and in the earlier iterations of the draft proposal that this is evolved from there was a very simple notion that you would set a "
  },
  {
    "startTime": "00:42:18",
    "text": "head of field and maybe the head of field would be changed by intermediaries along the path as they applied their knowledge of what the situation was and then it would come back with different values again such that the origin server could have some sort of input into that process and now we\u0027ve got this notion that well you have that process going on and at the same time you have something where individual steps in that chain would make statements about the next hop in that chain that\u0027s me sounds like a far more complex situation to be to be in and I don\u0027t know that that\u0027s really all that helpful do you have any information to suggest that this is absolutely necessary because its complexity and it\u0027s a sort of complexity that I thought that we kind of decided we didn\u0027t need I can give you my thoughts I\u0027m not sure I mean at the end of the day I think we kept coming back to the idea that there was a lot of interest in actually having a hop-by-hop header and that doesn\u0027t exist so I mean interest or or evidence that this is useful well I think we have on a hop by hop feature is really useful so I don\u0027t think that\u0027s really is that what we\u0027re talking about whether these things whether the signaling that we have and the extra information that\u0027s carried in the signal as input to prioritization decisions that are made at various points in the in the network is useful for performance this is a performance enhancement thing yes do you have evidence that the hop by hop signal in addition to an end-to-end style signal is valuable for performance I think I saw that there was evidence that so we have every signal as I have signal is useful and we have evidence that the kind of origin to proxy signal is useful we actually have no events right now that the and in signal is useful because no one\u0027s ever done it but we just talked about having an IP I that the head of field was sufficient okay long as he did we\u0027re gonna close so I think I was coming up here to address exactly these things hope we\u0027ll see if I succeed this Roberto by the way so one of the observations one was that in many many deployments it seems that the thing that\u0027s terminating a multiplexed connection whether that be a client for you p1 one stuff trying to do multiplexing or a reverse proxy that is terminating h2 or h3 connection the server that is being sorry the server that is receiving the requests is very often an HTTP one one server regardless "
  },
  {
    "startTime": "00:45:19",
    "text": "of how the client connection is actually terminated and so we need a mechanism of specifying to the thing that is terminating the multiplexing how it should do something right and if you have an HTTP one-one client is pretty obvious that the only thing you can do a sorry an h2 b11 server it\u0027s pretty obvious the only thing you can do is put a header in there unless you\u0027re gonna do an HTTP 1.2 I know so it seems like that\u0027s a pretty foregone conclusion then the next question you have is do you strip it or don\u0027t you strip it right and if you don\u0027t strip it then you have all kinds of additional complexity around caching that gets really interesting and fun clearly we could invent a new category of headers but then we\u0027d have to deal with the backwards compatibility of current deployments the thing that was mentioned in the design team there was hey you know even if it does screw with caching a bit at least it\u0027s not a correctness problem it\u0027s going to be an optimality problem so it is possible to do that and the system shouldn\u0027t fall over and do anything really terrible on the other end on from sending from the client side right the observation was that many implementations are composed of different libraries together and it was not obvious that there was any one API that you could specify that\u0027s going to go all the way to the part of the implementation that actually has to do the multiplexing which was the reason for saying you know ultimately the one thing that is HDPE gosh darn it is there\u0027s headers and then there\u0027s other stuff right so headers is the way to talk to the thing that\u0027s actually doing the serialization and the multiplexing I see Roy laughing anyway it\u0027s sadly true like HTTP man so you know if we decide to make that end-to-end I mean okay fine but then the question but then you have to do a disambiguation because you are trying to target a specific hop when you are a client trying to do signals prioritization so either you have to make rules for stripping or you have to make rules for mutation all right anyway there you go guys mic mic line was closed already thank you I just wanted to point out of that we are mostly discussing about how we convey the signal instead of the semantics that we have so maybe a path forward would be to talk about to see if we have a course or something other semantics of exam maybe talk further about well my claim is closed that\u0027s right okay so it\u0027s pretty clear that we don\u0027t have consensus on the solution and there\u0027s still a lot to discuss in my mind the "
  },
  {
    "startTime": "00:48:21",
    "text": "question is where should the discussion happen and how I don\u0027t yeah just my perspective I am a little concerned that I see things like we\u0027re you know the design team comes to consensus the design team is closing issues but it\u0027s not incorporating into our community and so I\u0027d rather have these things done in public spaces so we can get the input from the entire community and so I\u0027m thinking maybe we should hum to say do we do we want to adopt this as a starting knowing that it\u0027s not going to be the endpoint or do we want to give the design team more time to fight yeah and I think one question just if anyone on the design team thinks that having more time as just a design team would be like very important or change the output of this that would be good to know but it seems my impression is that the design team you know has what they have and they think that\u0027s a good spot and it\u0027s probably most useful to have that come into the larger group now so is that I say I see nodding so that seems to be okay we can hum well we\u0027re gonna do a call for an option that\u0027s the next step does anybody think that it does anyone stand and say that no we shouldn\u0027t do a call for an option yet Thompson stands up I mean this issue of whether this is a hop-by-hop or into any signal is kind of fundamental and we need to resolve it now sure we can we can say that we\u0027re going to adopt something and then decide to do something completely different to what\u0027s being proposed in that in that document but I don\u0027t see why we have to I think we should probably just resolve the issue before we adopt this thing since it proposes something why are you gaining adoption on that it\u0027s fundamental sure so it\u0027s also a I think as has been already pointed out by Kazu her like there are two parts to this there\u0027s what we want to communicate of essentially this the seven levels plus the progressive bit and if we think essentially we could adopt that part and say we\u0027re not sure about the communication scheme for it but we believe that that is the right thing to communicate however it is done yeah I think that\u0027s less contentious I think I don\u0027t care about that sort of things as much nearly as much as I care about the the fundamental question of whether this what it is that we\u0027re prioritizing and if we can\u0027t agree on what it is we\u0027re prioritizing I don\u0027t know where we\u0027re going so and I don\u0027t think we know where we\u0027re going yet but if you look at the history of documents we\u0027ve adopted and what comes out the other end there\u0027s often a remarkable difference and you know the higher orbit here is is the way HTP working group is working on this now and I think that\u0027s the question at hand I had a question for Martin about how we\u0027ve been discussing this particular "
  },
  {
    "startTime": "00:51:22",
    "text": "question for four months I\u0027m not it I don\u0027t like maybe you have some magic way to resolve it quickly but I think it\u0027s it\u0027s hard yes I\u0027m not debating the fact that the question is a difficult one I\u0027m just thinking about we\u0027re spending our time debating whether to adopt something where we should be spending that time debating the question to be clear we\u0027re out of time for this I\u0027m good so so that\u0027s why we\u0027re talking about it done or not yeah we\u0027re talking about next steps yeah so I think we\u0027ll do a call for adoption on the list before we we go to the next item you know if we adopt something we\u0027ll have list discussion we\u0027ll have issues the next opportunity to discuss this face-to-face for this working group is going to be in Vancouver is this urgent and and and topical enough for folks will they\u0027d consider an interim meeting I see some nods there\u0027s an obvious opportunity for doing that so Thomson are you suggesting collocation with the quick interim Cheers right that that seems far more tractable than any other thing about the implied by well we\u0027re not a force yeah so comments I I I\u0027m gonna be the quick interim I suspect a large number of the people involved in this discussion will be at the quick interim so maybe that\u0027s not such a bad thing I do we make sure that we don\u0027t we\u0027re not sidelining anyone who might might not otherwise be at that meeting so if anyone is inclined not to go to that meeting anyway but would be very interested in this topic I think probably a good idea to talk to the chairs well the really nice part of that is is that Julian and Roy are gonna be in the area at the time as well right so it\u0027s already a clarifying question about your proposal to co-locate as a potential host of the quick interim meeting the person who reserved the rooms for example what we have reserved now is currently split up for essentially speaking the Interop and then a few days of the quick standards meeting if you are planning to add two days to do that on the beginning or end I am not at all confident at this point that we have those rooms available if you want to replace the interrupts with a different standards meeting or run them in parallel that seems very different and I\u0027m a little concerned I was thinking about something else but I was not assuming any availability in your parts but we can take this up so thank you very much sure you\u0027re off the hook yes all right well we\u0027ll have more discussions about this thank you very much and thank you to Ian for the presentation that was very helpful so now we have HTTP core Roy do you want to "
  },
  {
    "startTime": "00:54:23",
    "text": "present this one okay so Rory fielding and editing this the HP one the X documents with Julian and Mark next slide okay so everyone probably knows we have the latest version of drafts or a draft zero six these are links to them it\u0027s like and there\u0027s also two sets of gifts out there that you can look at the first set are just the differences since the last version and the second set are all of the wording changes that we\u0027ve made since the RFC\u0027s we organized so that you can just see the the word gifts and that can be very useful if you\u0027re only interested in things that we screwed up then that\u0027s what you want to look at if you want to see how we\u0027ve reorganized everything then you want to look at the whole github history vast majority of our work so far has been trying to fit the rights paragraphs in the right locations and then making minor changes in the paragraphs after that so you\u0027ll see it\u0027s much easier if you if you\u0027re just interested in what the protocol changes are look at the franc and RFC dips thanks slide since since Montreal we closed a list of issues I\u0027m not going to go through them but they\u0027re all up there on the on github next slide and there\u0027s two we\u0027ve also been tracking their rata status julian has has kept detailed tracker while they\u0027re at a post against the 70 to 3x RFC\u0027s and we only have two left to fix in the drafts those issues 163 and 53 and I\u0027m not sure if we can talk about them later or not but there there can and next slide so what are the issues to discuss now work okay so if you go to the HP core issues list and make it here we use the label discuss to look at things that we think need discussion from them in the working group for each me and we only have a few this time actually I think I\u0027ve marked more but then we we resolved a few down the road sorry how\u0027s that so first off number 258 Titan language run delete request bodies so we had another issue to tighten the language or and get request bodies which was you know they\u0027re still folks who think because HTTP at the generic framing layer allows any requests to have a body that it\u0027s okay to put a request on a get when in fact that breaks a lot of things and so we introduced a requirement there to guide "
  },
  {
    "startTime": "00:57:25",
    "text": "people away from that design decision ever so gently a little less gently the last time I guess really we tried to do it last time and we were but you subtle so we were all this time third edition of being to several yes and at the time one of the one of the questions that came up was well delete isn\u0027t pretty much in the same a place why don\u0027t we say the same thing for it and in reality there are two different approaches we could take here one is is to let delete follow the path of get which is it was never defined to have a request body therefore you know interoperability dragons be there don\u0027t put one there or it would take the path of options which is there\u0027s a request body that could occur on this but we don\u0027t really know what it means that\u0027s up to the resource or something else to define the semantics self about covers it doesn\u0027t and options of course the request body is used more often than lots of other places yeah maybe you scroll down a little bit yeah and so Julian opened this he wanted this consider them separately so there\u0027s some discussion here and and Everett points out yes the intent of delete is just ability to target resource and so the question is what would a request body mean and especially for generic software that didn\u0027t understand a particular request body format what would that do and would it break any existing uses of delete and so I think he is proposing we take the get path for delete Julian not in this one but later points out that there are people who are using delete bodies this is Julian online and do you want us to press the magic button Julian and sixteen hours ago he gave an example aha hello we can hear you sure yes I think it\u0027s more like options and I\u0027ve seen lots of people actually so Roy you you responded here do you want to summarize what you said well I I think it\u0027s always been forbidden from the sense that semantics that\u0027s I mean I "
  },
  {
    "startTime": "01:00:25",
    "text": "realized that you can read it in a in a way that by not actually actually demanding that we\u0027ve not send it that we are allowing it but it had exact say the same exact text was used as the for the method get\u0027 for the same reason and we just didn\u0027t want parsers to change to not read the body because if you don\u0027t if you don\u0027t try to read the body then you\u0027re creating a security hole so we put that language in to be vague in the way it is because we don\u0027t want the semantics to be effective even if you put something in the body so you\u0027re not supposed to do anything in the body period even if you send it you\u0027re not allowed to do anything with it that\u0027s that\u0027s the intent so I know what I\u0027m absolutely certain what the intent is because I lived through that nightmare several times and I agree that some people have taken liberty of stretching what\u0027s there into whatever their latest application is but they\u0027ve always done it in particularly stupid way so I\u0027m I don\u0027t care if we break those just you know they obviously look like they\u0027re looking to be broken there\u0027s already servers they do not interoperate with and the point of the protocol to define what is interoperable not what is what everyone does in the interoperable on the internet not on little private networks or our servers yet I have to strongly disagree because I mean we don\u0027t say what semantics well a post is specifically specifically divined as look in the payload to find out what it is yes so but you can\u0027t say that we have some post and then claim that putting something into bed because I think we had an interesting discussion about whether and it immediately is allowed to what the payload on a delete request and I think it would be good to get to the bottom of this first because I don\u0027t eat this a spool I mean that\u0027s up that better implies that intermediaries can essentially drop any request body except for maybe post and that is certainly not true so I think that\u0027s something we need to come to consensus about first and then get back to the question about whether I mean if I have a client at the server and every month my API that I implement and I can be sure that informing immediately I just don\u0027t see why so Julian the difference is that "
  },
  {
    "startTime": "01:03:29",
    "text": "software that either drops errors on a post payload requests payload or software that doesn\u0027t make it available to the application would be considered broken I think by anyone but software that either rejects or a delete request a payload or doesn\u0027t make it available the application I suspect is quite common and I\u0027m thinking about web application firewalls I\u0027m thinking about various api\u0027s and various servers and very live various libraries that implement HTTP on the server side as well as intermediaries and see DNS and proxies so does anyone here have an opinion on this we have why are aligned and Julian is not but I understand Julian\u0027s position absolutely I am slanted so it\u0027s I I understand where he\u0027s trying her and why he\u0027d want that preference clarify which conditions and we can eat the payload and not follow it because I\u0027d like to understand why the need is different from for instance patch or a little message to be different well the only problem is that is there\u0027s no actual requirement that a gateway forward a request but that seems to be a packing respect because that\u0027s essentially yeah so we have some comments in the room Thompson are we talking about preserving the use cases that these people use these bodies for or are we talking about simply maintaining backward compatibility through some sort of adherence to the spirit of previous specifications because I\u0027m inclined to say that you know every every server I\u0027ve seen drops delete bodies or doesn\u0027t pass them through and so in terms of interoperability the request body on undelete is pretty damn close to useless yeah even there but it\u0027s going to depend on the software you\u0027re running and so I\u0027m kind of okay with what Roy and Mark had proposed on it on this one if you want to preserve the use case then you have header fields I think there\u0027s also a question of if we I mean are these people who are doing these use cases they\u0027re not necessarily gonna change because we write something in the court document and this is more about guiding new implementations or people who are trying to do something in standard interoperable way and those clearly are interpreting things in a non-standard way right so my point is that if we\u0027re defining what it means to "
  },
  {
    "startTime": "01:06:30",
    "text": "interoperate then clearly sending no delete body is the way that you do that and depending on a being there and remaining there is not necessarily something that would be advisable now of course people who do these things and will continue to successfully put bodies on delete messages are of course free to do so but it won\u0027t be following doing specifications anymore I think that\u0027s okay oh I agree if Juliana so sorry did you wanna jump in Gillian I think if we make a normative change it\u0027s not something that in my mind is clearly allowed right now we need to have a very and I haven\u0027t heard that yet and if the reason is that intermediary is actually I think you need a separate issue to clarify that I don\u0027t think they are and that also affects the whole extensibility story of HTTP so if there\u0027s any doubt about whether intermediaries are allowed to drop the crest bodies on methods they don\u0027t know we need to clarify that and that\u0027s much more important than this issue Julian that\u0027s not what\u0027s being asserted it\u0027s not that they\u0027re dropping bodies on things that they don\u0027t know it\u0027s they\u0027re dropping or not in making available or rejecting bodies on things that they do think they know because they have defined semantics substantial I just yeah I feel like there\u0027s a dangerous thing if we start disallowing bodies everywhere I mean I\u0027ve written with apps I\u0027ve you know I\u0027m sure I\u0027m gonna get in trouble for Spiegel here I\u0027ve put bodies and get requests and I love doing so one of the reasons is that semantically if what I\u0027m doing is requesting something I don\u0027t want to just push all of my push bodies uh sorry I don\u0027t want to make every request that contains a body end up saying saying post on it I think that means that all of the other HTTP methods become pointless so yeah I thought it\u0027s worth I think that it\u0027s still worth having bodies on get requests on delete requests and so on insofar as those requests and matching the semantics that are meant by getting delete but but you realize that that\u0027s not HTTP anymore you\u0027re not getting any value out of the ecosystem there yeah the right the problem that you run into is that there\u0027s something there is TCP or SS or TLS connections and then on top of that is HTTP and the only thing that differentiates the two are the set of agreements we\u0027ve made to restrict and what we send so I understand G are what I really want as a search method but I can\u0027t define a new method alts I\u0027ll just send get instead and I\u0027ll send stuff in the body there\u0027s a reason we didn\u0027t allow that in the first place it\u0027s to make the URLs valuable and linkable "
  },
  {
    "startTime": "01:09:33",
    "text": "across the web that\u0027s why it was there so as much as I appreciate that use case I deliberately killed it okay yeah it\u0027s it\u0027s not it\u0027s not and feel free to blame me for that or timber timbres Lee or anyone else Tim it Tim actually had separate methods but we have talked about bringing search back that\u0027s yeah searches searches a different method is it just it\u0027s not the sense that you have a good reason for I know there are other good reasons to not allow it so I get I don\u0027t think it\u0027s worth is arguing about it here but it\u0027s not argument and one point I\u0027d like to bring up to that is if we do you know if you did want to specify that yes you can have the body in there I think we we do need a good explanation of how we understand the semantics to make it interoperable I think that\u0027s the part of the bar that you it can\u0027t really satisfy because these are all nonsense you use cases yeah I mean that\u0027s that I I guess I just don\u0027t want all of my requests to be post requests like if that\u0027s the part that we go down for anything that\u0027s not that\u0027s not generic I sorry anything then that\u0027s what we have and I think that\u0027s it sounds like that\u0027s your vision of what HP is not at all not at all the our intent here is to make sure that we define very carefully and very clearly what the semantics of a body and requests are for all the methods we do to find and that\u0027s a case-by-case thing so it seems like yeah it seems like we should kind of wrap this up we have some disagreement among the editors but I think it\u0027d be good to get a good sense of the room of what the working group wants to do on this we\u0027ve had some comments but not a ton so I think you\u0027d be perfect to take a hum on this yes okay so essentially the two options are do we allow you guys going out to be able to home from yeah very good all right so they\u0027re gonna be two different options first is that we do not allow bodies on delete or essentially save the client should not send this we have it essentially conformed to to get format and then the other option is that we have it conform more to something like options and you can have a body in there so if you prefer that delete stays like get please hum now wait wait wait sorry you said space not yet that\u0027s that\u0027s not cool because you know making a change here so it\u0027s not staying like it would be change yes yes yes should delete be specified to behave like it okay so if you would like to lead to be specified to behave like it please Tom now okay and if you would "
  },
  {
    "startTime": "01:12:38",
    "text": "like it to not behave like it but to be able to have a body please hum now and Julian I assume you\u0027re humming for that but okay so I think within the room here the consensus seems pretty strong in favor of having it behave like get and so I think that\u0027s what we\u0027ll go ahead with now and yes we\u0027re adding that into the github thing thank you everyone so so just for the record we had one hum for in favorite bodies from the jabber room yeah okay that\u0027s good to know and we\u0027ll confirm that on the list as well how do I go back now can\u0027t see it I can\u0027t what okay I\u0027ll just do this control panel all right next up our old friend updating stored headers sorry our old friend updating stored headers so we\u0027ve had a fairly long-running discussion here of what to do about updating stored headers in a cache so when a 304 comes in and has new headers the current specification says that you update the stored copy with the new headers and it turns out that that is not always done consistently by implementations a few implementations don\u0027t do it at all which is to bug but especially the browser\u0027s omit some headers from the update and we\u0027ve been going through a discussion of why that is and then what the right design is and you can see it\u0027s been a fairly long discussion I wrote some tests to figure out what people actually did we got gathered some date on that and I think this is the most recent proposal oh and there was a comment an hour ago which is to replace the third paragraph and of course that\u0027s contextual thanks mark I think we\u0027re talking about this proposal here where we say something like due to their semantics updating some header fields can result in the cached estate becoming consistent invalid depending on how it is implemented for example updating content location might make a cache response incorrect we\u0027re updating content range of might might be unrealistic after partial responses have been combined likewise changing the value of a header field might have external effects that the cache cannot account for for example a user agent cached or as a pre render artifact instead of the raw bytes of an HTTP response changing the content post factor is not possible and possibly dangerous and so I think would it go No "
  },
  {
    "startTime": "01:15:40",
    "text": "thank you thank you in these limited situations a cache may omit the headers listed below from updates servers should not send updated values for these headers in a 3 or 4 response if the news items are critical to interpret the cached response whether they should generate a full 2-xx response and so I went on to say I\u0027m only comfortable with this approach the list is limited and relatively static I did as much digging as I could through the the browser revision histories and discussions and I think that there was a lot of cargo cult thing around old 26 16 and even 26 28 68 language around cache updates where people misunderstood it and then applied it unevenly and as a result a lot of headers are exempted from updates that don\u0027t need to be and I in the cases I talked about before work with content ranging content type and things like that I completely understand why the browsers want to exempt those headers but there are other headers like everything starting with X content is exempted which doesn\u0027t really make sense or content - and I think that\u0027s because they thought that those indicated what entity headers were of course we removed entity headers from Biss that that\u0027s not a concept in HTTP anymore and so it\u0027s really just talking about what the right list of headers are to include in this exemption and so I wanted to flag this for discussion to see if folks are on board with this general approach and if so if we can get a little progress on the list of headers to exempt setcookie and set cookie to a really interesting - by the way Martin you stretching your legs no I wanted to talk to Andy first madame Thomson I might be able to help with setcookie is it because what\u0027s happening is that the cookies are being taken off as the response comes in and acted upon at that point and then there\u0027s no expectation that cookies will divert will be available to cache responses right and this is this is an artifact of having a deeply integrated stack rather than one that is strictly layered right so I don\u0027t know that that\u0027s strictly a problem it\u0027s just an interesting side effect of the way this works is that the browser\u0027s effectively acting as an intermediary that\u0027s stripping off cookies because it\u0027s already dealt with them and when things request things from the cache they don\u0027t care about cookies because we know that none of those things care about course it\u0027s taken as a processing instruction almost right right and that is fairly consistent with the sort of way that cookie works in the sense that it applies at the time that it arrives not not sort of any any time thereafter it\u0027s not attached I think it is but when you start thinking about things like service worker and and somebody more advanced things people do with fetch things change I know and service workers always make me nervous when I start to think about these there\u0027s any good answers here but that "
  },
  {
    "startTime": "01:18:42",
    "text": "may be the model that we\u0027re applying here that\u0027s all what I found interesting is is that you know one could maybe make a safety or admit that it\u0027s not safe to cash that cookies because you know then they get reused but as you can see a lot of intermediary caches do cache them so that doesn\u0027t really you know hold hello yeah after that changed in the last set of tests here there\u0027s a little weird yeah I\u0027d agree with Martin it\u0027s most likely there they\u0027re causing an alert trigger on as they\u0027re being processed right they\u0027re probably still in the in the cached presentation that it\u0027s just not no I didn\u0027t know if we store that or not but we probably do yeah yeah but putting aside the exact headers the overall approach is this is this a reasonable way to go do you think yeah you got a deal with the world as you as you find it this is kind of what we would do anything yeah I will have a look at our implementation to make sure that this is okay obviously blanket prefixes are not great we\u0027d rather not have that sure yeah I\u0027m sure we can fix it okay so what I might do is the next step then is to put together a PR with a very conservative list and then we\u0027ll you know talk about the additions one by one we need to loop in Ottawa need to loop in you know folks on the browser side so all right thank you where did I go next up oh come on okay Julian um this is issue 163 which is a red ID 52:36 I\u0027ll open that up oh dear oh come on yeah right and so I think there was a thread which involved Roy this red Roy no I "
  },
  {
    "startTime": "01:21:48",
    "text": "let\u0027s page Roy back in I think it was you could be wrong I don\u0027t know the discussion in with Roy yeah not exactly sure I did just brief you\u0027re looking at the correct text it\u0027s not correct so in the sense that if you have if you have a validator that\u0027s based on content md5 for example or a hash of the content it is going to be the same validator no matter how many different media types you have for that representation so you may have multiple yeah you may have the same image for example in different media types based upon what which particular browser accepts what particular media types um like that which actually represent the same number of bits it\u0027s just that one browser called it X experimental image and last one and a more recent one calls it application image whatever first just purely because of versioning so the exact same content exact same bits that have the exact same validator and that\u0027s perfectly normal okay so make sure there\u0027s nothing else in the thread that many times and today I learned something I didn\u0027t realize that the validator only applied specifically to the contents of the body if that\u0027s not clear can we make it more clear I thought it was clear no if I don\u0027t know I died we did certainly put a note in the in this that in this issue that we should check it to see if it\u0027s good yeah I mean last I recall it was pretty clear but you know pretty much all the mistakes sir yeah we clear to me this is the problem that it\u0027s in your head but it might not know I\u0027ll check as well but I think this is this is a fine resolution to that right I need rewording it\u0027s a little it wasn\u0027t entirely clear to me what what it was trying to say so this might be helpful to I think this is why I said we can close this with no action I think yeah I think we can I think we closed it with no action other than maybe the editorial suggestion I\u0027ll take a look take another squeeze at making that clear okay thank you "
  },
  {
    "startTime": "01:24:50",
    "text": "sure editorial is fine yeah our old old friend 128 quoted cache-control directives so I did some testing again and found that different implementations handled quoting of cache-control director was pretty wildly differently and I suggested that how\u0027s that okay they should give us two mics but then oh nevermind but you\u0027re not using them like to tell me to use the mic and we had a long back and forth about this and I think yeah it\u0027s a very long beckons with about this this is another area where Julian I don\u0027t quite see eye to eye I think there\u0027s a proposal no there\u0027s not now there is can we resolve this with nothing must not generate and should accept quota cache control parameters Julian well I my question there is is that why do we need to change the why is it much much what is the compelling reason for it I don\u0027t see these other these applications breaking unquote they don\u0027t pay attention to quoted values which can break people\u0027s expectations about caching and there\u0027s a lot of them yeah I you know we found a bug in Apache 2 which is totally cool like I came this close to getting it committed and then I didn\u0027t oh that\u0027s not been committed yet no it hasn\u0027t been committed yet so it\u0027s it\u0027s there it\u0027s proposed it\u0027s ready to go we just need to give it plus ones ok I think Lex well I just I I don\u0027t think we have put it because it\u0027s been open for a long time and we haven\u0027t made progress on the issue so one way it would be not to do it I think that should be the default in the spec not to change things you don\u0027t have very broad "
  },
  {
    "startTime": "01:27:52",
    "text": "consensus that something needs to be changed tell me what more data you need I will collect it well we had that discussion I think with Matt\u0027s trying to figure out why their father actually preached things that way and not the other way and we didn\u0027t get reply to the to the actual question so the underlying question conforming to the tweet these things currently as suggested by the spec why did you do this and why don\u0027t fix it and I think my question right and my position is is that for whatever reason over the last 30 years almost no sorry you\u0027re talking about the changes that we made five years ago where we simplified the grammar to allow talk and quoted screen everywhere that\u0027s different from 2616 right so maybe we made a mistake then but 26:16 allowed both - it just did a different way right well we failed to communicate we and our predecessors although that includes Roy so I failed to communicate well enough to implementers to implement this correctly and the implementations don\u0027t behave well in this with this kind of input and as I understand it especially the client implementations don\u0027t want to change the way they behave regarding this because to them it\u0027s all risk and no reward they are compatible with the web as its deployed why would they change their code just to align with the specification that was never implemented and so to me the most obvious thing to do is to change the specification to match the reality of the internet how they manage to keep a certain feels and then not to do the remaining 2% so I\u0027m pretty sure that for any puzzle that you can show me that it\u0027s extension parameters correctly and does not treat the predefined characters as sort defined around as defined by the legislature did these specs it\u0027s either intentional or a buck and if it\u0027s intentional I\u0027d like to understand "
  },
  {
    "startTime": "01:30:53",
    "text": "why they did that and if it\u0027s a BAC I\u0027d like to fix that have them fix them and we are talking about three main clients right now or didn\u0027t only tool with HP 103 sorry so can we time bound it somehow so we can get this you know they\u0027re by January would be at this point yeah that fix will definitely be committed at some point regardless because we\u0027re actually parsing it twice two different ways and that\u0027s just bad sure all right well if we can get alignment with you know at least a couple of parlors which you know really we\u0027re talking about cash implementations here so browsers and intermediaries and CD ends so if we get a few more online that\u0027s great so but maybe we should just open a few bugs and see if we make progress in a few months at least some indication that they would address them and if not then we\u0027ll revisit the issue yeah okay can you go thank you all right that\u0027s the last one we had marked as discussed let\u0027s take a quick look at the issues list to make sure we haven\u0027t missed anything um filter outs so barring editorial issues we have 44 issues open Roy and Julian just yell if you see one that you think we need to talk about now a lot of these are relatively straightforward or we have proposals for them that we just need to refine a little bit so do we want to talk about this one all right okay I\u0027ll open a couple of windows and then we\u0027ll I I thought that was I think well we have a proposal for that [Music] all right the this the the question about is is there a specific separator so what are you talking about yeah get rid of some of these right and I think "
  },
  {
    "startTime": "01:33:55",
    "text": "the proposal was roughly this and then we we talked about whether this is you know a must or not yeah I mean I\u0027ll back ultimately this is exact separator used when combining header fields it\u0027s issue 148 ultimately we talked about what we could change the RFC to make it look more clear or what we could change that would make it consistent for all all applications and I believe mark proposed a requirement is this should or must must not no sorry no may combine without changing the semantics of the message by appending each subsequent value after stripping the surrounding interviews to the combined field value in order separated by comma SP all right and we\u0027ve never actually said anything about what\u0027s is it should be just a comma or a comment a space or a comma in the amount of white space and we just didn\u0027t care in the past I I still don\u0027t care so if anyone cares this would be a good time to let us know I think that the concern is I understand it well I don\u0027t wants to have one way to do it so that he gets consistency between implementations I think the concern is driven that in pathological cases when you have hetero combination and space is is semantically significant for example you\u0027re doing things like signatures then it would be good to have one way to do this especially if your signature algorithm is combine all instances of this header and then sign that or you know do integrity on that you need one way to do it yes presumably they\u0027d be specified in the signature algorithm itself sure does anyone else care about this my my trial issue my issue would be any additional requirement here would imply that everyone who doesn\u0027t do that is somehow broken and I don\u0027t think that anything any implications out there actually care in terms of you know whether they state comma their one space or commas no space or common five spaces the reason for that is is frequently when you\u0027re combining header fields and they\u0027re right next to each other you might want just white space everything between the two for so that you don\u0027t have to recopy in a memory but that\u0027s a really implementation specific concern relaying for Chris lemons I care that we have precisely one way to do it I don\u0027t care which way that is okay I mean my impression is is that the vast majority "
  },
  {
    "startTime": "01:36:56",
    "text": "implementations do do comma space but you know and maybe I think it was discussed before maybe one thing we could do is not put it as part of a requirement it\u0027s a may but it\u0027s still requirement language but say the canonical way to do this is X you know divorce it from that requirement language a little bit right absolutely if you can give people a hand rather than a requirement that\u0027s fine too okay well we\u0027ll figure that out there anything else oh I\u0027m mark this needs data because I think we left this in a previous meeting saying we wanted to get a little data about what\u0027s out there but just to remind folks we had this this issue of you know header field names are defined as tokens and that\u0027s actually an extremely fulness of syntax and so the suggestion was maybe we can cut it down a little bit and I think folks latched onto that initially because they thought okay if we can constrain the syntax of field names then that has potentially some security benefits when you have strange characters and field names and then they\u0027re put into things like the environment or you know other places that can have surprising and sometimes dangerous effects and then I think we got cold feet on that a little bit in that folks felt that if we constrain the syntax in any significant way we could be breaking deployed applications yeah we talked about this in Bangkok concerns about compatibility we\u0027re considering an impact on a case by case --is and then yeah that\u0027s Willie said what H a proxy accepts we discussed it twice in nine cup now we haven\u0027t been there twice okay and then in 104 still seeking data for characters used in the world looking at the HP archive so I took an action I think to do that we have any further thoughts about that I just want to keep that on people\u0027s minds if we do discover that you know in the wild these meta characters or they\u0027re not delimiter s because the owners are accepted from token but the non-ascii not non letter non digit and common you know tokens are used are we comfortable getting rid of those or at least cautioning against them perhaps any thoughts I for one unhappy to eliminate them just because we already have to do it in the backend for security reasons right and if we could get that pushed all the way up to the registry so that you can\u0027t register them all or you have to have an exceptional whatever that\u0027d be good okay I\u0027ll do that work then I actually have to do that work for something else right now so I can put two things together no that\u0027s fine that\u0027s fine I think I think we\u0027re done so I\u0027m just stepping back I "
  },
  {
    "startTime": "01:39:56",
    "text": "think Roy and Julian and I are planning to get together around the quick interim in early February or late January and work on the drafts for a few days and try and turn out some of these issues and especially editorial stuff we did a similar thing during HTV bists and that was quite productive so we\u0027re hoping that that\u0027ll get us the point where this issues list is much much smaller and we\u0027ll have some drafts review in the working group and maybe around Vancouver so I he\u0027s starting to think about when do we do last call that that\u0027s my thinking yeah I\u0027d like to have all of the the substantive text basically in there by the time we finish our meeting and then we start rolling the process towards you know working group review and then last call and yeah I do suspect that we\u0027re gonna once we get all the stuff we know about now we\u0027re gonna step back and look at the documents and say oh we missed that - no we need to think about that so there there might be a couple of more phases but the last thing I wanted to talk about was the the the issue about a cheap HTTPS and quick the authority you can run with the numbers oh yes what is that issue sorry was there a jabber comment yeah relaying for Roberto Polly he wants to quickly discuss issue 99 scope of retry after okay that was the one that you were with the comment anybody have feedback on that thread yeah let\u0027s get that up I think my personal feedback and I think I put it in there is is that yeah we can\u0027t really retro actively define a scope for the header in a meaningful way that if you wanted to find one that\u0027s tightly scoped it\u0027s probably best as a new header it is defined as something that\u0027s vague and so it\u0027s gonna be used in a lot of different ways where it is used and so narrowing it down is probably problematic unless it\u0027s for a specific use case that says use the retry after header to do X so some are not in Johnson I put a proposal for what might work as text in here which is essentially that you just scroll past it there which is essentially along the lines of what you said recognizing the fact that you can\u0027t really retroactive we go back and define something here it basically says that when the server uses retry after it it it applies to that request that it may apply to other things and the client may use other information to determine to determine what other things that applies to but otherwise it it\u0027s kind of on its own and sort of suggests that heuristics may be may be your best bet without the "
  },
  {
    "startTime": "01:42:58",
    "text": "presence of that other information for instance if it\u0027s attached to a 503 often that is something that means that the server\u0027s overloaded or something along those lines and you might want to treat that as applying to all requests that you might want to make to that server but it doesn\u0027t explicitly say anything like that it just says use your heuristics or whatever information you might get I don\u0027t know if you want to consider incorporating that text or something along those lines but I think that\u0027s fine I think we\u0027ve known we\u0027ve had this scoping problem not just for this but for a lot of our protocol artifacts for a long time yeah what I would like to do is probably put in the considerations for new headers and status codes and things think about scope very carefully and give some examples so that we don\u0027t dig further I think that might be a very good thing to have in general do you want another issue for that sure yeah you know I\u0027ve got another one for you okay I\u0027ll let the editors decide whether they want text along these lines but I think this text is fine I mean ya feel freedom rewarded and okay thanks umm so the issue you were referring to Roy oh sorry Roberto says if you think it\u0027s worth writing a draft on that I can try I don\u0027t think it\u0027s necessary I think we can take this text up is it open still I didn\u0027t think we closed it yeah oh yeah we open their implications of establishing Authority ah you open the new one oh did I all right yeah you might if you want to discussion go back to the one I for or from okay yeah which is closed yeah I went and thought about this and then realized I needed to get stayed again so it\u0027s probably good that we\u0027re talking about this yeah so so what we\u0027re working on right now literally in what I was drafting I\u0027m flight over and I read it last night and it\u0027s not as good as I wanted so I didn\u0027t submit it anyway the the notion of authority in for HCP and the notion of age what is an origin server in HTTP is sort of in meshed in the in the old way we think about the Internet in terms of using TCP and HCP you contact an origin server on a certain port and that defines the authority for four HUP four HUP s you contact a TLS listening server on that specific port using TCP and that defines the authority for HTTP URLs but the reality is there are lots there is a "
  },
  {
    "startTime": "01:45:59",
    "text": "specific way defining what the what the authority is in sense that we define the host of the of the origin server and the port and this the scheme as defining the authority for HTTP but then for TLS based services what occurs is a a certificate handshake which is applicable for the host regardless of what port it comes in because the port is not a trusted interface and of course Martin can explain this much better than I can anyway so what we\u0027re trying to do is rewrite the definition of what the HTTP authority is for HTTP so that it is applicable to not only define which server you\u0027re talking to but also allow things like alternative services in h3s use of quick to take over that authority will be able to represent itself as the authority even though they\u0027re not talking tcp over the specific port so it\u0027s it\u0027s basically redefining it as here\u0027s what authority is means for HTTP but here are these other ways in which that is also accomplished not deprecating any of the existing ones so that\u0027s the goal hopefully I\u0027ll get something finished tonight or tomorrow and of course won\u0027t be ready for review until this later in the quarter but that\u0027s hungry working on right now and if you have anything that you want to be absolutely sure I include in that feel free to add it to issue whatever issue this is which one is it - 37 - 37 yeah okay take word time so thank you wait one more presentation okay thank you right thank you all so Roberto do you want to press the magic button hello yes we cannot is volume try [Music] [Music] "
  },
  {
    "startTime": "01:49:40",
    "text": "[Music] [Music] just express it in Delta seconds so it\u0027s compatible with the retry after next so this is the response header that you will get in your response there is a mandatory part with the number of total units that you have got in a given time frame that we named window their remaining requests what units that you have in your window and how long out annual before the window expires and then after mother repart you can express up optional parts with multiple quarters for example in this case the first optional part states that you have 10 units every 5 seconds the W stay stays for window and then you are fully limited to 80 units per minute the specification support even comments in our cloud part the nice thing is that you can always ignore the optional parts and limit the parser to the mandatory part then we change when we are going to [Music] consume all the second policy parts instead of having 10 6 \u0026 3 you will get the information about the second policy so the response the mandatory part will always contain the data from the policy that is going to expire first next our technical choices the first one is to support only Delta seconds so you don\u0027t have to take care of enthalpy skew and adjustment issues just like they retry after that the second syntax what is expressed in units that may or may not be requests so that you can support multiple quota policies and you have "
  },
  {
    "startTime": "01:52:43",
    "text": "comments the semantics is quite flexible you can express dynamic policies sliding window and concurrency limits we do not mention infrastructural concepts like connection because connection HTTP to our pre-cana are multiplexed so we melt it to express just service information just like HTTP next we have other issues leading inputs well the first one we have discussed above is related to the reply after stuff so we want to meet to the final tripping school we may want to define header dependencies we might use structured headers to define the specification we may want to use an upper bound for read limit result which is Delta second and there have been some discussion about Hannah names we can postpone them once we adopted specification next thanks I have to thank a lot of people for the initial contribution that is mark there is many other guys and thanks to alex Martinez listen here and they hunted me currently and what questions I\u0027m here for you seems like this some of the things we\u0027re talking about priorities share some similar problems we\u0027re trying to express a priority to somebody who will hopefully take action to it and caching becomes really interesting the boundary by which we say where the implementation of HTTP or or where that interaction actually stops or begins is interesting is is the origin to the reverse proxy considered in this case for instance I think there are a lot of details that are similar here that we probably need to address in concept together yes I agree generally we think that the headers are applied by the origin server "
  },
  {
    "startTime": "01:55:45",
    "text": "the entity that knows the service limits and knows the service status for the baguette service and we find many considerations on that it\u0027s interesting if you can contribute and we are really open to the discussion our our goal actually is to put everything on a common ground because this kind of header can work only if they are the semantics is standardized while currently we have a high proliferation of header and this means that clients just ignore them because clients don\u0027t know which odd header they with limit headers that they can found I can\u0027t in some environment there are 12 but client just can iterate looking for 12 possible between headers so there and one of my concerns here is that rate limiting can be twisted to be a form of denial of service attack especially if your combined with cache poisoning and being under specified aware about where this policy applies and who kills it or eats it or what where it\u0027s not expressed becomes a very important security consideration so I think that we can\u0027t afford to avoid this if we would speck it thank you I\u0027m gonna close the queue and I\u0027d ask the remaining folks to be brief mum Thompson I I hope that you were paying attention to the discussion about scopes previously Roberto not this Roberto yes because I think that\u0027s that\u0027s a highly applicable here this is one of those cases where these things will apply across different scopes and it may be that you need a scope parameter and in this I\u0027m thinking about the case where you have a forward proxy that applies one rate limit and then you have back end servers that are responsible for parts of the space and each of them have independent right limits and when you get a response back you\u0027re gonna get multiple right limits back and some of them will apply across the entire server some of them were quite fly across like it\u0027s gonna get a little complicated to work through all of those things but I think it\u0027s workable with a little bit more expressiveness in in all this I am I do share some of Roberto\u0027s concerns about the denial of service thing relaying for Chris lemons it\u0027s going to be important to think about per hop considerations because in some cases a proxy needs to communicate "
  },
  {
    "startTime": "01:58:45",
    "text": "to a client that a given request is out of limit and in some cases a proxy might wish to retry a request after the limit has expired transparently to the client and then relaying for Thomas Peterson is there a reason why this spec isn\u0027t making use of structured headers this could apply to both the optional fields and replace three headers with one okay thank you so I had two quick questions one for Roberto one for the room Roberto there\u0027s a as you mentioned there are a lot of folks who are doing this in the wild especially for things like http-based api\u0027s have you have you engaged with those communities have you had discussion with them about your proposal at all yes the italian api co system so we had to engage with service providers to get the implementation of those hazards there are a couple of cloud providers they are working on that there is the co-editor that is from Chris Kael API get away from Reddit and so it\u0027s we are working actually for getting consensus and get implementation thank you and the other question I had for the room is who has read this draft ends up okay I\u0027d say it\u0027s a smattering of the room right okay I just it\u0027s Roy fielding I wanted to add that it\u0027s almost identical to what the kid hub API uses already except to github version of those same header fields is much simpler okay all right I don\u0027t think we\u0027re ready to do a hum or anything quite yet but but this is something I think is definitely on our radar what could please continue to work on the draft please continue to engage with the working group and and we\u0027ll have more discussion and we\u0027ll see what we said next time okay Thank You Roberta yes thank you very much so I think we\u0027re done for today thank you all very much we\u0027ll see you all on Thursday thank you "
  }
]