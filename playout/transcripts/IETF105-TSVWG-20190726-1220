[
  {
    "startTime": "00:00:04",
    "text": "we starting there but now are we okay and this is going to be the TSB WG working group please don\u0027t leave if you think you want to know the group because this group will be good and fun can you hear me I found an on button yeah okay I can walk around with this we are organizing the second of the TSV WG meeting thoughts is the transport area working group we have an agenda uploaded we have a note-taker over here and a backup note-taker is perhaps okay we have a primary note-taker that\u0027s okay we will need a jap ascribe partly because one of our working group chairs your notice is not here so could somebody volunteers a jabber scribe place over there Chris [Music] okay um David do you want to see if your mic works okay so we\u0027ll talk about the agenda here briefly here\u0027s the note well reminder we have three three major items for the agenda today we\u0027re going to start with the elf 4\u0027s drafts of looking at Gogol this meeting is to figure out where we are in terms of readiness of those drafts working group last call there\u0027ll be a number of presentations here the what\u0027s what\u0027s on the slide may not be exactly what we do in terms of slide decks although Bob wins a prize because he\u0027s he\u0027s almost first up and let\u0027s see the just-in-time psychometric I think was under ten minutes this time the some congestion experienced is second major item we do today and then we are going to try to leave some time down at the end for discussion of some proposed new work on DC CP multipath as we get started here we\u0027re going to explain exactly what we\u0027re going to do on how we\u0027re going to conduct the l4s discussion anybody want to bash the agenda we will be enforcing "
  },
  {
    "startTime": "00:03:07",
    "text": "some cut-offs in particular I\u0027m quite certain we could spend this entire session and probably until four o\u0027clock today discussing everything there is about l4s that\u0027s not going to happen there will be there will be a time cut off and apologize in advance to people who are going to get cut off at the mic lines based on what I think is about what what we think is about to happen but we are going to make sure that there is time for for the SCE presentation today and we are hoping to get to DC CDC CP multipath you\u0027ll see this man is david black in case you don\u0027t know him and I\u0027m Gauri Fairhurst where\u0027s Eddy as we said his remote mmm-hmm just when I need them it\u0027s not going 40 yeah that\u0027s okay ma\u0027am fortunately we got to the prom Pierre is serious you\u0027re the manager good does anybody know them thought that the magic opening me open a new tab sequence on a Chromebook all right control what control T control tenant guard let\u0027s try that I can start anyway counter okay I shall tell you a little bit how we\u0027re going to run the l4s part of the discussion today the this part we\u0027ll start with a quick review of the an IP our discussion that we\u0027ve seen on the list I shall say before I said before anything else is said this is what the chassis of the IP are staring down at the mailing list if you have IPR concerns please read the IP are associated with the documents in the tracker and please consult people who understand IPR concerning the way in which you view IPR we will not make a determination but we would like to summarize I\u0027m just summarizing which me after summarizing Bob will present the "
  },
  {
    "startTime": "00:06:09",
    "text": "current status of the drafts which have been asked to go to Wickham group last call these drafts were brought to the working group I think in 2016 in Buenos Aires if you remember rhinoceros and they were adopted in Prague so what No thank you for the detail adopts in Prague and now we consider that it might be an appropriate time for this working group to ask are these documents ready for a working group last call we need to have a working written last call to judge consensus we do have a working group last call to judge technical issues only when the documents were complete a working group last call when we consider progressing them and documents can go through multiple working group last calls or simply returned to the working group after that process so in no way just this terminate the process but it\u0027s the beginning of the end of a or perhaps at least the end of the beginning absolutely okay so there\u0027s been some recent discussion on the list and offline about IP our discussion I\u0027m going to quick summarize that but I first need to put in disclaimer you\u0027re looking up chairs are not lawyers this slide deck does not contain legal advice if you want legal advice you need to talk to a lawyer your chair is the ietf disclaim all responsibility for any legal consequences of using the information this slot in in in these slides to make decisions that involve legal matters okay hang on it should be okay no idea but I hit the right button here also works okay so the history our discussion is a toka raised concerns over some defensive suspension clauses in the Alcatel Lucent IP IP IPR declarations broad conditions was unclear whether the declarations superseded the previous IPA and terms in a previous IPR note this isn\u0027t resolved both when the apparently still apply we summarized discussion that was on the list you\u0027ll need to go for the details there\u0027s a link in the slide deck we can go find that the terms that we saw in those IPR declarations we\u0027re similar to terms that we\u0027ve seen in other IETF IPR declarations that\u0027s not a statement about good bad right or wrong it\u0027s simply a factual statement that there is similarity okay relationship of IPR "
  },
  {
    "startTime": "00:09:10",
    "text": "to the draft the 8 qm couple dual q-- draft is a framework for coupling a QMS with nan-oh imitation appendixes Bob Brisco who\u0027s been have an involvement posted his analysis the list quote he quoted extra exhibitor from that is the claims cut all cover non-essential and non-preferred aspects of a QM dual Q coupled we\u0027ve got a list here I\u0027ll turn it up a cake of a tournament ations of Aiken dual Q coupled you can find a pie - and a pen describing pendeks a of the draft curvy red described in Appendix B with there\u0027s been discussion the working group that\u0027s made it pretty clear that FQ could be used to do this and there may be others all this is just me provided as as information every participant needs to make up their own mind about applicability or lack thereof of the patents to the drafts we\u0027re talking about and level of concern to be placed on the IPR the contents of the IPR notices in alcatel-lucent any questions oh I love seeing empty Micra lines after legal nonsense okay with that I think Bob is up Bob okay you need to think about how let\u0027s see how many slides do you have here 21 okay yeah please please please be please make good use of time because yes we need all the background but we really we need to spend the time on discussion yep okay yeah it\u0027s about this redraw should work we think try that never worked bingo right so I\u0027m gonna take a bit longer to explain l4s background because the sort of heat around this debate may have encouraged some other people to get interested so the motivation for l4s is ultra low queuing delay for all internet applications with the emphasis on all the idea being that by changing TCP that\u0027s the problem so it includes capacity seeking and the sort of performance we can get is something like 100 200 microseconds over the Internet at the median COO delay as you see there "
  },
  {
    "startTime": "00:12:13",
    "text": "a 50 this plot is a plot of Q delay on the horizontal axis in milliseconds if you can\u0027t see that and log of the percentile on the vertical scale it\u0027s called a cumulative log cumulative distribution function and the tail is important this is the real message for this slide that for particularly real-time delivery you need the higher percentiles to not have high delay otherwise most real-time software will buffer enough to be able to pick up that tail and so getting the tail down to in this case 8 milliseconds at the five nines percentile is important probably wouldn\u0027t buffer to five nines you\u0027d probably buffer to three nines or to nine something like that and and just lose the rest the other interesting thing that\u0027s important at this slide is well there two more interesting things firstly this is with really hammering the link it\u0027s in there\u0027s two queues here and it\u0027s there\u0027s 300 web sessions per second hitting this link on in each queue so 600 web sessions for a second with a range of flow file sizes and all the rest of it details are all where I\u0027m looking to read them out and the other main point is that it is data center TTP or what\u0027s now called TCP Prague but this was done with the data since TCP that gives you the benefit it\u0027s really the end system that gives you the benefit not the queue all the queue has to do is have a ACN marking threshold for the N system to bounce off if you like and as you can see that it\u0027s the blue one is there is the one from David sense DCP so it\u0027s about an order of magnitude at every percentile and that\u0027s the trick it\u0027s because it\u0027s got smaller sorties so you can have both lower delay in the queue let\u0027s parents in the queue and still full utilization right moving on to coexistence which is going to be a theme throughout the the problem is that because of those smaller sore teeth it\u0027s more aggressive and so one solution is to use the dual queued couple they um and that allows you to do this without flow inspection if it has two queues and they\u0027re coupled together in such a way that there\u0027s a squaring in the congestion coupling that means that the l4s marking is more aggressive to counterbalance the more aggressive congestion control you can see the P versus one of the P sort of get the "
  },
  {
    "startTime": "00:15:14",
    "text": "laser pointer which I guess also I don\u0027t know which one to point that I\u0027ll point of this one the P versus P squared there and then one over P versus root P right next the where buried this in to the slide deck it\u0027s always been possible and that is to use an FQ system for coexistence to solve the coexistence problem so if Q X X X where X X X might be coddled pi whatever so if you want to do l4 s at an F Q X X X system it\u0027s a simple patch put FEC t1 mark with a shallow threshold Aram Eric the demos a put this code into Mecca Caudill quite early on and then you you base your marking on the immediate cue not on the stateful thing that\u0027s going on in Caudill or pie or whatever that\u0027s for the classic traffic Eric Eric by the way didn\u0027t didn\u0027t do it on FEC t1 he did it just on a PCT but it\u0027s a simple thing to do it just based on east t1 i\u0027m web added a description of that into the offerors architecture document right so that\u0027s the end of the recap implementation status gradually getting more and more implementations the transport protocols I\u0027m not going to read this all out you can read it in your own time just highlight that VBR b2 has been added to that as well as and TCP progress being updated I\u0027m gonna give more detail on that by the way you gave me 15 minutes and five minutes and the five minutes is sort of been subsumed in these slides if you like yeah in addition we we we got through our piece faster so I\u0027m going there\u0027s some components of the transports that are generic across them all and can be used our things particularly all note there we\u0027ve now got a freebsd version of echo ECM from Richard J Omega an ongoing work on the start up with paste chirping and also a lot of progress on stuff like a window or come up to that progress in the cable industry on chipset implementations for cable modems and see MTS\u0027s with talk of products later this year in this will often time frame the Chilkoot couple back here and we\u0027re trying to get that into the mainline of Linux it\u0027s been submitted once and going for again very shortly hopefully and the Linux patch for fq l 4 SF q code like that not going to go through this this "
  },
  {
    "startTime": "00:18:14",
    "text": "is just a list of links so you can find the code for those things from the previous slide that are open-source they\u0027re not all open source on the previous slide and that there\u0027s a link no there isn\u0027t I\u0027ll come to that there\u0027s a home page Angra right just a brief report back on the hackathon L sorry Andrew I just wanted to ask are you aware of anybody working on putting off for air support in to be special Q disk that is used bottom level of the lummix Wi-Fi stack you\u0027ll need to get close for the mic sorry Andrew but Gregor are you aware of anyone working on putting l4s support into the special cutest that lives at the bottom of the Linux Wi-Fi stack because you can\u0027t put a normal Q disk on a Wi-Fi interface and Linux anymore I\u0027m not aware of anyone doing that yet I\u0027m not sure ahead time and I\u0027m and I\u0027m pretty sure that the other person what the other of the four or five people who could do it who\u0027s sitting in the room doesn\u0027t hit Tiny Tim okay you\u0027re not coming for Mike okay so report from the hackathon Koon brought a test bed over from on the fly and also the SCE team brought their test bed over we put the two together so the big highlight of this hackathon was two teams working together on this in in a professional way I should add thank you very much right and managed to get some Flint regression tests done that is running regression tests on tests that Jonathan specified to see whether putting our press in there made any difference and as far as we got it didn\u0027t make any difference that is our first didn\u0027t make any difference so that\u0027s having up an elf Ross node before and after you coddle no than the embarrass orders but a lot of problems with the limits colonel during that hackathon I won\u0027t go into any more details due to lack of time as I said Richard chef Feniger did a freebsd a korean ecn implementation michael I should add was not involved in the implementation he was there as the sort of gatekeeper of FreeBSD to make sure all Richardson do anything silly and we had our first accuracy and interrupt over the internet between Linux and FreeBSD so two working together they "
  },
  {
    "startTime": "00:21:14",
    "text": "both had the same bugs that personally makes them easier to fix precisely they both got bored reading this back at the same point still work talk about the supply cat window and also paste chirping was integrated into the ns3 implementation that\u0027s still not open but hopefully very shortly but I have said that before right you wanted a bit more detail on TCP probe pieces this is an update of a slide I presented at ICC RG in March there\u0027s a few differences on it but the main thing I want to highlight is obviously that TCP Prague column but this also shows that some parts of it or quite a few parts of it the majority of parts of it are actually in base TCP not in the congestion control module and it\u0027s sort of reusing parts that people are doing for other things I guess the the obvious thing to that people focus on is the stuff that isn\u0027t green and we have now got a working implementation of scaling down to a window below 2 and below 1 and if that got 2.2 of a packet so facing down over five round-trip times and this is going at 300 micro second round trip time so that you can actually not just build up a queue in order to do that that\u0027s more per datacenter work and been talking more about our ttv independence but haven\u0027t done any more on it and in terms of implementation then the big open issue which i\u0027m going to talk about is reno friendly if there\u0027s a classic ATM bottleneck I\u0027ve got a slide on that right couple of slides on recent developments the dual PI squared implementation has largely been unchanged for quite a quite years now but we\u0027ve been changing the scheduler over to weighted round robin and also we\u0027ve put a management shim if you like on top of the parameters so that you can put in to human Rieman understandable parameters the typical round-trip time the max round-trip time and it will calculate all the sort of proportional integral controller parameters for you and the maths is in the internet draft on how it does that in pseudocode but i should emphasize that for the internet it\u0027s zero config you know this is for if you you were having to reconfigure it for some different scenario but the defaults work just fine for the internet "
  },
  {
    "startTime": "00:24:14",
    "text": "ii recent development all the other stuff going on is posted a new draft documenting the docs askew protection function that\u0027s not intended for consensus at the ITF it\u0027s just saying what DOCSIS did so that it\u0027s openly available in the ITF and the emboldened phrase there is the most important bit there\u0027s an objective definition of what your flow behavior has to be in order to avoid being rejected as you go into a doctor\u0027s link so how what\u0027s the sort of maximum aggression that you can still get into the low latency queue so just to emphasize it\u0027s not one of the core of elf race drafts it\u0027s not even on a tspwd jar draft you\u0027ll probably go into the independent stream mullet it\u0027s it\u0027s been accepted but it\u0027s in the cube and the the overload protection that\u0027s in the dual queue draft would be a sufficient alternative but it\u0027s this is this is perf la vie queue protection function so it kicks out particularly it will be how you flows but you have got a sort of bulk overload protection as a basis and it\u0027s really I guess part of the l4s experiment to see whether it\u0027s necessary to have per flow protection much as I suppose you could say the internet experiment has determined whether we need per flow rate control for the voluntary compliance with TCP friendliness you know it sort of that has determined that we don\u0027t really need per flow rate control the el Faro\u0027s experiment will determine whether we need purp low latency protection or not or whether the inherent incentives for yourself are sufficient - you don\u0027t want to run your own latency but this is obviously more for accidents and malice right I won\u0027t go into how the algorithm works because we\u0027re short of time because I want to get on to these issues a little bit of history about the number one open issue I believe actually 3168 ecn in a FIFO so if you have an a QM that behave like I\u0027ve said that obviously 3168 says and you\u0027re in a share Q and D see TCP or TCP Prague or quick Prague or whatever competes with existing TCP friendly traffic is the world going to collapse and history of this we we chose the UC t1 code point back in 2016 knowing full "
  },
  {
    "startTime": "00:27:17",
    "text": "well this could be a problem thinking that it may not be a problem because all the academic studies that showed that there was no deployment of such readers or we thought they showed that then in fact only a few months later Padma boomer Apple did a study published a study in mapache which the slide the black part of the slide there shows where there was C on the Internet at the time sort of dismissed it is probably fq coddle but the the controversy around this as made us think well yeah actually that is not a very scientific assumption we ought to check that so sort of the greys have not come out on this there\u0027s dark gray and light gray on this but there might only come out on though yep so as I said what if that assumption is unsound and really we\u0027re currently at an uncertain state in the in the left hand bubble where there are a couple of CD ends who are doing testing looking for these these CES they have been found I\u0027m not gonna identify here they are I didn\u0027t actually ask whether it was okay to identify who they are but I\u0027m not going to say I\u0027m also not sure whether even when they get results they\u0027ll be able to tell us or even you know tell anyone but but but unfortunately layer thirteen comes after layer or you know you have to get results before the lawyers alas accept questions on whether you\u0027re allowed to release them and so we have devised and test on how to look for these these raters once we get the results of the tests if we get the results so that\u0027s that\u0027s the sort of ground truth side of it what is on the internet at the moment then there\u0027s so that\u0027s more like prevalence and then the quantify flowing balance is more like their harm in other words the risk is a combination of how much of it is there and how harmful is it when it is there and so the next side we\u0027ve got some measurements on how harmful it would be when these flows join each other in a single cue Jake I J : I just wanted to self-identify Akamai has been running a few tests with me seein on the internet and we have observed EC ease in the while we are not sure where they\u0027re coming from it\u0027s we\u0027re still looking at it I hope "
  },
  {
    "startTime": "00:30:17",
    "text": "maybe one day if I have to have to to present something in my party about it but we have not proceeded to that point yet thank you yep so Jake it\u0027s bit hard to hear up here but you\u0027re saying that you see some easy unmarked traffic yes obviously we so we\u0027ve seen specifically what I was looking for on the download was echo the echo response right so we are we have some production traffic being served with ecn enabled and on those devices that we put up I was looking to replicate the the Apple results with Argentina and France it\u0027s hard to tell whether flows that do not see an ECE are uncongested or don\u0027t have an AQ m and path but we do see all of the servers that we put up some wild eazy-e mercs Thank You rod crimes if there are any operators or other people in the floor that could help Bob or myself get some of this data we are both very interested in that and I\u0027m just reaching out to if anybody knows any place that would be willing to help collect some of this it\u0027s very valuable yeah and actually the other CDN did do some thinking well actually I think I can say this because the yeah there is some other day to hear from apples original study and that Argentine Republic 30% CE Marking by the way that\u0027s 30% of devices so at least once the e mark in 12 hours that\u0027s not 30% marking right but they did do some digging into that and identified the ice be involved and we are trying to get hold of the people to to see where whether that is like a fq caudal deployment or you know or whatever it is and similarly the reason we\u0027re going for CD ends is we\u0027re looking for what it\u0027s more likely that single q ATMs are in the downstream whereas fq coal more like to be in the upstream however cake is also in the downstream at the other end of the access link pinching off the access and that would be caught potentially causing c e and echoes back that jake may be seeing that you know we don\u0027t know where these seas are coming from so there\u0027s all the way to be done and just before I go for the next slide about the level of harmless would cause the idea of this is that once you\u0027ve got the prevalence and let the level of harm you\u0027ve got an assessment of the risk and so I\u0027m sort of laying out a process that we\u0027re then got a spread of possible "
  },
  {
    "startTime": "00:33:18",
    "text": "scenarios if there\u0027s a high risk then definitely well put some code into you know the all the star Prague l4s code to try and measure this and it\u0027s going to be difficult we\u0027ll get false negatives and positives in the worst way you know it\u0027s just transfer what when you say there\u0027s a risk and you need new code is that a change to the three specs which are on the table or is that a future spec for the transport the specs currently assume the high-risk case yes but we haven\u0027t thrown it in the code okay that seems a reasonable experiment to go forward Korea if we don\u0027t find much and the harm if it were found or if it were added in the future to the Internet is relatively low then possibly sufficient would be to put advice in the l4s drafts to say do not or limit this experiment over your network eg bigot by disabling on CDN ports that are going into your network do not put our l4s traffic from a CDN into your network particularly if you\u0027re sorry I\u0027m the end of that sentence is if you know you\u0027ve got you\u0027ve deployed also see 3168 ATMs in your network obviously if they\u0027re it\u0027s cake and fq coddled that\u0027s going to be safe because they\u0027re in per flow queues so they\u0027re not gonna I\u0027ve run them right so these are the results we\u0027ve got for a range of link rates along the bottom for 200 Meg and within each link rate a range of round-trip times for the unfairness between DC TCP an ETA and cubic in the dual pie it says the dual pie squared l fresh but they\u0027re both in the PI squared IQ and they\u0027re poked in as if it\u0027s a classic a queuing they\u0027re not using the L key we mark the VC TCP traffic with these two zeros put it in the other kit so the worst case there is about something like that one that was not very useful yeah I pressed the wrong button the worst goes there between that one and that one I think is about 20 but in most cases it\u0027s about 10 along here and it gets the the sort of good news if there is any good news in this slide is that in a severely congested environment I get closer to 5050 at lolling rates and low entry at times so let you digest that in your own time I should add I put on the list this morning a copy of a paper we\u0027re "
  },
  {
    "startTime": "00:36:19",
    "text": "preparing for a journal with a whole load of performance measurements for l4s across all these linked rates and round-trip times and with different traffic models with different congestion controls and all the rest of it and I sort of attached it to the end of a paper so that the because the paper describes all the experimental scenarios and the original paper just had a selection of the plots but what we\u0027ve done we\u0027ve put all the plots just stuff them on the end of the paper so you you know we can\u0027t be accused of selecting results if you like me whereas when you put in a journal paper of course you can select results and I\u0027d like to see results like that so we always show not just queue delay we show utilization queue delay drop rate fairness etc etc because you can always focus on the good part of any one experiment okay so there\u0027s the less loss detection issue which is a particularly if you do finish up in the next five minutes that we couldn\u0027t pick there I think at least discussion submission which you probably ought to go to the main discussion as opposed to be done done while you\u0027re up here with slides I would I represent what what your view is we\u0027ll pick up again I\u0027ll just search clean yeah so there are objections to this requirement that an L press source also has to measure or detect loss in units of time and at the moment it\u0027s a must we have discussed a way to change the ordering switch to change the wording there there are three real objections to this same requirement one is particularly David\u0027s objection that it could be interpreted as a prohibition of using three view back in an environment where you don\u0027t need to do this anyway because you\u0027ve got a a link technology that doesn\u0027t reorder stuff and so I\u0027m sure we can deal with that with wording the other is a architectural concern that it overloads one code point with two meanings and those two meanings being low queuing that I am loath resequencing delay and then really the the augment against that I would make is that yes that is strictly two different meanings but they\u0027re both low delay and what would be the value of finding two identifiers for those things you know it\u0027s sort of worth conflating them and I "
  },
  {
    "startTime": "00:39:19",
    "text": "put a bit of discussion on the list about the the possibility you might ever have a case where you wanted one and not the other that you know if you were short of memory for the resequencing or something like that and and that discussion I\u0027m sure might continue and then there\u0027s an objection primarily from Michael Schaff that one experiment shouldn\u0027t depend on another and the underlying concern here is to avoid having a potentially successful experiment depending on a potentially failed experiment and bringing down me the dependent one that\u0027s not such a concern here because if RAC files and that\u0027s unlikely given it\u0027s widely deployed already this aspect of l4s can be relaxed Alvarez doesn\u0027t like we depend on this requirement no it\u0027s just we can we can relax that and we can talk about that and also it\u0027s not a dependency in a formal normative sense is not a normative reference to the right draft its dependency on the idea behind rack so we are willing to consider a shirred instead of a must of this requirement and maybe warm what would happen if you didn\u0027t do it and so we can have that discussion Thanks that\u0027s what is cooking it aside and then just of not going to read all this this is all the drafts that have been updated in the last cycle and the new one the queue protection 1 and then adopted one in nsh so as you can see quite a lot of ASCII writing going on as well as code writing you might write your code in SQL suppose just common we\u0027re short of time but we\u0027re OK for time so ok so what I think no I\u0027d like to do is offer a bit of time to talk about these drafts and it\u0027s sometimes the case in the ITF that the mailing list explodes with ideas and thoughts about what we\u0027ve been doing just before working group last call and it\u0027s sometimes that the mailing list dies out and you can hardly trace what\u0027s going on when we get to a working group last call this case and quite a bit been going on so what let\u0027s use a little bit of time to try and talk through the different things and we made a list as chairs of things that we thought we saw and this may be a totally useless list "
  },
  {
    "startTime": "00:42:20",
    "text": "but we\u0027re going to show it anyway because it may help some of the people and if your comment directly matches one of these or we want to come back to it then please say so but generally let\u0027s have a discussion about these drafts particularly relating to whether there are significant issues remaining or what the things that should be clarified at this stage before we hung on whether to pass them to the working group last call status so one who was going to be first Jake your queue shorter going Jake Holland I would add one item to this list which I was thinking yeah yeah I would add one item to this list which is admission control for untrusted marking on the admission control on the classifier yep okay um the IQR recommendations state this is research currently a something that we should be thinking about how to control floors not obeying with the traffic contract there the scheduler is expecting and what would you suggest we do in this space we have a a document that was put forward by Bob which in its like that which I very much appreciate which is revealing what one of the operators is trying to do right now but that\u0027s an information on what they\u0027re doing do you think we should be doing some working group work on this there is an interesting question i I I just would like to see it I don\u0027t have an opinion on that at the at the moment I just would like to see it added to the list as a concern that has an impact on the congestion control aspects of this thank you noted thank you Christian yeah it\u0027s something about the evaluation of the l4s experiments okay I have noticed that Bob slides always present comparison of l4s against cubic which is not designed to minimize and 2 ND days I would very much like to see comparison of l4s against delay based congestion control algorithm such as PBR presumably baby are the two of them via the general idea is compared to congestion control algorithms are specifically designed to minimize delay by opposition to those that are not and this is Bob Brisco that is the question if you try and compare with baby RV one things like your rape fairness it\u0027s not you that\u0027s problems its wake you for be "
  },
  {
    "startTime": "00:45:26",
    "text": "BRB to now to come out we can start to be able to do that but that\u0027s why it\u0027s not appear Johnson Moulton I have to get very close tonight because the chairs cut here okay better okay so I have four different topics to bring up that closely related points a B F and G yeah so um Jonathan Wharton okay so on point F honestly eighty-one one states that IETF approval is required for experiments involving congestion response differences and congestion marking differences as these could involve effective redefinitions of the C II and ECT one code points in other words I see 18 1 1 does not itself modify our SVC what the six eight to permit these behaviors itself for best desires and point G on incremental deployment this obviously requires compatibility with our cc-16 8 compliant a QMS this has not been demonstrated and there are serious theoretical concerns which we have validated by experiments as of last night which of course speaks to point a I was too gay to you on one states very clearly that effective congestion control is required with coddle now being the most deployed aqm the default parameters of code l and the vertically low latencies that l4s targets we found that within 10 millisecond RT t path a senior related DCP Park flow would require four seconds for cuddled on its default parameters to reach a controlling marking rate okay less is not active cuddle appear cuddle yes this is the caudal algorithm itself acting on a single flow and if multiple l4s flows were going through a single queue controlled by cuddle then the time required to reach the correct marking "
  },
  {
    "startTime": "00:48:27",
    "text": "rate would be similarly multiplied so this is I just need to clarify are we talking about widespread deployment of cuddle without fur queue I\u0027m talking about widespread deployment of cuddle in total I\u0027m if we include fq canal then it is extremely widely deployed now because it\u0027s yes default in most Linux and Mac OS 10 devices okay I think we can agree that taking four seconds to control the congestion induced by a 10 millisecond RTT flow is not effective congestion control now moving on to point B fair queuing a QM is pretty robust by itself introducing fair queuing would be reasonably effective I think but there is still a concern where you have two consecutive bottlenecks as presently occurs quite frequently when you have a last mile link that\u0027s controlled by a dump iPhone followed by a consumer equipment box which is implementing fq code L or something similar and for my experiments we have found that you can have quite a large delays bike induced in the DOMA FIFO until the the aqm downstream is able to control it so again this comes back to our four seconds to control it that\u0027s four seconds of assistant queuing in the last mile link it does sound like an FQ Cottle may have issues that need to be looked up hmm I think that\u0027s all I have to talk about at the moment okay does anybody have this can be a discussion people can follow up if they wish but yes next in line yes my name is Peter I stood with the SD team also I\u0027d like to raise two concerns we have one is to highlight topic II we have a strong concern about using ECT one as a global classifier RFC 2474 which is the DSC PRC to section seven the Security section talks about how dscp relies on its D s domains for its security relies on protection at the borders as well as the "
  },
  {
    "startTime": "00:51:29",
    "text": "integrity of the domain itself so with with using ECT one as a global classifier there are no domains so that\u0027s we\u0027d like to highlight that concern okay and this consensus to use this was agreed in Berlin in this group we can look at it again okay and second and finally is topic H regarding the implementation status what we what we didn\u0027t want to do is come in broadside the team with results that they haven\u0027t seen yet so we we won\u0027t do that but what we will do is confirm that there are issues on the five dead x-series kernels of the current repo where TCP Prague is overreacting to to seee marks and we saw that in our in our test results and we would also say that we want to make sure that the current code base is running on a five deck series of Colonel and not 3.19 so that we can be testing on a colonel that isn\u0027t isn\u0027t AOL so that we feel that that\u0027s very important for our testing and lastly we didn\u0027t get too much to our interrupt testing but in the next few weeks as l4s is reviewed we hope to do that that\u0027s it that\u0027s all okay David black speaking from the floor as an individual as Bob sort of hinted this concerns open issue number two which on the slides is C and D and I\u0027m going to take a reverse board the whole point of the single ends that I\u0027m definitely speaking as an individual on this the whole point of the l4s experiment is to go look at something that is an experiment that you\u0027re met as a whole and from what you\u0027ve heard from previous speakers the the the Q the interaction between floats that all forces is is trying to address can occur in any Q anywhere in the Internet sir netskope that experiment makes an enormous amount of sense the resequencing tolerance I have been complaining about in this remark the third IETF in a row where I continue to complain about lumping that in it\u0027s been hard to understand what\u0027s going on I want to thank some of the folks on your team for a little for helping enlighten me a little more here what I believe is going on there is that there are certain linked technologies we are using RF signaling particularly over wireless where on a multi channel or multi bearer link you get different loss rates different bit error rates things like FEC and retransmission come in and if that hits the lanes asymmetrically well then all of a sudden you\u0027ve got a week for this you\u0027ve got a week for the slope for the slowest Lane and there\u0027s a "
  },
  {
    "startTime": "00:54:30",
    "text": "resequencing buffer and delays now if that understanding is correct what\u0027s going on here this is not an intranet wide problem it does not happen in data centers we have experience in my company in looking at a center optical plant where we gave up testing for bit error rates at 10 to the minus 18 because the errors just weren\u0027t happening there better things better things to do with the equipment needless to say the underlying cause of the resequencing effect is not there in that class of networks I believe what\u0027s going on with the resequencing is it\u0027s not internet right it\u0027s specific link technologies in specific networks mostly access networks and ought to be solved with some kind of network specific approach as opposed to lumping this into one experiment at where where the goal is going to be we\u0027re going to get everybody than the Internet to adapt all their endpoints to deal with these link technology specific and network technologies that are problems I believe that latter approach is a major mistake david topic was raised by the chairs a number of previous things saying if this is the intention then we need cross error review before we can proceed is just bob want to speak about the text the text we talked about is in appendix Bob do you want to clarify whether the intention is to deal with reordering or the reordering is a future vision that can happen because you do this the latter definitely and I also want to make it clear that may from I\u0027ve heard David say this in number times and maybe something just clicked in my head as to something that David hasn\u0027t picked up on that we\u0027re not we\u0027re what we\u0027re saying is that when a link I think has the capability and the possibility of not doing resequencing on packet with the identifier that there4s not with packets from all n systems is that understood I understand that this is proposed as an internet wide service that would presumably be rolled out to and be of interest to a large population of of n systems yes I understand that Yuki you can\u0027t get in trouble if you didn\u0027t set the the code point that said that that says says go ahead and resi go ahead go ahead and omit resequencing but i still believe that that this is that this still has a major scope problem and it\u0027s not same experiment ok because then "
  },
  {
    "startTime": "00:57:31",
    "text": "given given that relaxation is only four packets with the ACP one code point the relaxation for the links the resources that this requirement is requiring to do this loss detection in time have to be modified in order to change their congestion control to set the ECT one anyway so you know that\u0027s why we\u0027re said there\u0027s an opportunity here to use a time-based lost detection which happens to be deployed in across TCP versions now in Windows vs the limits and all the rest of it in rack so they\u0027re in it seems like a good opportunity that that\u0027s the rationale anyway and we can have the discussion on the list maybe I think you\u0027re I had to have a glass half empty versus glass half full discussion I see the opportunity I view it as an opportunity for a separate experiment not one that ought to be lumped into the offerors experiment I concur with David\u0027s view as chair that this is a different experiment to the one we originally charted and I\u0027m not sure that is required experiment that has to go with this and if we do it then we must go to interior and we must then apparent the implications on interior and dry so so we if do we need to unpack this here as part of the alchemist bundle and this is a thing we should talk about today the the el Faro\u0027s drafts just say the the source should measure loss detection and detect loss in time units doesn\u0027t say anything about what links must do so that in that sense it\u0027s not saying this is a link experiment but it\u0027s saying that someone else could do that experiment with l4s traffic it\u0027s in our next to the speculum does it need to be that it doesn\u0027t need to be there no all it says at the moment in the annex is that links could do this it doesn\u0027t in any normative sense or shirred or anything like they just as they could all right I suspect part of this is also will come up with time if we see quick widely deployed with PT or best detection and Reich widely deployed that does time a base think we will maybe see a general reduction of the reordering requirement in the internet but that is a philosophical debate about what might happen in the future rather than what has to be in the spec and and the point here was to say if a link sees a packet with the l4s identifier it knows that it\u0027s got that behavior rather than there\u0027s some fuzzier possibility "
  },
  {
    "startTime": "01:00:31",
    "text": "that it might have it unfortunately the moment you seen knows you\u0027ve wanted to experiments together no no you haven\u0027t you\u0027ve just a we\u0027re not saying do that experiment at all we\u0027re just saying we\u0027re opening up the possibility for someone else to do it later it\u0027s not Jenks in line area are you on this topic Jake okay okay I I\u0027m not I\u0027m not sure there\u0027s much much much else much else to add there I guess I think it as one questions might give us part of that Bob is that an X part and parcel of the draft and hence the annex is experimental because the drafts experimental dirt or quasi annex intended to have a different status with respect to the rest of the graph well the Alex is informative okay this is just one possibility would make me happier I\u0027m still not satisfied what if we pulled that annex and I think this another couple of informative annexes out of the that L fresh draft put them in a second draft that is very clearly marked as informative and that there will be no normative reference from the LS trap with out annexes to this new informative draft I can I can take it out completely yeah we don\u0027t have to say that links could do this the issue is if the issue is the issue is not so much the links could do this it\u0027s the it\u0027s the you have the transit the transport protocol must have this behavior participate in our government that that that part is in the normative parts of it and then in the annex it says what limits could do if but but what I suggested in the talk is we could make that must into a sure I would suggest you consider removing the paragraphs resubmitting them if you want to later but avoiding making any statement about the reordering apart from what\u0027s actually happens when you use l4s maybe concerning the CEO whatever I don\u0027t that bit is fine speculating the future in that affects another area is a much trickier thing to put in an exp draft okay like to rethink this then because there\u0027s a lot of people that really like that aspect under a lot of people across the idea who like that and there a lot of people who also pray maybe don\u0027t like it but this could be the document that tests that if you wish our advice is let\u0027s think carefully I guess I guess I would characterize it as there\u0027s a lot of people who like it technically and there\u0027s a lot of people who dislike it procedurally if "
  },
  {
    "startTime": "01:03:31",
    "text": "you think people like it write it in a separate draft I think okay and back to Jack oh yeah so J holin this list is as I see it a list of the technical considerations I think there\u0027s and I I agree these are you know the the more important aspect of this there\u0027s one other sort of set of issues that I would characterize as editorial considerations I raised I raised a point on the list recently so I don\u0027t know if you want that in this list also the list of potential issues with regard to advancing the draft I you know I I only have an individual hat and it\u0027s I don\u0027t know whether I\u0027m being too picky but in terms of the sort of goals as stated by the RFC editor in my opinion there were some significant editorial issues worth addressing before removing the draft forward so I would also request adding that to to the list although I wouldn\u0027t it if you want that Jerez separately as a non technical issue that\u0027s fine okay Jake and let me just be sure what you mean by editorial do you mean that sections shouldn\u0027t be in a particular order or text needs to be corrected or do you mean that sections should not be in a document no I this refers more to word choice characterization I can respond to that and this is excellent feedback there\u0027s a sad to think about ITF process that we don\u0027t get people often sending those comments in as the group of documents progressed through the working group and they\u0027re very much appreciated by the authors on the chairs what group must call it is exceedingly good time to make sure that all words that as good as we can make them Irish see a litter will tidy up and we\u0027ll fix but it\u0027s our job to get the drafts as best prepared as possible so yes please send those to the list well I sent one section review to the list I was waiting for some feedback it there\u0027s been a lot of traffic on the list so I understand there may be some delay I was waiting for some feedback in and sort of other opinions on whether this is a useful contribution or whether there\u0027s some sort of because I believe if I continue on the path I have started it will be quite a lot of feedback Pope\u0027s getting to the mic hi Jay I suspect this is one of the emails I\u0027ve started and not finished and I think I\u0027ve sent to you but I haven\u0027t but yeah I\u0027ve accepted "
  },
  {
    "startTime": "01:06:32",
    "text": "and enough also said you don\u0027t need to go through the rest of the draft pointing out stuff I can do that that\u0027s my job you know I\u0027ve got the idea of what you don\u0027t like yeah okay likewise just because I don\u0027t like it doesn\u0027t necessarily mean it you know it\u0027s a it\u0027s a questionnaire consensus but I wanted to raise the issues and I hope it\u0027s been helpful would you would you rather I said what you obviously don\u0027t want to say that it\u0027s basically too high P so oh yeah much hype in it you know yeah yeah that\u0027s the general nature of the please reduce the height or else either your working group chairs will tell you to do so or your ad will tell you to do so but for sure it won\u0027t make its way through the full process but but but this is normal this is this is part of preparing a document for actual standards okay so any more questions in that case I think it\u0027s time for a helmet I get thrown put my working group chair back a hat back on so got two more ears to listen and judge please come and join me because if we start asking questions I want to know the answers given first of all could you indicate to me all right we have three drafts do we have list of the three drafts somewhere yeah we will we will be doing hums and at least I\u0027m gonna be down walking around the floor to find listen so first thing is I\u0027d like lists of drafts up and I\u0027m going to ask who\u0027s read a the current version or a recent version of these three drafts that the three trusts are listed here so let\u0027s go for l4s architecture could you please raise your hand if you had read this version or a recent version of this document could somebody tell me how many people got Hansa it looks like a quite a large number okay in more than twenty fifteen to twenty okay right and guess what the next month question is have you read the l4s ID please raise your hand if you\u0027ve read the l4s ID slightly fewer than the architecture maybe about fifteen okay and the dual cue the Jill couple deck um oh yeah okay so we have a maybe fifteen to twenty there as well so the first pronouncement from the chairs is that I believe we have sufficient number of people reading these documents that the "
  },
  {
    "startTime": "01:09:33",
    "text": "working group can know consider what happens oh just me and where\u0027s could comment if he needs to just remind it to wises the document Shepard where\u0027s does want to comment that\u0027s good I yeah one of the things I noticed is that we had ten cottages and we way were maybe one more very clear extra one and a couple of ones that I think are probably sub-bullets under the testing issues but the one thing I actually noticed I was keeping a score and no one brought up a topic J which was the IPR we want to do we want to assume that things are better with that now or not whereas this is David I think some of the IPR cephalo needs me so may need some soak time so let\u0027s let\u0027s hope that this is a sign that it will that it will not be playing a leading role in the future there\u0027s people at the might you know broad crimes I believe the people that would like to speak to that issue on the IPR are not present and will probably speak on the list is that subject comes up I know that took a whole and Jorgensen was planning to do so but the timing is bad for him today so I believe Toki hurlan gurgenson was planning to talk about this today but the timing was bad for him was this session so he will probably comment later yeah and we already have some input from him some more and more input will be welcome okay and Wes yeah that was really all from my summary I thought it was good discussion so then in this case I propose that we take the sense of the room using a hum to do if we should put these documents into the working group must call for comments stage the stage will open a formal process for people to comment on the documents please relate such currents as you think about whether your you think they\u0027re ready because if the comments you provide should be related to sections of these documents to see if they are ready and fit for progression by the working group um we would like to know if you think those documents are ready for evaluation in a working group last call please hum if you think these documents should go to a working group last call "
  },
  {
    "startTime": "01:12:33",
    "text": "now please hum now if you think these documents should not go to working group was coal no okay so if you didn\u0027t huh my the way and you wish to come and speak at the mic please do but first of all ask David what he feels the sense of the room was I heard weak hums for both alternatives there was also hums against in Java but just from Dave said there was also a hum in Java for against but just from Dave okay I still I still across the floor to see if our ad wishes to say anything okay so based on this that it\u0027s this seems to be some people\u0027s list to see it is not ready so I think the reasonable thing here is to give those people a short time a few weeks to send those points what\u0027s this cause it is not read it cetera and have a discussion on the main list to resolve that this sounds like a very good approach we will not start a working group last call for this document this idea we plan to do so but we will shall give a few weeks for people to respond to that plan and explain whether this is a good idea or not so if you think that that plan is not a good idea please explicitly comment on the mailing list to the chairs to help us decide what to do and Magnus yes and I mean if you have things that are technical reasons why it\u0027s not ready ensure that that also gets raised thank you I see shall be next it\u0027s a no working group draft and coming around presentation by on on list Draft Morton T s BW g SCE please come and tell us about it working well enough okay "
  },
  {
    "startTime": "01:15:37",
    "text": "my name is Jonathan Martin I already heard me at the microphone and I\u0027d like to talk about some congestion experienced and alternative proposal for the use of the ECT one code point so we would be defined ECT one as some congestion experienced as a high-fidelity congestion signal and you can see the table at the top of the slide lists the three existing code points in use buying IRS three three one six eight and the extra one and we also use a spare bit formally known as NS in the TCP header for feedback in that\u0027s what third draft is about we retain all other our SVC one six eight details for full backwards compatibility and that means that if an SCE endpoint communicates with a nut with a non SCE endpoint it automatically falls back to standard behavior if there\u0027s a non SCE middle box if then we also have standard behavior we have multiple instances of running code available okay so now design philosophy is based on the three following quotes principles which are illustrated by these quotes first do no harm heterogeneity is inevitable and must be supported by design effective congestion control is required so first for backwards compatibility which is part of our do no harm and heterogeneity acceptance normal additive increment and multiplicative increase and multiplicative decrease principles apply so we have a normal congestion window surveyed a TCP friendly response to loss and the TCP map and to congestion experience marks and existing middleboxes treat packets that a matress SCE as ECT and are still able to mark c e on them "
  },
  {
    "startTime": "01:18:38",
    "text": "existing endpoints ignore our signals this is completely harmless it\u0027s a transparent fall back to standard behavior the meaning of congestion experience is thus preserved and that means that SCE becomes a soft cruise control signal because we still have the ability to a multiplicative decrease on a standard C II signal or a loss if there\u0027s a big change a big reduction in the path capacity this is a big advantage of a DC tcp which only has the one code point to do it signaling on and therefore has to use it still has to emulate the multiplicative decrease for that scenario this gives us more flexibility in what we do as our response and here we have a demonstration of what happens when we go through a standard metal box these are two flows both endpoints happen to support SCE but the cubic flow is not using the SCE signals only the Vino SCE flow is and you can see that the two flows are proceeding approximately equal in throughput and this is what you would expect from a Reno versus cubic comparison anyway and the latency is also reasonable there are spikes of up to 5 milliseconds at 8 switches and I think you made a second path that\u0027s very little the way we apply se signals in se is a signal from the network to the endpoints the network boxes don\u0027t need to know anything other than it is an ECCN capable transport so se is a high fidelity congestion control signal which we apply as a marking ramp the probability of amp based on Q surgeon time or Q occupancy if you prefer high fidelity means that we have many marks per RT team as opposed to standard marking which is many RT T\u0027s per mark applying of course a steady-state situation we can easily add SCE marking to an existing ATM algorithm and that is what we have done for reference implementation and this is easiest to do if fair queuing is also implemented we will talk more about this later a simple threshold function is a valid implementation grant functions probably "
  },
  {
    "startTime": "01:21:40",
    "text": "perform better and seeing marks are still relevant you can see to the right of the diagram is the region above 5 milliseconds surgeon time in which code L does it marking so we have full Becker\u0027s compatibility of an SCE middle box with existing RFC compliant flows the response to SCE is signaled to e SC e which is the former NS bit which is released by the the historical status nonce some specification this is completely orthogonal to the ECE NCR cwl bits which are still treated as with our three three one six eight and when this bit is set it indicates that the currently act seconds carried an SCE mark the receiver logic is very simple immediate and almost stateless so it\u0027s easy to implement the patching of implementation to do so is a few hundred lines including including some with auxiliary things it\u0027s simple the center response it may ignore it as existing implementations do this is backwards compatibility we have DCTC theme which influenced the DC TCP response but to an SCE signal instead of a seee signal and as the it reacts the ability to do a straight multiplicative decrease to a standard RFC they one six eight signal main OSCE modifies this response to be less severe the we scaled by the square root of the congestion window instead of by student we also have in progress a cubic SCE response which also deals was the fact that cubic can grow at greater than linear rate we exit so start on a single SCE mark because we need to do that as soon as a congestion signal is received and here we have a demonstration of an ideal scenario where Kubek is competing with you know us SCE as before but this time in with the middle box that supports both fair queuing and SCE marking and here we can see that the SE "
  },
  {
    "startTime": "01:24:42",
    "text": "flow in orange is neatly using the space the capacity left over and by the sawtooth in the cubic flow mia cowan just a quick question on the graph and also the Ella bar and for the redirects or a cubic only flow do you also have any AQ m in a bottleneck yes the cubic flow is receiving Cee marks in which a key mi using anabolic this is effective we\u0027re using cake so it\u0027s effectively kado and the threshold marking special thresholds basically the standard parameters 100 millisecond interval 5 millisecond target thank you so you can see that there are no multiplicative decreases in the green OSCE throughput chart and this is because it is reacting sufficiently well to SCE marking to avoid the need for ze marks the green trace of the bottom shows the the latency of the SCE flow itself and you can see that the peaks of it are lower than the purple trace which is the cubic internal RTG that last with queueing but pinging the sink you as the data is that right or what was the pink the pink is the cubic internal agency that the flow latency yeah and you\u0027re using F chip we\u0027re using fair queuing and you\u0027ve got a ping is the ping in a separate queue or in the same queue something else the two flows gets there / queues in this case the two because it\u0027s fair queuing so the bottom flow right at the bottom yes in dark purple is a separate measurement flow which is using yet another for queue using a separate queue yeah so this is measuring how fast the queues rotating rather than the time through the of the traffic yes yes right okay so it\u0027s not the scheduler tix yeah okay all right so here we also have se use performance in a single queue with SCE support and as before we have a delayed start of the second flow so one has almost reached the link capacity and the second must then compete and we can see that it converges this is just like "
  },
  {
    "startTime": "01:27:43",
    "text": "FK I\u0027m sorry not speaking as char here maybe I should go down there but this was just like FQ I mean this is just two Q\u0027s is it not or is this something I\u0027m missing etc this one is single without fitting right okay and you can see it from the caption on the right yeah yeah but this is where SCE and you can see that was just the SCE response we do have convergence so we don\u0027t only support fair queuing we prefer it of course however with questions were based on the list about how we could do this with dual queues and we observed that any traffic data fire such as a dscp you may be used to direct seu traffic into a special Lyons cute and so such that conventional traffic would default to the first queue for robustness against mr. classification it is straightforward to arrange things the conventional queue does not mark with SCM and therefore if SCE traffic is misclassified into the conventional queue then it just receives standard RSC 3 1 6 8 behavior and this we think is a major benefit of using of the unambiguous signalling provided by putting SCE on a different code point than CD now if we put SCE and conventional traffic into a single queue then as standard SCE yields very politely to the conventional traffic you can see the Amish trace at the bottom shows much lower than the in the cubic flow computing with it at the top now this may actually be useful to some people if they want a scavenging transport we leave that up to you however we have an alternative approach as well by modifying the SE marking probability ramp into this two-stage format some of our seniors benefits can be realized without realizing multiple queues there are some compromises in the performance the current implementation is not an odd three you have to configure the level at which that kink in the graph appears but SCE can coexist fairly with conventional traffic and with the same queueing parameters run smoothly in competition was itself the vamp parameters are chosen at the single queue bottleneck node in question which means that this is a network administration decision and doesn\u0027t need "
  },
  {
    "startTime": "01:30:45",
    "text": "to be specially set up after the ends nerves and here is what happens when you have conventional and SCE traffic computing with this setup it\u0027s not ideal but you can see that SCE is getting more throughput than it did in the previous example and then when we put two SCE flows together you can see that they run smoothly for the most part there\u0027s a little bit of a glitch at the end where probably a stray see e-marketing but you know that these are tweak these sorts of things can be tweaked later with more experience now a really important matter is that we have a running code in fact we have multiple instances of running code four months ago at the end of I 80 f-104 we already had a Phoebe SD sender a Phoebe SD receiver and a Linux based middle box in fact - even two implementations there today we have Linux senders as well a Linux receiver with a better feedback algorithm and we have even have a Phoebe SD middle box thanks to this report that we got from Logan from Africa so Albert continues to mature desert diversify and character they characterize ever all of our work and as part of that we found some interesting things about TCP pacing first something fundamental which also I think applies to other high fidelity congestion controls the tie fidelity congestion signaling is very sensitive to burstiness of the traffic because these bursts collect transiently in the queue and cause this congestion signaling a clocking is not sufficient to avoid these bursts especially when you have delayed acts because delayed acts naturally leads to packet pairs so pacing is effectively mandatory when used with high fidelity congestion signaling in connection with this Linux actually exempts the first ten packets in each flow from pacing this is quite a nice feature it prevents slow start from working with SCE so we "
  },
  {
    "startTime": "01:33:45",
    "text": "patched it out this one line fixed we also found that the transition from so start to congestion avoidance requires a halving of the send weight normally this is provided by the first congestion signal experienced by the flow whether that\u0027s a loss or a c-- e-- mark so what we have to do instead because we don\u0027t have a multiplicative decrease all the time we use modified spacing scale factors which enforce a throughput change at that boundary and we expect to continue experimenting with that so if we we have also a yeah we have a public repository containing SCA code it\u0027s based on the Linux 5.1 next net next series kernel and I forgot to put the URL on the slide but you can send us revised slides and will happily posted I\u0027m sure we can we\u0027ll post a link on the mailing list as well please do post is very nice to Cory and please do post and where we can get the patches or whatever you\u0027re working on I guess they weren\u0027t up streamed the change you\u0027re talking weren\u0027t up streamed they were your own versions yes we have a complete git repository okay excellent post-up please know my question is accurate ecn is some of you been working on here as well how does actually see and figure with what you\u0027re doing because you seem to be reusing other bits well accuracy in takes over the NS bit for the three-way handshake and if it\u0027s negotiation is successful we found that a QC n was not actually useful for our purpose so we declined the a QC n negotiation and use the NS bit thereafter as if it were not some essentially hmm the reason why occasion was not useful to us it\u0027s because the the three bit field it produces counts EE marks which we already have perfectly adequate feedback with the RSC three one six eight but what we need is feedback of the ECT one code point yeah which is provided only by the TCP option in that case en DRA "
  },
  {
    "startTime": "01:36:47",
    "text": "and TCP options have their own problems yeah I\u0027m previously easy t02 ECT one was a non-normal transition which we didn\u0027t engineer to MU Daiko easy and I guess because that\u0027s not expected in the internet this is true and so of course we will need some experimental status in order to formalize this as an experiment however we believe it\u0027s mostly harmless Andrew McGregor I\u0027m quite concerned about your notes about pacing and the requirement to space it\u0027s out in that manner because that says to me that this is going to interact extremely poorly with a with an aggregating Mac if you end up dropping a few packets into the same Mac into the same Mac aggregate then and the for example is Wi-Fi the access point is congested so there\u0027s gaps between aggregates effectively the network reboosts the traffic for you and that\u0027s going to end up behaving poorly because if you don\u0027t land in the sand at the same aggregate you minimize the performance of the Wi-Fi this is something we have recognized and something we will need to explore reasonably soon probably and the other thing is I observe we have two proposals for how to do something quite similar who are using radically different evaluation methods and different congestion controls and all the experiments please you know use the full matrix in both cases because otherwise we can\u0027t evaluate me a cool event and so first two quick comments and equities and while I know that the discussion about this should actually go to the TCP I\u0027m working on but like one big part about equity CN was compared to what like data in a TCP for example is using that occurred easy and actually has a negotiation face so you know for sure that the other end is supporting it that was a very important point and the other point was also that the assumption is if you use the etc1 code point and the option is not available which you can test for then you need to opt out of that experiment eventually while that mechanism still ensures that the traditional way the solution thing is feedback accordingly so that\u0027s kind of the assumption for all experiments we do and with the assumption also that like maybe this whole option problem becomes better in future and then you can use it everywhere so it\u0027s a deployment thing yeah I\u0027m sure that\u0027s something we can have a discussion about in TCP yes I have rather a couple of questions because like looking at listening to your presentation looking at the diagrams a little bit the message I got "
  },
  {
    "startTime": "01:39:47",
    "text": "was that what you propose works very well with fair queuing while you don\u0027t have any guarantees that they will be effective in applaud or whatever however if you use it without fair queuing it\u0027s more as giving a approach and then you presented that you can be more aggressive but then it look to me that the more aggressive part also means that you get like more queuing delay which is not the perfect that you\u0027re looking for so for Mila but the confusion was if you this only works well with fair queuing is that the message you can agree to is that not what you wanted to say you may notice that off the diagrams in this slide deck only one of the most forgiving yeah but like the other graphs didn\u0027t show to me the benefits you wanted to achieve so I understand that it doesn\u0027t pressor system but it doesn\u0027t really show us any benefit to me well you might look at the the total throughput of this synovium until it glitches of course basically we eliminate the sources and we get better food yeah so but that\u0027s only if everything would be using SCE right the previous graph you showed again this is something either you use fair queuing or everything in the whole world has to use SCE only one that\u0027s like the two cases where it\u0027s really beneficial well it still works even if there\u0027s boxes in the network that don\u0027t understand SEO at all it\u0027s still safe to use yeah yeah I understood that part I mean if you have a network that internally wishes to use se form of an optimization then it can deploy a seee without requiring the rest of the internet to also deploy a C or FQ or anything like that I think that\u0027s important can I make John can I make one point if you could go to the graph with the Reno SC verse cubic single q with SCE marking where we have the threshold set just to make the point that this is 80 milliseconds so that throughputs you\u0027re seeing there are what you might expect anyway between cubic and Reno just to make that point if you look at it and say oh it doesn\u0027t look fair that\u0027s part of what\u0027s going on here as you\u0027re talking about cubic versus Reno at 80 milliseconds anyway quick administrative announcement Mike lines are closed and people will stick around I think we\u0027ll try to fit in the "
  },
  {
    "startTime": "01:42:48",
    "text": "multipath DCC P presentation the end so if we could keep queuing ain\u0027t quick here that would help all concerned I\u0027ve read the drafts and I\u0027m still missing the kind of problem statement and the space that you were exploring in addressing the problems that you want to solve so I\u0027m not quite clear if the problems that you\u0027re trying to tackle here are universally applicable to the Internet at large including low latency environments and that\u0027s one part the other part the other comment I want to make is it has a feel that the use of the of the NS bit for - bit has feels to me like you\u0027re jumping at a solution or a signaling mechanism is readily available without first everything if that would be the best option available because one observation that I\u0027ve think I\u0027ve made is s EE and also in the accuracy n slash data center TCP environment the normalcy mark both have a much less severe marking semantics than regular C II so I was wondering what are really the differences between SCE versus at the l4s architecture with with equities yen marking because from my point of view it seems that the signalling aspects are really a secondary problem and shouldn\u0027t be on the forefront we should discuss first what type of problem you should we want to address mmm I\u0027m sure we can address those in a future version of of the documents but the I\u0027d like to draw your attention to the last line on this slide where we have the unambiguous signaling semantics on the different curve points so we can make and implement DC TCP without leaving it unsafe for general use to be a to be a little more or pointed there was a chart that went up during Bob\u0027s presentation about what happens when you run a RFC 368 a QM on a set of traffic some of which is using TCP C II mark someone\u0027s using DCTC PCE marks and their problems there and what those are basically saying is that for SCE seeing means C e means CEC RSC 3168 and therefore you can\u0027t get into that particular problem scenario right I just to agree with Miriah this is this is "
  },
  {
    "startTime": "01:45:53",
    "text": "trading off some of the this proposal appears to trade awesome with the performance at particularly the latency performance proposed for l4s in order to gain some safety and so that\u0027s really the to me that\u0027s that\u0027s an interesting question of consensus to consider like how bad is the safety effect particularly with regard to the 3168 interactions and and that\u0027s that\u0027s what I would like to see most discussed on the list as well as as conditions of sort of malicious use in Europe in its various scenarios in the admission control okay Jake I take the comment and then there\u0027s a different trade off here and we need to talk about that on list and also we should not that the raziel so the a b ii proposal to use the same code point which is no RFC status which we need to coexist with so this doesn\u0027t take a free call point it reuses a core point which we recently standardized but and we can do lots of things here and please use the list to discuss this we\u0027ll take one last comment and then we will decide on what to do the draft or not the draft the code repository is cited in the test draft for anybody looking for it\u0027s actually in the drafts it\u0027s in the tester app and the other one there is a missing implementation that was not in the slides that there\u0027s actually a hardware implementation of SCE running today in 25 gigabit switch a year thank you and this achieved this in we learned about that actually today and the ports that are that it achieves far below a millisecond of RTT with big improvements in the link level beat rise needed to support one thing whatever that application is so that\u0027s a big things for us okay thank you very much and I would like to thank everybody\u0027s worked on worked on agree to both the Alvarez and and SCE work and all the hackathon work I think I think a very interesting productive weakest has been transpired okay we we are over time so I think we we probably get to formally close the meeting here however if you\u0027re interesting leap at DC CP we\u0027re going to go ahead and have that presentation Marcus you here okay cool oh here\u0027s to presented so let\u0027s let\u0027s give people about 30 seconds of those who wish to exit for whatever reason can and then we\u0027ll go ahead and for those who are interested let\u0027s talk a little let\u0027s talk about some completely different multipath DC CP hang on one "
  },
  {
    "startTime": "01:49:12",
    "text": "more thing where is it there it is click on that okay cool so just to clarify and the TS vwg meeting has has formally finished and this presentation we would have included they will get a gender time next IETF and since the room is not currently needing to be vacated we will let them proceed to tell people what\u0027s going on and maybe you get an insight into and this new topic and if the Secretariat come in and tell us we have to leave then you\u0027ll be cut immediately fair enough so thanks for those staying around my co-authors are not here anymore so I\u0027m on a bernstrom and I will be presenting our work on multipath DC CP as a way of carrying UDP IP traffic over a multi connectivity networks so a quick summary of the motivation so we had the markers from Deutsche Telekom had the first presentation of this as the previous IDF with a bit more details on the motorway but we have multiple ongoing standardization efforts and other organizations so in 5g for 5g 3gpp is standardizing the 80s SS steering switching and splitting and you have in the broadband forum the hybrid access which is for multi connectivity networks and they are using MP TCP to carry the TCP traffic but there\u0027s really no solution for how to carry the UDP traffic and for operators like Deutsche Telekom they really see you know the need to cater for both TCP and UDP if they\u0027re going to deploy any type of solutions for these multi connectivity situations and of course with the increase of quick traffic that we may expect in the future carrying UDP traffic could also get increasingly important so the goal with this work is to look at the multi part solutions for caring thing UDP traffic in this context complementing MP TCP and you can check out the last presentation as I said for some more details so this is an overview of the MP DCC framework so you have a sender and the receiver you have a virtual network interface that takes you connects you to the IP on the other side and then you have DCP tunnels you add sequencing information on top similarly to MP TCP and then you tunnel over the DCP flows so this is the basic architecture and this was also discussed in the previous presentation there are three drafts related to this a draft on the multi path DCP protocol a draft on the framework the role framework and the draft that Maps the "
  },
  {
    "startTime": "01:52:13",
    "text": "DCP header into the UDP header so that you can get through networks because DCP is not not generally passing through middle boxes so these are the three drafts related to this ongoing work we have worked since the last time quite a bit on the the implementation and experiment side so there is a prototype available inside the Linux kernel unfortunately not open source at the moment I know the Deutsche Telekom people are working on that internally and then we also have a mystery set up where you can evaluate the residential and mobile use cases so the way this architecture or the setup looks is that we also have a number of scheduling components because the key issue of course for carrying the multipath traffic here is how do you schedule over the different paths and as compared to multipath TCP when you carry UDP traffic you also have the issue of what do you do at the receiver side in terms of resequencing do you let the UDP packets through do you make sure that some of it gets reordered because you may now have different delays on the different paths that your traffic is going over so we also have a number of different algorithms that we have looked on on the reordering component of this framework so what I wanted to do today is just to show you some short sample of those results that we have been working on and in relation to the presentation last time as I said we mainly been working on updating the implementation and on some measurements there\u0027s been some smaller updates to all the drafts improving on the language spelling things like that for the multipath framework draft there also the requirement section added but in terms of the draft we of course need to include some more detailed specification for the multipath protocol we had some feedback regarding UDP options for the header conversion draft that needs to be taken into account and also further aligning with the discussions in 3d PPE and the broadband forum make sure the requirements gets right but let\u0027s look at a few sample results so this first one is from the NS three simulations with UDP traffic looking at what happens both for switching and an aggregation scenario and here we have a scheduler that prioritize the Wi-Fi path as long as this path is available and if not it moves over to the the LTE power "
  },
  {
    "startTime": "01:55:15",
    "text": "port so in the top graph it\u0027s the the switching scenario so then as expected here the path is has enough capacity to carry your your your traffic so as expected initially all the traffic goes over Wi-Fi when the Wi-Fi disappears it takes some time to detect this because we\u0027re now not using both the paths inauguration mode once the loss of the Wi-Fi interface is detected the traffic moves over to the LT path and once Wi-Fi come back it the end moves back to the Wi-Fi path on the lower graph here you see what happens when you are in aggregation mode so this also shows you one of the benefits of actually using aggregation or using a splitting also for a flow that does not need the capacity all the time but you see that when you have the Wi-Fi path quality going down before you lose the connectivity to Wi-Fi so the scenario here is that your you\u0027re moving so you\u0027re in Wi-Fi coverage initially and you\u0027re moving out of Wi-Fi coverage and you\u0027re moving back into Wi-Fi coverage and we can see that when we have the aggregation then of course things go much more smoothly because when your Wi-Fi path is getting worse you\u0027re actually gradually shifting over the traffic over to the LTE path and similarly when Wi-Fi is coming back its smoothly going back over there so this is kind of one one of the goals with some of the initial has also been to look at the difference between these different mechanisms between just having the switching or having the splitting aggregation modes and how that impacts performance so this is just one of the examples from the end the three simulations here is a second example that is from the testbed measurements and this is also looking at the handover scenario in aggregation mode and in the first scenario we have a handover that is triggered similarly by this this path that has the shortest RTT having the delay going up and we\u0027re using a shortest RTT scheduler here so what happens when the delay on the faster path increases then the algorithm as expected moves over to the second path which has a stable latency in this experiment and to the right side it\u0027s another handover scenario where you actually lose the connectivity on one of them on the the cheapest path completely and then you immediately switch over and traffic goes over the second path so the "
  },
  {
    "startTime": "01:58:16",
    "text": "two two scenarios here are just two examples of different scenarios one where you have a latency spike on the path and the second one where you immediately lose the path and this is also immediately visible to the protocol in this case and as a third example this module shows this graph shows a bit also the impact of the reordering module on the receiver side so what we look at here is the packet delay distribution so the digital in the wrong button the jitter that you see at the receiver side in the packets that arrive and we now look at some different scheduling and reordering mechanisms so the blue one here is just a dumb round-robin or weighted round robin 8020 share scheduler and of course then you would get a lot of delay differences in the packets that you receive if you use some more better scheduler like the shortest round-trip time first or even better the OTAs which is a scheduler that tries to also take into account how long it takes to send your packets over a path the queuing in the Sun buffer trying to equalize the arrivals you get as expected that\u0027s reordering but of course the most efficient is if you also have some reordering component on the receiver side and in this case it\u0027s using one of the adaptive reordering mechanisms that we have been playing with yes Jake Jake Alan I just wanted to report that on jabber media Co is reporting that they may not have to disconnect the remote participation shortly their equipment needs to come down another room is still I think she has one more slide and then we wind this up yes so let me move on to the conclusion then so this was just a quick showing you some of the results that we have so we now have a implement prototype implementation now also some industry simulations to test things out and some of the first experiments look quite good so we are tested both the switching and aggregation scenarios we\u0027ve also done some measurements with the congestion control UDP flows running nada the congestion control for real-time media that is being worked on in orem capped on top and and then of course things gets more complicated and more interesting so that port needs a bit more work and one issue here is how these things will relate to 3gpp and how we can get some of these solutions into 3d PP in time and my colleagues at Deutsche Telekom is having lots of discussions with other operators and vendors how to approach this whole problem space and we will try and "
  },
  {
    "startTime": "02:01:16",
    "text": "continue working on the drafts and happy to receive any feedback we have also the drafts up on github so you can make pull requests you can send those mails or any comments and you also have on this slide link for a paper that we have recently put together which has some more detailed experiment results there was a presentation material for I ICC RG that has a bit more results available and also the previous presentation at TS vwg for more background information so thanks to everyone for sticking around okay thank you very much apologies that we have we wound up doing this clearly we\u0027re going to ask for more time in Singapore and we\u0027ll get you better gender slot in Singapore I believe the Secretariat wish to dismantle the room so if you could leave that would help them you "
  }
]