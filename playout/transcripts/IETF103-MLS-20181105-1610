[
  {
    "startTime": "00:02:07",
    "text": "and the blanking I think do we have anybody who\u0027s willing to be the jabber scribe jabber scribe somebody we need some help chatting with the people on jabber I can do that except I\u0027m not on jabber is the jabber chart the same as the one on the meet echo charter is that different all right so we have a jabber scrab and somebody for taking notes anybody willing to take notes write things down let\u0027s pass around these blue sheets in the while we get somebody willing to write down the notes anybody yeah let\u0027s get those doors closed note-taker extraordinaires anybody anyway welcome to that Chris will do this okay thank you Chris you\u0027re a lifesaver okay so here\u0027s here\u0027s the note well it\u0027s Monday you might not have seen it that much basically it says you what you say and do it the mic here so it\u0027s gonna be recorded video and video and an audio if you have IP are you need to disclose it professionally there\u0027s a bunch of documents you can read about if you want to get the details it\u0027ll be sick of seeing the slide by the end of the week so requests we did a good job but it was we got a minute taker jabber scribe we blue sheets are on the process of just going around that\u0027s your name and your affiliation when you\u0027re at the microphone please state your name and also keep it professional our agenda which he packed up real quick basically is this administrivia the "
  },
  {
    "startTime": "00:05:07",
    "text": "interim recap where we\u0027re just gonna do kind of a quick summary and we\u0027ve got a bunch of architecture the both documents have been revised so when you talk about some changes that were made to the architecture document endings outstanding and then we\u0027ve got a bunch of presentations about that that guts the documents of the protocol tree cam and double join and authentication handshake encryption and efficiency considerations and some message protection stuff will note that the person who is going to present the message protection is uh currently doesn\u0027t have power in his building in France so we may have to see what to do about that so that may fall off um but we have another session on Thursday so I may go there we\u0027ll see what happens and then we might have some updates on Thursday if we get everything done early we probably will cancel the Thursday session but see all right so first up is our quick riff from our chairs here right so we had a great interim meeting it went pretty well we had quite a few people working on the documents who showed up we had several discussions here that will these presentations that are gonna happen today are going to kind of go over and summarize we had discussions about double joins and and proposal about blanking entries of the tree was was introduced and debated we had a discussion about art versus tree chem and eventually settled on going with tree chem as the the main construction with the caveat that depending on the formal analysis if if it turns out that tree cam does have some some larger deficiencies that were not known now that and we may be able to roll it back there was some additional discussion about message protection in particular about AES versus AES SIV this is this is something that we sort of tabled and we didn\u0027t didn\u0027t resolve at the interim as well there\u0027s also some discussion about authentication and we\u0027ll we\u0027ll recap this I guess in the presentation today and yeah so some other updates from there we planned to go to the hackathon and have attempt to do some some level interrupts and that\u0027ll that\u0027ll be discussed as well here today so that\u0027s basically the summary of the interim and yeah a bunch of ideas that were brought up but the notes are available say that um Richard did you want to say anything about the "
  },
  {
    "startTime": "00:08:08",
    "text": "hackathon before we go on or side in part of her three things in your bombs and slides so yeah we had some we didn\u0027t work at the hackathon we had two implementations there the Melissa one from from the wire folks and my mlsp p c plus plus one we unfortunately had a crypto Interop issue in that I hadn\u0027t implemented with P 256 and Raphael implemented with curve G five five one nine and I think neither of us got crypto agility working in time but we\u0027ve managed to get some basic level of Interop we have a now a common set of test vectors for the tree math so just the how you navigate left-right parent sibling with an implementation now a common set of test vectors that both sacs pass on so we\u0027ve begun our journey toward Interop with the first baby step i look at that crypto problem is a good thing in one way because the next third person that shows up is gonna be able to talk to one of the two of you right because there\u0027s really only two choices of what house debate crate that\u0027s right okay okay all right thanks a lot come on you\u0027re up it\u0027s one slide but still we\u0027ll give you the clicker yeah I got to use this okay I don\u0027t think I would use the 15 minutes for this but yeah I want to cover the of an issue without protection unlock first these two points that I should to verification more than a open issued something will still confused what the purpose of dark shadow quite we have 2.8 competing dogs with the protocol dog or not so our intention was to have a separate independent dog to find the function and security requirements through the pass code and this committee server from the protocol is not competing it just invented and we will keep of course changing this and updating it as we need in fact a third bullet point here is one of these changes were proposing after implements that protocol deniability so yes the neighbor is still one of MLF goals it\u0027s draft in the current dog as optional still an argument to have it as a required or optional so this is still open for debate to clarify the nobility what what we meant by the nobility here is children I bet you\u0027re not server than every key so tears can not correlate Masjid with the long-term identities des trust or delivery service trust so the current draft mentioned that delivery service should only store information needed to deliver messages however while implementing MLS there are some scenarios the trick general can cover later is it makes more sense that more efficient to store some public groups tape in the delivery service so the proposal here to add this is an optional mode like to store optional information about our public Google state information to the server it makes sense more efficient so it\u0027s safe to do so and it okay to iso-octane draft any question "
  },
  {
    "startTime": "00:11:13",
    "text": "if not I\u0027ll just I know I\u0027m just gonna say we did get some reviews and so the more you read it the more we provide comments moral jessalyn so please comment and review on list and there is a github repo as well so if you want to save some work for the offer all requests are accepted all right Richard I think you\u0027re our next that\u0027s the law that\u0027s the big one I called it stuff that is a good question cap so the tree command double join stuff so it\u0027s this one okay there\u0027s a pretty on the screen wait that\u0027s why yeah yeah sorry right I just sort of jammed all my slides for three different slots into one big deck so will be piecing through this as we go so wanted a recap real briefly where he ended up at the after the interim we presented a sketch of this at the interim and then I integrated that into the draft in between the interim and now and so it was gonna kind of recap where the draft is now it\u0027s people um kind of understand what the what the approach is so again this will kind of set the stage for some efficiency considerations that Rafael will bring up in just a second so it\u0027s something we need to emphasize on the dock a little more heavily is this idea of what I\u0027ve been calling a tree invariants so you\u0027ll recall that the way we get efficiency for big groups in MLS is we arrange the king material the crypto state that the participants hold into a tree where there are D H key pairs at each node in the tree and the goal of the protocol that we use to manage a tree is to maintain this invariance that the private key for a node a circle here is only known to the descendants of that note the cone underneath that node in the tree and that what that enables us to do is that when we want to send a secret value to a part of the tree to that orange area there and we can use the key at that point in the tree to encrypt to all the leaves at the beneath that beneath that point in the tree we\u0027ve had for a little while in the protocol this idea of a double join we the phrase comes up because it first arose we were talking about adding people to the group and the what we call a double join is when we have a violation of this invariant a point in the protocol where "
  },
  {
    "startTime": "00:14:14",
    "text": "the private key for that node in the tree is known to someone so the holder of a leaf who\u0027s not under that notice read someone who who shouldn\u0027t have it according to this tree invariant so these double joins make the tree more difficult to manage the invariants you know kind of assures it gives us a convenient calm mapping between points in the tree and subsets subgroups of the overall group and so if we have this double join around then it makes it more complicated to reason about because you have to track whose double join to a note in addition to who should have the know the private key according to the tree invariants so we\u0027ve been trying to eliminate these double joins to clean up the protocol and make it simpler to reason about who has which keys the trade-off is well let me let me just complete we can with double joins so prior to to draft o2 which we published for this meeting and the add and remove operations resulted in double joins so this is a kind of Modern Art depiction of an ADD operation so the the the intuition here is that this this left this node over here at the left is adding a new member on the right and in earlier versions that the end the members sending the add would set values for all the nodes above the new node the new member in the tree what that implies is that the sender of the add gets double joined to all of these nodes above the new member in the tree because he\u0027s not that new member but he still has access to those keys that he shouldn\u0027t have access to right because you can\u0027t set a value you can\u0027t set a private key without having access to the private key yourself so up in the earlier versions the draft we hit we had these these double joins and at the interim proposed a way to get rid of this which is basically just don\u0027t set things you shouldn\u0027t have access to so the solution to not having double joins us to you know in the ad case here instead of setting all of these nodes above the new node you just add that new node using a key pair that he\u0027s published that the new member has and is not accessible to the ends of you doing the add and for all these other nodes above that point in the tree you just leave them blank and and you don\u0027t set them now that can be made to work in a fairly straightforward manner you just kind of take all the algorithms we had for doing ads and removed an updates before and wherever you are going to encrypt to a node you instead encrypt to what I\u0027ve called the resolution of that node so in this scenario here the this this node is updating and it needs to send out private values for these it needs to encrypt the private value for this nodes of this node and the private value for the route to this node but this known is empty and so we flow through in this resolution algorithm to the populated children of that node so this this one here and then this leaf here and so the the ultimate encryption "
  },
  {
    "startTime": "00:17:14",
    "text": "you get in the messages is this encryption of this value to this node and the encryption of this value it says this node and this node so instead of having to encryptions you have three which hints at one of the you know the impending you know a problem here which is that resolution inherently involves more encryptions than encryption if you have populated tree and so that\u0027s the problem we\u0027re gonna insert in the yeah yeah this is dkg so i\u0027m a little confused by this example view how do you get into the state with this example view where the the root node is known but one of the children is not let me fast forward okay let me get to the next slide because then there\u0027s there\u0027s two scenarios that create incomplete trees the thing about it is we have adds removes and updates say adds updates and removes adds create empty spots in the tree in this way removes create empty spots in the tree by you know by removing the a path from the removed node which I\u0027ll illustrate in a second and then updates undo they heal the tree by in this case you know if the root note had been blank then this update would have reset the root node yeah so this is what our remove looks like when you remove this this third node here your blank out its path to the root it turns out that the content of the root node in in what we\u0027ve got so far doesn\u0027t really matter because you never you use the cond of the root node as a shared secret and and never really use it again when you\u0027re encrypting to the group you\u0027re using symmetric secret that you\u0027ve derived they\u0027re not the the public key that that\u0027s at the root yeah I mean yeah yes I agree with that statement Erica Scola but if I were to encrypt the entire tree let me imagine a pristine perfect tree then I wouldn\u0027t back and save for the root node correct I wouldn\u0027t say for the public he at the root node there is not an instance in the protocol right now where you would need to in cipher to the root node so in the update right but the the way those symmetric keys get used is they\u0027re fed into a key schedule and took in their ktf together with the history there you don\u0027t use the the contents of the root note itself it\u0027s as you write the only ephemerally to generate the EPOXI code because we you\u0027re gonna claim is that all the other cases require incursion to some subset of the trace out of the tree yeah seems like there might be times when you might need it could be in any "
  },
  {
    "startTime": "00:20:18",
    "text": "case yeah this is how you end up with a blank at the root funny it\u0027s just worth noting that like it\u0027s enough it I know quite thick had this vision of like it\u0027s trees all the way down and having that asymmetry were like we\u0027re like even though the root is populated you\u0027re not getting cooked it like totally destroys history\u0027s all the way time yeah in a case you cagey going back to your question this is how you end up with a blank root node if then say this the right hand node sent an update that replaced all the nodes in its direct path then you would end up resetting the root node to attend group value that\u0027s known to the whole group because the that update you know it would send this value to this node this value to this node and then it would send the new value for the route to the populated tree heads under that by resolution yeah yeah the slide that dkg was concerned about had a nice color scheme that would yeah similar idea what one of the interesting things and this gets us this is I think my last slide knew this is a great really makes the an efficiency point really clear one of the nice things about this we\u0027ve had a stub in the draft for an initialization operation for a while you know initialization of a new group with end members is inherently going to be an order in operation because you have to do something for each of those numbers and what\u0027s nice about this the idea of having an incomplete blank tree is that when you add you know so you start start with a one member group here when when you add the first participant well we we said earlier that the add just adds the leaf and doesn\u0027t add anything above the leaf and so if you just do that repeatedly you end up with this tree that has only the leaves initialized which is very natural very simple to describe initialization operation the problem with that is that now you\u0027ve created this tree where any operation you do any well if you want to send an update to reset the root you have to encrypt individually to each of these leaves so the the update you send is linear and so if you initialized a group with 10,000 members you have to do 10,000 individual encryptions you\u0027re not getting any benefit at all from the tree structure because you haven\u0027t said and it said anything up because that would have violated the tree invariant so we end up in this case where we have a very clean semantics because we removed all the double joins but we have very low efficiency in this initialization state you know because of that that increased semantic clarity and so we\u0027ve kind of gone all the way from the semantic ambiguity but high efficiency into the spectrum to the high semantic clarity and terrible efficiency into the spectrum and so I think Raphael has some thoughts on how some intermediate points we might explore I will observe that so this is kind of the worst case for efficiency if you have a tree that\u0027s that\u0027s reasonably full I "
  },
  {
    "startTime": "00:23:19",
    "text": "mean in kind of basing the empirical some simulation work that Raphael and I have done if you have a tree that\u0027s reasonably full then removes and adds will cause some blank notes to appear but they don\u0027t have you know the stray far from log and I think I sent some notes list with simulation results yeah so I feel like you must somehow lost me here so I certainly agree that that this state is like really terrible but as far as I know all the protocols that anybody\u0027s described have a linear or set up state set up base yeah so this first thing I\u0027m confused - hi yeah the question is how bad a hangover is there from the linear setup phase so the the initial creation of the group has to be linear the question is is the next thing you do so long or is it linear or is it half linear or what-have-you right so actually yeah so so if you do this what I said you have this like warm-up phase so the blue line at the bottom which you can\u0027t see because it\u0027s next to the axis is is login and so if you had a full tree and you didn\u0027t have and you had double the double joints the in the first operation would be linear size and then everything else would be log size and if you don\u0027t do that and you\u0027re just doing random operations you you kind of gradually converge from linear down to log so so let me just see if I understand the intuition here which is that can you go back so the first person who\u0027d update basically fills in his direct path and so then then updates the not part of the tree or somewhat more efficient they were four and then gradually more and more the tree gets filled in and then it updates get faster is that the right right yeah right yeah and actually the way you do this if you\u0027re gonna do it properly you\u0027d actually have an an l-shaped fill in here because the creator of the group kind of person an update that will go ahead and make things more efficient than they\u0027ve been yeah exactly been chaotic well don\u0027t you also expect a lot of the group members to be sending an update right away well in in practice yeah you would hope that like as people join the group as people like come online and and realize they\u0027ve been at it they would send an update but you know we\u0027re designed to tell or designing for asynchronous operation here and so as look you know if if half the group never comes online then they\u0027re half of the tree will never get populated so I think Raphael listen that\u0027s impossible turning this year yes yeah so the clear advantage of having this banking mechanism is that you can effectively evict someone from group by deleting all "
  },
  {
    "startTime": "00:26:22",
    "text": "the nodes in their direct paths but as Richard just said that is not adding to the overall efficiency so the idea was couldn\u0027t we do something about it in general and specifically for the in it which is completely inefficient at this point so just to look at it from another perspective if you blank something there is only one rule you just need to get everybody to agree on which nodes have to be blanked and that\u0027s it the next step only comes when you resolve a node when you prepare an update for example but that is in phase two so as I said you can evict someone effectively from a group but you also puncture the tree and that increases efficiency so the idea was that maybe there could be the opposite operation of a blank which would be a set where one participant of the group would simply set the note secret of an arbitrary node and so we looked into it a bit it is not generally super useful so this cup of this would be only to increase the efficiency and because all of the the security guarantees we have achieved with blanking already so there there\u0027s more than one route this one because if you set a secret of a node you need to tell that secret to the children of a node or to the resolution of the children if the children are blanked and this effectively creates a double drying the very thing we just wanted to get rid of so that means that whoever set that node knows that secret until the node gets overwritten by an update but if that doesn\u0027t happen and you want to evict the setter of the node you effectively need to blank this node in addition to the direct path of the setter the upside could be that this yields the tree and makes it more efficient downside is clearly the double joins so yeah this is a slightly different definition that which would cover that one already actually so double John is what we have when someone knows the secret to know that is not in their direct path so if we were to allow double joins we would have to track all of them to know exactly which member has the secret to which node right now we implicitly assume that every member has the secret in the notes of a direct path so there "
  },
  {
    "startTime": "00:29:24",
    "text": "is no need to store that anywhere but if they know the secret of notes outside of that we would have to do some bookkeeping so there would have to be some structure that contains that information that\u0027s what we would call the book and this book would have to be passed to new members or new devices in a multi device context and what is also important is that everybody has the same view on the book because members might have the incentive to lie about certain entries so for example if I invite someone to a group group I might be tempted to not tell them which nodes I have double joined so that I could maliciously still be part of the tree even if someone addicted me so for that we need a mechanism to make sure everybody hasn\u0027t sent you in a book and while the naive approach would be to make the book part of the group state which right now becomes part of the key schedule so we could thanks to the key confirmation mechanism detect any lies in the book immediately so this is a naive yet flexible idea of what a book could look like so for every node if there is an entry which might have zero too many owners and there are many entries in the book depending on how many nodes have a double join of course there could be more efficient representations in memory of a book if you accept certain constraints on how many owners that can be or where the nodes are in the tree in this Richard Barnes just to be clear we need to have this information available in serializable so that you can tell it to someone who\u0027s group because if that member needs then needs to evict someone who\u0027s double joined he needs to also tell everyone to blank out that note or no actually when he\u0027s processing remove needs to know to blank out and he notes to which that then they were being evicted is double joint um almost yeah it\u0027s a terrible idea outside of one limited case I mean it was it was worth investigating or at least presenting the results so that we don\u0027t do that twice but I mean this is exactly why it\u0027s a terrible idea maybe you suspected that already so if if piece the note that was previously blank and we want to set a secret in there then we would have to tell that secret to the left and the right children or the resolution of these nodes and so specifically when we set something and we suppose that the left children was already double joined by say Alice and now Alice previously only "
  },
  {
    "startTime": "00:32:26",
    "text": "knew the secret of L if we came the secret of P to L than Alice has effectively also double joint P and all we did was basically to just set P so this increased the number of double joins for Alice which is certainly not nice this this could be alleviated by the fact that instead of chemically so L and are directly if those nodes are double joined we could do some sort of a resolution there where we assume that any double join node is in fact to be treated like a blank node and in that case basically we wouldn\u0027t tend to l but to the children of L as long as they\u0027re not double john and that would prevent Alice from knowing the secret the new secret of P but it is quite expensive and it doesn\u0027t really help because if we do an update which as Richard pointed out earlier today could be seen as a number of sets really now the problem is that Alice initially double joined L she gets to know the secret of P and because in an update we hash up the secret all the way to the root so Alice has now doubled joined all the nodes from L to the root so ya worst factor would be log of n in this case so it gets messy yeah so aside from that there seems to be an invariant where you if you accept that the book would increase in size the operation cost would go down and vice-versa basically but a book that is increasing only means that you have postponed some of the work because it means that if you want to evict members at some point you will have to do a lot of blanking because of all of the entries in the book and then actually everything becomes very expensive again so if anything you could buy time with this so there is one edge case as Richard said and this is actually what triggered this whole research and that\u0027s the reimage edge case where you start with a completely linear model and the cost is in in o of n it does converge rather quickly so Richard did that simulation I I tried it on my end I think this is a graph so this is very thin on this monitor here so this means "
  },
  {
    "startTime": "00:35:28",
    "text": "is that thousand is the number of people in the group and so the very first update has a cost of exactly one thousand because the resolution will be one thousand so as people come online and you expect them to actually come online rather quickly typically I mean it is asynchronous but some people are going to be online and they will immediately start to do an update so this is going to actually decrease very quickly I don\u0027t know if you can see this blue line here so this is the average Co path lengths the average from from all members basically and there is a worse case and a best case so roughly after it\u0027s hard to tell from this graph but after less than 50 updates you\u0027re already below a hundred different operations so this is good in general the problem is that the first 30 40 members who come online they have an insane amount of calculation to do sorry can you there was a graph that was up earlier that showed a very different picture about convergence and I\u0027m wondering if you could just explain what the x-axis is here that differed from what the x-axis was on the previous graph right I think they\u0027re fairly similar in the sense that in the previous graph it was a time line and it was interactive of people who joined doing an update and also doing other operations whereas here I\u0027m assuming that people only come in line at some point and will do an update so you don\u0027t know so basically you don\u0027t have any removes yeah that\u0027s correct sure yeah exactly so the effort never goes up again that\u0027s not yeah I think there\u0027s two things yeah there\u0027s there\u0027s no adds or removes here and I think there\u0027s there\u0027s many more time steps here so mine was the first you know 50 or so time steps of the group and he\u0027s covering the first thousand for the whole groups update so so you\u0027re seeing some some horizontal compression in this case right so I mean it converges all the way down to this purple line which is log n so this is actually very nice scale to see the difference between n up here and low down here and that is only for a group of 1000 members so with ten thousand or fifty thousand it\u0027s even more dramatic we all know that but it\u0027s always impressive when you see it so the one idea that occurred to me is that potentially could be a good idea to increase the efficiency by warming up the top of the tree so what does that mean if the Creator was to precalculate some "
  },
  {
    "startTime": "00:38:28",
    "text": "of the node secrets and share the public keys with everybody and effectively double joining all the nodes in the top of the tree that could maybe have a very good impact on the overall efficiency because if if we look at this graph again so what we see is that the the problem is really only here in the beginning once we\u0027re like here we we don\u0027t care about the rest because we\u0027re very close to the login line and there\u0027s nothing to improve here really so we pre populate the top of the tree meaning the creator of the group generates secrets and and derives private and public keys and makes those available to everybody who\u0027s in Madinah group and it is most effective if that is done at the top of the tree it could be done anywhere because just like you can blank a node anywhere you can also set a node anywhere but it is most efficient at the top that\u0027s where you reach most of the leaves that are underneath and so a tree is composed of levels horizontally and so with every new level that is being populated you basically divide the cost of the first update by 2 so this decreases rather quickly so an example in numbers we take the group of a thousand members again we take the top 3 percent of the nodes in the tree so there\u0027s like 30 nodes in this case they are pre-populated so this is still fairly quick because we only pre populate 3% so for the creator this is really not very expensive to do and it\u0027s still linear in theory but it is fairly quick and so that gives us a completely new picture where the scale has changed quite a bit so the first update now is not 1,000 it starts at 70 and then it converges again in the same fashion as the other one except that you don\u0027t have these high numbers anymore and so this is a comparison chart between the two so that the purple one is the initial one that started at 1000 this one starts at 70 and then they basically very quickly not only converge but actually become identical because the effect of the the pre-population of the top of the tree wears off rapidly as updates will overwrite all of that so that looks good but we still have a double drawing "
  },
  {
    "startTime": "00:41:28",
    "text": "situation as such so there is some sort of a cleaning mechanism so as people come online and do updates they will overwrite the tree so we still have this proliferation effect that we saw earlier when you have a double joined node and that happens to be in the co path of an update but the big difference here is that first of all all of the nodes are only double joined by one person which is the Creator and so anything above a double on node is also alright double joins so this this particular problem has no effect here and what happens is that as as people do updates one level at a time the double joins are going to to vanish basically until you you really only have the top of the tree that is the Padron and then also that goes away and so if you warmed up k levels of the tree it would take two roughly two to the k plus two updates to do this cleaning and in the example before we had five levels so two to the k plus two is 128 in this case in a group of thousand so roughly when a bit more than 10% of the people have come online and done an update which they\u0027re supposed to do the tree is completely clean again and and reasonably populated if they don\u0027t for some reason you can still evict the creator of the group by blanking whatever nodes that are left and our double joined so you would also need some bookkeeping that need to be passed that it could be much more simpler than what we saw earlier and yeah question yeah how much support is life get if we just assume the Creator is special and can never be affected it gets cheaper if you don\u0027t blank the top of the tree so and and well you don\u0027t have to do the bookkeeping right depends on how we\u0027re gonna do that exciting I guess I\u0027m just saying like there are certainly all like you know their messaging system this which basically on the structure like you service in the Creator special and I\u0027m just wondering if you willin to tolerate you know if you only tolerate out that restriction like would that be that\u0027d be a very substantial game yeah I mean that that is definitely a good observation because most systems where you have a creator you\u0027d assume it\u0027s some sort of administrator or a moderator or whatever and those rarely get evicted from a group so the cost you would pay right now in such a situation would only be the bookkeeping if if there\u0027s only one person who can double join then you can "
  },
  {
    "startTime": "00:44:31",
    "text": "condense the bookkeeping to something that is bytes two kilobytes maybe regroups and that that just needs to be passed around so and the payload size it\u0027s not really a pain so the cost seems quite reasonable for still being able to evict even the crater the upshot if you want to do double join only at in it time is that you need to carry around one bit so if you want double join only at a time and you want to be able to evict the creator then you need to have one bit per node in the tree that indicates whether the Creator is still double joints it\u0027s at that node and the costs until you try and remove the creator is only that and then when you try to remove the creator you have the caught you take then the cost of removing all the nodes from the tree that the creators still double joined see which could you know drop you back until the new your state I mean I guess that to cut to the chase right it seems like the recommendation you\u0027re edging towards is that we do that namely the creator create the tree in a any any populated state with the bookkeeping to all the Creator to get kicked out if you have they have to do is is that where you\u0027re basically fitting for just that sounds like a good plan so and there\u0027s to be super clear if you allow the creator to be double joined and never to be evicted then you don\u0027t have to keep any extra state at all oh yeah that would be correct him right quick summary so generally setting nodes is expensive and doesn\u0027t really do any good but warming up the top of the tree certainly can increase efficiency so this whole thing was really only about efficiency so farther the whole security aspects are only tied to how well the bookkeeping works so that that we would have to make sure that the bookkeeping is reasonably secure but it\u0027s nice for once to have a discussion early about efficiency ya know I mean any questions and so I think to coke continue our was going with this I think thinking of this is warming up the top is probably probably not worth well if we\u0027re gonna take the bit of state we\u0027re gonna have the bit of state around you might as well just initialize the whole tree and get max efficiency yeah it would be interesting to do some simulations because so again if if we go back to this graph so the the situation comes you know more than bearable after 20 percent or whatever you assume to to be a good situation so if you pre "
  },
  {
    "startTime": "00:47:32",
    "text": "populate the whole tree I mean yeah you you converge more quickly towards the log n line here but that\u0027s really it and you you would put a lot more load on the Creator so right now the Creator only does 3% it could be a different number of course but doing 100% in large trees can be much more expensive cause you derive for keys couple of clarifications if you pre populate the whole tree then you are never not logged in so you you\u0027re the first update that someone send is is immediately efficient like it\u0027s it\u0027s immediately log in so there\u0027s no warmup period if you pre populate the tree and the second thing which which John Milliken convinced me a little while back is that you don\u0027t actually have to do any additional diffie-hellman operations because you\u0027re already assembling a secret key with each of the new participants it\u0027s just additional stuff you should go to that into that water I mean that\u0027s something we can certainly look into that so this is daniel ganc Gilmore I just wanted to observe that we\u0027re having this discussion based on the idea that what we care about is a large initial group and that not every group is large initially right yeah so so those yeah if they\u0027re gonna be ads that like a large number of ads that happen later than this analysis doesn\u0027t necessarily apply to that cage yeah absolutely I mean if you start with a small group and probably most groups will start that way where you don\u0027t have a fixed set of participants in the beginning then but the the big difference there is that the tree will already you know be populated with the small group of people so it will still be expensive to add a large chunk of people but it\u0027s gonna be much better than linear it\u0027s not just expensive to add a large chunk of people it\u0027s expensive to operate the group if the large chunk is added post creation right if we\u0027re talking about special casing creation that\u0027s what I meant yeah adding them is still cheap but then doing updates it gets expensive I agreed I mean we we could probably do some simulations there as well see how bad it really is my gut feeling right now would be that it is still a lot better than the linear in it as such is it the case that doing updates is the only expensive thing or is actually sending a message more expensive so no I mean the message is only encrypted once under one key that everybody should have so with with blanks yes okay thanks as well yeah that doesn\u0027t change so I mean sending message is always constant time because you establish the symmetric key that everyone has it\u0027s only so ads are easy in any case because you\u0027re just okay well ads get more more ish expensive oh no actually the latest one "
  },
  {
    "startTime": "00:50:32",
    "text": "no you just ratchet forward so you don\u0027t actually have to send you to the group and you just send entropy to the new member its updates and removes that get expensive because you have to send information to a subset of the tree well I think I\u0027m like just about tuck at numbers I have to bias between first about the bias between like upfront great time versus work by people once the crease created um I think I\u0027d prefer to buy us for our own work create time because you\u0027re creating a person group like first of all you have to do like the crap ton of work just to get that to work I mean like you know like you just select out what people like super expensive and so like if you have to burn like comp if that operation takes seconds nobody really cares but I don\u0027t you don\u0027t want to be the case that when I joined the ten thousand person group then like I got to spend my CPU for a while don\u0027t like just do anything at all so I think I tend to buy us that way in terms of efficiency I\u0027m true to pre-pivot of the whole tree just yeah yeah yeah exactly it\u0027s like simple of the thing about I\u0027m like dumb so you know it\u0027s like easier the is it is as I understand it in the case of the tree gradually grows it\u0027s like not after that efficient you build the tree that way but the spaced out over time so you kind of don\u0027t know is that not Korean thinking about it like in the version where you like add people one at a time that\u0027s actually not likely to be efficient way to do it but it\u0027s like but but it\u0027s like no we know this is cuz like you had the one guy and then our guy in our guy right yeah right so that seems like like that seems like I should apply encase these kids that I was worried about was if we\u0027re talking about like say company size groups is that the admin sets one up with you which is just like you know small tests to make sure the group works now now it\u0027s working now we\u0027re gonna turn around and add you know the entire division because we\u0027ve because now we know that the group is working and now we add the entire division and if that suddenly becomes expensive then that\u0027s kind of a weird like you\u0027re the UI becomes weird yeah that\u0027s a good point now so that could lead to recommendation as to the user experience sort of fact I\u0027m in love with the tree map well enough but like if you need to do if you have a if you have a existing small tree and then you need to do a book out of a perhaps other people is there an efficient algorithm for that but is not there\u0027s more efficient than I\u0027m guessing the right well I mean what what are we considered with the setting mechanism is that you could pre populate the direct path of the each and every one of the people you add the problems and the double join so you you end up again with the tree that has a John so yeah it would make it deficient in the D key do this example right I mean I mean indeed use example that "
  },
  {
    "startTime": "00:53:33",
    "text": "person is the admin and so double joining them is like like it\u0027s like hey you know what if that pushing its fire you just deal with it but I think something I guess I\u0027m sort of like generally like I mean I sort of have my head that there\u0027s four to main to main environments here one is basically Enterprise cases in which case you\u0027re like a lot of people but you do a lot of bulk adding and that person just like when they hire you deal with it and there is sort of like spontaneous groups that grow gradually and in the and those don\u0027t need math master Baek joins but maybe the case is that you know I\u0027m the founder but then I\u0027m like an awful awful Jorgen I get kicked out and I get you can kick out a bolt but the doesn\u0027t have this doesn\u0027t have this weird property of like you know one a set up right right I mean if we assume that the creator should you know never be evicted or if we want to evict the creator it\u0027s allowed to be super expensive then we can actually calculate the direct paths for the people we add I think that could work if you had a ton of people after the creation but would have to look into the details I think that would be a simplification I propose unless somebody thinks alike those important kiddos or I like Seth or a lot of different additions and I spent more time sure I spent more than average thing at the tree mouth here I\u0027d like to nevertheless I spend the first 10 minutes being like you copass and resolution like my head like hurts it\u0027s like the more we can make this not complicated for people like unless like this like a lie again I think the better Richard you know aside from simplicity for poor implementers whose heads are spinning it may also be that the mod like the model for the users about what is expect what is an expensive group to operate in versus what is like not an expensive group to operate in might be like if the if the efficiency is unpredictable and people are like I don\u0027t know why this group is so expensive to operate and the trade-off is between that or a design where we say yes some groups have admins and admins are expensive to evict like that\u0027s a very clear and predictable behavior and that might turn out to be easier just to manage in terms of setting expectations for the users but no I mean later on we\u0027re gonna talk about efficiency more in general so probably would connect to that again so I guess I\u0027m trying to figure out what the action item is for the stack here well I think I curves idea to basically extend the the warming up to a situation where you add a bunch of people after creation that would be interesting to see if that words are searched by pre-populating their direct path and and what the efficiency is there and if we come to the conclusion that that does well then yeah we should "
  },
  {
    "startTime": "00:56:37",
    "text": "simply add both things to the spec yes I think I might propose we do this in kind of two tranches I think we should do in it first because we\u0027ve had a stub there I would love to assign you the the actions room to write a PR that does in it and with this and then I think along with that in that first rush is adding a flag to the trees tree node struct to indicate that a node has tainted its double joined yeah and I think you will you hear out the details almost but you need the flag there so that\u0027s kind of the first caution and I think the second trust you might consider is effectively a batch add function where you can introduce you know maintains it nodes I think the the normal one off edge should continue to be free of double joins but we might consider a batch add they can have a bunch of people at once that\u0027s effectively the same as in it in terms of how it taints the tree yeah right so so the yeah that\u0027s that\u0027s why I pause and make noises about figuring out the details because the critical thing is that the participants in the group need to know which part for which participants when those participants are evicted do they need to delete all the tainted nodes right so in the init case it\u0027s the Creator but in the batch ever you might have other administrators around you one of those administrators is Vic you might have some blow away the taste of goods as well so that\u0027s that\u0027s seems a little more complicated but I think we can discuss it on the list so yeah I think let\u0027s do in it with full tree warm-up and then figure out this bad Chad thing and Caidic how much different or how much more work would it be if instead of trying to do this batch add we just said I\u0027m gonna do a new in it for a new tree with everything I want you know thought crossed my mind I guess it depends on how many people are in the tree already like the ratio of existing to being added people and I know so I mean you you destroy everybody\u0027s local state by doing that in a way which yeah sounds at first sounds very dramatic and the true if they\u0027re there you know actual bad consequences coming from it but yeah short answer I don\u0027t really know him Marko zaror scam trying to get my mind around how the bulk ads detect the shape of the tree so if a member does a bulk add of many new members that they all get added to the same part of the tree or did they get this you get across entire width of the tree so right now they get added to the next free spot in the tree basically to the right exactly two unbalanced razor yeah "
  },
  {
    "startTime": "00:59:41",
    "text": "I mean trees are not guaranteed to be balanced anyway they\u0027re they\u0027re supposed to be left balanced but now that you can remove people and rank their path they\u0027re punctured anyway so trees really have really changed in shape with blanking quite a bit because you can think of them as a collection of Supremes some extent but yeah can they get quite badly unbalanced it from the on the left side of the tree you have a lot of blank nodes then yes otherwise it just grows the tree I mean that they don\u0027t get really unbalanced the only thing is that they miss a lot of inner nodes so that that\u0027s why it becomes inefficient there is however one proposal on the mailing is right now which I think makes a lot of sense and that is to add people into the spots that have been blanked previously simply to make the tree look nicer again so back to the bulk and I like to think the bulkhead has three merge operation like if you add the new people to add separate tree you can find a way in the genus to merge the two trees I\u0027m ritual and I think I might find a way to merge trees I don\u0027t know yet okay yeah make a proposal another that would be an excellent topic for the next session of our graph theory seminar okay there are no further questions I guess we can move to the next one that\u0027s Richard medication Richard yes all right this has no treatment yeah that one so this is kind of a recap of kind of like with the blanking stuff of some stuff where we had an initial proposal at the interim and we went off and implemented some stuff after the interim between the interim and now and now this quick recap of what we did so in the version we published before the interim I had ginned up an authentication mechanism now when I say authentication this is how do we ensure that all the participants of the group have a consistent view of the public keys and identities of the members of the group and how do they use that information to authenticate handshake messages as they come in so in the in the version before the interim I you know ginned up a scheme based on some group authentication work in the literature scheme from Jonathan Katz and that\u0027s a young that basically folded a "
  },
  {
    "startTime": "01:02:45",
    "text": "bunch of stuff into the key schedule that ensured that if you if any two members of the group had a different view of the roster of the group where the roster is the list of identities and public keys for members of the group if any two entities had different views of the roster then they\u0027d arrive at different group keys this is great so that the confidentiality keys are tied to the consistent view of the group state so you have a nice correlation there the thing that someone observed at the interim is yeah that\u0027s great but you never have a the participants never realized they have different keys and some messages don\u0027t decrypt so the suggestion that Cass Kramer\u0027s made at the interim was to have some explicit key confirmation as part of this and so that is the addition that was made in the latest version of the draft so in draft o2 we had now have a key confirmation back so we you basically process this check message to update your group state to get a new group key for this new epoch and then you use that new group key to compute a Mac over the handshake message to verify that you\u0027ve gotten the same thing as the sender so now by the time you\u0027re finished processing a handshake message you know that if that processing succeeds if the Mac passes then you know that you have the same view of the group state that the sender did so now you know transitively across the group the group should have the same view the only real question that came up can you fix the amoment there another one question that came up in the discussion of this which was admittedly a little rush because it came in right before the draft deadline was whether to have whether they have this confirmation be a Mac or to just derive something off the key schedule so I made two PRS the one of them got merged I forget which is which only got merged the other is still open the observation here is you know in TLS following CSS pattern we derived the key that you use for the Mac off of the key schedule but the key scheduled this derived secret operation already folds in the group state which includes a hash of the the handshake message you just processed so the group state and the messages process are all included in the derivation of this confirmation key so in principle I think without having built-ins hammer and model of this I think that if you just publish that group that confirmation key in the handshake message and everyone checks they got the same confirmation key that\u0027s sufficient if it proves the same thing that you would get as using that thing in a Mac so it\u0027s a Mac over the handshake message now what\u0027s it what actually landed in the draft is you take that confirmation key and you use it to compute a Mac of the handshake message so which is very much parallel to what TLS does in terms of doing it\u0027s finished Mac so to do the confirmation there so the challenge here is though the reason "
  },
  {
    "startTime": "01:05:46",
    "text": "that seems like kind of useless is that this drives H KDF extract and the drive C operations are HK DF which is based on H back to start with so what we\u0027ve done here is take a secret use it with H max to derive the confirmation key and use it with H back again without folding in any new entropy just to generate the thing that we published in the handshake message so it it doesn\u0027t seem like there\u0027s any security difference between these two cases due to this extra HVAC but the feeling on the list was that you know people are vaguely more comfortable with the extra HVAC because it looks more like TLS so I just want to put this on the screen in case anyone had any other opinions anyone wanted to express their visceral discomfort with publishing things derived off the key schedule or it says publishing and Mak values otherwise I think we\u0027re going to just going to keep the Mak until the academics toss something one way or the other you know have a nice thumbs up from Chris Wood alright that\u0027s all I got I think it\u0027s over to Nadine to do yes okay can you hear me is this working yep okay hi everyone so I\u0027m gonna be presenting about its it\u0027s not really a finished proposal but rather something that I think might be interesting in certain parts of MLS which is a sort of primitive or scheme that I don\u0027t think has been discussed before even though the underlying problem has been discussed very much I think since the beginning so next slide please alright so the idea that I would like to talk about is hierarchical deterministic keys or also known as hierarchical key derivation and this is something that we can apply to signatures in order to try to get closer to obtaining ephemeral signing in in MLS and so why is ephemeral signing interesting because in MLS as in signal as in OTR and essentially any mainstream secure messaging protocol you have a long-lived signature key and that signing key never changes and it\u0027s always assumed that if you have a compromise of the state then that long-term identity key is going to have to be leaked so I I think that it\u0027s obvious that we cannot change the we cannot have a rotating long-term identity key that\u0027s definitely out of the question but I do still want to see how we can address that problem and how we can sort of try to limit the impact of long term identity or long term signing keys as much as possible all right so the the idea behind hdk is "
  },
  {
    "startTime": "01:08:46",
    "text": "essentially that if you have a private key you can generate a public key from that private key so here in this notation we have a base point B we have Alice has a secret key K there\u0027s a public key generated from that secret key was just just K multiplied by the base point and then you have a random scalar X and the idea is that if you take a signing primitive like SEC p25 six k1 which is the one that\u0027s used in Bitcoin then if you just add a value to the private key and then you add the scalar multiplication of that value to the public key then you will just get a new key pair where essentially so this is to the right of the of the current slide you\u0027ll see that there\u0027s the same value that\u0027s added to both and then the key pair that you will receive is immediately you know the secret value corresponds the new secret value corresponds to the new public value and this is interesting because it means that you can essentially have different parties generate a new public like essentially derive new public signing keys without there having to be some kind of exchange for that new public key pair to be sent by Alice to Bob and so on and so next slide please so this is already used in Bitcoin essentially exactly the way I just described and it\u0027s also being considered for use if not already in use and tour I\u0027m not sure what\u0027s going on there but it\u0027s definitely been discussed next slide please but the thing is so one potential roadblock could be that in the in MLS I think that the discussion has largely been centered on maybe using edie two five five one nine as the signing primitive and so this wouldn\u0027t emit obviously apply to et to five five or nine because it\u0027s not just naive scalar multiplication in the way that SEK p25 six k1 is but however what really was encouraging to me is seeing this paper called hierarchical deterministic keys over a nonlinear space which essentially shows that it\u0027s possible to apply this technique to 280 to 509 despite 8255 or nine having clamping and clearing of individual bits and hashing and other things that are just not a linear scalar multiplication so that that was encouraging so next slide please so this is how this would generally work so if you just have a so at the top we will so it\u0027s essentially a tree like structure and at the top we\u0027re gonna have this root a signature key or a root public key so that\u0027s KB and blue and then from that you can just do an HK D F with Kb but also with so sorry if you "
  },
  {
    "startTime": "01:11:47",
    "text": "look at the left here you\u0027ll see that we\u0027re essentially initially generating the secret K and also the value X from shall we say like some some secret value W and also the session ID of the and this is just something I made up to to explain how this works and then from there you can essentially derive a bunch of new sub keys that are individual different signing key pairs based on HKD effing x with the public key with the root public key and also a counter for each block that you\u0027re deriving and then from that so if you look at the left most child key the leftmost green block from there you can also derive something that is called a hardened child key and the reason for that is that the hardened child key shown in orange instead of just using X uses actually the output of the previous edge KDF so it has a higher level of sort of separation shall we say from the original key material and hardened child Keys have stronger security properties for reasons that I don\u0027t think are relevant right now but we if we end up using it we want to focus on hardened child keys next slide please so I think that I\u0027ve been pretty hand wavy so far and I want to try to bring that all together so we know that currently in MLS there\u0027s only one signature key and this is the case with any secure messaging standard and we usually use that one key for what we always use that one key for all the conversations always and if your mobile phone gets compromised then that key is stolen and then you can be impersonated indefinitely and so I think that the interesting thing with hdk is that it allows us to compartmentalised signing keys per conversation per epoch and the conversations without an additional key exchange so I think that the improvements here are clear in case of partial state compromise but that\u0027s that doesn\u0027t matter because already the initial signal like method of dealing with identity keys is considered to be sufficient in case of partial state compromise in fact we never consider the danger of a signing key being compromised except if we\u0027re talking about full state compromise right so so far it\u0027s not really clear what hdk can actually bring to mls and so I\u0027ve been thinking about this and I think that uh there\u0027s one way in which the additions that are possible because of hdk or the improvements can be explained so next slide please alright so let\u0027s look at the way that signal desktop currently does key management and so all of the popular secure messaging applications currently essentially focus on smartphone usage "
  },
  {
    "startTime": "01:14:49",
    "text": "for obvious reasons because most people are texting and messaging using their smart phone but also sometimes maybe you want to use them at work so you have a desktop client and so the way that signal does this is when you\u0027re setting up your desktop client first you have to register using your phone but then there\u0027s a pairing mechanism and then all of the keys are sent from your phone to your desktop client and that includes the identity key as well as really just anything and also all the conversation information and so this is how it\u0027s done in signal and so both devices now will have your identity key so if my phone gets compromised I can be impersonated and if my laptop gets compromised I can also be impersonated and definitely across by any device or attacker because it\u0027s the same exact signing long-term signing Keeper next slide please so let\u0027s look at not whatsup does this so I think that what\u0027s up maybe well I don\u0027t know this for sure but perhaps they were aware of this concern or this trade-off and they wanted to avoid it so the way that whatsapp works is that your phone still has all the keys and what\u0027s up uses the exact same protocol as signal does however the phone still has all the keys but there\u0027s like a symmetric AES link established between the phone and the computer and the desktop is essentially just a view into the phone so that desktop has no keys as doesn\u0027t have identity keys doesn\u0027t even have the ratcheting keys it just has an aes link to the phone that\u0027s established by scanning a QR code and then it\u0027s just sending requests to the phone please encrypt this message for me and then the phone as we see is forwarding the encrypted messages back to the computer and so notice here unlike in signal if you turn off your phone you will not be able to use whatsapp on your computer the phone has to be turned on and connected to the Internet at all times for this to work because otherwise otherwise the computer cannot contact the phone and send any messages because all the keys are on the phone so next slide please all right so if we look at signal it would seem that they\u0027ve decided to focus on usability so they wanted to so that you can turn off your phone and you\u0027re still okay and that\u0027s a reasonable choice and if you look at what\u0027s up it seems that they\u0027ve decided to focus on maybe security because generally the environments in which you\u0027re executing all this secure messaging code on the desktop tends to be from an engineering perspective maybe more susceptible to compromise it maybe is running in the web browser or using web runtime environments and on on phones you especially if you\u0027re using iOS you have really good security when it comes to key management and security in general on Android it\u0027s different but on iOS it\u0027s it\u0027s very quite secure compared to everything else so I think that maybe what we can do with hdk is actually arrive at a better compromise when it comes to having this sort of desktop "
  },
  {
    "startTime": "01:17:51",
    "text": "like system or any kind well you know sharing sharing your session with a desktop or sharing your session with any multi device system that MLS might end up including so as we saw in in signal you\u0027re just sending your identity code key over and if that identity key is sent over then if your computer gets compromised you\u0027re done with what\u0027s up sure if your computer gets compromised nothing bad happens except maybe some plaintext leakage but you\u0027re okay I think that maybe here the interesting innovation with hdk is that we can essentially from a never changing unchanging long-term identity key and this is important right because it\u0027s it simply cannot be the case that our long-term identity key ever changes we needed to be unchanging for for identification of authentication to work at all but what we can do here is that that can stay on the phone and then the hdk root derived from that key for that conversation or the hardened child of it or whatever you know these are details that we can come to if we decide that this is a lucrative thing to research and investigate can actually and only that for the existing sessions can be transferred over to your desktop and so what would happen in this case is that if you turn off your phone your phone is not connected to the Internet you can still authenticate yourself for the existing chats if you want to establish a new group chat perhaps yes you will have to turn on your phone however for existing group chats you will still be able to authenticate yourself and so you have the ability to keep using your multiple devices without really having a huge risk in the way that signal does have and at the same time you will have more usability in the case that your phone is offline which is superior maybe to what\u0027s up and so this can be really good from a usability perspective because I don\u0027t know if you guys have ever had this experience I use whatsapp all the time and even if my phone is online and connected and powered on and everything there will still sometimes be a delay because of the power management features and so if I send a message it\u0027ll take time to arrive because the phone like needs to be woken up and I need to open whatsapp because it\u0027s in the background and so all of these things will be avoided as well I think if we look into this mechanism and so this was proposed on the mailing list very briefly a couple of weeks ago some people said that it\u0027s interesting but there are potentially better ways of doing it and I am very open to these better ways we don\u0027t necessarily have to use hdk specifically but from my from my perspective the htk was the idea that got me thinking about this and I think that it might be interesting to well actually next slide please so Nadine we got two people in line do let\u0027s just go ahead and try to get their questions going out that\u0027s okay well the "
  },
  {
    "startTime": "01:20:51",
    "text": "next slide is the conclusion it\u0027s just 35 there it is all right so what I what I the the general question the larger question that I was asking is to what extent can we generalize stuff like hdk in order to restrict the damage caused by state compromise especially with regards to signing keys and that\u0027s all that is my presentation sorry if I took too long no thanks Mindy this is Daniel con Gilmore so if you can go back one side so this this intermediate proposal that you have is an interesting one and I wonder about the consequences for users if they\u0027ll understand that I can have a continuation of an existing chat but I can\u0027t start a new chat unless my phone is online I\u0027m wondering about the sort of usability implications there and that led me to the question of well maybe you could actually maybe the phone could send some like a handful of not yet used hdk routes to the to the laptop so that you could start a new chat but you can maybe only start three or four or something like that as so that\u0027s just so the users don\u0027t typically run into this problem of like wait I you know I need to I need to message you know so and so now and I don\u0027t have an active conversation yet but then I started thinking about that and I\u0027m and I\u0027m wondering like well okay at some point the compromise of all of the roots of all of your active conversations sounds pretty bad to me I\u0027m not sure how it\u0027s it\u0027s definitely not it\u0027s definitely not a story illegitimate compromise it\u0027s still something that is bad I think that what I\u0027m trying to do is to arrive at a well compromise is already being used in another sense at a middle middle ground between between what signal does and what whatsapp does because both approaches have really strong capabilities signal is really nice to use and fast whatsapp is I guess more secure but slow really like in some cases like 30-second delays which are annoying in them in the middle of an active conversation with someone and so I do agree that if you want to do a kind of pre key approach and forwarding all of those keys onto the device especially that would even exacerbate the window of compromise that you\u0027re mentioning which is already quite serious right being able to be impersonated an existing chats is is a bit of a problem but the thing is I think that this is outweighed by how easy it becomes to recover from that compromise because in the past if I lose my phone and then I have one I want to use signal again I have to regenerate a new identity key and then I have to like everyone\u0027s going to freak out and if I\u0027m in a security centric community everyone\u0027s gonna have to be authenticate and check my "
  },
  {
    "startTime": "01:23:51",
    "text": "fingerprints and so on and so there\u0027s a sort of like large hurdle to overcome in case that happens because the compromise is absolute right here if yeah so I think what you\u0027re saying is that is that recovery from compromise is actually the goal here right because because the compromise that we\u0027re looking at in the laptop case here is basically impersonation on all of the active chat active conversations that I have right and so so the goal here I think is to provide recovery without modifying the the long-term identity key I suppose I suppose that would have to be the case yes it\u0027s also it\u0027s also if so it\u0027s true that all of the active chats would not be protected by this and therefore it does make sense to restrict the conversation to recovery from compromise the thing is if we look at the current MLS spec there is some notion of ethics that\u0027s being discussed and so perhaps I don\u0027t know how this would affect the usability element perhaps it would destroy it entirely and thus this would not be a good way to do things but perhaps it would be interesting to see whether we could have some kind of new hdk thing happen at every epoch and therefore the phone would have to be online at every epoch so I don\u0027t know maybe that would make it better but at the same time in that case you will need your phone to be online intermittently but maybe that may be in fact that\u0027s more realistic because in general people\u0027s phones are indeed turned on they\u0027re just not always connected to strong Wi-Fi and they don\u0027t always have whatsapp in the foreground they do certainly have it at least once every half an hour so perhaps that is the better way to do things so sorry this sounds really interesting from a brainstorming perspective and I don\u0027t think I want to like push further on on like hashing it out at the mic but I but I think this requires a lot of usability and like saying hey you could do this with some arbitrary schedule because we assume that people\u0027s phones will be connected at some certain times like I think that\u0027s going to require quite a bit of okay so I first of all I just want to say I strongly strongly agree and this is why this is not like a you know guns blazing full proposal this is like the the title of the slideshow it starts has a question mark at the end at the same time it\u0027s not like the devices are supposed to be online at certain times we\u0027re talking not about a certain time but actually an interval so I think that expecting devices which is like whatsapp expects them to be online 24/7 I think expecting them to be online at least once every hour is extremely reasonable given that it gives you these legitimately improved authentication guarantees in the event of a compromise so that\u0027s something but yes this is something that I need to sit down and work out properly but I did want to present it because I think it\u0027s interesting and I think I will certainly be like have a better opportunity to work it out properly if I have your insight and feedback any more I don\u0027t work for whatsapp or or Cigna but from my personal experience or if you know "
  },
  {
    "startTime": "01:26:51",
    "text": "more please come in please come up I strongly suggest it nice that signal choose readability what I\u0027d say - security it\u0027s actually quite the opposite like whatsapp it\u0027s the simplest thing possible just to make multi-vise work which in this case not too much advice however signal made too much device he just changes in idle its key the second comment is the contractor shot as humans for multi-device world every in every device is a separate in point with a separate Alinsky how much you how this works with your proposal so just to be clear I\u0027m not really commenting on the security or superiority of any system I\u0027m just comparing the approaches that they do I\u0027m not judging this was just a colloquial feedback in order to facilitate the conversation and to make it more digestible that being said it is the case perhaps that in some in some cases like for example Oh MIMO the specification which was created in order to facilitate multi device signal in existing XMPP deployments which is actually used by a software that I wrote does indeed encourage multi different identity keys and so that would be I think an entirely different proposal and at the same time different different identity keys come with some complications so you would have to essentially perhaps authenticate every device separately if you were to do that and so I don\u0027t because like if you look at the way that whatsapp or signal does it you have these QR codes that are generated from identity keys but in the case of multiple devices and the deployments that I\u0027ve seen for example Oh MIMO there is a different you know hash or fingerprint or QR code for every device and so certainly this is a potential direction to look into but there are some complications with regards to authentication Richard Barnes the observation a couple observations here right now as you may have noticed the spec only talks about identity keys within the scope of a conversation and so it\u0027s completely possible with MLS you have a separate identity for every conversation and you know with you know that\u0027s probably going to be bounded by whatever your authentication infrastructure is if you have something say Acme based or some highly automated authentication system that may be feasible to have separate authenticated identities for every conversation whereas if you\u0027re in a manual key verification regime like things like Sigma or whatsapp assume you probably going to reuse them so I\u0027m not sure we can assume we can say a whole lot about cross group usage of keys I\u0027m not sure that that cross group usage is all that salient for MLS so what what is salient though is the scoping of the key within the context of a single conversation single group and in that sense it\u0027s it\u0027s "
  },
  {
    "startTime": "01:29:52",
    "text": "more I\u0027ll say linear than hierarchical I think I I think it\u0027s there\u0027s still possible applications here but I haven\u0027t quite cracked all the way it might be interesting to contrast with the kind of naive approach to mitigating the risk of signing key compromise which is to have you know sequential signing of identity keys where you roll over the identity keys inside have the the old keys on new key and basically have a thermal signatures in that way which I think Purdue should propose a little while ago so it would be interesting I don\u0027t know we need to hash it out here at the Mike but it would be interesting to be able to kind of compare and contrast that approach with the approach you\u0027re basing it on hdk all right so the the best information I can go on with it is that long-term keys especially like signing long term keys are supposed to be long-lived and this is based on what\u0027s currently in the so if there are potential directions in the future where I use something that\u0027s like CT or acne or different long term identity keys or every every group group session I don\u0027t I can\u0027t predict the future and I haven\u0027t seen these things discussed so when I present something like this I have to have some axioms some some foundations and the best found a that I was able to come up with the ones that seemed to be the most standard or unsafe is that we currently are operating in a model where we just have a long term identity key that never changes and how can we proceeding from that starting point make things better I think you\u0027re mixing the content between identity and signing keys so that is a contract for the official dot saying the long the only long-term one is the identities for signing keys we\u0027ll have couple of modes as I mentioned earlier about deniability but we always mentioned signing key keys are to change it like per conversation so I don\u0027t think that is mentioned someone is that right let\u0027s say signing keys are long-term peace I didn\u0027t give the ex-king well but but this would be a way to do that so this would be a way to have I debt loan term at any keys but still be able to compartmentalize them even in a fine-grained way if necessary to have different signatures or different signing secrets for each group conversation we\u0027re gonna question from hi yeah Nadine for this proposal so I was just wondering really how this compares against a situation where say every device has their own key but when you do that when you scan the QR code and irrelevant exchange and to have the master device just sign the identity key "
  },
  {
    "startTime": "01:32:56",
    "text": "of the new device so you sort of effectively still have a single identity key but other devices have revocable keys without having to actually share anything so that could also work that that device would be able to start new conversations on its own without querying the long term identity key on the original device that may come with a different set of consequences in the event of the compromise of that device the second device which could be could could be weaker I\u0027m not sure I can\u0027t you know do a symbolic analysis right now no it\u0027s it\u0027s it\u0027s it\u0027s definitely I I think that\u0027s also a good solution Thanks yeah like I hinted earlier wanted to talk a little bit about general efficiency considerations in the context of MLS so if I try to completely oversimplify what the goals are of MLS one is to make secure messaging efficient for large groups and we\u0027ve been saying 50k is a large group sometimes we said 100 K and so this is what I want to focus on a little bit so in in order to measure efficiency operations that are generally expensive like DPM and key agreements or signing or other things is what we need to measure and so if n is the group size the number of people in a group then some of it can be a linear some of it can be logarithmic and sometimes we also have a constant time for operations so with a number of current messaging systems when you want to send out a message in a group you encrypted individually to every participant you can call that bgp style in a way so this is very expensive because it is an operation that happens at a pretty high "
  },
  {
    "startTime": "01:35:57",
    "text": "frequency assuming that the messaging service is actively being used so you constantly hit the O of n line and so one one of those simplifications there is to introduce a group key which is also known as sender key sometimes so this makes it much more efficient to actually send a message because initially you send out your encryption key to everybody in the group and then they know it and you can encrypt further messages under that key and only do it once and not for everyone anymore but you still have peaks that are very inefficient and and linear in the group size with such a system and you also have some security trade-offs so the question is how is MLS better in terms of efficiency and so one thing that was clear immediately with the our proposal is that establishing a group secret is quite efficient because you should put members in a tree then that becomes logarithmic but the question is are there other operations that are not logarithmic and what are those and and what\u0027s left so just want to give a brief overview of that and so the tree kam actually solved the problem as we discussed earlier for adding and removing people so when you remove them you can you can blank direct path and generally that is still logarithmic although there is a certain overhead now but it\u0027s certainly not linear other than image cases and adding is the same particularly when you warm up the tree as we discussed earlier so that is then roughly logarithmic as well so what yeah one one way to basically understand what efficiency means is operations that are costly should be in log of n and if if we don\u0027t manage to do that then essentially we have a peak at the end of the day in the user experience which which is not great so this is maybe how MLS is gonna work most of the time so once in a while there\u0027s going to be a group operation in our vlog and at least for the creator and that can be processed on the recipient side in constant time actually messages are encrypted in constant time decrypted in constant time as well so if we can get everything to look like that that would be the ideal solution in terms of "
  },
  {
    "startTime": "01:38:57",
    "text": "efficiency and so as I mentioned already so for the the group creation we\u0027ve made it sort of logarithmic now but we still have two scenarios where it is linear and they\u0027re sort of correlated so one is when you invite a member and the other one is when you add a device if you run MLS in a multi device context so when you invite a member that you currently you create a welcome handshake message which contains all of the tree and all of the roster because the spec says that every participant should have a complete view of the tree and that goes into the key schedule so everybody needs it and so this is directly sent from one member to another as part of the working message and when you add a device so this is not particularly well lined out in the spec right now but one way could be that you transfer all of the state from one device to another which requires some sort of device pairing mechanism the other one would be that we use something that was initially in the spec which was user ad where a user or device can request become the member of the group but then we are left in the same situation as with inviting a member that device still needs all of the state and someone from the group has to send that to the device somehow so this is absolutely linear and so just to give you an idea the cost we\u0027re talking about here is data transfer costs not th operations yeah that\u0027s correct yep so can I just ask on the previous slide here for device ad it sounds like you\u0027re talking here in a situation where we are assuming separate identities per device and we\u0027re treating the device ad in that context because there is another approach which says that a device ad by a given user is simply reflected to the group as a refresh right you run tree camp for your own devices and then adding a device just means that you prefer you change your yes your node and then you push that that\u0027s true so the though there are other ways to optimize off adding a device case yes or no so I mean that is true you can basically mask how many devices you have to the rest of the group by having just one leaf and under that leave you you have like your own private tree of devices and then you just do the update but it doesn\u0027t fully solve the problem in the sense that the new device still needs some state needs to get it from "
  },
  {
    "startTime": "01:41:58",
    "text": "somewhere needs the at least you know that the public keys of the tree it needs its own private leaf key sure but that\u0027s transfer that\u0027s transfer between the users own devices and not transfer out to the entire yeah yeah sure it\u0027s it\u0027s not broadcaster to the group of course yeah because why would you do that but um it needs to be transferred between the two users if you assume that you have some sort of device pairing process if you don\u0027t have that and most Sims currently don\u0027t have that if you basically log into your device and want to connect that to your MLS account then that device needs to get the state from somewhere so if your current devices are not around or you lost the mod or whatever it really needs to get to safe from somewhere and and as Richard pointed out this is clearly a question of payload it is in this case it is not a question of computational resources so currently the welcome and check message as it is defined in the spec growth rather quickly so for a group of 50,000 it\u0027s almost 5 megabytes so right now when you want to invite someone to a group of 50,000 people you have to upload five megabytes from your phone or whatever device you\u0027re using and the other person has to download that so this is very far from the efficiency we have achieved with all other operations and in the context of adding a device the payload per conversation is basically a welcome handshake message so you can multiply that by the number of conversations you have on your device so if they\u0027re small it doesn\u0027t matter too much but if you have a number of large ones this could be you know tens of megabytes at least so I mean it sounds like this chart is just showing that the Welcome handshake is linear in the number of group messages and to some extent we had already accepted that there was gonna be a linear amount of state in terms of the roster and the identity keys and whatnot and so it\u0027s a little bit unclear to me how worried exactly we need to be about this because there is this or unavoidable linear cost and I mean yes you can argue about the constant factor but it\u0027s still just the house infecting yeah I mean one aspect of this is to actually make it clear that this exists and then Richard later is gonna talk a bit about potential solutions so yeah "
  },
  {
    "startTime": "01:44:58",
    "text": "that\u0027s right below a so the question is can can the tree and the roster be signed out of band somehow and could the server be this out of band Channel and assist with storing at least some of the tree yeah and I guess that you stand over to Richard so yet to the point that was made earlier I think that there there is inevitably the the new Anuja node joining the conversation is gonna have to download linear state and the question here is whether the entity adding that node should have to upload linear state or whether the server can kind of glean and maintain a copy of it on its own so yeah it\u0027s a recap those two questions and these reflect those different changes to the spec as well first question is allowing out-of-band roster / tree distribution to keep them welcome that\u0027s our small and the second thing is to possibly allow the server to see stuff yeah so just for the rest of question one when it says should we should we allow like can we prevent what though but so also right now that the Welcome message the only way you can respect defines to tell someone to give the new member their state for the group is to send it all in this welcome message that has everything so like and and the current mechanism for getting that to the user to the new user is through the distribution server right right but there\u0027s nothing in the spec that says it can only pass through the distribution server it\u0027s just that\u0027s the typical way that you get data that\u0027s great so this question about like should we allow out-of-band transfer seems odd actually well actually I think the the dis it\u0027s a little more important than that in that if we assume that the welcome message it well that the information here is that these commitments here are whatever goes alright let me just summarize the slide the proposal here in protocol terms is to take the roster entry and instead of having those by value and the commitment just put a in the welcome message just put a commitment to those things so if these things that the hashes of these the commitments to those parts of the state are what go in the group state objects probably should have shown in the group stay here instead well so if those commitments are what going into the group state which is what goes into the key schedule then the new member can join the group and compute the current group keys just by having this constant sized object and not downloading the group\u0027s the whole linear size state immediately he only needs that linear size stuff to process the next message that comes along for the next handshake message so "
  },
  {
    "startTime": "01:47:59",
    "text": "we can you know do do message messages application messages all day long but he only needs the linear stuff when an update or remove or an ad comes through or when he wants to actually review who he\u0027s sending messages to well yeah so yeah it\u0027s kind of a lazy lazy joint you can and he could download that stuff it doesn\u0027t block his entry into the group and his ability to read messages that are being sent to him particularly I think this is probably a good idea just because it maintains looser coupling it would it would allow out-of-band distribution in cases like Raphael proposes and we could also define some IND and stuff just like roster and tree nuts just the hands and stuff in band if people want to have mechanism to find here so again just just for terminologies clear foundation it\u0027s not something like you\u0027re saying out of order actually not out of band because well because what you\u0027re proposing here is is lazy evaluation of the the tree state right and so whether it\u0027s in band or out of band isn\u0027t the question the question is whether you need to have the state in order to like get into the to get into the game here yeah that\u0027s fair enough okay yeah because I think the spec change would be to replace these values and welcome message also replace them in the group state so right now we have a transcript hash in the group state it would also have roster and tree hashes instead of the things by value so that you could join the key schedule without having one at linear size state yeah yeah maybe try to that so I mean right now you need a view of the whole tree for the group state but if we replace that with hashes but could still work so there\u0027s situations where you need certain elements of the tree is when you want to remove someone or an actually that\u0027s it right now well you need your own co path if you want to update right yeah so but I mean this something that you could do at a later point in time clearly to address the the other voter and yeah yeah - right I mean it\u0027s always so well I think my understanding is is in order to like just send messages all you need is the route in order to process updates you need your own you need your own path in order to send updates you need to click your own Co path SEC correct correct and so and and so only time and and and and um you need you need a list of the people but you don\u0027t necessarily need you don\u0027t necessarily need this one state the tree well it\u0027s it\u0027s actually slightly worse than that in that when you receive an update you need to update the tree hash that you have which means you know depending on how we construct that hash you might need to have the whole tree like you\u0027re just taking a hash of a representation of the tree "
  },
  {
    "startTime": "01:51:00",
    "text": "that he needs up to girls and stuff I assumed that was computed as a Brooklyn tree we have to find anything but even if it were a Merkle tree like you need to have the rights slice it when you find your Co path again not if I\u0027m process no I imagine he\u0027s grown processing it Mads update in which case I would need his Co path on the Merkle tree so I think I think these things can be designed but it gets to be a lot more I think if you just assume people have the whole state yeah yeah I think it\u0027d be useful to lay out like for each operation which subset of the tree you need and and which pieces those are specific to you yeah I mean so it you can do that I\u0027ve been trying to avoid that complexity by just assuming that people download the tree sure but it seems like it\u0027s like it seemed I mean that me and that may be the case that\u0027s what you need to do but like I\u0027m gonna be kind of like a sad person if I gotta add it to the tree like I can\u0027t do anything at all I\u0027ve received like five megabytes of data like I mean I about that so um you know um I mean yes so I think you know like I\u0027m all for reducing complexity but I think it\u0027d be I guess like maybe we can increase the complexity now and reduce complexity later which is maybe we can actually worked out what the answer these questions is and then and then see like if there\u0027s a sweet spot Jonathan pointed so a lazy client could just repeatedly down the Ross download the hashes from this server and never ever compute who he\u0027s talking to if he so wished assuming that functions up yeah and you know one thing you could imagine is just like sending out the updated hashes in the handshake messages and then you know a responsible client could download the state from server and verified that the hashes are right but lazy clients could just believe what the other numbers tell them so in practice no one will have verify any conversations and it will just end up - yeah exactly all right that\u0027s all I\u0027ll take the action point Rebecca it\u0027s like go through the analysis and see you know if we can come up with a hashing scheme that can be selectively updated for the operations ok this is this is perhaps the more interesting question so I think the the model Rafael is positing is that the server you know in order to or avoid this need to upload linear state when you add someone you could have the server just watch messages go by and where this comes in detentions we\u0027ve discussed often on this idea of encrypting the handshake messages as they transit the server to hide things like the state of the tree the membership of the group in order to you "
  },
  {
    "startTime": "01:54:03",
    "text": "know enable the server to maintain a cache of the roster you would need to expose to that to the to the server the stuff that goes in the roster so the identities of the people in the group and their credentials likewise if the server is going to cache the tree you need to expose the public keys and and indices you\u0027re operating on if you do that there\u0027s not a hole if you expose it so you know the stuff that\u0027s in colors here is the stuff that you\u0027d need to expose to make that cashing effective the upshot of it is you if you do if you expose all that stuff and there\u0027s not a lot left in the handshake messages its protect so it may not be worthwhile even pondering any sort of handshake encryption if we want to allow the servers it\u0027s a cache all this stuff [Music] so that\u0027s kind of the question like where do people right so what we\u0027re exposing here is mainly public keys in terms of the contents the amount of the handshake message that part doesn\u0027t Samee seem all that controversial because it\u0027s just public keys public keys are public but the what my what\u0027s more concerning here as perhaps the credentials that would expose the the identities involved in a group but even there I think that some folks have pointed out that the server has to in in most deployment scenarios now the server has to have some idea of who he\u0027s delivering messages to and thus has an idea of the roster already so you men see me tomorrow I\u0027m all-in for storing information for the server it\u0027s not clear to me if the server cache information how it keeps it up to date it\u0027s a client pushing up its overall server proactively reconstructing the tree by observing that a dynamic operation yeah I think the idea is that the server would have a copy of the tree and it would read this the handshake messages and perform the updates the corresponding updates the tree this is dkg so I think that the medic like just throwing in the towel on metadata protection at this stage of the game is premature and I would be pretty sad if we decided to do that and I think that\u0027s what the no handshake encryption publish all the identifiers to the server basically means is just punting on metadata protection I will acknowledge that I\u0027m not convinced that so the way this was presented was basically like look at these huge groups look how expensive they are to join and I\u0027d be pretty sad if this meant that MLS in a non huge group lost all metadata protection simply because we expect to lose all meditative reaction for large groups right it\u0027s true I don\u0027t actually care that much about metadata protection for a group with a hundred thousand people in it like because probably it\u0027s all exposed to all hundred thousand of those people and those hundred thousand people one of them is gonna leak that metadata list somewhere but if you tell me that a group of 12 people or a group of a hundred people who are using MLS to communicate are gonna have that group membership directly leaked but by the handshake message to the server that would make me sad so where it says two "
  },
  {
    "startTime": "01:57:03",
    "text": "modes I would hope that in that that if we define this we\u0027re not talking about you know your MLS deployment should offer mode a or mode B but we should talk about what is the reasonable cutoff where a group converts from the the order n mode to the order one mode right so that small groups can continue to have like the the better protections until some other any circumstances in which one of these messages might be rejected by endpoints and it\u0027s just so ever going to be able to say that yeah we discuss that some I think that it is possible that end points for reject messages I think my initial reaction that was you know you could have some knack scheme where yeah you could just provide feedback to the server and say never mind that one but but to be sure there are you know can issues with maintaining consistency I assume in that case the server doesn\u0027t need to see that you\u0027re saying you the server needs to save you the knacks can you also simply say that if the server sees another message with the priory pocket the same that backs that one out and puts the new one in like there are there ways to do it but you would need to have some consistency mechanism yeah yeah coming back to your point so I fully agree that it is a bit harsh to basically get rid of the privacy we had around handshake messages just spoke very large groups so I think it could be a model where this is entirely optional and we keep on encrypting or we go towards encrypting handshake messages and having a very opaque modus operandi the the other question is how much identifiable information does the server really see with that because there\u0027s like various degrees of metadata so there is a public keys in the inner node of the trees which you cannot really correlate at least but now I kind of think how you could correlate to them to anything but then the credentials is is something different so they\u0027re potentially I think the idea Richard was that we would only expose part of the credentials and that\u0027s why they\u0027re in blue here so in the user init key you would only expose the diffie-hellman key of that to the server but not the actual signature because the server does need the signature to to basically cache than fake messages so yeah it\u0027s it\u0027s not something that that is quite clear in general so we need to come up with a concrete proposal to basically take "
  },
  {
    "startTime": "02:00:05",
    "text": "decisions the idea for today was simply to raise awareness around the discrepancy we have between these different kinds of operations and and the payload around inviting members or adding devices yep so that\u0027s we\u0027re out of time for today we do have another session we\u0027re gonna kind of bump the message protection stuff down to be done Thursday Benjamin can\u0027t make it but Richard said he could do the slides and we\u0027re basically just gonna recap what we did at the the interims to get people up to speed so just to recap this you know action items are this last slot so I\u0027m I\u0027m gonna plan to change the welcome message and group states use commitments and then do the analysis that echo suggested about who needs what money how do we can make that commitment updating and scalable Rafael I like to assign you the the action items to take a look at at this question of how you might be able to do it out to bowl handshake message encryption so a lot of the server decease or so said alright thanks cool and thanks Chris for taking notes see y\u0027all Thursday "
  }
]