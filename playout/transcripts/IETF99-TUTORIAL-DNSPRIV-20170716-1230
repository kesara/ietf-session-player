[
  {
    "startTime": "00:00:04",
    "text": "previously tutorial and on that page I have a link to the set-asides I\u0027m going to use today there\u0027s also some material from the previous time I gave this which was in Seoul and the material has been updated slightly so I would recommend you grab the latest set of slides so to start what I\u0027m going to do today is go through an overview of why DNS privacy is important and why previously on the Internet in general is important I want to chart the huge amount of progress that\u0027s been made in last three to four years in this area for DNS and I want to give you a snapshot of where we are now and what\u0027s coming up in this area so these first few slides are ones that I gratuitously borrowed from Daniel Kahn Gilmore who presented this with me in Seoul last time but wasn\u0027t able to come today so I will try and channel dkg as I present this one of the arguments wanted to make first is why does privacy on the internet matter at all and the answer is that it can be used surveillance can be used as a tool for social control in ways that aren\u0027t immediately obvious now this is a picture of something called a panopticon which was a prison designed in Victorian times and the idea behind this building was it was a circular building and a single guard could stand on a turret in center and see hundreds of prisoners who were easily in his view to give a one or few people control of many and we\u0027re in a similar situation with the internet today which is that if you have a viewpoint somewhere on the internet and that gives you access to the activity of you know uncountable people depending on where that viewpoint is and also the kind of machine learning we have today that means processing that data is completely feasible one of the counter arguments about worrying about surveillance is well I\u0027m a law-abiding citizen I don\u0027t do anything wrong I\u0027m not worried about being surveilled I\u0027m really not but there\u0027s been some really interesting research to show that just the fact that you think you\u0027re being surveilled actually changes your behavior so the experiments involved of getting pee people who thought that behavior wouldn\u0027t change and valence asking them questions some of which their answers were in the majority some of which their answers were in the minority and doing it into two sets of conditions one way you told them they were being spelled and one way you told them they weren\u0027t what happened was that bottom line you can see for the answers where they were in the minority the ones that thought they\u0027re under surveillance changed their answers so what we\u0027re seeing is a direct if unconscious effect of the act of mass surveillance of people in the bigger picture we know the whole of the Internet is not watertight it leaks information through a variety of mechanisms it can be traffic analysis it can be timing two of the most important ways it leaks today are through the DNS "
  },
  {
    "startTime": "00:03:06",
    "text": "which I\u0027ll talk about here but also through the fact that the s and I in the TLS handshake goes in the clear so one set of arguments that\u0027s been circling around for quite a while is well there\u0027s no point in securing the DNS if the s and I is still going to go clear text but one thing I do want to mention is that all the work that\u0027s been done to move towards private DNS and last three to four years is now changed in the discussion in the TLS working group about how important it actually is to encrypt SNI and although it\u0027s a really tough intractable problem in the last six months there has been a big move towards it even though it\u0027s not part of the base TLS 1.3 spec there are staff efforts to now try to do that so what I\u0027ll talk about today and what I\u0027ll focus on is DNS but what we need to be doing is having a concerted effort to fix all these leaks out of this boat in order to make the internet a safer place so I\u0027ll move on and talk a bit more about where the IETF has come into this and where the DNS working groups have come into this so a positive history of privacy considerations in the IETF work actually started on this back in march 2011 when the IAB worked on a document about privacy considerations internet protocols now you\u0027re all probably familiar with when you read Narsee there\u0027s a section at the end that says security considerations and that\u0027s been there for a long time the goal of this document was to create a foundation for adding a privacy considerations section at the end of every document to show that the development of that protocol had taken privacy and into account now being the ITF it took a couple years to get it to be an RFC and the month before this document was published a chap you may have heard and heard of called Edward Snowden revealed what the NSA had actually been up to in terms of mass surveillance so it was an interesting timing because what was in some ways a rather theoretical document suddenly became incredibly real and incredibly pertinent and in fact you probably know that in response to Snowden revelations the ITF came back the second document with a title that pervasive monitoring is an attack stating that that attack is on both organizations and Internet users as individuals that document went one step further and what it actually said is from this point on and pervasive monitoring needs to be mitigated in the design of new protocols so this is a change of stance from the ITF and recognizing that this really was an issue and that moving forward all protocols had to have this as part of their design so back when this was all happening around 2013 I want to give you a snapshot of the state of Dennis previously at that time and that really to do that properly you actually need to go back even further back to when Dennis was originally developed the aura sees four dienes were published 30 years ago so if you go mentally back in your time machine you know your DeLorean your "
  },
  {
    "startTime": "00:06:06",
    "text": "TARDIS your whatever you want and think about what people imagine the internet was going to be 30 years ago they had absolutely no idea of what it would become today so the design goes involved in the original Dennis specs were primarily availability redundancy and speed and those are the key things that mattered additionally DNS in privacy terms is something that\u0027s called an enabler it\u0027s not a service in itself it enables you to access other services so it\u0027s kind of frozen neglected in this sphere because it wasn\u0027t seen as a direct service so as you well know the standards for DNS originally said use UDP and they use TCP only as a fallback mechanism when responses were large so as a result for the past 30 years all DNS queries have gone clear text over the wire so this became very evident how easy we were making it for organizations to do mass surveillance because they didn\u0027t have to go and talk to operators all they had to do was sniff the wire and they could see everything that was going on now additionally one of the things about the DNS is that there\u0027s been a long-held perception that the DNS is public public data in that it doesn\u0027t hold anything personal it\u0027s not sensitive and so there are lots of questions about why would we bother to encrypt it it just it doesn\u0027t fit into that sphere and I\u0027ll come back to that later so this is a sort of how does DNS work 101 and where does the data leakage start so this is a very simple model of how a Dennis query works you have a stub resolver typically on an M machine like a laptop or a phone it sends a full query to a recursive server for something it wants to look up and the way the DNS works is that that recursive resolver then walks through all the authoritative servers it needs to to get the answer but it sends the entire query to every single one of those authoritative servers so right off the bat we have data leakage here because the root server doesn\u0027t need to know the full query to be able to delegate to the servers that run dot-org and so on write down the authoritative chain so this was done because it\u0027s slightly simplified the devant the design but it\u0027s quite some simple symptomatic of the way the DNS just didn\u0027t put previously first in any of its design considerations so things got a lot worse a few years ago with the addition of something called eating a zero into the DNS protocol now this was actually a much-needed extension because inside DNS queries and responses you really only had DNS data this was an extension mechanism which allowed a flexible data to be added onto the end of a Dennis packet to do really important things like signaling the MTU path to figure out when you needed to fall back to TCP or signaling server capabilities something that\u0027s really rather lacking in the DNS however because this was so flexible it meant that it could also be "
  },
  {
    "startTime": "00:09:08",
    "text": "used to do other things for example embed information about end users into that DNS query there are two examples of how this has been used both of them were done from the viewpoint of somebody an operator wanting to provide better service to their end customers and this provided a really natural way to do it at the time the problem was really with the the implementation so two examples of this is one is how some ISPs chose to implement a parental filtering and another mechanism is the way CD ends do geolocation so in the first case the parental filtering what happens is you want to set up some rules and you want some DNS queries to be blocked now what you might think is that your ISP who gave you your home router would put the logic in the home router and then everything is encapsulated within your home network turns out not everybody implemented in that way in fact quite a lot of people didn\u0027t what they did was they put all the logic in the recursive server which meant to make this work they had to embed in every single DNS query going from your home rooted a recursive some piece of identifying information about who was doing that query now if you are lucky they used some sort of hash of an identifier so it obscured you specifically but it allowed identification of multiple individuals behind a single Rooter if you are unlucky they did something like put the MAC address as the machine that was doing the lookup in there with some other information the worst cases I\u0027ve seen are usernames being propped in this little extension and remember this is going clear text over the wire and this was all done with non-standard extensions so this is where a noble piece of protocol design allowed for a misguided use of part of the protocol in the CDN case this is between the recursive and the authoritative so it\u0027s not revealing as much information but the idea here was that if an authoritative that was going to save you content knew something about the geolocation of the user that originated the query then the answer could be customized so that it directed that user to the nearest geographically located server so they got the fastest service they could I mean nobody likes their cat videos buffering right so this is a great idea it\u0027s wonderful get go to the server down the road not the one on the other side of the world so again it seems a natural fit to tag a subnet client subnet into the e dns zero but again this is just compounding the problem of data leakage up on that recursive to authoritative lag so when you use the dns from home you might think your queries it really rather anonymized but the reality is you\u0027re behind in that and you don\u0027t have anonymity there are many cases where individuals are being fingerprinted similarly even right up to the authoritative service and the DNS information about our activity is being leaked so and remember what\u0027s going over that link it\u0027s information about you "
  },
  {
    "startTime": "00:12:09",
    "text": "know where you go what sites you go to what you do when you\u0027ve got bored all sorts of personal information is going clear-text think about it pretty much every activity on the internet starts with a DNS lookup so it really isn\u0027t just for names try it fire up TCP dump and wash are looking at port 53 and just watch how much traffic goes out of your machine as you just surf around and send email because every time you send an email you need to get an MX record so that reveals the domains email domains of the people that you\u0027re emailing every time you go to a service you do an SOP lookups this reveals the variety of services you use open PGP key is a nice standard where you can secure email with Dane but that reveals the entire email address of the contact you want to email and the problem here is this is only going to get worse people are putting more and more in the DNS we\u0027re not in any sort of scheme where we\u0027re trimming what goes in the DNS it\u0027s it\u0027s some advantages have been seen in lots of places so all your activity is being sent clear text through your DNS queries and because it\u0027s being tagged with user identifier information I hope your spidey senses are tingling in the sense that what you do it\u0027s out there clear text on the wire in a way you really might not have realized so that\u0027s really the picture we\u0027re talking about what goes over the wire there\u0027s an entirely separate concern about what happens when it hits the unser VORs of course so most people here use an ISP and you have to ask yourself who has access to the data that your ISP has is it strictly the ISP is it the government of your country is it security services who else is it also who does your ISP share your data with and under what terms and conditions equally there have been cases where ISPs have these huge data stores and they get breached so how much do you trust your ISP to keep your data and secure now of course all these concerns change as you move from your home where you\u0027re using your ISP to your work where you\u0027re in an enterprise situation to a coffee shop to a hotel and in everyone all considers all the privacy considerations change and that known not only applies to the recursive but as I says also up to the authoritative because the data leakage goes that far along the path so what\u0027s happening in the DNS is we\u0027re leaking metadata okay so we\u0027re not leaking your bank account password and email address but we\u0027re leaking who you bank with we\u0027re not necessarily leaking what you buy but we\u0027re leaking where do you shop where do you go for your entertainment the whole range of things that create a fingerprint of a human being on the Internet so what\u0027s been shown is that just by looking at DNS queries you can fingerprint injured vigils and you can read n tafolla as they move across networks because the DNS queries are so "
  },
  {
    "startTime": "00:15:11",
    "text": "characteristic that you can figure out who it is that\u0027s moving around on top of this there was some other interesting research that said okay that\u0027s all well and good let\u0027s encrypt recursive disturb it turns out DNS traffic is so characteristic in terms of its timing and size that even less alone isn\u0027t enough and if you have an observer who has enough visibility downstream of recursive to see encrypted traffic and upstream to see the clear text traffic going to an authoritative you can still correlate the activity and you can still identify individuals within those traffic patterns so we need to do more than just simply encrypt and as I mentioned operators can also see your queries and log them so if you were thinking your DNS behavior really didn\u0027t reveal anything about you well then Toto were really not in Kansas anymore there\u0027s lots going on here and it\u0027s really really really underreported think about the last time you read a magazine article talking about how to secure yourself on the internet that mentioned DNS they talk about encrypting a phone encrypting your disk using HTTP if you can going to tour all these things but I haven\u0027t seen one article yet that puts DNS within that overall perspective so this is trying to summarize the situation in terms of the risks that you have so crews are going on the wire can be passively monitored and actively monitored both between stub to recursive and recursive to authoritative and also there are risks associated with the data at rest okay so just to start the story by going back to 2013 and talk about what were the privacy options at that time well there were no standards for how to do dns previously at that time at all there are a few protocols have been developed and deployed but some of them come to the ITF installed some of them haven\u0027t even gotten here the main ones were DNS curve which is really designed for the recursive to authoritative communication and deana script which was stub to recursive and Dena script is still around today there are implementations it recent got picked up by the Yandex browser so it is around but one thing to remember is these were developed really as anti-spoofing and anti-ddos devices they weren\u0027t designed with per se as the primary design goal here and you kind of get privacy as a by-product from these things and the unbound recursive server also implemented DNS over TLS in 2014 so that\u0027s been around a while but again this was just sort of a side effect they really did it as part of their doing a set trigger project because it gave them a tunnel to access a DNS SEC aware recursive if port 553 was being blocked so it was a really mixed bag at that time there was no standard way to do this that\u0027s where the IETF came in and the deep rival working group so deep rive was formed in 2014 "
  },
  {
    "startTime": "00:18:11",
    "text": "and clearly you can see it had a really big job in front of it so the first thing it did was trying to narrow down its Charter and the original decision was that it should focus just on that stub to a cursor step and you might say well why not have multiple avenues of protocol development and the answer was let\u0027s not try and boil the ocean this is a really tough thing to solve the stub to recursive is where most of the information is revealed so let\u0027s target that first and then let\u0027s use what we learned doing that to move on to the recursive to authoritative there\u0027s also some differences in trying to solve those problems primarily in terms of authentication so as an end user somebody with the stub resolver on their machines you tend to have a relationship with a few recursive result with so it could be tens you know between work and everywhere you move but in most of those environments you actively choose to use that recursive in a coffee shop you you actually choose to join the network with all its faults the situation for recursive resolver it\u0027s quite different it has to go to whatever authoritative it needs to to resolve that query so it essentially has no control to the set of up streams that it has to talk to and that makes creating an authentication mechanism much much harder than it does in the stubs recursive case so the first piece of work that the d5 really did was to produce a problem statement RFC 70 626 it\u0027s really well written it\u0027s really good reading and it does in much more depth what I did in a few slides which is to walk through the ecosystem of the DNS and to present all the places where there is risk and leakage of information one of the key things I think this document does is it tackles that question of the alleged public nature of the DNS and what it says is it\u0027s correct to say that the data in the DNS is public but individuals transactions in the DNS are not and should not be public and the analogy it uses here is well the content of the websites for alcoholics Anonymous is public it\u0027s a public website the fact that you as an individual visited that website is not public data and it shouldn\u0027t be the next question the working group had to answer having tried to scope out the problem was there was agreement to encrypt the stub to recursive how do we do it the working group spent quite a lot of time churning over a variety of options not just these ones here they looked initially it starts here last because that could be done on port 53 for various reasons people then started favoring getting a new port and using TLS or DTLS and you might think looking at this that actually detail us as a natural way to go for DNS given it runs over UDP but when people started digging into this a few issues were found with things like fragmentation but also on the key things is that if you try and do dns over D TLS "
  },
  {
    "startTime": "00:21:13",
    "text": "you run into exactly the same problem as you do have UDP which is a big response can\u0027t fit in a single message so you have to fall back to an alternative transport and the obvious one to fall back to is TLS so the discussion went a bit back and forth and decision was let\u0027s not go down this to protocol route again let\u0027s just start with tear less and get that right and and choose a single protocol so what emerge from the working group was that DNS over TLS became a standard and DTLS became standard with experimental category so choosing your encryption protocol is one part of the process there\u0027s another to-do list if you\u0027re gonna fill out this picture one is you actually have to actually get the new port you wanted the other one is you have to address the fact that historically and TCP implementations in DNS servers absolutely sucked because they were only used as this once in a while fallback mechanism no attention was really paid to doing them properly and if you\u0027re going to move a step further and use tear less then you have to address that there\u0027s also a new problem for DNS in terms of authentication which is bootstrapping of course when you go to a website you know the name of the site you\u0027re going to with DNS when you go to your cursive server you typically only have the IP address of it so that doesn\u0027t give you a natural mechanism to do authentication so we have to find some solutions to that and as I mentioned before we still have to deal with traffic analysis so there was a lot of skepticism in the working group initially about whether we will get assigned a new port but actually I Anna recognized this was a really concrete use case and actually in October 2015 they signed Paul 853 and so both TLS and DTLS can run over that port the next one wasn\u0027t quite so easy this was to go back and look at what DNS service did with TCP what they did was they tended to do one-shot TCP if they had to fall back to TCP they open a connection fire of a query got response shut the connection went straight back to UDP so using that kind of implementation was just unfeasible there was a really poor perception of DNA of TLS as well so TCP because all the performance tools that were used were based around this one-shot mechanism so they made TCP inherently look or you know at least an order of magnitude worse than UDP DNS servers had really really basic capabilities they often were hard-coded hard-coded to only have 20 connections and have like a one-minute fixed timeout and that was it no other defense mechanisms in there so it was very basic and yes yeah that\u0027s "
  },
  {
    "startTime": "00:24:16",
    "text": "true so and I mean in general the server operators didn\u0027t want to do TCP so they wouldn\u0027t tuned for it they have no they treated it as a second-class transport I think it\u0027s fair to say so to fix this part that really had to revisit the specs so the first thing we had to recognize is that um the DNS people are not the first people to try and do TLS there\u0027s a bunch of people out they\u0027ve been doing it for ages so we should just piggyback on what they\u0027ve done so latency is an enormous concern in DNS so connections set up we needed to be optimizing what we did waving all the available techniques so we needed to be using TCP fast open we needed to be using TLS session resumption and of course we started rubbing our hands when TLS 1.3 started coming over the horizon because of course that was targeting things like 0 RT T and 1 RT T resumption so that looks good we also had to directly tackle the DNS standards so there was an RFC in 2010 which was actually the first time it was mandatory to implement TCP for DNS before that it\u0027d been sort of fuzzy option that RFC was based in 2016 and in that it basically said don\u0027t do one shot TCP if you\u0027re gonna do TCP do it properly open a connection pipeline your queries over it as a server when you receive it you should process all your queries concurrently and then you can send them back in whatever order you have the answers ready and clients you need to be ready to get those answers out of order because in about 2015 the survey was all the top DNS client implementations couldn\u0027t handle getting answers out of order over TCP because they simply never thought a server would send them like that we also developed a signaling mechanism so that clients could signal to servers that they wanted to keep connections open and because that was completely absent from from DNS signaling and of course as I mentioned for this loads that we can learn HTTP world in terms of just generally improving what servers did here so this is for example one of the simple things that got fixed in that spec which is that traditionally service when they were listening on TCP they picks a query of the connection resolved it sent it back and only then did they look for the next one and of course resolving that query could take a long time if they didn\u0027t have any passing cash so the simple fix was to tell service no you need to be doing this more intelligently pick pick the queries up and process them concurrently and that\u0027s going to take a whole RTT off the clients time and the goal here was actually to work towards trying to get performance on a par with UDP by combining all these changes to the protocol and persistent connections so to move on to this question of authentication clearly we can\u0027t go from where we are in a single leap to everybody\u0027s using UDP today everybody\u0027s "
  },
  {
    "startTime": "00:27:16",
    "text": "going to use authenticated TLS tomorrow that\u0027s just not going to happen so what the draft that\u0027s currently going through deeper I\u0027ve suggests is being able to do authentication in two ways and they\u0027re called usage profiles so one is called strict which is um you must have both an encrypted and authenticated connection to your server or you just don\u0027t do dns so this is the sort of purist approach but it\u0027s also the protectionist approach if you are somewhere where monitoring for DNS queries could imperil you then you want to have you want to be able to have a level of security that they\u0027re just not going to be monitored so strict is where you would go there and we hope that this will become the default longer term as we move towards it though we need a pragmatic solution and that\u0027s called opportunistic so in opportunistic what you do is you first and foremost you try to get an encrypted and authenticated connection only if you can\u0027t you\u0027re willing to fall back to you adjust an encrypted connection and this at least protects you from passive monitoring but there\u0027s a third fallback which is to say if I can\u0027t do either of those and then willing to fall back to clear text because that\u0027s no worse than what I\u0027m doing today but as you can imagine as the deployment of DNS over TLS increases the the state to which clients will fall back will hopefully become higher and higher and through that list so I mentioned the other problem is that you need additional information if you\u0027re going to authenticate your Dennis server because typically a client only has an IP address so the current draft proposes two ways to do this you can either configure an authentication name into your client which in some ways is easier because it can be human readable fairly easy to check the other mechanism is to use an SP care pen set so again we\u0027re borrowing from what\u0027s already been done in HTTP so that can be a little harder because it\u0027s not human readable but it can be a little more flexible in some ways to allow for key rollover um but of course you might be said again these are the DNS folks these are the folks who dreamt up this dang thing and keep telling us all of us to stay in for authentication so shouldn\u0027t we the desk people really be drinking our own champagne here well the draft does also go through the details of how to do authentication via Dane you still need an authentication domain name configured into your client to start that but once you have it you can do Dane to get the queries in fact all this work prompted a new solution for T less in terms of Dane called the TLS T in a sec chain extension and I\u0027ll just walk you through that so this is how a traditionally do Dane as a DNS client so you would have some configuration information that told you where your cursor was and what its authentication name was as a client is add in a sec validating client you would go off and opportunistically because that\u0027s all you have available at this bootstrap time do lookups ordain records "
  },
  {
    "startTime": "00:30:16",
    "text": "then you get the Dane records back and you\u0027re ready to make the connection you do a traditional TLS connection getting the certificate or key information from the server validator against the Dane records and you\u0027re good to go the new proposal that\u0027s still going through at the TLS working group is based on this on the recognition that hang on this thing I\u0027m talking to you and I\u0027m trying to authenticate it\u0027s a DNS server it knows about Dane so rather than me going getting the records is a query I\u0027ll let it do the work so you start from the same position in terms of configuration however this time it\u0027s the server that makes sure it has its own Dane records what that means is with the new extension the client can signal in the client hello that it is capable of validating day that receives in the TLS handshake knowing that the server can send back all the dane records necessary that\u0027s the entire chain for the client as Adina SEC validating client to do the work during the TLS handshake decide that it can all Center Kate and again it\u0027s good to go to in a service the nice thing here is it reduces latency because everything\u0027s happening within the handshake and it eliminates the need for that set of opportunistic lookups before you can even start the connection so this is quite a nice technique so it\u0027s a circle back and summarize what has been achieved in and this is specifically in deep rife in the last three years so we have a standard for how to do DNS over TLS and we have another standard that tells us how to power our queries I\u0027m not going to go into this in too much detail but this basically took number four under to do list and I quite like this because what would what happened here was that EDS zero option that was being used in some cases to expose user data has kind of been taken back from the dark side and we\u0027re actually using it to put up adding in exactly that location so we can obfuscate the sizes of DNS traffic we have a experimental RFC for how to do DNS David DTLS and we have a draft describing all these authentication mechanisms which is in is G last call at the moment so looking back for three years that\u0027s not by going for a working group okay we haven\u0027t solved all the problems but we\u0027ve come a long way and what the working group now is looking towards is tackling that recursive to authoritative step there is an expired ID that proposed a few options that is probably going to be revived and a slightly different form narrowing down the set of options to look at the working group is probably going to consider reach our Turing and also one of the things they want to use to feed into that is data on what\u0027s happened today on recursive to stub link in terms of implementation and deployment of detail s and so there\u0027s still a bunch of work to do but we\u0027re getting there lots of work has happened outside of the deep right working group to you remember I mention this kind of schoolboy error "
  },
  {
    "startTime": "00:33:16",
    "text": "of though you\u0027re leaking all the in every look up so there is an answer to that now and it\u0027s called queue name minimization this basically says only send the part of the query to the server it needs to give you the correct referral and this looks really rather trivial and obvious but actually the devil is in the details here there are lots of corner cases there are lots of little nasties hidden and some of them weren\u0027t found actually till the spec was implemented but most of them resolved and there are implementations of this in unbound and not it\u0027s gonna be in the next version of find so it is being much more widely used and hopefully this will become the default mechanism there\u0027s a bunch of really interesting work going on about doing dns over HTTP one of the potential upsides of doing this is that clearly given as a dedicated port for encrypted DNS if somebody wants to block your dns you encrypted dns they can just block poor 8:53 whereas if you\u0027re using Dennis type of HTTP there are mechanisms waking them run over 443 and something would have to block that port and all your HTTP access to defeat you getting encrypted DNS and a good four years ago rather under the radar and with a proprietary implementation Google published a DNS over HTTP API if you have the slides as a link to the service there you can go and look at it there\u0027s a nice little gooey you can play with it it was targeted at applications that wanted to do very lightweight DNS lookups and so it\u0027s interesting it\u0027s different it to my knowledge it never progressed through the standard side what did progress through the standard size and and actually there\u0027s been a lot of flux in the drafts here quite a while ago those proposal to do um DNS over HTTP in Y format and this is essentially a tunneling mechanism so you\u0027re not changing anything about HTTP you\u0027re just embedding wire format DNS in it this draft is still active there are several implementations several servers out there if you want to use this but what has come along much more recently which i think has some really interesting potential is a proposal to do is over HTTP - doing it as HTTP and this is really about doing it in the sense of query origination from a client directly using this mechanism and and this is done in a much more naturally HTTP way and it takes advantage a lot for the HTTP idioms so what this essentially means you\u0027re doing is mixing DNS queries and HTTP queries on one connection so again this gives you the ability to do a couple of things - hydrogenous queries but also to get your DNS answers from the server that you\u0027re currently connected to and this has a lot of interesting propositions and so having a look at that and going to the working group as well is worth considering "
  },
  {
    "startTime": "00:36:19",
    "text": "something that\u0027s happened recently but it\u0027s really in a very very embryonic State it\u0027s talking about doing DNS over quick how many folks in the room are familiar with quick most of you I think yes so quick set developing protocol it came from Google it\u0027s being used in the wild in its experimental form the things that make it attractive for doing DNS are that even though it runs over UDP it\u0027s reliable it has all those mechanisms built in it\u0027s also low latency so it should take a lot the performance boxes for DNS the things that it also gives you over doing plain UDP are you have increased source address validation over doing UDP which is very important in DDoS mitigation 14s and it also doesn\u0027t suffer from the problem of hitting an MTU limit and needing a fallback to a second transport so this can be a standalone solution and of course the killer feature for privacy is that it\u0027s encrypted there is no unencrypted version of quick so doing this naturally gives you privacy so the last place I want to talk about in terms of other work is really around data handling and this is where I think the focus probably now needs to shift we\u0027ve done a lot of the standards work on protocol side but really what hasn\u0027t been tackled is what happens about the data handling and how many folks here have read the small print of their eyes P and actually know how long our HP retains their dearness data for whether they\u0027re not a miser and whether they sell it to a third party I do because that\u0027s the question so I make sure I read mine but typically it\u0027s not something you do life\u0027s too sure right except with changes in legislation for example the rollback of net neutrality in the states that landscape could really really change in the next few years it could become normal for operators to sell your DNS data so there needs to be attention paid to things like government policy I live in the UK we have the snoopers charter that gives my government access to my browsing data whatever that means legally which I don\u0027t know so there\u0027s government policy and this government practice that we need to be considering what would be great is increased transparency from providers what I would like to see is that you get privacy by default and you can opt in to share your data as long as it is explained correctly what you\u0027re buying into there we also need to be paying attention to cases what operators say they share data it\u0027s been anonymized to be sure that is being anonymized correctly because a lot of that is done in and rather ad hoc fashion today and a lot of days to get shared for things like research through databases like passive dns and again we need to be ensuring that that\u0027s done in conformance with proper data anonymity now a lot of this work is probably well outside the scope of the IETF and it\u0027s not really technical solutions in all the cases but without solutions to this work going hand-in-hand with encryption on the wire "
  },
  {
    "startTime": "00:39:19",
    "text": "we won\u0027t have the full picture available so to come back to that matrix I had earlier on and talk about which parts of it we can mitigate with the work we\u0027ve done to date well we can encrypt stuff to recursive to protect against passive monitoring if you authenticate that then you\u0027re protected against active monitoring which is good for the recursive to authoritative we can do cue name minimization which it at least mitigates the leakage of information and we need to still do more work on tackling data handling policies and practices at rest um I\u0027m going to very very briefly talk about service discovery because it is DNS but a lot of people don\u0027t realize it\u0027s DNS so service discovery is a mechanism that\u0027s used to discover services and very often it\u0027s done on local networks but there\u0027s nothing that limits it to a local network and very often implementations the leak information on a global scale because they do lookups out onto the network so in this situation one device advertises a service that allows others to discover it sounds all well and good but what\u0027s common in terms of doing this is that you give your laptop a name and your laptop uses that name when it advertises your services so you may some of you who can actually look on the network right now you may be able to see devices on the network that are sharing in this way and figure out you know it could be you know Bob\u0027s phone as well so the thing here is that what you\u0027re doing is you\u0027re advertising a lot about your personal devices so not only is your name attached here the set of devices you have here is advertised and the set of services you\u0027re advertising so in situations like a coffee shop where there\u0027s like ten of you in the room go through the thought experiment of sitting there looking at this and being able to identify each person by looking at what devices they have and whether they\u0027re male or female or various like things like that and that\u0027s what you can do very easily what people you really know what they\u0027re doing this can do it\u0027s drill down into the details of which services advertised with which parameters and this allows fingerprinting of devices and this research that has shown you can fingerprint down to both software and hardware even to software versions because bugs get fixed and you can see oh they\u0027ve got the version before this bug got fixed so again this allows fingerprinting of individuals and re identification through something that people see is a very very benign mechanism the good news is that the dns SD working group are also working on this problem they\u0027ve recognized it it it\u0027s a different problem to solve they have some drafts recommending this so if you\u0027re interested coming onto that working group later this week so now I want to skip on to we\u0027ve done the standards work where are we with implementation so one was also want to direct you to is the DNS procedure org website so the goal here is "
  },
  {
    "startTime": "00:42:20",
    "text": "organizations interested in promoting DNS privacy to be a central reference point for where we are in the evolution of this so various people involved in this say \u0027cimmanon are involved and on that labs are contributing a lot Salesforce there\u0027s too many to mention here lots of individuals are contributing and we\u0027re getting grants from a range of organizations so the kind of things that we want to do here is is be a first stop shop for what\u0027s going on with Dena\u0027s privacy how can I help how can I protect myself so one thing we\u0027re doing is key is trying to keep track of the state of the implementations in the major open source DNS name servers so you can see here that not resolver is doing really well they have a bunch of stuff available and bound is really close behind and bind has chosen not to implement here less natively inside the name server what they are proposing instead is that when if you want to deploy this you do it by putting a proxy in front of your name server and there are lots of proxies out there internet atah a proxy the bind have actually produced a article in the knowledge database for how to put a stun on in front of bind and this can work really well although there are some disadvantages because of course that load balancer isn\u0027t DNS aware it\u0027s rather blindly passing through some danis options that would normally be catered for by the DNS server additionally it means that the source IP address of the query doesn\u0027t make it to the server so some of the features in the DNS server like ACLs can\u0027t work effectively because they don\u0027t know where the queries are from everything looks like it\u0027s coming from the proxy and there are actually some drafts proposing mechanisms to to mitigate that and pass information from these general proxies to a server what would be nice is if we got tearless support in DNS dist dearness dist is a DNS load balancer which has a huge range of features it\u0027s a really nice piece of software and a lot of people use this in front of server farms to distribute queries and there is a feature request into this and I have heard encouraging noises from the padding this folks thing they\u0027re working on it I personally think if we had this it would be a game-changer in terms of running servers because people would feel confident about using it and it seems like a really natural solution on the stub size the pictures a bit more mixed there\u0027s a relatively new Dennis library will get DNS which has really tried to become fully featured in terms of what it takes to do good DNS over TLS and I\u0027ll talk about this more in a minute the other implementations are there and they\u0027re catching up to my knowledge there isn\u0027t a TLS implementation in a native "
  },
  {
    "startTime": "00:45:23",
    "text": "resolver Library on any of the Oasis that\u0027s officially supported and released today that hopefully is also changing so in that picture the summary of where we are in terms of implementation status are that there\u0027s better TCP handling dealer servers there\u0027s been a very encouraging uptake of queue name minimization there are several implementations of Denisova TLS and what we haven\u0027t seen yet is any implementations of DNS over TLS I\u0027m not really sure why but the interest has really been focused on TLS and as I mentioned that our implementations out there doing a form of DNS over HTTP to move on to where deployment is and we have today experimental servers that are available we don\u0027t have any large-scale deployments I am aware of two or three organizations who are planning to do that in the next year or so so it\u0027s on the way but at the moment we have a set of 12 experimental servers that use a mix of software that information about all these servers can be found on the DNS that DNS privacy or website oops that didn\u0027t work very well that block shouldn\u0027t be there should be a nice pretty page under there showing you a monitoring page with lots of green and red blobs for each of the servers my animation clearly failed that so if you want to see the status of those servers you can go to this stage and see it and it also tries to tell you some of the capabilities for example whether they\u0027re doing keno minimization whether they prevent present through some mechanism authentication credentials that you can use to do strict privacy things like that the thing I did want to announce with my last-minute addition to my slide was that for the first time at this ITF the network operations team are running two DNS server TLS enabled servers through the ITF network so if you do want to start using this and playing with it then we have local servers to do that and I believe the information for that is on the meeting network page and if it\u0027s not come find me or email me and I can I can share that with you and I hadn\u0027t even more epic fail that was just a minor minor freeze okay right so that\u0027s the story on the server side what\u0027s the story on the client side as I mentioned the best place we can recommend you to go today is to use stubby stubby\u0027s an application that "
  },
  {
    "startTime": "00:48:23",
    "text": "works as a previous enabling resolver on a local machine it\u0027s based on the get dns library and it\u0027s it\u0027s really a wrapper around running get dns library as a daemon there\u0027s a user guide available to help you get up and running with it it came out in the that the best place you shouldn\u0027t take anything less than the 1.1 release of get dns if you want stubby and it runs as a daemon locally picks up any queries that go to localhost so by reconfiguring your system resolvers to same queries to localhost they will all get picked up by stubby and proxied out over TLS and it comes with a default configuration which uses a subset of the servers the experimental service I mentioned earlier oh boy okay my laptop doesn\u0027t want to play so I\u0027m gonna n let\u0027s hope we can make it there so stubby is currently in a prototype stage we\u0027re kind of saying it\u0027s from fans technical users it\u0027s not for everybody yet it does support all the features we talked about in terms of choosing between strict and opportunistic and choosing between a name or pin and authentication a word of warning we are actively working on evolving stubby and some of this work happened at the hackathon this weekend we\u0027re going to separate stubby s at the moment it\u0027s basically a tool that comes with the getting us library when you install it we\u0027re separating it out to be its own standalone application we\u0027re rewriting the documentation redoing all the packaging except Russ so if you go and look at information related to stubby it probably will evolve in the next few weeks as we we do all that work we\u0027re also working on we have a homebrew tap at the moment which should be a formula hopefully next week we have docker images and we are in the early stages of thinking about what a GUI on this would look like because if you want events accessible to non-technical users you have to think about that so we have a GUI that I\u0027m happy to demo to anybody who\u0027s interested given my flakiness of my laptop I don\u0027t know to our live demo right now basically it\u0027s a little control panel that lets you run stubby as a service gives you a button that flicks your system resolvers you can look at the configuration which at the moment is in the ugly configuration file that\u0027s going to get prettier and you can see a log and what we log is the opening closing TLS connections to all your upstreams and you can configure multiple up streams and distribute your queries among them so as I said this week at the hackathon there was work on stubby there was also some work done by folks in the room starting an implementation of how "
  },
  {
    "startTime": "00:51:24",
    "text": "to do the Dane method of authentication and that included doing it using the TLS extension and there\u0027s also some really good work starting support within Android to do an opportunistic form of DNS over TLS and I\u0027m really excited about that so I want to thank the guys who who did the work because I think that that\u0027s a really important step in making this more broadly available but it does bring an interesting question which is how do we make this usable so the thing is dinners privacy is going to be a completely new paradigm for end users think about how much people struggle just with HTTP to you know not going to insecure websites and think about all the effort that\u0027s been put into getting the icon just right there\u0027s server certificate warning messages right there are whole teams that do nothing but look about work on how to make this work for non-technical users so people barely grasping HTTPS security suddenly telling them that they have to worry about DNS security as well is going to be a real challenge in terms of communication and another challenge to add on to that is that message is probably going to be coming from DNS folks who really aren\u0027t used to dealing with end users we\u0027re used to having DNS under the hood and just work so I think that will be really interesting dynamic as those two worlds meet to make the succeed what\u0027s come out of the HTTPS world is this concept of not just that well but all the studies into things like trying to make email encryption easy a whole variety of different places is you have to have something called usable security which it means that a really nice good you isn\u0027t good enough because users don\u0027t if they don\u0027t understand what they\u0027re doing they can still make huge mistakes even with the best of intentions and even if they do know what they\u0027re doing they can still make mistakes so you have to basically do everything you can to protect users from themselves and enable them to get the privacy they want so this is a non non-trivial problem and that again is probably not for the protocol folks but has to be solved if this is going to become realistically rolled out so to summarise these are what I think the key challenges short term so one is awareness both among technical and non-technical folks the second is clients is getting usable clients and getting DNS over TLS support integrated into operating systems usable clients for non-technical users we are still held back by not having some walls wide-scale deployment of servers and but I think that is coming and as I will keep banging on about I think we need much more transparency from operators in what they\u0027re doing with DNS and of course the big problem to solve is still recursive to authoritative so to summarize dinners privacy is a real problem and it\u0027s one that most people aren\u0027t aware of and I think you "
  },
  {
    "startTime": "00:54:25",
    "text": "hear many of the discussions many of the political clashes between the human right to privacy be needing to being protected against government\u0027s desire to wanting to have a back door into encryption and Dinis it\u0027s not alone but I think it\u0027s becoming increasingly caught up in that discussion and it\u0027s a very large solution space and it\u0027s not going to happen overnight it\u0027s going to be years before we get there but we have made progress you can do Dinis privacy today and that situation is improving because I really think over the next year or so we will see a lot more dinis privacy services emerging so with that I think I am out of time all those I hope this time for a few questions so I\u0027ll thank you for your time today and take any questions from the floor right hi Chris seal with the NSF HTTPS is the idea it would come from the same website that you\u0027re browsing them that\u0027s one of the use cases yes so you go you\u0027re connected to link here LinkedIn and LinkedIn gives you your DNS and my question on that is I\u0027m there for trusting saying if I\u0027m on a malicious website yeah I mean I\u0027m in the world where I can\u0027t tell from the main names or anything that I\u0027m in a malicious world of poisoned DNS round so where\u0027s the how do I know that cool so my understanding after talking to one of the authors of that draft is that the current draft is basically specifying the the transport just the way you do the transport what is a separate question is what\u0027s the requirement to do in a sec validate the answers you get back yeah it\u0027s just obviously part of the beauty of DNS is independence authority oh yeah name resolution so so and it\u0027s when you talk about doing it over HTTP I find interesting because it is shifting that model to saying that you get your you can get your DNS from a variety of places that there\u0027s an argument that says you\u0027re you you may want to restrict doing that to sites you have already authenticated with HTTPS in which case now you have some context but the details of that aren\u0027t clear yet quite right it\u0027s very good question so it\u0027s back to the iam if we don\u0027t trust websites in the first place yeah why would we trust them with DNS anymore yeah and you have to it also comes back to you have to trust somebody I know it comes back to your usable security I could see it actually making things worse because you know I get a phishing email and I hover over it and it\u0027s easy to spot because the DNS is wrong now in future the DNS will look right to me because it was everything about it looks right is it\u0027s all because I started on the website somewhere that I thought was correct yes yeah so there\u0027s a lot to detangle there I think before that\u0027s deployable and so speaking of things we "
  },
  {
    "startTime": "00:57:26",
    "text": "bang on about that works actually a segue into my personal peeve is this term DNS over HTTP because it means different things to different people you presented kind of a DNS world view of it the web browser people have a very different view of what it means and those views are strongly opposed to each other as far as the involvement in DNS servers and invalidation and generating in what the data represents and unfortunately I haven\u0027t myself come up with better nomenclature about it and until we have better nomenclature to reflect the two different views of what the term even means you just have to be excruciatingly ly clear and in this particular case it wasn\u0027t it crossed that fuzzy boundary of well which are we just talking about encapsulating the DNS protocol through the HTTP transport or are we talking about how a web server delivers address information ya know that\u0027s a good point and I think probably could have been clearer here and you\u0027re it\u0027s very good to take on board you\u0027re saying yes I looked at it with a DNS point of view and me maybe it\u0027s DNS in HTTP or something like that rather than over for the second one but I think the draft actually specifically uses that title DNS over HTTP and I agree it in and I and again I sort of worried a little bit about as that progresses it getting enough cross working group review with all that input there because it it isn\u0027t clear and I think use cases are evolving for it as well frankly just as the spec has so I really interested to see whether that is in say six months like what\u0027s yeah emerge from view yes yeah hi sana this is Mohit Petra I am from national internet exchange of India and I am also ISO fellow for this ITF meeting so my question is is the DNS privacy solution being discussed at deprive working group applicable to that dot onion top-level domains which are used for browsing websites in what context EE as far as I know that dot onion is a top-level domain and its resolution is does not follow a simple path and that is from stub to recursive and because authoritative it follows that different adjective altogether I mean it does not follow the normal DNS resolution that\u0027s because it\u0027s not know tnx so my question I don\u0027t know where it\u0027s a valid question or not but still just 2 km I doubt whether this DNS privacy solution applicable to the back I mean wo domains "
  },
  {
    "startTime": "01:00:26",
    "text": "or not and yeah I\u0027ll just repeat that to Mike so was that probably the biggest thing that mr. gates in that circumstance is using cue name minimization so that the full query doesn\u0027t go to the onion servers so reducing data liquid leakage in that fashion but of course we\u0027re only talking today about a solution that works stub to recursive not recursive to authoritative so the cue name really is the only investigation you have on that path there\u0027s been what might be helpful is there\u0027s been some interesting work on the fact that tor is actually leaking information because it does clear-text dns after some of its exit nodes which they\u0027ve realized is a data leakage and then are interested in using D instead of TLS for their dns resolution because they haven\u0027t really recognised it as a an attack path but they have more recently recognized that so is that helpful okay I\u0027ll just do some more homework and get paid back to later on yeah we can talk offline okay thanks okay so I think if that\u0027s all the questions today thank you very much for your time everyone and I hope you all go for also and use dns previously please do you you "
  },
  {
    "startTime": "01:03:31",
    "text": "you you "
  }
]