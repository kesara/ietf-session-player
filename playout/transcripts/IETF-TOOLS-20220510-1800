[
  {
    "startTime": "00:00:07",
    "text": "so ours folks as you join if you are willing please go ahead and share video let's make this uh as much of a meeting around the table as we can make it see so it's like meat echo but you know like zoom or i guess that's the other way i should say the other thing like zoom with echo so i guess i'll put in a feature request i want like virtual backgrounds and things now uh-huh you know what like emojis animating are you listening jay like you're getting this like yeah yeah exactly just check i've got that right animated backgrounds and um you want um something about flying emojis yeah yeah all of that absolutely okay sure right away wouldn't you think the idea for animated four grounds"
  },
  {
    "startTime": "00:02:02",
    "text": "get just a minute more people are still joining now the joining is slowing down so i think we'll go ahead and start everybody's had a chance to see the agenda for a couple of days i'll ask for agenda bashes but remind people that it would be nice to have the agenda bashes um in the notes before we start does anybody have anything that they want to add here not hearing anything we'll jump in we um alice notes that we don't have anything blocking um from rsc production we do have some um gearing that is in the works for an xml rfc release today that um the rbc is waiting on for um releasing on uh rfc that has an author that has non-latin script characters in their name so that is underway we are getting very close"
  },
  {
    "startTime": "00:04:00",
    "text": "to finishing the transition from tools.itf.org to the other services that we've set up to replace it i am expecting this week to build the final set of redirects um for glenn and sometime next week or the week after next we'll um put those into place we've got our own instance of bib xml the bib xml service running i sent a note to the ietf list the chairs the irsg tools discuss reminding people that this transition is going to happen um um very soon um we got a suggestion from mark nottingham that i wanted to bounce off the the folks on this call that we should consider um decoupling the name of the service from the particular format that the service happens to be kicking out now with currently it's we're targeting it being named bibxml.ietf.org um we he asks that we name it bibliography.itf.orgbib.iatf.org if the bibliography is too long does anybody does that resonate with anybody do they care should we stay the course and just call it bibxml because it's kind of what people are used to looking for any any feedback yeah jay just go ahead anybody yeah i'm sorry about that yeah so do we think that the same service might provide the bibliography in any format other than give xml it currently also serves things in"
  },
  {
    "startTime": "00:06:03",
    "text": "ribose's well then i i think mark's right i think we should call it or something whatever um and um that then provides us future proofing as we provide in other formats because we i think in the way that we provide these shouldn't just be thinking about um ietf authors writing ids we should also consider external authors writing in different formats that are because we're going to use a more standard bibliography format than um viv xml you know right now the data tracker serves bibtex so this thing might serve bib tech in the future so um casara let's consider um in fact let's just go ahead and execute on um running the service as bib.itf.org we can cname bibxml.itf.org to it for a little while we can get um maddie to give us the domain name well since glenn's out for another another day so i'm targeting as i mentioned in the notes doing the basically the delegation of tools.itf.org serving that domain name from the ietf infrastructure um the week of um may 23rd i did find this morning a spot in ribose's code where they had um they were scraping the legacy service and i'm coordinating"
  },
  {
    "startTime": "00:08:02",
    "text": "with them to make sure that that scrape stops so that we don't get into a loop when the legacy service was replaced with with our own um and depending on when they execute on that it may it may nudge us out of that that may 23rd week but it won't it won't be a big nudge anybody have any questions or other thoughts about what's left with the moveawayfromtools.itf.org all right uh we had a small group meet um including medico we were talking about um our plans for 114 during that meeting we decided that we would set all of the rest of the working groups up with the zulu channels needed for mediaco to use zulip as the chat back in for ietf114 we're expecting and this depends a little bit on on glenn when he gets back but to have those channels all set up by the end of may um during 114 we'll still have all those channels bridge to jabber um whoa cindy put in some stuff here i hadn't seen so it's just the getting the jabber bridges in all of the zoolop streams have already been created thanks cindy um the we need to decide um this is probably a conversation that should be taken to the isg so that they're not surprised um whether or not we continue to keep the jabber bridge up and offer any jabber"
  },
  {
    "startTime": "00:10:02",
    "text": "services at all post 114 um assuming that the zulub stuff works so this is a i thought that may not have been on people's radar we need to start socializing it any thoughts or questions yeah hi um this is i would think one of the main blocking factors from yeah so they've um prototyped this and are not expecting to encounter any impedance they think they're going to have the integration in place but well before we get to 114 and we're planning to use a tool syndrome to test it um before we get into into the meaning great um one of the things that we discovered on the call this is going to open up and it's part of the you know experience that we need to consider for people at 114 is um with zulu as the back end um and medico's expectation that they're just going to be using a a very very thin delegation model into what zulit provides people are going to be able to use rich text in the chat and include images and emojis and stuff and these are not going to translate to jabber so all right so as people know we successfully made the transition on to"
  },
  {
    "startTime": "00:12:00",
    "text": "an upgraded version of ietfa this went much smoother than i expected it to and i'm happy with the how few issues we had there were a handful of issues the largest i report in the notes was a issue with microsoft 365 and all the corporations using microsoft 365 um being affected by our new ip address not being on their list of addresses to accept high volume mail from so it took a bit of a scramble took three or four days to resolve to uh find the right people inside microsoft to get the that access list updated so we've made a note should we ever do a similar migration in the future to reach out to the people that we identified this time around um send a bigger signal to the community about um other places that might need to be touched and to investigate um having a different approach to the mail infrastructure that would allow us to use both the new and the old mail server addresses at the same time to help condition the new address for everyone as we are as as we move into into a transition any questions about this oh i did mean i mentioned in the notes um you can look at do comparisons against now versus a month ago on scout apm you can see that the data tracker is running about three times as fast on on the new infrastructure it's a combination of the new infrastructure"
  },
  {
    "startTime": "00:14:01",
    "text": "new infrastructure underneath us and running on a a slightly more recent version of mariah db all right nobody's jumping in with questions about server migration just a thank you and congratulation ah yes and thanks for everybody that helped us um during the testing period was helped make that go much more smoothly there is a conversation in the isg right now noting that there are some groups some of which have been around for quite some time that don't have the global white list configured in their accept list for that that particular group um we're talking about um whether or not we program automatically just going in and shoving that into the configuration for every list like every day um whether to do this now or after we make the mailman 3 transition um and whether or not there's any you know what lists it wouldn't make sense to have the this global allow list configured for and i just wanted to um note it here i don't know unless somebody has a uh this sparks an idea for somebody i just wanted to bring it up to share awareness that this that this was an issue one thing in the conversation that i i just pointed out to the isg our allow list has many addresses in it at this point that i think we should purge um side effect of"
  },
  {
    "startTime": "00:16:01",
    "text": "adding any successfully created data tracker account to the um allow list in our super low barrier of entry for creating data tracker accounts we've had conversations among this group in the past about tiers of um reputation i guess for data tracker accounts um where you would have to have done something a little bit more than having created a data tracker account before it would cause that thing to land in the global allow list or not um these are our questions and conversations that are are going to come to the surface again over the next few weeks so i wanted to plant the seed so people could be thinking about it but for sure there are some mailing lists that should not be acceptable this whitelist right so for instance iot directorate is mostly only the the member can be consent to the list but everyone can see it and the same thing for the oscar 48 right so we'll have to have some way to know which ones we should go and flick this on should we decide that this is a will will inflict and it could be a matter of just active working groups and research groups and programs right we limit it to that yeah yeah um if um we're adding people that have a data tracker account do we add all the emails that they have in the data tracker account or just the main one i believe we add all active ones but remember that the white list is also a monotonically increasing thing at the moment nothing comes out unless we explicitly take it out so if it was ever active even after it's been marked"
  },
  {
    "startTime": "00:18:00",
    "text": "inactive it doesn't get removed from that from the list as it currently exists yeah the all addresses thing is coming up in lots of um contexts right now there's a bug on the data tracker for the api submission interface where the user presents themselves as an identity that's not there um it's not the same as the identity that they present in the draft um it it does the wrong thing and we just need to change that one to accept and to to realize that any address known to the data tracker for that user should match the address that's presented inside the draft so um [Music] jay just added a a note to the tools workshops that it's we're going to have a survey out soon and take the results of that survey to prioritize when we have which workshop and then we'll start working on scheduling them we've made nick in particular has made significant progress on the integration of wikijs and the data tracker we believe that this is now finished and we're ready to um start the effort of moving the working groups that still have track wikis into wiki js instead of track so um"
  },
  {
    "startTime": "00:20:00",
    "text": "i've got a question in the list and i've received a couple of emails suggesting some points i'll ask in a moment for people that sent me these emails to go ahead and bring those points up my first question is um to the group mainly to jay at one point we were expecting um okay so the edit here is that that we were just gonna have one big wiki the wiki.itf.org and that's still what we're planning to use for these groups um to to migrate their things to does that exist yet is it yeah or is it an older instance do we need to do it it exists we were just um going to uh wait till we were ready to probably turn on the integration wiki js and data tracker and when that's done then we can start all content across well greg and i need to talk about a plan for it it's going to be a mix of um of staff and secretariat doing it and um working groups doing it so we just need to sit down and um look at it to um to plan that we're going to do that now i think now that the um data tracker integration is ready for us to go so if there is a wiki part of it for working group what's the situation when the working group is closed i guess the document do not disappear right but how can we can we can keep the access running the point is basically next week in the retreat we talk about living documents like implementation status or deployment status it needs to be updated even after the group is closed yeah sure so um the permissions model that we are building into the end wiki js uses data tracker roles"
  },
  {
    "startTime": "00:22:02",
    "text": "so um the access um for a groups pages could be limited to the chairs the chairs of the groups are the ads right the group gets closed um we could have um the past chairs continue to have access if we want to this is something we could set up the ads would always have access the secretariat would always have access and any editors specific editors that we designate at any given point in time you know we can the the the um group that jay just mentioned where there's you know a core team that is knowledgeable about wikijs and is moving these things back and forth and and moving out of we may create a group for these people and give them roles inside this group so um just add a couple of things i mean i think we should treat this as an ordinary wiki which means that we don't really have we don't use those restricted permissions unless we have to we leave the whole thing open anybody can edit and it is self-policed so that you know if you notice something that looks like it's bad then you revert back a previous revision and discuss it with the person in the same way that we do on wikipedia somebody put something you know strange about the building famous building down the road then i revert it and discuss it with them so that i think is probably the best way to start and if that fails then i think we implement the um permissions mechanism but i have a great deal of faith that actually the ordinary mechanism will work to start off i can see from your face you don't you know you are trusting the mankind and i i don't but it's okay right let me put it we can try it i mean as you said right you can revert yeah i think has a data tracker account might be an"
  },
  {
    "startTime": "00:24:00",
    "text": "appropriate at least a minimal barrier to entry as opposed to just anybody anonymous editing because we're yeah no that's taken for granted it has there has to be a net data tracker account you can't you can't edit otherwise yes yeah and to be clear that's the equivalent security model we have now for track okay nick could you look at that particular instance the wiki.ietf.org instance and make sure its configuration can support what we just discussed all right so i've got a few things to note about the data tracker um it's only been a month since we've talked but we've crammed four or five months of progress in on the data tracker since then um we had the deployment of version eight um it's our first deployment from github uh the had several deployments since then we're starting to work on some pretty major infrastructure changes the velocity that we had hoped we would start to experience making the change into github um is appearing so the the changes to the data tracker i think are going to um continue to be fast and furious so for example the release that i'm working on um building and testing today and i hope to have deployed sometime tomorrow moves the data tracker to python 3.9 it's only 3.9 and not a more recent version of python than that because 3.9 is what we can get on the"
  },
  {
    "startTime": "00:26:02",
    "text": "bare os at the moment but we're making steps eventually towards having that part of the data tracker in a in a ultimately in a in a container so what the barrel s provides will will no longer matter um we have a good proof of concept already for making things like document submission asynchronous so that we don't have the long blocking http transactions um we'll be testing that during the week this week it won't be part of this week's release but um i'm expecting that it will be something that's in production before we get to our next tools call so this brings us um in our production environment where we're going to have the data tracker talking to some parts of its functionality running inside a container notably there'll be um a celery instance in a container running that the data track you greater tracker uses for these asynchronous bits our near-term focus has several large items in it i've listed them here this is where we're prioritizing our focus there's one bullet that i need to add to that from something that we discovered this morning so again focusing on enabling the asynchronous interactions we need to finish the work to correct the non-com eligibility issues that we've noted um we need to add support for the new rfc editor model that's on my plate i expect to have that"
  },
  {
    "startTime": "00:28:01",
    "text": "not as part of this release tomorrow but hopefully by release i'd like to say towards the end of the week but more likely into the beginning of next week um and then we need to start the work on the time zone where timestamp transitions again and that's a really really big piece of work it's been holding for the server transition and the move to github and it's time for us to go ahead and bite that off and do it that's going to have several of us distracted for um quite some time i think from a programming perspective this thing is going to take us it's a big bite two or two or three weeks of of pretty hard work and we're hoping that we can re-architect the way that um that it's being approached from what we had planned the last run we made it this so that we can avoid the four-hour outage that the last planned attempt at this entailed um i'm trying to see if we can find a way that we can actually make the transition a little bit more incremental um so that the um down the the final necessary downtime is much shorter now the wallet that i need to add to this that is um missing as we as a bit of a priority action discovered a problem with the xml rfc uh library implementation this morning um it's one of these things where you know no good deed goes unpunished"
  },
  {
    "startTime": "00:30:01",
    "text": "as we have made the data tracker run more efficiently we have relaxed some constraints on the way we are operating it as a web service we are allowing our workers to run for a much longer period of time before killing them the number of of requests that they can run before we we tell them that they must restart um because restart is expensive people have noticed when we restart the data tracker it is slow on that very first request that hits any given worker as python um brings everything into memory right so we've we've moved things to where we have on any given thread these restarts are now days apart instead of hours apart and we've discovered an issue in the xml rsc library that is an architectural issue it shows up um several places uh jennifer's started digging in deeply to identify these places and can start working with it where it loads in its notion of what today is um as it's loading and and just writes it down hard so now that we have threads now we can have workers that run for days we're having things like people submitting a draft today in xml that doesn't have an explicit date inside of it so it creates the text version with the date that it woke up as which was two days ago we have another draft that is um somebody's having trouble with that excellent that the data tracker is complaining that the date's not okay because it appears to be in the future and it's not so it's an and this is"
  },
  {
    "startTime": "00:32:01",
    "text": "actually an architectural issue we may work around it in the short term by doing a daily restart of the data tracker and crying because we're having to do so um but the uh um we're going to prioritize this fix over over um many of the other things that we're working on soon after we get through the time zone aware time snaps i just want to bring these up to people because uh again i i think we've got the isg to have agreed to this already but we may want to send a note to the community and i don't think that we've done so um because i think we need to do just a little more work to be sure that what we're going to ask the community to do doesn't become a burden is to require draft submissions to have all our references fully expanded or any other includes inclusive diagrams or whatever fully expanded so that the thing that is in the repository is doesn't rely on something that externally that could change after the submission for your no well reasons if nothing else um and there's a whole lot of else's besides than nothing else so we've had this conversation before we know we're going down this path but it's time i think to go ahead and implement it one of the things that we need to do is to make sure that there are um that they're supported author tools for uh an author to get their hands on a fully expanded draft easily and um for a way to be able to interact with the data tracker when somebody walks up to the data tracker not knowing about this requirement for them to quickly get the fully expanded thing and review it and submit it we also discovered a bug"
  },
  {
    "startTime": "00:34:03",
    "text": "self-inflicted when we started parsing xml instead of text when somebody submitted xml for things like references um the code that's doing this parsing didn't expand includes so the code that determined references between documents started just not working um complaining with warnings into logs that nobody reads different issue that we need to address but the um there are a lot of drafts out there right now where the referenced and referenced by graphs are absolutely incorrect um we need to fix the code and rerun all of the uh just rebuild the reference relationships for the draft since we started um parsing the xml for for building these graphs it's not going to be hard it's not going to be a big deal but but we've got to go do it okay anybody think that there are any things that are a higher priority to focus on with the data tracker than what i've listed here anybody thinks that we're focusing on something that we shouldn't be focusing on not be a good time to bring it to bring it up robert can i go back to the um the fully expanded ids um where the x includes point to our own um with xml citations don't we have sufficient um uh certainty that those will not change that we can leave those unexpanded it what i'm just thinking about is that when this goes to the auth 48 process"
  },
  {
    "startTime": "00:36:02",
    "text": "the if they're fully expanded then that significantly increases the work of the rpc because they need to check the conversation that we had with this in the past we would have something similar to unprep right okay that would that would you know programmatically turn those into something that could um they could work with it would get current versions okay but it is so if somebody has put in a fully expanded rfc um reference and then edited it because they didn't like it then the unprep tool would detect that and not unprep it and yes that we've discussed right okay all right then okay right thank you um but yeah the the the downside of um leaving the things unexpanded again gets into the um just ultimately decoupling these services somebody wants to actually use one of these things especially if they want to use it offline um then they can't right the the service has to be live in order for them to be able to actually get the content that that was needed so the path that and it's going to take work but the path that we're going down if something started off with an x include in v3 that we would leave some tracks to what that x include was like in a comment or whatever so that um reversion to that x include would be um i'm fairly straightforward so"
  },
  {
    "startTime": "00:38:02",
    "text": "all right um yeah it it if anybody has any thoughts around this after they've had a chance to go think about it again um it is a fairly big thing it's likely to have very subtle unintended cons that the opportunity for unintended consequences is high so do spend time thinking about it and and bring stuff to the list if if you have even vague feelings of concern about where we're going casara you've got a stretch of things here i'll let you take take the floor can't hear you there are two places that you might be muted there is the mute button in the left hand bar and then there's the mute button in the very bottom right corner there's any local mute of course yeah it looks like he's gonna bounce and try again we'll skip ahead and when he gets back we'll we'll come back to his sections on the common bootstrap thing no changes since the last meeting there's been some discussion of the new data tracker coloration mark nottingham opened an issue that was titled it's so"
  },
  {
    "startTime": "00:40:00",
    "text": "blue but he had in the thread some legitimate complaints about contrast and accessibility that we might want to um take a look at we have not deployed the common bootstrap theme that um springload built for us with the data tracker yet i'm still expecting to have that in in an upcoming release but that set of changes is not going to address several of the comments that that mark made in the ticket that we've linked to here i am going to agree that we would close that ticket and just take it as input into a bigger conversation ongoing conversation about what the styling for the data tracker um should be we can and we'll just continue to have that conversation as we go forward jay we may want to have spring load take to run the data tracker as it currently exists or after we apply the um the common bootstrap theme to it through the test tools that they have for accessibility and just give us a report on the um findings that it it produces good idea yeah all right while we're waiting for casara to well rain for casaro to return i'll go ahead and skip over xml rfc um ryan i believe yeah you're here do you want do you want to briefly talk through the points that you've added um yeah just a couple little changes i noted in here one um we had support for bat receipts so those should be going out um in the next day or so we're just kind of validating the"
  },
  {
    "startTime": "00:42:01",
    "text": "format of them um also people that have registered for 114 may notice that there are some changes to the gender options there's latest nomenclature there um that's mostly at me so greg and i have been having a conversation about the efficacy of analytics.itf.org among the what it's telling us about what the at least the iatf community members are are how they're interacting and the registration system i think is going to give us a way to see um the gap for how many participants are actually interacting with the registration system versus how many of them are letting the analytics tool gather anything um whether through their own choice or because of browser configuration like if they've got something like ghostery because ghostry does block analytics i noted this when i registered that my my browser configuration caused the matomo javascript to not load we also deployed analytics i'm really skipping ahead to the web analytics section of this thing we deployed this with the data tracker as well and it ran for a while before i noticed that the configuration at the data tracker would cause every major modern browser to not load the moto mo javascript because i did not include analytics.itf.org in the data trackers configuration for the content security policies"
  },
  {
    "startTime": "00:44:00",
    "text": "um the next release will will include that and we'll start to see a change in what the analytics are gathering um i guess greg do you want to throw in anything else on the web analytics thing as i'm skipping around the agenda here uh just that i think that uh we expected there was going to be fine-tuning and i know better that um eric uh there's also fine-tuning for yang catalog where analytics is also deployed and uh understanding what it's actually telling us is uh something we'll keep looking at so um let's go ahead and kasara can we can you try talking see if we can hear you now can you hear me now yep okay changing interfaces but so on on autotools um the major update was to remove the requirement for that record api key and i am planning to release another version today to support wd and wdf on our id comparisons are there any questions about other tools email on the call not gone and tried to do things with author tools yet i mean if if you've not touched it and if you've not really tried to make it do something useful um please do so you know in the next week um because we are going to start redirecting the xml to rc tools.iatf.org and you know the slash"
  },
  {
    "startTime": "00:46:00",
    "text": "page in this slash experimental page towards it um very soon so moving to um xml rfc uh there were a couple of releases since the last call and now authors can put now they now accept rfc renders non-latin characters properly on on the rfc front and there's another fix coming on to fix a fixer defect on the text format for references with non-electing characters i have added a notes page about what data create about xml direct settings things non-letting letting name be lighting character means uh so there's a bunch of um uh unicode code points there on the link if you go to that link you can have a look at that and we might try to come back to that in the field sometime in the future to update that list or make it a better of representing what letting nailed characters are uh on upcoming work for xml to rfc i will i plan to go through the current issues there are more than 100 open on github and close any v2 only issues that that only happens on v2 formats and on on the track instant xml rfc was used to capture issues for other tools so i will be moving around those tickets to the character"
  },
  {
    "startTime": "00:48:01",
    "text": "repositories uh hopefully cut downs of the open tickets on xml to rfc and that that's it from me um there was a section on the website we can take is read but if anybody has any comments about the the the website as well slightly puzzled by seeing the whitetail moving to python 3.10 while data tracker is just moving to 3.9 i mean those things are unrelated but this kind of strange will run to find one wagtail is already in docker the web the main website the the wagtail portion of the website's already running in as a docker image the data tracker is running bare on the os sure i mean it's it's more about for the developers right having two slightly different versions but that's all yeah we're hoping to get to a world soon where um things are all tracking a reasonable version of the most recent python right so yeah we really need to get off three six because three six um support for three six ended um may 1st yeah okay um eric you"
  },
  {
    "startTime": "00:50:00",
    "text": "have an item here on yen catalog where you mentioned nothing specific um that you're optimizing the montomo analytics um if you could and i know i'm probably catching you cold you know this is a flat-footed question i apologize um but could we start here on this call to get a little bit more insight into the road map and any any new features that you know any okay milestones in the roadmap that we've that we've achieved you know we since we have um given um pantheon a little bit more um lead on this um it would be nice to to see what we're you know for everybody to see what we're doing with it okay then the next big step is basically to incorporate the sid not the service exit but more or as less in the young catalogue and we got already a couple of calls from this uh with carsten and the other people in young catalog but next time i will prepare more thing on this stockton and that to be done um i believe that the rest of what we've got here um we could reasonably take his red unless people have questions about it the ongoing care and feeding of our databases on the upcoming security review for on the things running on ietfa we've got about 10 minutes left anybody have any other business that they'd like"
  },
  {
    "startTime": "00:52:01",
    "text": "to discuss like to say how impressed i am at the level of progress that is being made on some of our core tours of core tools at the moment um the work that i am now you know is very transparent through github um just shows a remarkable rate of progress and it's um it's very very good to see it's good to see the um many people in the community contributing um to all of the github issues it's good to see things being done quickly it really feels like everything's coming together and i'm just very i'm very impressed and i want to say thank you to everybody for that yeah it's awesome thank you and yes it it it feels good so um since we've got a a few extra minutes um i ask everybody to you know try to think out of our normal um pattern of conversation here um what do you think we should be talking about next year right if you if you had if things were going to go optimally for over the next year for knocking off the the the small things and even the big things that are in the way right now what's the big thing that's after that comment three is something what we want to see sooner rather than later mailman okay mailman three um rfc editor uh tooling and website i'm not sure if this is us or if it's contractors or"
  },
  {
    "startTime": "00:54:00",
    "text": "if they're doing it but um some of us will need to be involved there we probably want to have that um that effort at least touch base with with this team if the team isn't actually actively involved in some of it i agree you know and you know personally i think the data tracker will need more work i like what nicolas has been doing in terms of the uh ui revamp for the agenda page i think we have a few more dialogues like phone editing and others that would certainly uh uh like a redesign oh yeah that would be good let's keep going definitely so do we think that uh let me throw a a thing out there and see how you and and eric at least react um we got a lot of tension right now around um [Music] markdown not being the same on in many platforms right is there is is the ietf a venue perhaps that we try to bring all of these champions of different flavors of mark down together and make a superset or something so that um you know there's a a chance of resolving this issue for everybody and not just us or is this somebody else's problem i'd like to um if we can get the people who are driving these various flavors uh in the room right otherwise we're setting ourselves up for you know another markdown variant yeah a common one but i um i mean we did talk on the isg about whether we want to define our own flavor because we have authors that are using"
  },
  {
    "startTime": "00:56:01",
    "text": "markdown at the moment they're using two different flavors and we're also using markdown for the wiki and we're using markdown we want to use more market on the data tracker so um i like the idea of trying to make that a broader effort and basically define you can't call it a common marker you can call it like you know standard mark or something rather than just doing one for us but it requires us to figure out if we actually know these people and we can approach them we can get them interested yep find them engage them yeah it's one that i would like to see and then you know i also i have a i brought up on the calls with the change management team for the rsc vocabulary a few times i think that it's um not an improbable future that we might want to move our authoring actually move our authoring format since we have so many authors working in markdown to where we actually move to a model where the rf where we're at least getting at least accept getting into the uh um through the ietf review stage where the the lingua franca is marked down and not xml so i would even go further in the sense that when we when we did the xml to our c stuff when we started with xml with the modern thing and so obviously we're going to use it as an editing as an authoring language and"
  },
  {
    "startTime": "00:58:02",
    "text": "also a publication language right but now it's like i don't know almost 20 years later and and we're finding ourselves in a world where quickly markdown is the authoring format and xml is only the archival slash publication format um and and so these these two worlds are colliding pretty hard in the itf right now where a significant fraction of authors are basically living in the markdown authoring land and have no interest in ever editing an xml again right and we we still have a lot that are doing xml directly um and then we also still once have never did xml with a little reading text right um but i i i think especially sort of the younger generation of participants i think they're very much marked on base i think it's important to notice that the the only real discontinuity we still have is the oauth 48 process and you saw me saying oh 48 four minutes ago i think we really need to understand how to make the the auth48 process working better and doing the the right amount of github and whatever is one part of it but also making it easier for people who also in in markdown would be another part and alex he is probably right that the rswg will be part of this but i think we need to understand that this is something that needs to be done at some point if i just add a couple of things i think firstly i think it's probably time for us to get some more data um we did an author's survey a couple of years ago and they gave us some data but things have changed and uh some point in the next few months i think it might be worthwhile us considering redoing that to get more data about how people do things um we also have the monthly surveys that john levine does um as the temporary rfc series project manager of authors and perhaps we can"
  },
  {
    "startTime": "01:00:01",
    "text": "get that data better shared for people to see whether we have a change in the number of people using xml or markdown or other things and secondly i'm not sure it actually matters to us to get various markdown implementers into the room all that matters to us is that we have a markdown that is sufficient to cover all aspects of the authoring process we have carsten i think is close there in cram down rfc i think mark is close to that i think although of course we have their two separate ones if we have a single markdown that covers all of our use cases then that's sufficient for us to take that forward for internal tooling trying to solve the larger problem of standardizing markdown across all different sites i think is perhaps too difficult to try to tackle go ahead it's going to say yeah carson i think published the xkcd thing about standards yeah just pick the one that's closest to us that does what we need it'd be great if we could unify the two that we've got it might be a few years out but certainly getting unified all the markdown people you know step two will be then they have to convert all their existing data content and that's not gonna ever happen so there's a trap people are thinking about just draft authoring and when we're talking about markdown we need to remember that we've got far more going on in markdown in the community now than just draft authoring so the notes that are being taken on notes.itf.org are being heavily used for what end up becoming minutes and the tension between the markdowns that the data tracker uses using the"
  },
  {
    "startTime": "01:02:02",
    "text": "markdown library and what the um what notes support is is causing people grief um the um we're going to have markdown support for um buff requests um we'll ultimately go and have these things for charters um we're going to be moving into places where we have we're going to be taking advantage of things that markdown extensions even that um haven't been available when we just had plain text objects um they're gonna need to be uh portable cross services so um i mean it is a far bigger problem that we need to address than just you know reconciling cram down and mark um and if there's a dividing line that's between that and solving this problem for the entire world maybe we should look for that yes i agree robert i think that we ought to be looking at our use cases and solving for our use cases and you've just then identified some more so you know we need to make sure we have that list properly documented and understood but i don't think we should attempt to solve beyond that initially that's sufficient for us that's hard going to be hard enough as it is all right um we've gone over a little bit thanks everybody for for um staying on i appreciate the time that everybody puts in um to helping make sure that we're we're going the right direction and now we'll see everyone online as we are moving towards our next meeting and i really hope to see everybody in person um at the next ietf we'll talk with you soon"
  }
]
