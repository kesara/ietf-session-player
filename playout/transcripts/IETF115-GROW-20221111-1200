[
  {
    "startTime": "00:00:05",
    "text": "um today's group is about 30-ish people it seems remote plus local commands all right welcome to the grow session at ietf 115 in London if you're not supposed to be in London please consult an adult um thank you so much for attending this session uh the grow working group concerns themselves with operations of the global internet routing system um and these days we also spent a lot of time on BMP the bgp monitoring protocol uh today's session will be uh mostly split between focus on BMP and a novel proposal uh about describing bgp communities in a Json format Chris is my co-chair I'm job Snyders um let's start with the first slide deck would you mind pulling that up Chris foreign we had chair slides you want to cover this first please pay attention to the note well the note will outlines expectations uh about behaviors and processes uh but I think by now at the end of the week most of you have seen this slide multiple times next slide please here's an overview of the resources related to The Grow working group uh our agenda is available online everybody submitted their slide deck for today's session"
  },
  {
    "startTime": "00:02:01",
    "text": "um and you can find those online we have a mailing list that is open for everybody to participate in if you're interested in routing operations on a global skill please consider subscribing to our mailing list next slide please the blue sheets no longer is a sheet but a QR codes the QR code was at the entry point into this room make sure to scan the QR code and log in with the data tracker login this helps us with planning the next session in terms of room size um minutes taker we need somebody to uh keep notes of what was said and processed in this proceeding is anybody willing to volunteer to be our minute taker today well if nobody is volunteering I I'm gonna try to give the job to somebody Jeff would you be so kind uh to be a minute's takeaway session anyone else Jared March you're volunteering that is excellent news we have a minute taker uh the jeopard stripes task is to keep an eye out on the chat room and if questions emerge we try to make sure that they are handles oh it's it's zulip these days um I'll keep an eye on on sulip agenda bashing um can we skip to the next slide for"
  },
  {
    "startTime": "00:04:00",
    "text": "that Gemma uh we're gonna talk about documents in Flight uh Paulo is going to give an update on EMP tlv um Ebates progress we have an update on BMP High availability data collection uh and updates about the bgp young model and finally uh BMP path marking is there anything that should be added to this agenda oh wait I see that Martin tells us uh item didn't make it into the slides our last item is smart and Pals on a mechanism to describe HP communities in adjacent format so I think with that we'll we'll need roughly an hour next slide please all right um let's kick it off hello would you mind stepping forward to the stage and uh sharing with us your thoughts and insights on that the bmpe bits and tovs okay yes all right you want me to do it you got it thank you foreign can you hear me yes so um actually I have uh three items to to talk about two are the microphone yes this wow that close okay fantastic really close"
  },
  {
    "startTime": "00:06:00",
    "text": "um so I have three items uh it's uh the tlv the ebit plus this uh new brand new idea that all of you is going to love not like love so next slide please we start with the tlv um next slide already because this is just a problem statement you remember it from from the past uh it's just to make sure that there are tlbs in every uh BMP message and we were missing that for root monitoring and for uh peer down um so what happened since uh version seven we skyrocketed to version tank first of all and there are there are there has been a lot of minor fixes but the two main things are uh first that um so we are ex we are extending the root monitoring message with the tlds and I think in a protocol it's important to be consistent to something else that happens in the protocol so um until the previous revision of the draft we were being consistent to peer up peer down uh to let's say init and tournament messages but actually uh you know that was a kind of a sub-optimal I think Jeff was the very first to notice that you know you have to parse the whole pdu in order to skip then to the tlbs and the tlvs they may convey in some characteristic about the PDO so it was like a not so nice and beautiful but let's say overall we got through the revisions with the you know comments like the one of Jeff but saying okay it's not nice but it's okay right um I would say finally I did take this decision that you know we should be consistent to something let's be consistent to the root root mirroring message which is entirely TLD so now we have a bgp message tlv and the pdu is"
  },
  {
    "startTime": "00:08:01",
    "text": "part of the bgp message TLP so now you can do whatever you like you can really put it this bgp message tlb you can put last first you can sandwich between other tlbs and things like that I think it makes sense and it's much more beautiful than before and based on team events feedback uh on the list I did introduce the group TLD Group tlv is because uh Team said like we can do essentially want to we can model one-to-one like um tlvs to angle arise we can do one to one because there is the index 0 meaning it applies to everything but then we can do not do M twang right kind of relationship so I said you know let's do the group tlv and essentially we just uh yeah and I don't know it it can get complicated but um it it is one of the way forward of course on all of this I very deeply appreciate your feedback if you have any next slide right and um what is the status I would say that the status is simply that there is a little bit more feedback from Tim Evans that I have to process actually I am in weight instead I mean waiting for some answers from him on the list um and I would say like um uh yeah I this is the status and probably there will be more changes uh coming up in the next uh um version of the draft so this is it for the tlb draft I don't know if uh there is any comments if you want to make them now nothing share remote chair no all right next slide"
  },
  {
    "startTime": "00:10:00",
    "text": "so this is about the ebit uh uh next slide and next slide again because I just recap the problem statement for the ebit but you already know from previous version so what happened is that first the document was adopted by the working group thank you so much and to be honest with you I mean there have been only really minor updates updates to the to the document um nothing really worth mentioning maybe I removed a little bit of text and word because they were repeated from the tlv draft and then I said instead of you know repeating all of this let's just refer to the uh to the other draft um I have still one open question I don't know if anybody has any thoughts on it and whatever like the ebit so far we do apply it to the informational tlvs and things like that but of course we have a stats message we have a statistics message and I was very much wondering and that is in a tlv format so I was wondering three would the ebit apply to the stats message as well if so a little bit of text should be added and I am really looking forward also on this aspect to feedback if there is any I think it makes sense but um you know open to your thoughts um and with this I'm finished on the ebit as well any thoughts comments cool next next slide please thank you um so this is um like an idea uh that we have a little bit discussing with Camilo as well um which is a logging of routing events in BNP right"
  },
  {
    "startTime": "00:12:00",
    "text": "um so what is the idea next slide please what ah okay Chris I I never sorry Chris um um so what is the basic idea here um the idea is that like we have a state synchronization with the root monitoring meaning that we it is mandatory that we have an initial flooding of data and then we get all the rest we have debugging with the root mirroring okay and with the root mirroring we should send the verbatim copy High very high fidelity of what's going on and then we have a you know session data and we have stats and all of that right but what we are really missing is a message type that is Event Event driven right so um I don't know you have a policy that policies uh I don't know blocking uh or denying uh prefix uh then uh you know we want you know to be notified let's say or for example there is some sort of validation taking place on the router uh I don't know replica validation or some sort of other validation we want to know that something didn't validate and things like that right so all of this so far uh as I was saying it doesn't exist also the unchanged um so the um unchanged analysis I mean you have to do really a differential analysis for example address being a pre and post policy you have really to go like and scan the whole pre-policy all the POS policy and then you should derive what change change it there right but you could also have you know some sort of notification like again these specific prefix didn't make it to the post policy and and things like that um so this is the intuition uh it kind of makes sense to me uh I hope it does for you guys as well super duper looking forward to your thoughts"
  },
  {
    "startTime": "00:14:01",
    "text": "um next slide please and um so that was the intuition this is the execution so what essentially we did is um we again uh did a message body that is consistent with the root mirroring again so it's all tlv we have a bgp message pdu um bishoping massage tlv that includes a pdu with the so-called event subjects event subjects would be nlri okay and then the indexed informational tlv are the event attributes right and so far the only tlv that I did Define was the event racing right so why we are reporting something so essentially now you can say that at the third the angularri of this bgp update message that of course is an artifact it doesn't exist it didn't exist it's just a way to convey the information uh that for example it was policy denied or it was not valid or something like why I choose to go for a bgp pdu right to convey this information because I thought like uh we already have a code to encode and to decode this kind of information so I really wanted to be a little bit low touch you know it is an artifact I could have invented something totally new uh and things like that but it kind of didn't make sense to me right uh but again super duper looking forward for feedback uh lasting it's a tiny detail uh in the flags we have something that tells us whether it's pre or post policy something I just removed that flag because it still following an intuition uh the the you know the the event happens between a pre and post policy right so it's in between something is happening and it's generating this kind of event"
  },
  {
    "startTime": "00:16:02",
    "text": "super duper again looking for feedback next slide please so status uh I am super duper conscious that the draft uh need to be still worked upon uh it's incomplete probably uh there are also some errors in it and things like that it was really a work done in rush but I wanted to make sure to present it here so to collect feedback in person other than the mailing list also it's a very humbled down uh proposal so far like it only applies to before V6 IP prefixes um Can it can it apply to something else than just IP prefixes right and also so far I'm just saying that the bgp update is enclosed in the bgp message tlv but can we maybe report on different uh bgp messages right so I am here uh crucifix me throw me Tomatoes I mean I am you know looking for feedback thank you uh first up is Jeff and after that I am relaying a question from the audience sure yeah Jeff is we shall I crucifix you because you know you would not be able to type so well um so you you have reached a magic point of popularity you know with a protocol when you know that you're trying to throw everything into it so this is a good time um the wisdom I would share with you is that uh when you reach that point there's a lot of discussion about should you do this yeah you're at the borderline right now of you know you know have interesting things you wish to report you have a good mechanism that can carry it you have some use cases that this may make sense for you are heading down the road very quickly to a generalized streaming Telemetry mechanism that other things"
  },
  {
    "startTime": "00:18:00",
    "text": "may be trying to attach to and you probably went to as grow figure out what that line ends up being and try to keep the lines nice and crisp your overlapping spaces that you have to worry about are you'll work out of like netconf or uh streaming Yang extensions uh you have gnmi coming out of openconfig so these are all good things uh specific to BMP the thing I would suggest you is the same thing I'd give for the streaming Telemetry feedback this is critical data that you're trying to use the more things you put into you know the drinking straw that's carrying the fire hose you know the less you're able to carry through quickly so you're you're starting to get to the point where you're looking for additional channels that carry the same type of information same protocol but perhaps don't overload it on the same session okay uh shared matcha how can I um I want to Echo some you know impart what what Jeff said which is uh if we're going to have different bgp messages and stuff be you know be reported um I mean BMP is largely uh just the bgp on The Wire in a wrapper and so the ability to pass through the MP and you know what other whatever other stuff it is there uh and then you know back on the uh you know kind of the specific monitoring piece is the vision that the router that you would configure in the routers or the b2p speaker the things that you would want it to highlight to The Collector or is that something that would happen in The Collector it sounds like that would be you know in the router exactly that it would highlight it yeah and then you know that that makes a lot of questions about you know then you're sticking that in an ephemeral database on the router or is"
  },
  {
    "startTime": "00:20:02",
    "text": "it that live it live in the permanent configuration store etc etc right um which you might want both and then that gets back to the you know is this you know is this analysis should it just be done offline uh after the fact and that's that's the way we've done it is we're just taking all the data and we're processing that uh after the fact out of the routers um and just getting that mirror that basically the mirror copy of all the information so um you know how much do you want to build the alerting mechanism into that and have that be integrated in the routers and I think having the routers alert on that is a very dangerous and slippery slope yeah I I see to be honest with you um like uh yeah uh what I found out is that like if you want to find a difference like a pre-policy to policy you have to mine a ton amount of data at The Collector just because you are fine trying to find one tiny bit but you know if the router is denying a prefix for example for some reason I mean the let me put it in between quotes the router already knows um so it just seems a more I don't know efficient process although I see that then you know you may be um let's say uh uh yeah uh you are overloading maybe the router um on another um aspect I that I wanted also to say I mean this is uh similar I mean the Rel naming it doesn't come out of nothing I mean it comes from a Nell the netflow event logging so I was kind of thinking you know uh we are building a super similar mechanism but tailored to bgp something like that I don't know if"
  },
  {
    "startTime": "00:22:02",
    "text": "I think next up is ahmed's El Hassani this is more related from swisscom so this is more related to the tlv uh draft and I noticed that you bombed the version from three to four for all messages which even for the messages that are not touched by the draft uh the bars that have to be updated and you have to do something different I'm wondering why not just change the name a bit to indicate this is actually new version that's coming up and maybe bundle some of the other changes with it as well since we are probably changing the version anyway changing the name of the that draft oh make it more clear that there is a new version coming up um okay thank you yeah I I will think about that yeah you said you wanted to relay something from the yeah I wanted to relay a question from Jared Mauch but then he walked through the microphone and asked questions thank you so much Carlo yes thank you uh next up BMP High availability data collection my Lin how do you pronounce your name would you mind sharing that um it's Joya thank you take it away please okay [Music] um my name is Julia Lin and I'm a master's student studying in a global Polytechnic in Paris and I'm happy to introduce to you the high availability in vnp data"
  },
  {
    "startTime": "00:24:00",
    "text": "collection which is a project that I have done in Switzerland for the past six months from March and next slide please the goal of this project is to guaranteeing and is to achieve BMP data High availability and also do possible load balance for other natural telemetric data wire nuts why not bringing a lot of data duplications and nowadays as the network going larger it's more and more important to uh to network monitoring so we are so Network Telemetry is very important and the network Telemetry protocol we're using in these projects is the BMP which is based on bgp and BMP can provide us access to different reps as well as skipping being kept update about the bgp events happening in the network um and this all this data is crucial for monitoring networks the page the BMP works as following it will have one bgp router in the bgp network to export BMP data to an external BMP stations but as the network going larger it might not be enough uh with it might not be enough to have only the the single one BMP one router and one stations architectures so we want to introduce more collectors and next slide please for Prototype designs we have used two collectors in the systems each collector will expose it no sorry each router will expose this BNP twice to to the to the collectors means that both collector will maintain bmp's uh identical BMP sessions to guarantee BMP High availability also with this architecture it's also it's possible to do low balance for other network telemetric"
  },
  {
    "startTime": "00:26:00",
    "text": "data for example ipfix but it's not further discussed here and then since we are having BMP data in both sides if we dump all if we dump both of them to the database we might bring a lot of duplications so at the end of uh dumping the the BMP data in the collectors we have designed a share internal logic Across The Collector to guarantee that the BMP data is only forwarded once but cached twice and next slide please the design is the following we will make the collector to work in active standby States and this active standbys uh why only the active active collector will be thumb paints BMP data and the standby collector will not talk but still keeping the BMP sessions the active standby feature is decided by its timestamp the timestamp is set at the establishment of BMP sessions and the time step will be set to the will be sent to redis as a key and in this case The Collector The Collector can exchange it about their uh about their Works Day by by The Key by the by the timestamp kids and redist and also signals are used for maintenance purpose since we also want to manually configure the active standby States during runtime next slide please since redis is using key value form 2 or to sort records the timestamp keys sent to redis is designed as the following to include all necessary informations to identify the collector and the session so we have included the clustering and cluster IDs and the cluster here includes all the all the collectors in"
  },
  {
    "startTime": "00:28:00",
    "text": "the system in this in the previous introductions we have two collectors so in the cluster there will be two collectors so the questioning and cluster ID will be used to identify which one is this and the core processes core process name is used to identify which session it is since we might have different network Telemetry sessions and this records these kids will be sent with a two seconds time up what so it needs to be kept refreshing and if it's not refreshed then it will be time it will be expired and deleted after two seconds and then every seconds The Collector the program PMS Mississippi running in the collector will list all the timestamp it gets from redis and set the damp flag accordingly if the down flag is true then the collector will be active and if it's forced then it will be stand by it and there are the following four possible conditions if the if if if in redis there is only collector Ace timestamp then a will be active and uh while the the state of B will be unknown because if for B radius is available it will it will not be it will not be aware of the existence of other collectors so it should be set to it which it should be set to active to make sure that the collector won't lose any data and uh if in the radius collector a has the smallest tangent then it should be active and B should be standby and if a has not the smaller timestamp then n should be standby and B should be active next slide please since we're using uh pmcct in the collectors it's easier for us to implement this sure internal logic BMS CCT is a powerful set of it's a powerful"
  },
  {
    "startTime": "00:30:02",
    "text": "network monitoring too with pmscity we can simply Implement uh the the the software logic at The Dumping process and The Dumping program of the BMP data so it can um so it can so we can and Implement our implement the logic uh easily next slide please there are two uh there are two workflow for the for the projects for a regular workflow we should first uh the system will write collectors timestamp key to redis with a two seconds time out and then they will get all the timestamped from redist so that it can be uh be aware of the work states of other collectors in the cluster and then it will make a comparison a month or the timestamp and set the template accordingly um more specific key the forward conditions that I have mentioned before and at the end they will sleep for one seconds and repeat the whole workflow and but if we want to manually configure the states we can put it into maintenance mode by sending a signal 34 for example signal 34 is used to refresh the timestamp and if this signal is called it will set the collector will set the timestamp to current times and the right is ready New Testament to reduce since it has now the larger timestamp we will definitely become standby immediately but for the other collectors they will be aware of the change of the of this change by getting by getting time stamps from ready so there might be some delays and this delay will be maximum two seconds"
  },
  {
    "startTime": "00:32:00",
    "text": "next slide please we have mentioned before that only the active collector will dump but for the uh but the standby collector will not export any metrics to the database but he will kept receiving BNP data and BMP rips BMP events in um in the local cache for two seconds this is to avoid that if a flip if a failover happens for example if it needs to switch from standby to active uh since there is a delay there without we do not want to lose any data so the the new receipts BMP events will be cached in the local buffer for two seconds and once there is a failover happens the uh the data that's in the buffer will be dumped firstly and the failover magnets work as following assume that there are two collectors A and B while accepting and B standbytes if collector a has crashed and has crashed and for example it has been shut down the then the braid is then the key in the radius will be timed out in maximum two seconds because we don't know that if it's been shut down by sending signals or um or shutting down the shutting down the collector if we shut down the collector then we need to wait until the um until the key expired itself and only after the key in the the key in red is expired then the the other collector can be aware of the change of this collector and let's say B is now the collector uh who has the lowest timestamp so it will naturally become active and then it will for what it would do is to firstly send the local cache to the database and then it will work in no normal workflow to send all"
  },
  {
    "startTime": "00:34:02",
    "text": "the BMP traffic that they have received to the database next slide please for testings we have designed two demand setup and three demand setup the three demand setup is used to prove that this project can also be applied for multiple collectors next slide please uh we don't have animation here so we can see that there are two pictures and the first one is the results of two demon setup and the second one is three demand setup for the two demand setup if we look at the first picture of BMP metrics we can notice that even there's there are two collectors maintaining BMP sessions there will be only one collector dumping to the database so it's only there is only one line uh at the uh at the same time but at uh on the right on the right side there are two pictures of ipfix loads received from uh the two the two demons so ipfix is always received and uh uh from from both sides and it will not be influenced but since here we uh we we use uh we try to simulate the failover by shutting down the collector the ipfix flow received from these two sites will be slight difference so I prefix received from a uh will be slightly less than that from B since we have shut down H to make the active failover to be and for the three demons setup we can also notice that there is only one a month a month three demons there is only one um one one demon dumping the BMP data and but however ip4 is always received from all three uh all three collectors"
  },
  {
    "startTime": "00:36:03",
    "text": "so it works for both two and three demons even for more and if we want to add more demons it's just a matter of configuration and it's easily to add next slide please to sum up this the goal of this project is to um the most important goal is to ensure the high availability of BMP data and in the other hand we also want to do a possible load balance by introducing more collectors to the systems for other network telemetric data however we don't want to introduce data duplications since we have more collectors maintaining identical BMP data so we have designed assistance to make sure that BMP data is cached twice in The Collector but or only forwarded once to the database to help in scalability and let's forward the introduced introduction thanks and for backup uh if uh if we go to next two slides there will be the the state machine of The Dumping process and the data queue and that's all for my introduction thank you so much thank you so much for sharing uh these insights and outline of the designs who establish High availability in data collection um I think we have two people that want to ask questions let's go with Chris Morrow first as he was the first one to indicate on zulup that he has a question I think actually Jeff has the same question so I'll be easier with him in the room I think okay we go to Jeff this is Jeff has thank you Joel for your presentation I had first one question about your time"
  },
  {
    "startTime": "00:38:01",
    "text": "methodology what time stamp exactly are you collecting what what is the trigger event is this coming from the DMP protocol or is this messages that are coming from The Collector receiving a thing no it's just the current time it's uh it's the Unix timestamp Unix timestamp of The Collector receiving a message uh no the the Unix timestamp of the start time of the collector okay so this goes into my comment about methodology I think so one of the problems that you'll have for BMP is that uh with your displayed slide here collector a and collector B receiving from the same router there is no guarantee that they will receive the same messages um in some cases bgp suppression of no route change may cause different messages to show route orders may be different and other such things so one of your challenges is for deduplication that there may be different reasons why the collectors are not in the same point of synchronization with a a router learning its state from bgp if the routers go quiet and the state converges at The Collector the final State should be the same but there's no guarantee that during learning State especially during High degrees of churn that the state will be identical have you accounted for this since is since the BMP session is established from uh from 1 pm from one bgp router it's just about configuration so we have configured the router to stand identical BMP session to The Collector I understand your configuration what I'm telling you is that in such a configuration there is no guarantee that"
  },
  {
    "startTime": "00:40:00",
    "text": "data is the same uh the eventual converged state will be the same so to give it easy example you know presume that collector a receives prefix 10 8 no from Pure a and much time goes by and you know collector B eventually could receive the same state or maybe 10 8 has changed at some point as well and collector B is instead getting the most recent thing while collector a has yet to receive the recent update so eventual consistency shall happen but incremental consistency is not there this is a common problem with uh distributed computing type things so my suggestion to you is as part of your uh continuing work uh maybe consider how you would want to address this in the database yes we have we have discussed this uh at the beginning but since this is just for Prototype we have skipped this we have considered to also think the BMP data that you have received from the router to uh to redis so that we can make sure that they are working synchronously but since this just the first day we have skipped this and we by default consider that they are receiving identical BMP data and uh in this way uh if we ignore this we can um we can just implement the active standby feature but but you're right this will be the next step to do uh that we need to sync the BMP data that it receives okay thank you any other questions comments remarks Chris yeah so first off I also would say this looks like pretty cool work I appreciate you presenting it and it wasn't clear from the slide deck that you're sort of in still the"
  },
  {
    "startTime": "00:42:00",
    "text": "discovery phase of how this all works but I or how it's going to work I should say uh I think the point Jeff was making I also had the same question about which what's sort of the primary key that you decide you got the same message at both places it's not it seems like that's hidden in your redis custom key comment so I think if you skip down the road later you'll come to the same state where you say oh wow the BMP uh collection isn't necessarily guaranteed to be guaranteed to be synchronized in time that's sort of Jeff's comment and that you'll have to figure out which nlri which be it which bgp message in BMP is the same to tell which one is which collector has you know you want to to use here and it may be that you don't even care so much about primary and and backup State you just care about getting a single stream out the back end so anyway I appreciate your your presentation it was super nice thanks thank you yeah this is Sarah and Ellsberg from Austin University I have like a question about you talked a lot about redis so has have you also thought about like introducing an intermediate service to um not only safest timestamps into your radius and KV but also like in other technology like memcache D or something like that uh could you repeat the main cached it I because I never heard about that before yeah I think it can can be like makes a lot of sense if you have like this intermediate service to just use also another technology not only redis I mean of course that is maybe the the major one but uh maybe another company that does not use already so you would have like a lot of uh advantages when you introduce like this intermediate service yeah the the reason why I'm using redis is"
  },
  {
    "startTime": "00:44:01",
    "text": "that we have we are the swisscom is already using pme CCT to uh to the network telemetric in The Collector and where this is naturally supported in PMA CCT and if I explore the timestamp to read this since uh PMA CCT is already years across the collector then it's easy for them to exchange but uh so I would say this design is is highly based on the uh pmsicity which is already used in the collectors then but if we want to play for other companies and need to um who is not using pme CCT then it will need to decide another solution probably all right okay makes sense thanks thank you Sufferin would you mind emailing uh the presenter a pointer to memcache because I heard absolutely I will have an offline talk with them thank you thanks all right thank you so much for your presentation thank you so much move on to the next item Camilo Cardona I always get nervous here really yes no need to be nervous we're all friends here my first time was Soulful so okay so a couple of updates for a couple of drafts we have currently running on the working group first of all is the update on the BMP and module next one please um so this is a short one so uh compared to the latest version we we presented in the latest ITF we had a few a few differences so first of all Tom patch went full young doctor to the"
  },
  {
    "startTime": "00:46:01",
    "text": "model I can only thank him enough uh he made multiple comments we tried to address them all uh we have still yet to change the names of some containers and identities we had attending we will do it Jeff has of course always checks the model and he's very helpful I also again can only thank him for his observations uh for the more midi stuff uh since the first email that's about the first time we introduced the model team Evans mentioned that he would like to have initial delay on back of timers uh that doesn't hurt so uh initial delay we added um back of timer is actually part of the BMP RFC so we try to model that in the Yan module uh if anybody can take a look I personally check if there was any exponential back of this container somewhere in the ITF I couldn't find it so I mean we did it from scratch that's it for the more controversial part yeah um uh jimin Chen I think I mentioned this briefly the latest ITF he mentioned a news case in which he would like to send specific prefixes to the station to the VMP station uh this goes very well with our thought or what we have presented previously in which we would like to have a very flexible but very accurate way of defining what to send to the station because not all of us have ways of ingesting 50 million packets every minute and so having a way of this of selecting exactly what you want could help and extend adaptability adoption of BMP so he jimin actually also mentioned that there was this routing policy model already available in the ATF already standardized so we're using that uh the relative policy model even though simple is still powerful enough that maybe there can be some some stuff that"
  },
  {
    "startTime": "00:48:02",
    "text": "makes no sense for BMP like if you mash or filters on like an attribute maybe that makes no sense but uh but we'll see I mean we'll check it out how it works uh but but we added it yep next one please uh that's it uh the call for adoption I don't know if it got a bit orphaned cheers I don't know what happened there but we'll continue working on it on on this because I think we need it I will double check the status and uh do the needful thing thank you for the reminder okay that's it any questions or comments let me see there's no let's see what's your path marking one now Camilla but what you want your path marking deck now yeah let's do that no questions about parking you're up again okay so for the next one um so uh this is a another draft that we introduced previously even a couple of years ago um just an update on this one next one please so this is the path status steel beat um so just as an overview uh what this DLB does is to as to convey the pets the path status of a path in a tlb optional what is a path status whether the path is installed whether the path is a backup whether the path has been rejected or filtered uh whether parties have not passed where the path is for forwarding like this sort of thing uh and there's an optional reason field if you want to go crazy and convey also why the status happen like if it's filtered because of local prefer oh sorry if it's installed because of local preference or I mean if you can do that then there's"
  },
  {
    "startTime": "00:50:00",
    "text": "an optional result field for that um it depends on the tlb draft power already I mean this that's getting progress so it's getting mature so we were more confident about this also about with the ebit um I don't have to follow the a bit where I will just introduce it so thanks to David basically every company could do their own uh their own status right so I mean if they have a property way of status then they can use David and convey it and next one please um so there's no much difference on this draft compared to the latest version uh so in small editorial changes we added a few more examples some bad status so here's the thing in the draft we actually don't want to standardize any path status we want that to be done somewhere else I think I I always get lost I don't know if it's Indiana or I get lost where where this sort of thing gets standardized uh but I still I really well this is me I really think that uh without the examples it's very hard to understand the draft so uh but maybe with this is a bit more clear so I do not know whether uh whether I mean just to make an expression without the examples of bad status and just continue doing it like that or keep it there for a while so to make it clear for the people that read it or I know uh reference a previous version which I don't know if you can do that so that's a general question I I do not know how to do that so or at least I maybe we can discuss it later uh next one please okay so uh again uh why this is interesting um uh in our first use case um it will be for instance interesting to know uh when a path is being filtered uh right now yes we can do that we can take the pre in the post in compare it uh it's a lot of work and uh and and this is interesting information if you can"
  },
  {
    "startTime": "00:52:00",
    "text": "achieve obtain it directly from the router uh and if you can know the real well the reason or the status like maybe a path was filtered because of a policy maybe a path was filtered because it has an invalid graph I mean this sort of thing can be useful because if we have data other data additional data from the network or historical data then we can know if maybe it's hunting is wrong before somebody calls and complains uh I mean that's like a low hanging fruit uh again we can do that already but comparing pre and post in can be very painful if you have a lot of messages or a big routing table um you know in a more com I mean complex cases but it's still useful at least both co-authors of the wrap at some point careers we're working in a system that uh that basically would like to offer what if scenarios for networks and of course nobody wants to do bgp Simulator for that but if the router somehow can send what paths are backup then you can let's say cheaply do some what if a scenario analysis like okay if this fails then I already know the backup it might not be perfect but it's better than nothing so that's for instance one other example and also if you have a very diverse environment with a lot of a lot of paths then you're getting from the local group for instance then you might be able to know which parts are being is for forwarding or not and I mean you can have different use cases for that uh um okay next one please um the status of these from what you understand but I need to visualize Huawei already supported we have uh I mean I I I model this in escapee and against pmsgt and it's already showing it so at least there's or there that the wire format looks good enough uh so there's a bit of implementations I mean we probably need"
  },
  {
    "startTime": "00:54:01",
    "text": "to officialize that so to move this forward but if anybody has any more questions or comments please let us know or I mean ask here and that's it thank you so much any questions comments all right thank you Camillo I would say this was a smooth presentation thank you for your time uh next up we have Martin Pell's for uh a topic that is not yet an internet draft but perhaps uh beautiful things will come out of this take it away oh and make sure to point the microphone at uh your mouth say it's okay no maybe just hold it all right here we go um so yeah as job mentioned this is not a draft yet uh could be maybe I just wanted to throw this at the group to see if there's uh interest for it next slide so the basic idea is you're gonna have to get closer to the mic you're just barely audible yeah you have to actually speak directly into the front of the mic so hold on your hand and your yeah great pretend you're 50 Cent okay um so yeah it's another draft uh it's just an idea I wanted to throw out the group um and the idea is to uh to Define uh BHP communities large communities extended communities in a Json structure uh why would you want to do that first of all to have a standardized way for publication right now isps published their bgp communities on"
  },
  {
    "startTime": "00:56:01",
    "text": "their website or in their autumnum objects in the irr but it's all uh plain text and if you want to do anything with it you're going to have to figure out what they actually want and how to parse that uh so yeah that's the second reason uh if I wanted to do this is if you have tools that want to look at bgp communities uh such as uh looking glasses then it becomes much easier if we have a structured way to describe them next slide please so an example tool that could use this is a Looking Glass um so I'm a part of uh you know knock and uh here we run a Looking Glass that that we recently uh modified to display descriptions for bgp communities and this is basically a self-compiled text file with communities and descriptions and yeah if you want to change anything to that you have to go in and modify text file yeah which is not really a nice solution uh next slide please so uh I made some examples of how what this could like look like first example is based on the RFC 8195 this describes a way to use bgp large communities and sets up a structure with ASN a function and a parameter so it divides the community up into three fields and then the RFC also gives a couple of advantages examples such as uh defining Community for uh"
  },
  {
    "startTime": "00:58:02",
    "text": "to instruct an ISP not to export a route through a certain as next slide please so how would that look in adjacent what could it look like um we would have a template for the community in this case I'm calling it RFC 8195 and there we defined the two custom fields that this community has function field and the parameter field next slide please and then based on this we would have a large BHP community in this case advertise instructing a as64497 not to export to as6551 and there we uh indeed again take the two Fields the function field we set it to four which in the previous slide was uh was set through no export and as a parameter we take the as of the beer that we do not want to export to and of course we also have the global administrator field that we filled so that's the Azam uh next slide please another example is uh for an RFC 4384 this defines HP communities used for data collection and that can be used to tag your prefixes with a for example a region or a country code to show where they were originated next slide please so here we do a similar thing we have fields for the region uh this RFC also has a satellite field which is one or zero and a country code"
  },
  {
    "startTime": "01:00:00",
    "text": "which is uh encoded in a bit stream next slide please and again then we would have an uh an instance of this community which would Define routes originated in the Netherlands which would have a particular region EU this is the bitstring defined by this RFC for you uh satellite set to zero and the country code for the Netherlands encoded according to this RPG next slide please so yeah this is all just a rough idea I would like to hear some comments if this is interesting and if there are people that would like to work on this please come talk to me all right Jairus was Jarrett was first in the queue so um let's start there so I think this this could be interesting I think there's a couple concerns I have um which mostly can be solved so for example that uh there is the Ayana registry for example that has all of the well-known b2p communities in there uh and so I don't know if we would want to look to that for some of the formatting and stuff because they do already have an XML format I know Json is the current sexy thing until we all moved to seabor or something else um you know or whatever is in the future but we may want to just look to that for for some of this because uh there is a lot of ranging here the other thing is uh having been involved in a different discussion earlier today about regular or this week about regular expressions and how to define those a lot of us have"
  },
  {
    "startTime": "01:02:01",
    "text": "bgp communities that match regular Expressions that we would maybe not want to specify all of the things but be able to drop a regex in rather than expanding the entire thing because it's going to be very large so we need to think about how we would encode either regexes or ranges um with some of which is done there I think the other thing is we want to also be a little cautious about this because uh there have been efforts in the past to try and Define a number of uh new softly well-known bgp communities like same country or country codes and stuff like that and trying to standardize that across the industry as well and so um we we should be conscious as we're doing this and then the last piece is the same as many other things like geofeeds and such is how do we discover where to find the list of them so if I is Akamai or Aya's you know you use coloclue you know have a list of those you know where is how do you discover where they're well-defined and well documented list is is that something we want to have in scope so that's a couple of my thoughts on this I don't know I don't know if you have any feedback on that uh thanks that's a very good feedback on the last one um Europe actually suggested maybe we could do something with the RP API to publish and publish them there but uh good feedback and thanks hey Camilo Cardona from NTT uh I would just say um I mean this is not a anything against I'm just saying consider also doing it in yank or doing it in junk and making Jason a Jason a schema from it I mean I'm not going to say no to Jason's Kim it's also fine I'm just saying that maybe for the Machinery of the ITF you"
  },
  {
    "startTime": "01:04:00",
    "text": "will fight at some point somebody that says why not Young uh well I I maybe a structure is simple enough I think there will be nothing no problem doing it there that's it I mean just consider doing it in junk and I think you can compare that to Json schema easily from there so that's it okay files I've been having a flavor of this discussion three or four times with different people including with job and you know Jared and a few other people so the thinking is in the right ballpark so this is a good idea I I think you know I would suggest taking a number of different directions but what also just directly is I'm happy to directly collaborate on this one because I have a large wish list and suggestions on how this can move forward if if you're interested but the easy ones are you know Yang schema to model the thing and then at that point you have many places that you can transfer the data including seabor the thing you're going to find is high level problems uh Jared hits the point of we don't want to try to be too normative about how people use communities mostly what we're looking for is a way to allow for communities to be described and allow that to be consumed by routers for informational purposes or config purposes that moves us into the problem of how you distribute the thing you know rpki is an example of how you would want to maybe discover these sort of things or at least where to pull the data from signing the data you know from the provider falls into the same place and finally these the speed at which you can consume these things you know Json is not a it's not the worst format ever but it's pretty darn close um and you know you're going to find yeah it could be xdr or something like that um but uh being able to consume the things fast on the routers would"
  },
  {
    "startTime": "01:06:00",
    "text": "probably push us through something more long lines like Seaboard we're starting to get good experience across multiple vendors with that is a nice binary format for fast consumption of structured data so a lot of comments good idea thrilled to collaborate if you want that much appreciated thanks from swisscom very interesting for sure um just a few things I would like to point here I'm not sure if you think about it before or not but um you know right now we have collectors like the MCT which is collecting a little bit traffic and then push it back to uh for further analysis in some kind of message bus and they look at the bgp messages and then transform it in non-standard way to another format Json or outdoor or something like that and would be nice to look at this use case in general uh it's very interesting use case because you know most of the analytical programs on top of these things will not consume the wire bgp it's not only about the community but maybe we should start to consider like what other type of applications in the network automation mode that will need to understand the B2B messages as they come from the router but they don't want to deal with parsing visually messages because that you have it's kind of complicated and you don't want to have it everywhere just FYI thanks uh rudiger folk is remote can you say okay maybe I okay I think I'm being hurt now uh uh kind of interesting stuff when I inch when I got around to work on the large communities for my"
  },
  {
    "startTime": "01:08:03",
    "text": "uh policy definition and configuration generator system um I invented something and got it implemented that I called Community registry uh actually I think uh almost all uh points that Jared was mentioning uh were covered uh actually there is even the documentation in our uh internet draft form but uh I have been told uh the complexity of the whole system and to a specific application uh is really confusing so that internet draft form cannot be really used to share uh the main characteristics of the community registry are the presentation instead of doing Json is uh it looks a little bit like uh say domain name uh notation or similar stuff where you can put in symbols and parameters into a structured string and you have an XML definition of how the community feels uh uh are defined and you can put you can uh even uh generate the regular Expressions used in vendor uh policy languages for matching uh simple communities or sets of"
  },
  {
    "startTime": "01:10:02",
    "text": "communities or communities with some of the used parameters wildcarded um and as far as I can tell I think that is still working and about the only major thing that has been mentioned in the discussion uh right now uh that I think uh has been missing in our work was that yes we did not address uh how to make a a system for Global access to definitions uh thou in fact uh kind of that would probably fairly easy easily uh fit into the XML that Ariana is using for its registry um uh I'll try I'll try to uh pull out uh some easy uh stuff from the old documentation and share that and people who are interested uh uh probably should bother me in private email um uh yeah well okay just as a report so far though no Jason would happen or did happen in that that was XML based uh and uh uh uh yeah well okay so much uh to tell thanks all right thank you uh we would definitely be interested to uh to look at that to see if we can learn from it and not reinvent uh the wheel or make"
  },
  {
    "startTime": "01:12:01",
    "text": "mistakes that maybe were made there thanks sorry it's Chris Morrow Google uh I have a question have you looked at I mean the community's Json thing is interesting I think ahmed's point about perhaps the larger bgpe message as some standardized form other than binary bgp data would be useful as well we ingested all of the route views data and put it into bigquery and in that process converted it to Json kind of on our own I don't know that we picked a particularly terrific format for that but if there was a standard format we could just go redo it to make it useful our point where our project was really to make the data available to researchers uh in a fashion that didn't involve them having to download it all parsed into something and then do something else with it so some more General conversion would be helpful I think also if it was standardized would be helpful okay thanks for the presentation too Jeff Jeff is hey Chris just as a follow-up to your point I I don't no I don't think it's quite in the scope for what we're looking at specifically for this presentation uh so what you're sort of talking about is it'd be sort of nice for things like you know like the prior presentation redis Costco know what pick whatever your bus happens to be for throwing bgp State at something that needs to catch it of having consistent naming for the fields uh it would make you know like even MRT parsing program is a little bit nicer that sort of thing so that all the schemas can be folded together this is sort of an interesting related piece there which is once you have parsed out components like communities or as numbers or whatever having a"
  },
  {
    "startTime": "01:14:01",
    "text": "consistent uh mapping component where something says here's what this means you know as numbers you can point to like the who is Data or what they claim their network name means and I'm sure you probably fold that stuff at the back end yourselves so this is the same sort of thing of you know what would you do with a operator to find thing like a community extended Community especially for like VPN context um some of the best stuff that we're seeing you know in terms of uh user-defined data having a more generic format to try to unfold that into a user printable component uh I think if that's your goal as well and this impacts the discussion here is part of the challenge will be internationalization components to this so if you say here's a definition file for communities uh part of the requirements discussions I've had with other people and other contexts is how do you provide multiplicity for some of the fields like a description so here's the English version of this string maybe you want this also in a native language now for the operator as well thanks Jared do you want to take a mic over so it seems there is a good amount of interest to explore their space and everybody has opinions on almost every aspect of this proposal which to me means this this is a good candidate to to take on uh as as work with the goal of making it a working group document um sorry exactly that small detail"
  },
  {
    "startTime": "01:16:00",
    "text": "I'll make the logo you guys do the internet draft um no but really uh Martin I would encourage you to to write an internet draft and submit it to the working group for consideration and um I I think the time is ripe to to try to standardize mapping Community Values to human readable text um cool thank you thank you and with that we have almost reached the end of our growth session uh I noticed that I forgot a small agenda item uh I was going to go over uh drafts that are in flight but then I didn't actually go over those um we have one ongoing uh call for working group adoption related to the EGP well-known Community for any cast a few people already responded on the mailing list um the the call will be open for another week or so from the top of my head uh so please take a look uh at that internet draft and uh reflects on the mailing list whether you support adoption wish to contribute with uh or not um and that's it thank you so much uh the next growth session is going to be at ietf116 in Yokohama in Japan and I look forward to seeing all of you there have a good day foreign [Applause]"
  }
]
