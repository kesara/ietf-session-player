[
  {
    "startTime": "00:00:08",
    "text": "check slack all right we have a note-taker all right it\u0027s time to get started welcome to TLS at IETF 106 in Singapore I\u0027m sure you\u0027re all familiar by now with the note well if you\u0027re not please familiarize yourself with it the blue sheets are now going around we have a jabber scribe and we have a note-taker all right so should we just get started with yeah okay does anybody here\u0027s the agenda for today any additions and modifications any additions or modifications to the agenda yes [Music] with no hat on so he said it goes nicely alongside come back to us I would prefer to not do that we can move before batch signing if that works I mean we could move it before compact CRS you ready one sure yeah can you if you could stick to 15 minutes that\u0027s fine I can do it in 12 perfect any other requests all right on to external PSK all right so this we "
  },
  {
    "startTime": "00:03:13",
    "text": "have like 15 minutes for this but it shouldn\u0027t take that long we\u0027ve been talking about this for a while importing the external piece case for TLS there have been a number of updates since the last draft in particular we used to have this weird way to express what was the protocol for which we were importing a PSK and what was the specific hash algorithm that you wanted to use to import that PSK we sort of simplified things and now the way you import and target particular protocols by saying this is specifically the protocol I want to use the you know the two byte code point value and then here is the specific KBS for which I want to import this PSK there was a new registry defined in the document for identifying these KDF currently it\u0027s just the TLS 1.3 kts and if we have more in the future for TLS 1.12 or whatever we can add them as needed we also added a new slot to the imported identity struct which is this opaque contacts field primarily to help mitigate and deal with the selfie attack so the idea is that if you or have a deployment in which selfie is relevant fill out the contents of this context field accordingly and there\u0027s guidance and how to do that in an appendix and we also added some security considerations to document where as previously they were just sort of TBD and still there\u0027s kind of all still TBD although we have started the analysis to sort of give us confidence that it the imported BS case do have the desired properties that we want and ideally we complete this before publication of the document there are two outstanding PRS right now the first of which is a clarification on the selfie attack it rewrites the appendix in a way to help provide more crisp guidance in my opinion I think that a lot of it can be simplified by just stating that role should be unique however the author of the PR is here to make the case oh boy yeah you can leave me for sending this pool request and it may seem overly complicated but one challenge I faced when I posted the paper on the mailing list is somehow people thought that this is a Mis configuration issue and not not really not really a problem with the TLS external PSK so maybe was my poor explanation but I\u0027ll use another example and cheers please please let me have my minute of Fame so if Joe and Joe and I are chairing another working group and we want to have secret chat or communication we I call up Joe we exchange a PS k and a PS K identity and now he can open a connection to me and send a message and I can open a connection to him and send a encrypted or protected message and this is vulnerable to selfie attack and attacker doesn\u0027t need to know the PS K so depending on how you look at it some people say this is not group "
  },
  {
    "startTime": "00:06:13",
    "text": "communication this is client and server some people might say this is a group of two or group of four because both of us can be client and server so I think there is many variations it\u0027s not just that oh you\u0027re using PS k in a group and someone with the PS K and the group misbehaves can cause selfie attack there is also your shin so selfie attack where it\u0027s possible to do this without knowing the PS K and this is the reason I had added that text that if the PS K is shared between two parties you only need to make sure that that the identities are or the identity of the the part is not the same as yours and if you share the PSK across a whole group then you definitely need some some better information about the identity I also go to comment from Martin Thomson that this requires some kind of signalling I actually disagree because you can\u0027t open a TCP connection without knowing like the MAC address or IP address of the other party so you don\u0027t necessarily need need the signaling to do that I\u0027m happy to make changes to the pull request but my question to the working group is soon this be a rata on it for 4:6 and like shouldn\u0027t we fix it once and for all in this draft burn do you want to comment on that wrong you know Martin Thompson\u0027s really hard to do this without the text in front of me in the comments that I made I forget what the signalling comment was specifically but I wanted to sort of go to the core question here yeah the I said that then I think there may be a comment on the text not the design as much and I think there\u0027s a point in here that\u0027s really important which is that understanding what role you you\u0027re expected to play in here is is critical one the text in the appendix preceding this poor request was I think adequate to that task probably my biggest objection to the text here was it was starting to create new privacy implications that I think would regress the properties that we\u0027ve already agreed existing in TLS the signaling aspects of this thing I don\u0027t think are as as critical to that so sure Mohit so even the previous text was saying that you can use identities such as an MAC address I just elaborated the text saying that if if it\u0027s only between two parties you only make need to make sure that the MAC address or the other part is not the same as yours but if it\u0027s shared by the group you need some some more protections so kind of clarifying both the cases maybe TLS as a working group decides that PSK should never be shared between more than two parties which is fine but I\u0027m sure people will still still do something else but you know that\u0027s that\u0027s a decision for you guys to make "
  },
  {
    "startTime": "00:09:13",
    "text": "yeah I\u0027m sort of viewing the PRS and it like I say an attempted clarification of the existing text so I don\u0027t have a strong opposition to it personally I just want to make sure that you know to Martin\u0027s point we\u0027re not like regressing other properties in introducing and trying to you know flush out more details about the mitigation if that makes sense go ahead John John of northern CloudFlare I think the only thing we just need to make sure doesn\u0027t happen and this is what I feel is the underlying cause of selfie is that people assume that role and identity are in some way tied and so you know if I had a few people suggest that Oh instead of just putting whatever instead of putting you know whatever your name is they\u0027ll say oh just put client and server and of course that doesn\u0027t fix anything at all because either party can be either client or server so it\u0027s just about making sure that they have always different which is not the same as always unique identities I mean so the I means I as I understand the current text or the design idiom here is to start with one PSK and create N squared PS case um um which basically correspond to the mesh of possible possible talk each other correct yes um and then in some unspecified way um its I\u0027m not specified way figure out which PS Katie\u0027s for any connection right namely like I\u0027m aware of I\u0027m aware the identities and nexon and that the system has some set of rules for like how I construct for like I name people and how and how ice and and how I turn my show then these these context rings right yes um so like that seems like a reasonable line not the only one every single design um and I don\u0027t quite understand like I guess I\u0027m not understanding what they said towards the text the prayer is different it seems to be it seems it seems to be somewhat confusing and worse like I don\u0027t understand what is recommending each 10 points less one globe you identify images in all PSK handshakes means um like we\u0027re aware that if how is that enough are used I mean I mean the the text here is like the text here is like I have some unspecified mechanism for getting the keys so so one thing is not um so anyway um yeah the current textures choice yet to punt that sort of to the application because that\u0027s a strictly and deployment sort of problem so that\u0027s the goal of the current text and whether or not we "
  },
  {
    "startTime": "00:12:14",
    "text": "need to be more specific in this particular document is the question I guess and I my opinion is no so bang hey Doc it seems to me like when we were doing a four four six we were thinking a lot about the resumption tsks and we sort of left external pious k\u0027s off to the side and we didn\u0027t think about them too much we didn\u0027t give them a full analysis for all the cases that might be applicable so I think my suggestion would be to have a standalone document that sort of fills in those missing pieces and gives us like these are the considerations for using external PS case with TLS 1.3 and it can go into the analysis about how the identities come into play and what you need to do to avoid the selfie attack and other attacks and the privacy considerations of those identifiers x\u0027 maybe even come up with ways do you like rotating identities that you have less of a privacy issue I think this could evolve into a larger scope thing and so I\u0027m not sure we need to stuff it into the the current document per se that seems reasonable as well well he well hit a quick tool quick clarifying question should we remove selfie from this document then and and solve it in another document sure date for force have an errata and bowie as a working group warned to allow use cases where the PSK is shared between more than two parties I so I don\u0027t think we should remove any mention of selfie because like we specifically added that spot to deal with to like but let this other draft that Ben just mentioned possibly exist in you know the details about how it\u0027s used to go there I don\u0027t think we need an errata on a four for six to deal with this and I\u0027m not sure we can say much about like PSK is not being sure I mean applications will do crazy things and deployments with you crazy things so yeah yeah Martin mom times when I was gonna get up I got up specifically to say what Ben said the a lot of this is uh I think going on a little bit further down the path of doing a design then we\u0027re comfortable with in this document and to do that design justice we need another document because an appendix is definitely not the place to start embarking on something as complicated and as nuanced as this and and that\u0027s I think where my objection was coming from and so if we can do this in and in another document and keep this high-level advice that would be that would be fine recognizing the existence of the problem is kind of kind of important because of this assumption Jonathan talked about but yeah all the stuff with how we agree on what the identifier czar and how you construct those identifiers and how they might be might be exchanged and and built into PSK IDs or not is is kind of complex and I\u0027d rather not do that yet yeah so so what I\u0027m hoping to do what I\u0027m kind of hearing is that like we know we have this problem and we need to identify and "
  },
  {
    "startTime": "00:15:14",
    "text": "write it somewhere so we need to mention selfie here so we have text already so what I\u0027m hearing is this PR gets rejected we start another draft possibly led by a design team to delve more into this but that basically means when you reject this we push this draft forward like immediately no does that does that basically sound like a plan is there anybody who\u0027s interested in joining a design team to look at these these different issue all right so I see Hannes yeah ed Martin Jonathan hecarim water so plenty so does that sound like a way forward does that work so I think I guess I think I\u0027m gonna get this for a little bit now and I think it\u0027s probably for tonight in between several things which I think are not well just not having been that well fleshed out this discussion so first of all on Sophie is an active network attack bicep idol if your attacker doesn\u0027t none of the endpoints right and so on and so it has two modes one mode is confusion between like you\u0027re acting as a client server for the same connection um and um and that and that\u0027s that\u0027s that\u0027s all the number of ways including basically comparing the key shares as John Nelson suggested um um it\u0027s also possible by basically splitting us you have a client server that you you only use one Kishore as a client one case your server the one client server role on the as a separate class of attacks which are about rerouting between rerouting between multiple clients of server pairs and yet a sort of and and then um and the typical way to solve this problem this is the Canada have identifiers in the protocol as opposed to as opposed to diversify key the key material and um and now so finally to get to the point of the text here right is there\u0027s a separate class of problems which is that if you have a group if you have a group that all show the same key then one member the group could appreciate another member of the group and that bob has to solve by giving them individual keys it can\u0027t be solved by expanding the keys this one squared this way because they still could all generate any any any group because at all so um so without like an extremely would wind up um I actually think the power you remove all this material um because the key diversification is because the the proper the proper solution these problems is identified is role identification the handshake it\u0027s not key to versification and because which Alan was alluding to earlier and so there\u0027s one way to do roles in fact the trivial role of agent and shake as I say is this like you know um is is for the two party cases just it\u0027s just like that reflection comparison and the end party case actually is like put something if I was mistaken handshake and don\u0027t treat the PS Cayden if I were to humor than if I as an option we\u0027re getting a bit into the actual but yes I think we definitely just this PR but III think we actually sure taking altimeter lab rights like we\u0027re gonna I think we\u0027ve come did a conclusion right basically unless somebody\u0027s going to get up and radically screen is that we are gonna reject this PR then I\u0027ll kick out the processing River before it will form a design team to get some you know some additional "
  },
  {
    "startTime": "00:18:14",
    "text": "information up about self you know how to deal with it that well I won\u0027t lose sleep over rejecting this PR that\u0027s fine if there seems to be consensus for that maybe my only quibble was if we are going to add identities to they say into to importing external peers case at least the text could still give some guidelines on how to mitigate cell C so the previous text in my opinion was not saying that the other identity the identity or the other party should be different from any of your own and and perhaps at least it could do that it just boils down to a question of do you trust everyone who has your key and if you don\u0027t then like why are we here no it doesn\u0027t I said in the first comment that selfie attack can be caused by someone who doesn\u0027t have your PS k yeah so there\u0027s actually one other outstanding pull requests and Jonathan you might not want to sit down because it\u0027s just your poll request so basically the idea is in addition to or the proposal is in addition to you importing an external PC and doing the key deprivation based on the protocol and the KDF you also change the label you use in the binder computation and then he is that in some pathological case where the identity some other application constructs happens to match an imported PSK identity and the PS K is the same that both parties potentially aren\u0027t in agreement as to whether or not a key was actually imported whether or not that\u0027s an issue in practice is less clear so I think this is potentially something that like helps formal analysis it you know it gives us good it keeps things separate so maybe that\u0027s better I\u0027m not sure it\u0027s needed though so do you want to comment yeah so I I think it\u0027s needed is it I think it need is a general thing I\u0027m not sure it should happen here my presentation later also has this change and I I think if it\u0027s better in the other document than here so so we should still use when the labels but where those binder labels are defined I think should move okay let\u0027s sort that problem that separately that\u0027s document engineering not protocol engineering so I mean well now we have a video document yes it they have to be here right um so I read oblique included that we have to do this it makes me sad a sad panda but um like we just like had "
  },
  {
    "startTime": "00:21:15",
    "text": "too many problems with people with complicated attacks where people would you know we would take a take the drive key and then stuff it in in some separate slot separate like I mean the way they this like like we\u0027ve introduced another rung in the ladder right we\u0027re you know here\u0027s where the keys went in and now we\u0027re have a thing and we put them in here and I don\u0027t want somebody going in here which is what this prevents so we\u0027re Greta bleah I think we\u0027ve made this change great anyone opposed to inject are changing the label I\u0027m not opposed those please state your name at the mic yes thank you great so we work with Jonathan to tweak this PR and land it we will reject the other PR and then hopefully move forward so there are other outstanding issues for the document honest um dishonest I always feel a little uncomfortable if we make some of those changes just based on a gut feeling where we think there could be a problem but then we don\u0027t really know because it always makes heavy everything sort of implementation wise more complicated true it does change the implementation introduce additional complexity however like there is a case where this is potentially a problem the one that I outlined earlier sort of described on the slide so I mean that seems sufficient to me so we do know of an attack it\u0027s just we can\u0027t think of an implementation stupid enough to make themselves honorable to it that doesn\u0027t mean people won\u0027t be stupid did you is that that described in a document in your PR it is not described in the poll requests it that Polaris just sort of describes what are the effective properties of the change not so much what the motivation of the changes it would be it would be good to document the motivation as well yeah absolutely in the security considerations perhaps rather than we can add some text there actually think we\u0027re sort of out of time but Martin if you can have if it\u0027s quick yeah I you were just summarizing I realized in this discussion that I wasn\u0027t sure about something in the document I just went back and checked you say in here that you there are no changes on the wire in the protocol except for expanding the set of identifies that appear on the wire yeah and that\u0027s a very important it\u0027s a very important statement to make but I also realize that you don\u0027t really capitalize on you don\u0027t really expand on what it means to expand the set of identifies and I\u0027m wondering whether or not there\u0027s a formal structure of those identifiers employed by the document or whether there\u0027s an expectation that people work out what those identifiers are because it\u0027s not very explicit in here so I just like to raise one more "
  },
  {
    "startTime": "00:24:16",
    "text": "issue and on the structure of the imported identifies yes that I\u0027m not here say identified that you use one on the wire I think the intent is to use the structure that you\u0027re having here right exactly yes you need to say that clearly yes we can add a sense can you an issue for that I will follow an issue thank you excellent I think that\u0027s it oh yeah status we\u0027re working on implementations and hopefully when we\u0027re done we can move the document forward well Nick Sullivan you\u0027re up for the next two Seibert sorry cut-and-paste I\u0027ll fix that so we\u0027re on the back nine for TLS expert Authenticator sis but we\u0027re gonna have a bug on both so this has gone through last call and it\u0027s gone through reviews and essentially there is one last point that needs to be addressed this is right raised by your own Scheffer and it comes down to the specific line right here as a reminder TLS exported authenticators is a way to export a a piece of data that corresponds to essentially a certificate request and then a certificate it\u0027s useful for higher-level protocols like HTTP that need to have the security of a is essentially the proof of ownership of a certificate but without having to implement the crypto at a higher layer it relies on TLS to do so one of the use cases here for export authenticators is for client initiated server authentication so this is a use case that\u0027s not present in TLS so it\u0027s you can think of it as the server has already if you\u0027ve already made a connection the server\u0027s already authenticated for one certificate and you wanted to authenticate for a second certificate and so the mechanism for doing that exported authenticators is to create an Authenticator request on the client and then a which mirrors what would be in the certificate request in in TLS and then the server responds with an export Authenticator which contains the certificate certificate verify and finish message because in TLS this is something that\u0027s almost all with that is always initiated by the server the set of extensions that fit into the certificate request "
  },
  {
    "startTime": "00:27:16",
    "text": "is determined by the list in Ayana so mcclee something like SNI is only a client extension where it\u0027s not it\u0027s not a server extension and so this use case implies that you have an extension in certificate request that\u0027s not allowed according to TLS 1.3 so the suggestions were to change the document to update RFC 84 46 which seems like a pretty heavyweight change for this document that actually does not update this RFC significantly the other suggestion is to kind of spin out a new extension point for s and I well that is basically an extension point that says this is an S ni but it\u0027s in a certificate request not an S ni that sits in the client hello that that seems like it also might be a bit of an anti-pattern there you might have to if there\u0027s any other extension that\u0027s going to fit into this and you have to spin out a duplicate mean meaning folks extension sni is exists in client hello so it\u0027s it\u0027s not finding certificate request in TLS but this this is this is a certificate request looking structure and then there\u0027s the third third question and the third option here is my preference and i put up a pull request for this but essentially the certificate requests like structure and the client generated export authenticated request treated looking like a client hello when generated by the client with respect to which extensions you can add so allow client hello valid extensions when this is allowed and if it\u0027s coming from the server allowed certificate request extensions and these are the three proposals to help solve this I\u0027m clipping the line after Jonathan right good I think this is the right approach one of the things we did in tail s13 was start to pull apart the various extensions and the and there but we never really did that for client hello and there are multiple different types of extensions that that exist in client helotes we have the ones that change the shape of the protocol we have the ones that are the govern key exchange we have the ones that are used in selecting certificates and some of them are overlapping and they fill multiple roles I think this is the simplest way to manage this by simply saying that yeah this is the client asking for a certificate that\u0027s exactly what it does with a lot of the extensions in the client below there are some in here that won\u0027t make any sense key share for instance but you just ignore them as once it\u0027s fine kinda crits I\u0027m not sure if this is exactly what you\u0027re saying by Z but what it "
  },
  {
    "startTime": "00:30:18",
    "text": "makes sense to essentially treat this is a different message like client certificate request if we\u0027re going to have these like weird mismatch of requirements anyway if so I don\u0027t think it makes sense to request a new column in Ayana for this but I think just one line of text here should be enough then Schwartz with option like option C that my one concern is if you think of your safe you put yourself in the shoes of a bad server implementer I wonder what kind of mischief could be created if for example you just said Oh this contains client hello extensions I\u0027ll just process whatever client hello type extensions show up in this field yeah it might make sense to just have a whitelist on certain client hello extensions mandatory which would make this very weird because you\u0027d either be like we ignore the mandatory ones yeah I think the text that I proposed does not say treated like a client hello just allow client hello enabled extensions so it wouldn\u0027t have the mandatory requirement it wouldn\u0027t be at mine hello would be a certificate request looking structure then allows specifically one client hello extension which is sni and so yeah white less than sounds more reasonable because otherwise steak what does the server do when they receive random client on our extensions okay yeah I\u0027m not not sure what I do like but I don\u0027t like see I\u0027m concerned of the same thing Ben Schwartz just raised it just seems like really like what the heck does that what the heck does like Keisha I mean here and I don\u0027t want to ignore and I want to like um I want to follow draft IEP you know what\u0027s it called now the stuff was wrong you know and and and reject it if it\u0027s bogus so um I think we could discuss pellet um III no problem about being from 84 46 as a general matter Ivan is that we think about the technical point but like I mean get away how do you feel about just whitelist client alone um yes and I for example I mean this is the only contentious point is about s and I and that\u0027s the only it client hello extension used to select certificates that is relevant in this use case I\u0027m not sure prepared to like I understand it yet I think okay all right so more discussion required okay this is this is on the list so please if you have a comment posted list okay this is also not CFR gene whoops alright delegated credentials this is another one that is been moving along pretty nicely particularly we have an update here of running code there\u0027s some public announcements of support for the "
  },
  {
    "startTime": "00:33:19",
    "text": "draft version of this protocol in Firefox nightly as well as CloudFlare and Facebook has done been doing they they have an endpoint that supports it and have talked about supporting it more thoroughly in their in their infrastructure one of the issues that was raised at the last ITF that indicated there\u0027s another potential small issue here this is really a flexibility issue and it\u0027s not clear that there are too many stacks this would affect but one of the one of the issues in TLS 1.3 that came up was this idea of having supported algorithms and supported algorithms certificate as to lists of supported algorithms one for which spki is allowed in the leaf certificate verses which spki is allowed to be used in the certificate chain for signing the leaf certificate and because the peak a stack is sometimes different from the TLS stack these two things are potentially just disjoint lists or different lists in kind of polling the implementation audience here there\u0027s there\u0027s sort of a dual a overloaded use of the supported algorithms and export of authenticators explore an authenticator x\u0027 does not use the leaf certificates spki to sign the handshake it uses the delegated credentials extension spki to sign the sun handshake so there\u0027s potential for a mismatch here if your TLS stack supports an spki but your PKI stack does not support that spki in assert so the the specific use case here is say you advertise support for an IDI to 55.9 signature scheme as a supported algorithm and delegated credentials and you support at 255 or ninth Ella gated credentials but your PKI stack does not support extracting the IDI - five - nine spki from the leaf cert then you\u0027d be in the situation where the server supports this type of key and doesn\u0027t support delegated credentials that could send down a cert that supports this key type and your stack isn\u0027t not able to effectively communicate that distinction to the server so this this is not necessarily a problem in in some of the stacks that we\u0027ve seen but it\u0027s it\u0027s a potential problem in one or two of the stacks and I\u0027ve heard anecdotally from from folks that this may be a problem yeah some tomaten Thompson we originally struggling with problem with RSA PSS which I don\u0027t think "
  },
  {
    "startTime": "00:36:19",
    "text": "anyone\u0027s actually going to deploy but the implementation kind of had to deal with it so we sort of run into a few problems there we have multiple pieces of the stack and multiple pieces of the policy enforcement infrastructure that all have to support this thing before we can turn it on and it turns out that it\u0027s okay for us at the point that we can turn on PSS generally we\u0027ll be able to use it here but I can see how others might be affected by this I\u0027m okay with this I think that having a very small controllable set of signature schemes for delegated credentials is a nice feature I don\u0027t think it\u0027s absolutely essential but I can i I\u0027m ok with this proposal okay yeah I would imagine that the typical deployment will only have say two elliptic curve support and not say RSA of any sort support in that yeah this prevents you from having to deal with RSA base delegated credentials if you don\u0027t want to so I guess so you see you\u0027re privileged to put field in the DC extension that is like here they\u0027ll remove the support that\u0027s right just a list yeah I guess I like how you have the with it here because I guess I can live with that if I can also live with not having it I think you know yeah I think I guess this is like one of these like beauty contest things so I guess is there is there anybody feel strongly on one side of there is there anybody ok Kyle nekritz um I agree there\u0027s a use kiss for this but I guess my question is is anyone going to actually use this I don\u0027t think we would use this like advertise a different algorithm or advertise a different set of algorithms so as online you mean or as a server is this is that this is advertising as a client somewhere but if someone really wants to use it then I have no problems it yeah I think this the the reason that this will come into play is in moving forward with new algorithm types it likely gives us more flexibility with adding new things like for example on the semi static th side we might be able to advertise in this without necessarily supporting semi static th and the leaf cert yeah not in Thomson I was just about to get up and say let\u0027s not add something that when we don\u0027t have a good clear use case for but that\u0027s a good reason to do this we\u0027re having a we have a little bit of trouble getting all of the different pieces in place when it comes to our certificate validation infrastructure and being able to say do a PQ algorithm a 4dc would be kind of a nice way to experiment with those signature algorithms without actually having to commit to putting all "
  },
  {
    "startTime": "00:39:21",
    "text": "the cab form rules in place for instance or changing here so I think this summary is basically we\u0027re gonna accept this proposal what son what I would like to comment on on a separate issue which is okay can I do that yeah is this from so the maximum lifetime of the delegated credential appears to me pick pretty randomly and seven days so I wonder what is that\u0027s really good idea in in use cases that we are looking into seven days seems a little short um and I was wondering whether you can sort of motivate someone in the seven days or why I would want to do that rather than five days or 10 days understand that you ideally would like to put the number in there but I\u0027m not sure it\u0027s a that\u0027s a great idea yeah it\u0027s a maximum and it was based on the typical deployment of OCSP so what works right now as the minimum for revocation and for short-lived certificates measured on the web is where we came up with she\u0027s veena but in context that\u0027s the context in which this came on yeah so someone Thompson this is really coming out of the way right though we\u0027re basically basically assuming that this is a web deployment scenario and maybe maybe the right way to thread this is to essentially say that absent other information endpoints should set a policy of seven days maximum but that would leave it otherwise unspecified so that those deployments that want to do things like I don\u0027t know putting a certificate on a camel that\u0027s gonna then go across the desert and then have to be valid at the other end of it and I don\u0027t know so I guess honest and you have a use case for which you have a certificate that you can\u0027t shorten to the time that you want but a DC that you want to expand to past seven days I don\u0027t imagine that there\u0027s any case of that so yeah I can\u0027t talk entirely about the use case but it\u0027s originated in the IOT space where some of the devices are not always connected and so having them sort of the connect to just to get that delegated credential just for the sake of fulfilling that Cerf requirement appear to be a little tricky given that today there OCS B is not even used at all let alone a certificate revocation which is more used in a in a sort of like firmware update a sort of scenario we can argue better that\u0027s a good approach or not but I think using that work this this recent work there in those environments would improve security overall so I think Martin\u0027s approach of tying it or augmenting it in to the specific context and I I the web "
  },
  {
    "startTime": "00:42:23",
    "text": "context in a bad context that makes total sense to me okay so you understand the based on mark yes yes great Ben Schwartz I\u0027m not convinced that there\u0027s a web context in that is detectable or identifiable to the server operator who is deploying an HTTP service in particular that they don\u0027t know what kind of client it is at this point one thing that you could do is signal a maximum expiration lifetime in your client hello yeah we discussed that and we do not this this only fits into the I don\u0027t know what the client has in their trust or space I don\u0027t know but that the policies are I don\u0027t know there\u0027s a lot of that vagary already in in practice so I don\u0027t know that we\u0027re making it worse by making this one thing Carla crits if we don\u0027t have a must on the validity then I\u0027m worried what we do in a client-side if we get a delegator credential that has a fluidity over what the client is willing to accept right I mean I mean the purpose the purpose of this is to ensure that the server never sends the client something with too long a lifetime and the clients willing to take and so right now what PGI certificates like how like a maximum I like essentially if it\u0027s not a lifetime no like Ryan\u0027s levy she\u0027s like dialing a town um and but it\u0027s like a rule right and so the claims are we on this or if the sir rules on the client something the client sir will make like a two-year GC into the client aquatic nope and then you like screwed so I mean in what you want is like thee and so either we have to have like a rule written down or if the signal light and suddenly it seems like are right on the I guess what I would suggest is um that when we get to the point where those an aggressive use case it needs a longer value like we can there\u0027s a way to signal a death nice I\u0027ve Hannes is saying like I have a use case right now our new super long value like they may we have to live with that but I quite understand like how how how real that is yet for you yeah I was I was one I\u0027m specifically also in a TLS specification we have some some wording specific for the algorithm Sunda mandatory to implement algorithm absent a specific profile we those are the mandatory to implement algorithm and and I could imagine in in this case its symbol a similar absent to a specific profile the default is seven days and yeah um guru that one um so I guess the other change this change proposed solution of adding "
  },
  {
    "startTime": "00:45:23",
    "text": "the list I think let\u0027s confirm that on the list and I\u0027ll just merge it in and then I think at this point with that change I think we\u0027re ready for working your class call um vote did asking github whether we should do an early at early Co point allocation are there people that are trying to implement this now dancers yes I mean I think the answer is yes but like do you wanna needle already it up it\u0027s already in Firefox so alright so we should start kicking that process off yeah you think so actually um this is this is a very magenta bash um but I\u0027m gonna do anyway um we really need a thing like MT is invented for quick or we have provisional point allocations so that we get earlier or not so that we can like do this kind of stuff and so that we don\u0027t stop at each other like by accident huh well I\u0027m happy to do that yes so I\u0027ll start kicking off the early code for an allocation process for that this afternoon okay thank you very much agenda best did you change your slides - hi everyone okay so I want to talk about TLS extended petite schedule so why would you want to extend the key schedule TLS has some like really nice properties but maybe we want more better more exciting properties fine for example we might want some privacy properties for the client hello we might want to do some sort of hybrid key exchange where we use quantum safe keys as well as classical keys and the question is can we achieve these new different properties without breaking anything so we know that TLS has the properties we think it has because it\u0027s undergone quite extensive analysis and modifying the key schedule might mean we have to redo a bunch of that but it\u0027s non-trivial to get these new exciting properties if we want them to without changing the key schedule but it\u0027s also important that we don\u0027t create new attack surface so so I was motivated to do this because there are a bunch of "
  },
  {
    "startTime": "00:48:23",
    "text": "drafts that are like we want to change how the key schedule works and we want to do this or we want to do that so for obvious examples hybrid key exchange if you want to be able to use a quantum safe key exchange simultaneously with TLS without having to allocate new code points you could just define yourself hybrid key exchange draft and this would that you include these keys and injecting key schedule with having to worry about all do we define composite code points do we define you know multiple lists this just sort of walks around all of that yes and I as we\u0027re going to see later there\u0027s been a bunch of inks built on whether we should inject into the key schedule or not external PSK importers how do we diversify keys before they\u0027re imported before they\u0027re used by TLS rather than having to have N squared keys or whatever and semi static if your Hellman also wants to adjust the key schedule to allow them to do various things okay so what we need is an extensible framework all the drafts are just mentioned modify the key schedule in neutrally incompatible ways and they generally haven\u0027t had huge amounts of security analysis and they definitely haven\u0027t had security analysis of when you what happens when you use them with other key schedule modifications and there is lots of dragons there so this draft attempts to do two things capture all of the work already done with key schedule changes and providing a framework that lets us use all of these key schedule changes in a consistent secure and composable most importantly composable way so this is a TRS key schedule truncated at master secret and we\u0027re proposing to inject at two and perhaps three points we want to modify the way PS k\u0027s are are used such that we can do fancy things and we want to inject an extra secret before the diffie-hellman Karthik suggested that we could also inject just before master secret but you know that\u0027s for discussion so the zeros are actually non-trivial the to zero aren\u0027t the same even though they look the same the top zero is a salt and actually just says we assume that PS k\u0027s are uniformly random and the I "
  },
  {
    "startTime": "00:51:24",
    "text": "understand that point I\u0027m I\u0027ll check out the bottom zero so the your then you\u0027re then using the HK DF as a dual PRF and because you\u0027re injecting two secrets and you\u0027re assuming that both of them got the same property um no maybe ignore the top oh yeah and the bottom is their bottom zero like everywhere else in this key schedule but then it comes on the left is this is isn\u0027t is the is the is the one IP k right um the initial random ikm and the thing that comes the top is a salt right so like and if you just like scroll up like 1 HK DF craft above do your extract has a DHE secret as I\u0027m saying like when you want to when you want to do like I don\u0027t understand I don\u0027t understand why you can\u0027t you why you can\u0027t put a rant a I came at that unless 0 slot at the bottom so okay so if you want to inject stuff before the handshake secrets you then have to do something with the EC athe no I know I agree that the first two points the points through a shady green I agree with you oh yeah okay I\u0027m saying that this last point the one that\u0027s shaded white like that\u0027s called like the thing that 0 there so that will so you could also do that but the question then is do we want to do this in a consistent way and just like always do the same thing okay so Thompson I would I would say that the consistent way is to change the thing on the left but we\u0027ve had this discussion wait till my last life exactly but the that\u0027s the approach taken by the semi static thing with that zero which is what which is what I could got up to object to and the PSK importer stuff does that with the PSK one there and but it does in a different way it doesn\u0027t yeah it really does doesn\u0027t it that\u0027s that\u0027s curious which wait to do something that and a CD is another one that I\u0027d like to have as well wait till my last slide okay so just to like point out that there\u0027s a bit of syntactic sugar we\u0027ve got HKD have extract and derive secret derive secret is syntactic sugar for an HK TF expand just FYI okay TLS uses an HK D F and it has extract expand extract takes non-uniform randomness and makes uniform randomness expand takes uniform randomness and makes cryptographically related keys just yeah okay so this is the change we\u0027re planning to make to the PS k extension all we do is add a context field and then use that as the ID instead and you can do that recursively so the you might "
  },
  {
    "startTime": "00:54:27",
    "text": "want to say add three or four PS Kaizen chain and just each one comes with a context and you just compress more and more of that into the yes key ID the context is not necessarily secret but could be but should be non guessable it should probably be a channel binding if you\u0027re doing anything complicated but leave I sort of leave that implementers if you\u0027re going to design complicated to sound complicated okay so what is this change give us and you combined extra information into the handshake so I can bind non secret information to the handshake and this is analogous to the TLS export or interface so in the same way that I can layer something on top of TLS this lets me layer two he LS on top of something else and that\u0027s where you would effectively end up with channel bindings and this sort of just harmonizes the sort of structure that we should have done in the first place and if we I don\u0027t think it affects the security proofs and we shouldn\u0027t have to do anything fancy well I\u0027m not gonna feature trolling there about what was your in the first place but I just want to have a question so um ah one might the this at least one more reason about as injecting into the transcript instead of injecting into the key schedule right mm-hmm okay just running sorry like I mean if we like had if like if like every message had light like if every message had like a extra like a like a notional like here\u0027s extra crap like it could hold in the transcript that would be the same as this right I think okay I know the other stuff doesn\u0027t like that that the pescado stuff is like is a new secret interview yeah this is just like new stuff in the transcript yeah this is just saying here is a place to inject well I think should be channel bindings but like effectively whatever back one slide how is this different to the importer things it\u0027s not this is not even bashing I think it should be moved here yeah it\u0027s basically a copy yeah there\u0027s an extra label that one\u0027s going to working group last call I don\u0027t think we can do that you might want to use this document to rationalize that but I would not change the structure of what\u0027s already been agreed there okay Daniel kind Gilmore I don\u0027t think this is exactly the same as putting stuff into the transcript where that car said earlier in particular a few stuff arbitrary stuff to the transcript it might look the same as stuff that is already that might already have been in the transcript and this case is additive yes so this is that\u0027s why you have to "
  },
  {
    "startTime": "00:57:28",
    "text": "use a different point a label if you look on the bottom right there\u0027s impact minder and in res binder basically if you\u0027re doing an extent an out-of-band PSK using impact pointer as your label we might need to shorten that and basically that says you can\u0027t confuse and also fan PSK using this and that\u0027s been key not using this oh yeah I\u0027m sorry uh my my hypo was it we like injecting my favor was like we don\u0027t like a faked handshake message that was like additional crap in the hint in the in transcript don\u0027t put it in there and that bad I think will have the same properties as this in my head and if it doesn\u0027t that I want to reason about like the same way we did with the with with the reinjection for ch1 like I hope so because otherwise I\u0027m not reason about this correctly that concerns me but I\u0027m not saying our problem with the tetragram they\u0027re trying to make sure I understand what it\u0027s doing yeah the labels are important but yeah okay oh did I finish this oh yeah the route the reasoning why it shouldn\u0027t affect the security proofs is we\u0027re doing an HK DF expand and we assume that H k DF expand gives us disjoint key spaces or computationally distracted key spaces okay the second piece is here you have a an extra drive secret and an extra HK D F extract which is an extra expand extract and the idea is that this will isolate the injected material from the rest of the handshake and in the inputs are injected in a fixed order we\u0027ll have an eye on a registry that says you know this goes first this goes second this goes third okay so what does this give us it\u0027s not the same it gives us to add new secrets to the handshake before we could only add we could only commit to new public values in the handshake so we for doing cryptic line hello extensions or we can add quantum safe secrets without giving up any classical crypto Hugo pointed out that if there\u0027s no PSK and there\u0027s a weak diffie-hellman key then a malicious out input may be able to bias the handshakes secret but if the if all your secrets are weak or controlled by the attacker do we really care if we do really care we can use this design so this basically just uses the dual PRF property of HK DFS and we inject this is copied from drafts tabular and labels combining ATF "
  },
  {
    "startTime": "01:00:31",
    "text": "one and basically we extract from the EC DHE and the well in this case we next-gen would be post B quantum safe but we\u0027d replace that with just anything downsides to this the key schedule is no longer linear and also we can\u0027t necessarily repeat this I\u0027m sorry we wouldn\u0027t be doing the same thing lower down although I guess we care if you want so Thompson drafts a pillow covers a number of options that look like this or like the one that you\u0027re proposing yes I I\u0027m proposing that we do one of them yeah and I would also propose neither of the two options you\u0027ve presented on the screen okay so yeah I\u0027m perfectly comfortable with taking all of the inputs that we have at a given point in the key schedule and then combining them in some fashion I don\u0027t think we need H KDF extract for that we we just need a mapping that is clear and by directive you do just concatenate them in in a simple case because of that most of these things are fixed length but if they\u0027re not fixed length we put length prefixes on and but everything\u0027s gravy the reason that I say that is that we have in most implementations all the necessary machinery in order to switch out the thing that appears on that left-hand side input to HK deific extract and building on top of that machine allows us to effectively reuse an existing joint that we have in the protocol rather than invent new once and extend the tissue dormant in the way that your proposed and I do think that Hugo\u0027s concern is valid because there are cases if if the construction of HK DF extract as a dual PRF is not as strong in that in the direction coming down the down the chain as as coming in from the side then well maybe we have promised with peers K\u0027s on their own but I would rather have a come in the side okay yeah III generally concur with Martin on that basically a Center which we think so if you go back to King I see you were previously sorry to uh that\u0027s a curry yeah so like attack so it\u0027s like it\u0027s like I think they like if you sort of scroll back and Inter like acceptor trolling previously we should have done right um you know the the annoying thing about the current a loss and shouldn\u0027t tell askew schedule is that we basically only allow one secret each of those insert points right and so like when you\u0027re trying to send that you\u0027re like well this one says now we have to and it has the same annoying problem and so does it invokes is like the same "
  },
  {
    "startTime": "01:03:31",
    "text": "annoying problem as well there\u0027s only us two and so like the you know the original sin here is like our failure to like allow an arbitrary number of key values ation certain points and so on and so whatever we do is you fix that if we think it\u0027s good we should fix that and so like either we should do it by being like you know like so users do it by being like you can have it over terminal things you just expect justice justice tracked that\u0027s one possibility and the other is you have a combiner and then you glue them in I think the combiner and glue them in like obviously makes more sense I\u0027m willing to like you know I\u0027d be a caveman also like naturally do what Martin says which is like concatenate them with like link fields and like him like like and I treat it all as one giant thing I\u0027m more than happy to be told wasn\u0027t weird Reiger further along the caveman and like I should XOR them or I should be some other garbage um but like I leave that to like the crypto people but I think we should do is define an algorithm for saying take n Secrets crank him down to 1 I add an entropy bottleneck at at the KDF and then shove it in the left yeah sound good Russ Housley could you back up to the green box one second yes yes thank you so what basically Ecker said was if you look at this you if you combine all of the stuff you can replace that one zero and get a result except for the early data situation and I couldn\u0027t tell whether he was proposing something that affected early better or not is my put is everywhere in this key schedule that we have a thing with we have a thing with an arrow on the right you\u0027re already hkh give abstract we defined a new rule that if you have n things you combine them with formula X and then you shove it in and I guess just to make life simple if you have one you just you just shove it in um and um and then and then and then like very simple and like um and in fact Martin\u0027s things nice because Martin\u0027s thing like actually couldn\u0027t find it in coding which is exactly this property it\u0027s just a serialization now her forceplate do and actually this XOR by the way um if we\u0027re forced to do some sort of like nonsense with like multiple HK TF stages that won\u0027t work but yeah my point is basically it\u0027s just just take each of those hkfs right joints and like redefine that we defined this my left Honus the lines cut after honest and honest please keep it brief yep if you compare the Skip schedule of 1.2 to 1.3 like it became so much more complicated um and the argument back then was we need this because it simplifies the proofs and and that\u0027s great but I think look and listening to your presentation we are making it incremental e more complicated and I would wish that someone actually looks "
  },
  {
    "startTime": "01:06:32",
    "text": "at how to simplify the proofs or to tailor it proves a little bit so that we don\u0027t have to make is more and more complicated because if you look at the code and that we have today in 1.3 it\u0027s it\u0027s this part is actually one area where it where you have way more cryptographic operations that you need to do way more code and that also is has its there\u0027s side effects of that right yeah so that\u0027s actually one of my further questions do we want to extend the master secret should we just concatenate the injected secrets should we be worried about the number of new hashing vacations yes and how should we a handle extension negotiation so because this is crypto you have to if you\u0027re doing the PS KS you have to send either just one PS k that says we are using these extensions or you send a group of PS case that say I\u0027m happy with any of these combinations or you can send one PS k and rely on how to retry if the server\u0027s like actually I only want some of those or I want to add some of your other some other ones that you support and the most important question is is there interest in adoption till Russ house way I think this is very interesting but I think it\u0027s also very complex and the key schedule is the core to TLS 1.3 and so it looks like TLS 1 4 to me so just to answer that question does that mean you think we should not do any of these no it\u0027s very interesting and we should do it but if we looked at it as a new version number it would solve a bunch of those problems that you just listed so we should open tell us one for now that\u0027s a reach out or any discussion it certainly would be so let\u0027s take this to the list because it really quick ok so I just want to emphasize I see presents\u0027 a major change so we have to be careful and not to rush that yeah all right thank you some wonderful green shirts and these slides are designed to ensure that you pay attention you know Martin and I had pretty walked in a contest to make the most offensive possible looking slides I think maybe hive is orange next David\u0027s "
  },
  {
    "startTime": "01:09:35",
    "text": "Knaus II cool may I offer a slight suggestion that the two of you can take your rivalry about making really bad slides somewhere else but yes okay so um this is some work done by me Richard Barnes and Hannes the yes see I guess I guess I felt like if I thought I didn\u0027t ever actually name what it is see is compact by the way that\u0027s why the C is lowercase so okay what problems were trying to solve um so despite like the you know with the fact that everyone\u0027s like really thrilled with how one three turned out jonathan especially the you know things are not perfect there\u0027s still someone annoying like a legacy craft the TLS handshake especially in like the like the client hellos if it feels like a wave of legacy can\u0027t be changed those are awesome um now like unfortunately like in many con has like stuck with that because like welcome to the web and like you can never send anything different ever ever ever but like maybe I saw something had a little bit forever it\u0027s like like particularly like we did quick it was kind of still later like we have these quick messages that contain like like a legacy he like version numbers that nobody uses on second um even from the beginning of one three um there was sadness about the sort of rich feature set um and that has a number of problems um sometimes um one is it made it hard to do like say I don\u0027t want zero duty and I made only and I like like how do you define like what the minimal feature set that like maybe ease your implement is and maybe there\u0027s a reason about is um um so um and second obviously makes the it makes the constraint up it makes the partition size bigger and the joints that you need to make work also make the make the call the wire bigger um so like in particular like if you only have a phone key share like why do you have like a bunch extra values telling you how many he shares you could have and if you only for one key share like why he needs it why thrr and if only for one key share like why do you need some way to like say these are the these are the name groups that support because it\u0027s got all the same stinking thing um and um so finally um the UM you know there\u0027s there is a separation in one three between a handshake and the record layer but it\u0027s not like quite as clean as you might have hoped oops um and um and so like and you see that like it looks fine we did one three but then we tried to do quick it was like obvious that like maybe that was not like quite as clean a set of cuts as you wanted I\u0027m so quick is really like t lost one point three like handshake with a quick record layer and that like you know like that works but like you know it\u0027s like like the document is like take these ports or to your lesson like throw away these little parts to 0s and so try to cut that out would be it would be nice um there\u0027s also an issue if you look at like lake and when you might think I\u0027m oh s course your record layer so in general like um you know it\u0027s it\u0027s from a pedagogical perspective it\u0027s like much easier interpret if you think isn\u0027t one protocol but from a but from a like a pluggable perspective it\u0027s maybe not I think Christian we have made this point "
  },
  {
    "startTime": "01:12:35",
    "text": "actually quite a while back I think Paul Baker did as well on so number of these issues like we\u0027re known but we\u0027re kind of punted out of one three either because like being done as a feature and they didn\u0027t really affect one for itself or because we couldn\u0027t change them like this in the case of of the legacy Croft um like we always knew we could like do like a rubies profile but like we were too lazy um I think Watson lad talked about doing like a TLS one three light at one point but never got done um so um that we thought might try actually solve some of these so there\u0027s a bunch of motivating use cases for this work IJ\u0027s one is quick other than I was indicating another is a TLS is is that what you call it as a TLS set okay the Google thing has some other name like alts or something um there\u0027s a lake for the screen key for hand constrain sizes and there\u0027s eat as well we\u0027re also has been issued to have like a message sizes and anytime you try to map there\u0027s also kind of an issue for DTLS I\u0027m not as not as much but kind of one um so um so say that there\u0027s a but and and again in a TLS you might think about maybe you don\u0027t need the record layer for instance on and like the same way um so there\u0027s like two-and-a-half technical pieces here which we might adopt somewhere all off or none of for that matter so one is some don\u0027t clean up on the handshake messages to make them like less like kind of gross and crafty um I\u0027ll talk about each of these in detail the second is this kind of like um vaguely advanced specialization mechanism for describing substance the TLS like in a way that isn\u0027t just writing new document profiles and finally um or more clearly delineate the handshake in the records record cutscene so it\u0027s no you know exactly where to cut um this last piece as I say actually doesn\u0027t reappear in the spec when I\u0027m pitching it now on and on it\u0027s not quite clear on this back mechanic way how we do it because what you really like is like sort of go back and rewrite eighty-four 46 but in practice probably wanna write a met a document which says these are the pieces you would need and these are cut points and in particular this is what you like to pinned on or not um so okay let me start with the first point um so cleaning up the handshake messages um basically I\u0027m so like I think we can like in retrospect agree that like maybe the encoding hon would kill us like why are encoding it\u0027s not amazing so in particular like lots of places where there like integers was like were you too large for their like intended uses or would you small for their intended uses and so like even though queuing up space on the wire for no good reason or contrariwise on there um contrariwise you\u0027re like hey I can\u0027t fit and um and also like if you look at like they look like everybody\u0027s implementation they all have like for every time you have to include an integer like they\u0027re functions for encoding and decoding integers all come with like a like some number that tells you how big the integer is that\u0027s like really amazingly awesome on you know I feel right if you like this if you just didn\u0027t see you like how like decode you int X and like there\u0027s a field this is a big it is if you do in C++ you like start thinking function overloading and like my time fly specialization and like that does "
  },
  {
    "startTime": "01:15:35",
    "text": "work except that then I said then there\u0027s no there\u0027s no you ain\u0027t 24 and so things don\u0027t work out so well uh-huh so it\u0027s like not great um so like replace every integer with a variant is like actually makes life substantially easier it also means they like you don\u0027t have these goofy situations or you\u0027re not trying to decide like like I I can\u0027t tell you how many arguments I\u0027ve been we\u0027re arguing about like should like the maximum length of this field being code be 65,000 Val 65,000 like objects or up bytes or like 255 bytes um so like let me solve this go away which like is it your crease is loaded on us on um so removing some unnecessary legacy fields like as I say these like these like veiled fields which I only exist to make 1/3 look like 1/2 hum session I need a good example of that um also Richard Barnes suggested removing the handshake message length from the handshake framing on and just saying look the handshake messages like are self describing in terms of lengths there\u0027s nobody get confused this is actually quite a point of confusion your implementations were like you have like you know think about that on so one difficulty here is backward compatibility obviously you can\u0027t like you wouldn\u0027t be able to emit a client hello like according to these rules it was possible by like but person why existing implementation so um so I think we probably have to do realistically is you would do this but then you\u0027d say like hey um you know um you also have to be like if you don\u0027t know what the server does you have to be able if it won\u0027t quite hello as well and receive it um the server hello I\u0027m sure we can find some way to make it obvious so they\u0027ll only change the first message um so this is like semantically identical right this is just like what you thought you might have thought of if like you like had a different kind of online philosophy went where necessary 3 was designed by 25 years ago I\u0027m exact we\u0027re just inheriting the structures from V 3 right on this would be like a non-trivial simplification at least in my implementation I suspect that others um next slide now on the next slide so so like that\u0027s a simple piece right the that sort of fancy piece is like I said TLS is like generalized protocol so like you can do like an enormous number things so all these joints to let you to go she ate every possible thing um that\u0027s good in the sense like you get a very powerful object and you have a powerful object and particularly we have like an analysis of entire thing and so we can tell you like you know when the opportunity to tell you this is like this whole secure profile she\u0027ll us and but like with that said maybe you don\u0027t want all that stuff and so on and it\u0027s like why are you paying for that book from the wire and the implementation and so the idea we had actually do to karthik Bhargav on um is to um I\u0027m your sole term from rust run or vice so you have a on you have like a Jarek system which is polymorphic and what you do is you Mon Amour physis so you take a given axis of flexibility say the version number and you say well in principle like the system supported like 1.3 1.4 1.2 but we\u0027re gonna model mortifies it down to 1.1 and so all 1.3 and so all the code you need like process versions negotiations just go away and all the wire machine where you need to negotiate goes away and so you "
  },
  {
    "startTime": "01:18:36",
    "text": "can and the idea here is you can like independently montemor flies in every axis and then and here\u0027s the cool part the karthik suggested which is you reconstruct the transcript as if you had not montemor as if you had not specialized and so you get the same wire transcript as you otherwise do you have the same thing and then in the key minute in the key schedules you otherwise would have it so you can just think of it as a piece of compression um so um so that I have italicized my term so we have monomer files and reconstruct I thought you\u0027d appreciate that um so the key idea here is you got specialization but you also get forward compatibility so um we like remove extensions you don\u0027t need cuz you\u0027re not using them but if you if there are new extensions you need they just work fine and so on and so as an example um you know we can ah ends and so otherwise unknown extensions just work fine in the future um I\u0027m also get to it on known certificates it certificates point um but it\u0027s a general point this gives you also way to compress certificates but a way to also deal with difficulties ever heard off on so one way of thinking about this um I think also do a Karthik um is that this is like a compression layer between the handshake and the end the record layer and so on like a mission you compress using that using the profile as input to tell you what to compress out and on parsing you decompress using the profile as input to tell you how to decompress DG\u0027s love in the second al um this is like a lot simpler that sounds Barnes\u0027s are like really compact implementation of this in it um so especially themselves are this was supposed to be hidden I apologize I didn\u0027t mark it hidden um especially since elves are like basically defined in JSON so here\u0027s like a simple specialization this it this says like you do only tell us more three and do only these on the cipher suite and so when you do this you just don\u0027t put those things in the mark they just appear so you just save yourself what like I don\u0027t know like a octets so like that was some the but again and so when you decompress the transcript you have only the fields as you have like those long things reported that means you have a once one version in the version supported verses list and you have on both directions and you have one cypher Swedish brushes well button Tom some question for clarification more for other people to understand what\u0027s going on here you\u0027re gonna signal which one of these profiles is available on the wire or assume that there\u0027s something available in the context thank you yes yes quite so and so that the nonsense previously they thought I admitted was you might imagine actually having a way to signal on the wire that actually you was always like injective and you could figure out what was going on but on my supposed registration um okay um so um like so they we have a whole bunch of percenter points you can actually see c\u0027mon horrifies on it\u0027s worth on dealing with extensions cuz that\u0027s probably most complicated one in the source of most of the - hold i was the actual size of Chalfont 3 um so whether they did a whole predefined extensions and basic the ideas you say this extension only has this value so "
  },
  {
    "startTime": "01:21:36",
    "text": "like here\u0027s it only a OPN value and you just basically spit on a fixed text string your stuff in the profile um on you on the extensions do pair of the transcendent as i say um this allows you to have other extensions which are encoded as usual which aren\u0027t the ones that are predefined so it\u0027s just pop in normally and we we in order to make the the the decompression work properly and the question work properly we require extensions to appear in code point order which is a change from 1 3 but it\u0027s a compatible change um namely you can so you\u0027re always allowed to do this isn\u0027t for PSK and PSK just has to be at the end um of our call crypto had this property to their didn\u0027t have PSK um so um now we have a few places where um their asses and their sort of non orthogonal axes that we\u0027ve defined um that I don\u0027t think appears here yeah um that um don\u0027t just involve predefined so as a given example like if you say why only due to curve two five five one nine that like has implications on a bunch of things but it\u0027s one axis about an organization so here\u0027s like a good example um this is like a sort of highly compressed profile um so you can see a center version has one cipher suite there\u0027s this D age group parameter which means I only support to 5 5 a 9 which means I\u0027m not going to send supported groups and I\u0027m only gonna send one key share and like by the way don\u0027t do HR because I doesn\u0027t make any sense um this has like reduced random the finish sizes to give you a high a compact on thing this is like this is going back to the lake use case and then here the extensions um so that\u0027s s and I and that um and their signature algorithms as well force difficut requests so this also implies you\u0027re gonna do TLS indication um so this is sort of like both conditional convenience but I\u0027ll see you might imagine having a machine-readable implementation which could process this and then either either enforce this automatically or actually to go back to the circuit or extended rust example really Mont amorphous where like I have an implementation which is really too many implementation it processes this and it spits out a straight line implementation which only does these things um and the idea is in that case what you do is you just like pick over the you just pickle the strings on the Indira publication directly um one special point which is worth getting at which is this million certificates so like in any real on any real situation um we\u0027re um a vast majority the data on the wire is the certificate himself so you need some way to compress them um there are some nice work um by uh um I think I got entire who did this work now um who\u0027s only who\u0027s in the name of this um some people um about um compression certificate generically using like compression algorithms but you can do much better if actually what certificates are and so on Richard had this great idea of basically you basically have a map of this difficut s-- which is just the like the flat-out certificates and a nickname for them and then you literally just encode the nickname in the certificate entry fields if we were certificate and as long as you make sure that like you can distinguish them from certs then it\u0027s not a problem so like don\u0027t have them begin with o x3 o or have them be like "
  },
  {
    "startTime": "01:24:36",
    "text": "holy short on and then these get blown over the transcript like everything else that\u0027s actually a really important point because you don\u0027t want to have like very short names that don\u0027t appear in the transcript because that creates confusion about in the transcript you\u0027re talking to so like you know you can type seductive attacks so um this is like very straightforward but it works nicely um it\u0027s kind of analogous it\u0027s kind of like it\u0027s kind of like a specialized version of cash info um so um this gives you an enormous amount of compression if you do all this stuff where the profile I just showed you um basically you like reduce the size of TLS by like you know a factor of three or four so like this oppress are pretty good about of reduction um a lot of that ought to be honest is Judas difficut but not all of it um so um this is something obviously we\u0027re working a little bit we have a draft implementation in mint yes sir you might look on the front anyway it\u0027s boring back there Christmas here kind of game out so this is the compression you\u0027re showing here is actually bytes on wire now it\u0027s nothing to do with code by some wire yeah yeah yeah those 21 bytes of code yeah this is the this is the fights of the wire and so basically on these over what the overhead numbers mean is like there\u0027s some there\u0027s like some basic amount of data which you like need to have in her to like make it work at all like the crypto variables has to be given given given fixed size and the overhead is like how much more we are over the fixed over like the minimum fix ID you had to have it\u0027s like you know you can\u0027t have diffie-hellman without like carrying you to five funding keys around and so like that means they\u0027re like if he\u0027s like a minimum size the handshake is like is like we\u0027re also it\u0027s large so this is all about reducing things about that um so like just let me like let me open with like I understand that like this like this like pressurization thing looks a little fancy and like and like we\u0027re sort of back and forth on like how overwrought it is I may be a little overwrought so definitely you know um feedback who desired unlike maybe we got too fancy and pieces of it but um it actually worked out pretty well and I think it\u0027s a good way to define sir these noble profiles as I say both for compassion and also for and also for you know implementation want to be simple as I sort of the cost of some at the cost of the simple limitations of having a bunch of like fixed strings floating around at this system so um right so the final thing is this handshake record layer separation and say this doesn\u0027t really appear in the draft very much of some hand waving about it um the nominally we like actually had a handshake in a record layer but actually and like like the security proofs of TLS like actually don\u0027t really depend on like the record layer at all at least for the handshake um but nevertheless like like the record layers like glued in there um quick separated them but like not like in any any freezes carefully not a principal in an unprincipled way from a document perspective but in a fine way from a tactical perspective and the reason from the document perspective is we given them no hooks to do this with and so the proposal here is is to actually do the "
  },
  {
    "startTime": "01:27:37",
    "text": "like do the document engineering describes this is where the cut point is this is the expectations TLS has about the record layer this is the points at which the keys get emitted this is what you can do here here and here um and that and that and that basically this is arising after interface be the record layer intention and the handshake layer on so yeah as I say here this is really retconning what we did we didn\u0027t quick but the idea is if you wanted like another thing like that like say for like say for OS Koroth it would then be straightforward you know exactly with interface points work so um I don\u0027t have anybody read this okay I see some people raising their hands I mean these are your questions online the question really is right so where this would go the 80s directed us that basically if it was going to get adopted anywhere it was going to get adopted in this working group so this is a request but we can only really adopt this after we change the Charter so I\u0027m going to take this home because I want to do this it\u0027s obviously module on the fact that we can get an agreement on the Charter Daniel so Daniel me go Ericsson I think it\u0027s not the first time we\u0027re compressing protocol it\u0027s a well-known thing the IT I forgot a lot of experience in that and the LP one working group has been focused on that and they\u0027ve defined a framer I think we should work with them and try to be as close as I was I mean to reuse the concept at least ever use the dimension and use the same syntax at least to express the compression so I think we should work with them enough in the way that work but I\u0027m happy to take a look Richard you\u0027re gonna have to come forward that mics not working I\u0027m also going to cut the line yeah I think I think certainly like this is like these V like negative one so like if like if they\u0027re working who wants to work on this and like go in this general direction like I think we\u0027d have like a lot of like a room to like screw around with what the actual syntax was like this was like made up by me like in two hours over a beer dudes cannot see quick enthusiasts just first off clarifying question you mentioned quick as a use case just state what I think is the obvious but to double check you\u0027re not suggesting this for quick view one you\u0027re suggesting a first rate reversion right I think what I\u0027m suggesting is is that the arm yes yes and as they say what I\u0027m suggesting is is that on V this piece here would wreck on what we hit in quick so it just matched wouldn\u0027t create dependency on quick but what natural we didn\u0027t quick and that then ins and then if we did cool things that they might have kept dodging quickly to cool in that case it just wanted to say that I like this I\u0027m really supportive and I would like to see it move forward in this working group and if that means a recharter then that sounds fine to me this plus I think it\u0027s an important work and I think that the less working group should go convict but I have one "
  },
  {
    "startTime": "01:30:37",
    "text": "clarifying question so it seems that profiles are distributed out of band and client and server must have exactly the same profile to be compatible and what will you do in case the profile need to be changed for example in the extension is that it or I don\u0027t know something is removed for how will you solve the problem of simultaneously changed profile for client and server without any disruption of the service so assume this problem should this sort I agree I have some ideas they\u0027re not they\u0027re probably even too half-baked to make up at microphone but I agree it\u0027s a real problem Tommy Polly Apple so yeah I think this is very good work I\u0027d love to see it adopted here so I also working on quick I think it would make a lot of sense to streamline things but to the point that like Daniel was making earlier I mean yes we have a lot of other things that do compression but I kind of see this being having other benefits besides just making the handshake smaller and giving compression it\u0027s not merely that because I also see a lot of trends in you know people doing kind of like new application cases in which people look away from TLS because like oh it\u0027s too complex it\u0027s too extensible or these other things so I think this will also make I\u0027m TLS more attractive to people looking for these lightweight use cases and that\u0027s a really big benefit in my mind yeah that\u0027s really something we\u0027ve been thinking about and I think that\u0027s a bit of a point where Richard and I but going back and forth a little bit and that there\u0027s like syntactic compression mechanisms you can use and there\u0027s semantic compression mechanisms you can use and I\u0027ve been definitely more her semantics in many cases that\u0027s the cost of some some syntactic complexity so I think that\u0027s the part worth is it where is to think about like is what\u0027s the most awesome ol mix of those and I think there\u0027s geese um and you can see even here there\u0027s some you know like there\u0027s some pieces with your basic syntactic which is like replace this extension with this like string and there\u0027s some places with your semantics which is like we only do this diffie-hellman group and trying to find the right mix of that is very difficult Daniel I cut the line center of Internet do we really have a serious advantages because of switching from the fix Atlantians integer variable lengths integer it is not enormous you get probably I mean I loved when I looked at this I think we got like we offer a basic TLS handshake we probably saved off like 30 or 40 octets so it wasn\u0027t like enormous it was partly like so like I\u0027d be I\u0027m not fixated on keeping that it\u0027s just like like I felt like doing any kind of like doing any kind of work here and not cleaning from those gross bothered me a little bit but like I\u0027m not I\u0027m not gonna lie down on the road over it alright so I\u0027m gonna take two hums and then we\u0027re gonna take it to the list first time is whether we want to adopt it as a working group item one is whether we do not want to adopt it as a working group item so please huh if you "
  },
  {
    "startTime": "01:33:39",
    "text": "would like to adopt this as a working group item please hum and now if you do not want to adopt this as a working group item please home now the yeas have it again we\u0027ll take this to the mailing list I would I will note that it was silence on the know great alright we I\u0027ve gotten multiple multiple complaints up here about this slide color selection so going forward will try to be a little better yeah so I mean if somebody did if somebody did want to say no and get to the microphone feel free to explain great Ted are you taking the Vantage tardy it was really no and which is the the unusual variation of yes and I actually think all of the work is interesting but that it should be decomposed the retconning for example I think is going to be much faster and very very useful quickly where some of the the compression stuff there\u0027s lots of different ways you can approach this and that if you split the split the work up in it might be significantly faster to get some pieces of it done that that\u0027s not a no to the work in other words it\u0027s no to this particular cluster being all one thing at the end of the day but I\u0027m fine with the answer being yes after the homes are taken I\u0027m it\u0027s a very tiny place in the rough to be in I\u0027m also happy to defer to the wisdom of the chairs and AEDs and the working group on like I\u0027ve got these pieces often great all right so this is the heavy stacked if you helmand draft the looting to earlier we have talked about this previously in London Nick gave the presentation draft has been sort of revved a couple times since then not much changes but given the you know renewed interesting come back to LS and how this helps we figured we bring it back to the working group and see if there\u0027s interest so for those of them for those of you that are not familiar the semi psychic tiffy Hellman is basically plugging a hole in the opt LS design that was not yet filled by TLS 1.3 which supports the normal one RT t case non semi static where the server actually gives you a certificate instead of you know a Tiffany share getting them both PSK variants so the semi static case is instead of the server sending a cert and a signature computed over basically the handshake transcript you get a you know static diffie-hellman key "
  },
  {
    "startTime": "01:36:40",
    "text": "share either in a delegate credential or via carrier pigeon or something else mix that into the key schedule and then replace the certificate verify which is typically a signature with a Mac and presumably everything else will sort of fall into place this sort of that looks like if you think of it in the opt loss flow so claim hello goes out the door server low comes back you get both a diffie-hellman key shear and a femoral one which is G the Y here and is and in addition to that a semi static key which is typically represented to you the s and then the rest of the computation is sort of the same instead of my signature we there\u0027s a Mac great a motivation for this is I guess they\u0027re a couple points that we want to highlight the first of which is there there may be scenarios where you only want to use a single primitive you might not to use signatures at all like you can imagine clients and servers supporting 70 settings iffy Holman client only need to you know support like have code to do diffie-hellman operations they wouldn\u0027t have to do any signature verifications assuming that the server did not deliver you know the semi said a key share by a certificate or anything like that and potentially also that the client is like pinning the diffie-hellman visit a static share that the server gets so it knows like we\u0027re saying to use and doesn\u0027t have to like basically punting but punts the authentication of the semi static share in that context and in the web where a semi static he shares deliver vital you credential you still have to do a signature verification on the certificate this just allows you to potentially do different algorithms like the ones that Nick was referring to earlier and also has benefits in that it\u0027s potentially a lighter key exchange variant not in the you know certificate case but in this you know sort of deployment model where you have only diffie-hellman using semi static instead of massive signatures or massive certificates and signatures is potentially more appealing in those those contexts also has the benefit of mixing explicitly missing a long-term secret which is the static share into the master secret of course there are other ways to go about sort of mixing things into the master secret or like potentially helping with bad randomness or something like that there\u0027s a draft in the CFR G which kind of talks about something different or a different proposal but this is you know this has that consequence so that\u0027s nice the the idea is basically to where we this is the current TLS 1.2 1.3 key schedule we\u0027re in the master secret is derived you\u0027ll notice that there\u0027s this nice convenient little zero on the left that Jonathan was actually referring or you know covering earlier in his presentation the change with the semi static key schedule is basically to take the output of the client ephemeral and "
  },
  {
    "startTime": "01:39:42",
    "text": "server static and put it in that slot more or less and then computer Mac with that secret how convenient that we have that zero there to negotiate this thing there will be a extension of art you know addition to the signature scheme enumeration that says I support signatures with p2p physics or whatever in the name group you want and if the server supports it it would just you know send back either a delegate or credential if you who also supported delegated entries or whatever mechanism I think the actual like details of how we get the keys deliver to the client and potentially something we can work out I\u0027m sure there are you know many ways we can paint that bike shed yeah you know nothing Thompson I know this is just a spelling exercise but I\u0027m wondering whether the the scope of the changes you have here are appropriate for doing something in signature algorithms rather than for instance having a new extension to signal these things and even potentially a new message that you would send in in replacement for certificate verify for instance so go for one point one of the open questions this one that we just drop this tip here verify entirely and just rely on the aad kind of giving us that confirmation so yes that\u0027s potentially one option you know new extension to negotiate it a new message is to forget verify potentially this yeah I think they\u0027re a little more comfortable with making making this a new extension I\u0027m not sure that I know how to make the decision about certificate verify and finished here it seems like finished might work but I\u0027m uncomfortable with that but yes that certainly needs more analysis the nice sort of appealing property is it makes it more of like a noise like protocol where you don\u0027t have like explicit things giving you confirmation you or just like fold it into the key schedule as you go forward yeah yeah so they think pieces right um I mean I think that the reason we did this way that the design were like is indicating is is like the size the purpose that is the function these are serving right I mean it is it is verifying their certificate is binding the certificate to the to the transcript to the traffic you\u0027re sending in fact you know if you like if you are if you will notice like but cozy cozy and hose they refer to these things as soon as I believe very often I don\u0027t like any more than you do um but it is definitely I mean it\u0027s not a signature bit certificate verify um so on the on this question about stevia verified versus finished um this turns out to be a full circle problem on a few electric we\u0027re here we would tell you is that the the reason why you have to have to forget verify is because you are using the warm diffie-hellman key to authenticate the short trend refueling key and that means that and and that me and that and that "
  },
  {
    "startTime": "01:42:42",
    "text": "and that means that you have to have a and so there\u0027s this question that circular dependencies between those two and so and so finish to use both of them and so uh and so like so this is a purse is so you must of you verify what you want to have is you want to have a Mac that is solely composed of jadx and GES over the rest of the transcript and so I thought we thought the spec said but am III was a while ago I would it does yeah yeah and so and so you so and the purple are finished is to provide liveness for the entire if I live this for the entire the entire liveness and verification of both keys right and so um and so it\u0027s and so and so I mean you can measure moving the finish in TLS ordinarily but then you lose the property the property that seek a property which is the handshake alone without any reference to the record layer guarantees completion of the handshake in the properties so I think you do I mean um that that\u0027s so I mean you could say I don\u0027t care there\u0027s a girl dependency and I sort of like Hugo told me this I was kind of like like I\u0027m like a caveman so like whatever um but um but like it seemed important and I\u0027m gonna uh this is a situation I\u0027m kinda for any cool talk refers he told me that like this early fantasy she\u0027s important point I was I was more worried about this extending to changes in the protocol that were more than just confined to the signature negotiation and construction because the insertion into the key schedule is is is a new thing that that some implementations maybe you\u0027re prepared to do if you do that solving inside the certificate so I guess I would say that like um so good can we go to Chris\u0027s on benefits your benefit list yes so I mean we could simply I mean way could simply say we don\u0027t care at this lost benefit right and then we could dole sit your bowl assistant which is isomorphic to 1/3 which really just use max instead instead of instead of instead of signatures and um and would actually be like perfectly fine protocol right um and um I guess later later on Chris I think demonstrate Chris talks about client authentication and it\u0027s in the current clients in vacation mode we do not in fact we not in fact mix them um and so it is a little goofy honestly um and so like I would not actually I think Karthik was was pushing for basically keeping the current TLS like structure and not using that last joint in the protocol so I\u0027ll be a totally valid thing to do um um it would be um I am like different people have different laws I guess you weren\u0027t in Lake yesterday but different people different levels of sympathy for this petitioner at the long term versus short term secrets I have like not a human and sympathy because I generally figure they\u0027re sitting in the same like in the same like memory locations um but if you had the usual rationale is that you have the is that you have like the long-term secret in some way special box somewhere [Music] two quick points is it obvious that this gives you the same guarantees or equivalent guarantees as tell us 1/3 in "
  },
  {
    "startTime": "01:45:44",
    "text": "its ordinary mode the authentication properties are slightly different obvious might be false I believe this the case and I think digital modeling of it but I think like that would DVD right sorry isn\u0027t I believe it does but yes um it may be to false is the intended design that it does yeah can we make this quick because yeah we just do separately I\u0027m second thing this is yeah a draft that is modifying the key schedule and we should do that in a consistent way Oh convenient cheap plug yeah so there\u0027s also open question of how we have want to do clarification the draft has one particular approach maybe that\u0027s not the one we go with there is a entire open question about whether or not you use the semi sector for zero RTT and how you actually deal with early data instead of like using tickets to you know potentially internalize like early data encryption to a server and how you get the semi set of key and those particular scenarios and they\u0027re so an open question about how and when you can reuse a you know semi static diffie-hellman key share particularly when you\u0027re dealing with post quantum stuff which not it\u0027s not always safe to use Viki more than once so explicitly considering that we have compact TLS going on and there\u0027s interest in this particular work and this has benefits relevant to that like to know if the working group is interested in adopting this and moving it forward of course there are a lot of holes to plug and things to work on but I think we could sort them out especially in you know in cooperation with Hugo and Karthik and folks like that going forward so yeah so I think we\u0027d like to get a sense of the room so we\u0027ll have a homme on first if is this working group interested if people interested in pursuing this topic yes and no so hum if you\u0027re interested in in pursuing this topic um if you think the working group should not pursue this topic okay there\u0027s somebody want to get up and voice their discontent how many folks are willing to review this draft about 10 our folks willing to contribute text at 5:00 we\u0027ll take that to the list to verify group consensus for adoption and we\u0027ll kick that off David Benjamin you\u0027re up next "
  },
  {
    "startTime": "01:49:10",
    "text": "hi yeah so problems always get better when you throw more cultures at them so why don\u0027t we do that yes so if we look at TLS handshake cost we\u0027ve got like various symmetric junk which is basically free as far as we\u0027re concerned compared compared to the other stuff client and server will each do any CDH operation which is much slower than the symmetric stuff but you know we can negotiate a fast DC curve and that\u0027s pretty independent of like other things and then you\u0027ve got like a signature with a long-lived key which can get kind of expensive in some scenarios for instance if you\u0027re a hosting provider the customer may be provided you an RSA key so you don\u0027t get to use any nicer like elliptic curve algorithm also there\u0027s a long-lived secrets you may apply various things to be less paranoid about them maybe you like RPC to some remote thing maybe you stick it in some hardware thing and these things make them more expensive and so can we lower the signature costs so other proposal is you go combine a bunch of concurrent batching signatures into a Merkle tree sign one thing and then that will cover exponentially many clients and that way we can amortize the cost of things so yeah the structure is fairly boring you have you can like either hash a leaf or hash two nodes together and then the signature is a path this is more useful with a picture so if you have say three clients come in at once and you\u0027re signing thread wakes up and you\u0027re like oh okay I need to go make a signature they build a Merkel tree on top of this I\u0027ll talk about what the weird blind or nodes are later sign the signature sign the root and then you ship a path or rather the nodes to the side of the path to each client and this constantly logarithmically many okay it\u0027s not very coherent she slides after all to verify you do the usual Merkel tree verification thing you recompute the rouge hat root hash by hashing the path nodes up so in this picture you would start from input to go hat like compute the hash up there pick the bottom node in the past recompute the next level pick the next node in the path recompute the level after that until you get up to the root and then now hopefully that value matched and you\u0027ll find out because if not the signature in the that you got chipped will not verify yeah that\u0027s fairly boring the draft define so in order to advertise we define some new signature you\u0027ve seen code points which say do the normal signature thing but also this thing and as a result we can now amortize our signature costs while the signing thread or whatever is busy right you\u0027re presumably going to be queuing up inputs next time and wakes up rather than picking up the next input it picks em all up and signs them all at once and at the cost of logarithmically many hashes added to the signature size you can increase your signing capacity by "
  },
  {
    "startTime": "01:52:10",
    "text": "two to the N and so for a few hundred bytes you get a hundred or a thousand or a million x in signing capacity so basically you do not care about your signing throughput anymore at all the TLS implementations need to be modified but yours but you can use the same certificate you can use the same like signing RPC or whatever because the only thing that changes as far as the signing machine is concerned is the input we do require modified peers and so presumably if you have if you have a new deployment you could say just require this and then you don\u0027t care about the legacy case if you have an existing deployment then you can still get some benefits here because the average load will decrease if many peers support it and under load when you\u0027re doing the Austin have to decide which piers to which requests to like throw away you can preferentially serve the basketball ones since they\u0027re much cheaper and I\u0027ve been essentially saying piers and everything because this applies symmetrically on client or server although usually the dose concerns are on the server side some details the domain separation of the inputs is preserved because we don\u0027t throw away the contact string the signature on the root has its own context string so that can\u0027t be mixed up with non batch signatures since presumably your client it\u0027s your your key is going to be servicing both kinds of clients the blinding nodes which may not actually be necessary but since in yes and I the signing the assigning payload is secret and if you look at the tree the first know you would get is the sibling the bottom node in the path would be the sibling it would be the hash of a sibling in your tree then in order to not have to think about it or like well it will just cost you to pay one extra level of the tree to just put some randomness in there and all the other nodes will have randomness merged into it doesn\u0027t actually leak the information what else do we have at some point Unicode pad stuff it\u0027s not a power of two so just copy of them from other nodes of the tree levels and then some information is revealed about signing loads sorry oh yes sorry there are details on this slide they\u0027re not super important and there\u0027s a draft are there questions hey this is cool Merkle trees are always fun come on Omar Eric was crawling little trees got a blanket moment is always cool obviously um can you control contrast\u0027 on this design against issuing jutsu DC with a very fast algorithm for this use case yeah so I think the the main thing is that this will work with like without change like the DC thing you have to go build some infrastructure to go and and like deploy new news new certificate new DC is regularly you need to deal with the DC\u0027s only work if these are only useful if the lifetime is bounded by something relatively short and so that means the verifier needs to have working clocks but yes it\u0027s true "
  },
  {
    "startTime": "01:55:11",
    "text": "that like if you do this since if you if you do DC\u0027s instead than like that will also get you some of the alike offsetting of things because then you can punch some of the protections on the long-lived key that you would otherwise have had I\u0027m German supporter of this I just wanted one I didn\u0027t wanted hear from you you thought this is worthwhile doing if you had DC\u0027s yeah they\u0027re definitely addressing very similar scenarios there are some snares that we\u0027re interested in we\u0027re shipping short-lived starts for weird we like apparently that\u0027s difficult for some reason think all right so we have five minutes left so I\u0027m clipping the line all right Thompson to birthing z\u0027 I think you can avoid the extra full hash for the blinding I think that was discussed briefly on the list but I must yeah we can talk about that later and because this is so clearly orthogonal did you consider minting a different type of certificate verify in order to avoid having to define an entire new axis for the signature schemes I\u0027m not sure I\u0027m following if if you were to signal this is a separate extension and that caused you to generate a different certificate verify message that had all the additional information in it I think it would both be more efficient and yeah I\u0027m sorry easier to manage long term so that it don\u0027t give me an answer right now because I did consider that the main reason was just so that like this this was slightly different constraints on the hash and this way we didn\u0027t have to think about that Daniel con Gilmore I\u0027m supported this work you mentioned that it may leak some information about the server load I don\u0027t think you need to do that the signer can always sign a tree of arbitrary depths and it\u0027s going to be cheap when especially when you\u0027re not under load which is when you need to extend the size of the tree so yeah well good and thank you for including the binding I think it\u0027s you know it\u0027s right to not want to have to think about that rich Souls Akamai yeah I support this stuff you had me it when you\u0027re signing thread falls behind Ben Schwartz if this seems like it could be good for slow post quantum signing is that a is that a consideration so my understanding is a lot of them are batched to begin with but I haven\u0027t looked at it looked at that space too much maybe okay thanks Christianity mom that\u0027s we could walk but it kind of makes me sad and the reason it makes me sad is that it makes the big servers more efficient and thus it reinforces the advantage of the big servers above the small ones and it pushes towards ever more concentration on the market in the internet and that\u0027s what makes me sad and also the big server I guess so yeah if the big servers are also putting everything on one key then yeah you can batch more but I yes I understand economies Law \u0026 Order "
  },
  {
    "startTime": "01:58:13",
    "text": "yes but I mean and and Eric was asking the contrast wisdom in the DC solution and a DC solution as the property of also making it better for small guys which which is an advantage I think I\u0027ve cut the line guys because we have like two minutes to do this and I want to I\u0027ve seen I\u0027ve heard a lot of support for this so this is a good idea because I essentially changes the cost of handshake from owing where n is the conditions 201 and I really like it from a toast activation perspective so at the last hour here we think when indulge hopefully you\u0027ll indulge me and stick around for the last two minutes so we can do these requests there are a number of requests or a number of people study that they were in support of this draft so I would also like to do or can group adoption hums for this draft so two questions yes or no basically well let\u0027s start off without other people interested in working in this draft if you are interested in working in this draft please home now show of hands and people that would be willing to contribute like five six seven hands so let\u0027s do the formal home if you would like to adopt this as a working group item please hum now if you would not like to adopt this as a working group I didn\u0027t please hum now great thanks for take it to list oh yes for the minute taker it was yes I made some tweaks to the CTLs if you just read that real quick and I can send it "
  }
]