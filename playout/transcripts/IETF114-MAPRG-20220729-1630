[
  {
    "startTime": "00:00:18",
    "text": "yes okay everybody welcome to my budgie um welcome to one of the last sessions of the ietf meeting 114 in philadelphia so you're nearly done and this is an easy session so sit back and relax my name is mia coolevent dave do you want to introduce yourself hi folks good afternoon i'm dave blanca i'm remote at my home in madison wisconsin okay so there's still a few people dripping in but we will start as we have a packed agenda so this is an irtf group but this still falls under under most of the node well points one point is intellectual property everything you contribute here it's also converted into the itf and you have to declare intellectual property you might know this already by now hopefully otherwise please read it up then um as you can see or is it hard not hard to miss um this meeting is recorded and will be published on youtube at some point so which is also good if you missed something you can look it up and also in the irtf the privacy policy"
  },
  {
    "startTime": "00:02:03",
    "text": "and the code of conduct apply um usually i think this group is like very friendly and we're very nice to each other and we should generally do that so you're very encouraged to ask questions but always be friendly and be constructive and be positive again this is an irtf session so it's a little bit different than the ietf working session in our case we are mainly inviting researchers with really good papers and contribution which might interest you and provide you the presentations in the slides you find a couple of links that might be useful for you about what this group is about about the agenda about our mailing list please subscribe to the mailing list even so there's not much going on you will see some announcements which might be helpful and then this one you should also kind of know by now but many were telling you if you want to say something at the cube please join the queue and meet echo please also if you don't want to contribute please join me echo because that will also generate our blue sheets and the blue sheets will tell us like how big our room is next time and these kind of things that's really important to sign up when you're in the room you don't need to put on your video and audio you should actually take it off but when you're in the room you are obligated to wear a mask and i think we are currently doing really well in this room so thank you for that for remote participants we use the same queue that's very convenient and if you are not shy and we're happy to to see you on video and have an interactive discussion with you and that's it already from my start as i said we have a very packed agenda so we will start immediately the first talk is is a heads-up talk"
  },
  {
    "startTime": "00:04:01",
    "text": "because it's a little bit kind of out of the focus of this group what this group is usually doing our focus is on measurements of protocols um but we thought it might anyway be interested so we invited tal to give a short 10-minute heads-up of his work and i think he's remote yeah hi webcam hope you can see me in here yeah we can okay do you want to request a slight sharing so you can control them yourself yes i'm miriam just since we didn't go through the whole agenda of the presentations today i think we have seven including this intro and so um people will have the 10 or 15 minutes and then we have a few minutes in between but i want to apologize in advance if we have to cut you off but we're just going to try to keep to that so everyone has their allotted time okay tom the floor is yours okay thanks so my name is thomas rahi and this is joint work with jose luz we're both from the technion and actually this is work in progress but some of our preliminary some of the preliminary results are already available publicly in archive you can see the links at the bottom okay so the conflict in ukraine started in february and we started looking at various measurement data from various sources and we looked at publicly available data from all these different sources and currently we're showing some of the results"
  },
  {
    "startTime": "00:06:00",
    "text": "focusing on the first two months of the conflict so one of the first things we saw was kind of an asymmetric trend around the border between ukraine and russia so what we see here is our speed test results and basically download and upload speeds and on the left side we see ukraine we see uh the download and upload speeds as a function of time and we see that starting from the beginning of the conflict the performance degraded and that's not very surprising but on the right side we see russia so starting from the beginning of the conflict the performance actually improved and it improved more significantly than in previous months so that was kind of surprising so a few words about the reason for that in a couple of minutes another thing we looked at was uh the google google search rate okay so what we see here is the google search rate the rate of google searches uh as a function of time we see it in ukraine on the left side russia on the right side so in ukraine we see that from the beginning of the conflict there was a clear degradation in the web search rate and in russia there's kind of a an increase in the web search rate so if we consider what happened in russia it's slightly connected to something that was observed by the cloudflare ceo matthew prince who said that they were seeing in cloudflare they were seeing a dramatic increase in requests from russia to worldwide media consuming world news"
  },
  {
    "startTime": "00:08:01",
    "text": "not just local news and that's something that can be seen in the google web searches and also on the cloudflare data the rate of traffic from cloudflare to russia so that's one aspect of the performance in russia another aspect is related to what happened at the beginning of march which is the russian government blocked facebook and you and twitter and at the same day they blocked facebook and twitter the rate of youtube traffic also dropped and so obviously we know that youtube traffic a lot of times you get the links from the social networks so once the social networks are blocked some of the youtube consumption also drops also on the same week netflix announced that they were disconnecting their uh russian users and so what we see here is basically a significant decrease in the streaming traffic rate and this can be a possible explanation of why we saw an increase in the performance in the speed test results so we talked about russia but we haven't explained the degradation in the web searches in ukraine and in general the degradation and performance in ukraine and we believe that the main reason for that the refugee crisis so we've all seen these heartbreaking pictures and we know that there was a very very large refugee crisis millions of people crossed the border to the countries around ukraine and millions of other people had to be displaced inside ukraine and there are statistics statistics that"
  },
  {
    "startTime": "00:10:01",
    "text": "are published by the un we can see here a graph showing the number of refugees as a function of time so if we take this graph and we take its first derivative we see the rate of refugees as a function of time so we take that graph of the rate of refugees we see it on the left here and we compare it to the rate of google maps traffic okay this is what we see in the middle the google maps traffic rate and we see that there is a very clear correlation between these two graphs and obviously people had to move around people had to travel to the border so they had to use google maps that's not surprising what we see on the right side the rightmost graph is the mobile to desktop ratio so again people had to travel people had to use their mobile phones so we see a significant difference here in how the basically the usage profile changed over this uh period of time one one of the important things to point out is that in order to help the refugees what the u.n is trying to do is to try to map where refugees are staying so the u.n is kind of trying to keep track of how many refugees are staying in each country and that's obviously that's very important in order to help them and in order to do that what the un does is it collects data from humanitarian organizations from governments and the data from governments is based mainly on border crossing but the problem with that is that when people travel inside the eu um basically that's not monitored in any way so if people cross the border"
  },
  {
    "startTime": "00:12:01",
    "text": "there's no way for the governments to know that so the information published by the un is not necessarily accurate regarding the eu countries so what we're suggesting here and that's what we see on the right side in pink is to use publicly available available measurements from the internet in order to try to estimate how many refugees are staying in each country so in order to do that what we did was look at ukrainian websites so uh for each of these ukrainian websites we looked at data that tells us how many visits or the the visit rate from each country so for example we see here on the right side of the slide we see google.com.ua which is the ukrainian version of google and we see that almost five percent of the visits to this site came from germany so more generally speaking we took uh data on the top 15 ukrainian sites the most popular ukraine ukrainian sites and we use data about the visit rate from each country and we computed a maximum likelihood estimation of how many ukrainian people are staying in each country and that's basically what we see in the graph here at the bottom kind of a histogram showing how many people in each country and what's it basically we believe that this methodology can be used in order to complement some of the data that is already published by the un so it can be kind of another piece to complete the picture so that's in brief uh the work in progress that we're working on some more detailed results will be published soon"
  },
  {
    "startTime": "00:14:01",
    "text": "in the meantime we would be happy for any feedback and obviously we hope that the conflict will be resolved soon so if there are any comments or questions this would be thank you tom we have one question hi max thank you to you um so it's been pretty well known that stalin was shipped like a lot of stalin's worship to ukraine um do you have any statistics on that or do you want to try to incorporate some of that like yeah so yeah starlink was something that probably improved some of the connectivity in ukraine but we don't have any we haven't analyzed any data about that but that's a good point yes um and second question you had statistics on the google searches do you also have statistics on like the the search trends so what was search do you see like a return to normal and what was searched for after a while or is it still mostly conflict related um again another interesting question but we focused on the uh google search traffic crate and we didn't look into the actual content of the searches all right thank you interesting presentation thanks uh hello ian williams with amazon i just had a question one of your slides had some points regarding the redirects from or like visitors from certain countries on like say google uh uh google uh ukraine was you know how many visitors from from from germany i know google has like a no country redirect option if you were in google's shoes would you have recommended say enabling that for this crisis to prevent this kind of disclosure or do you think it would wouldn't have been useful"
  },
  {
    "startTime": "00:16:02",
    "text": "yeah that's an interesting question it's kind of related to privacy and um and actually google.com.ua was just one of the websites we looked at and and like you said it may be affected by redirection um but when people look at news websites for example uh it's not really uh related to any redirections or something like that so i think uh the fact that google may be based on redirections is just uh one one small aspect of this i hope it didn't affect the results too much cool thank you thanks one more question uh kenji china mobile i remember during the the war and after a couple of weeks the starling has installed is like a second pass so have you ever mentioned anything for it like a backup that's going to know the damage but they're going to at least relieve some burden from from the damage the infrastructure through the starting thank you okay so if if i understand the question it was related to how damage and infrastructure damage affected the performance and that's uh something no no the things like i remember after a couple weeks the starlink has been in store over the sky on ukraine and then that is like a backup pass so have you ever measured anything it's like a backup does that like a relief some burden from the management that you have done for those damaging infrastructure thank you on correct on terrestrial network thank you okay so"
  },
  {
    "startTime": "00:18:01",
    "text": "i think it's related to the first question and we haven't gone into specific data that would allow us to analyze that aspect so but it's a good point jack the name is up here jake the queue name is up here so that's easy no okay thank you chao thank you for the quick i'm very interesting next we have jeff do you want to share your slides over everything i do it okay good afternoon all my name is jeff houston i'm with ap nick and with my colleague joao damas who is right in the back row we've been doing a fair deal of work on various forms of measurement and one of the more recent ones we started up which is actually at the start of june is to actually look at the incidence of the use of quick inside the context of http 3 uh next slide uh you know all this don't you next slide uh you know all that don't you next slide standard intro don't eat it the way we do this is trying to actually do extremely large scale measurements equipping the server and using an online ad campaign to enroll almost unwitting clients it's an ad it's a really simple ad if you click on it i pay more so if you see an ad from ap nick just leave it alone okay don't touch it i pay more if you click the ad system that we've configured does around 20 million eyeball based networks"
  },
  {
    "startTime": "00:20:00",
    "text": "eyeball-based users per day and one of the interesting things about ads is that the ad network tries extremely hard to enroll a different set of people every sort of period so we don't go and inflict the same ad on the same set of users and it actually gets around some forms of measurement bias because if you keep on touching the same endpoint you just see that end point you don't see a generic collection so it's the best thing we've found to do a massive sampling of users the downside is the script only does so much and that's not much because the only thing that's running is the injected html5 that you put through in the ad and all it can really do is get a url and do a delay and oddly enough that's enough because what we do is equip the server so if you make sure that every time an ad is impressed on a user they go and do a collection of urls which is a dns lookup followed by a web lookup with a completely unique dns name every time so you're trying to get rid of quite deliberately most forms of proxying and mass other forms of caching which means all that material from the end client ends up hitting our servers and we run a number of them in vms all over the planet this started as an initial measurement around ipv6 deployment simple stuff three urls one dual stack one v4 only one v6 only you're trying to see the number of folk who can get to the v6 only interesting and the number of folk who use v4 to get to a dual stack entry in other words the number of folks who are not for some reason or another doing happy eyeballs"
  },
  {
    "startTime": "00:22:01",
    "text": "and comparing it with the baseline of e4 so you can see how you do control and then experiment bundled up in an ad we've done exactly the same thing for d and sec validation and more recently there's been an ongoing debate in v6 circles about how good or extension headers does fragmentation work does extension headers work hop by hop or destination and despite other claims to the contrary by other measurements the ad system and the predominantly mobile devices that are eyeball networks in today's network go no but that's a different talk what we're looking at here though is to actually see the level of penetration of quick in today's environment inside that eyeball based network does quick actually happen next slide now to do this it's quite easy um we use nginx as our server platform it runs on a number of servers around the planet um 121.7 now has a beta version that actually does quick functions enabled yahoo it all comes we set up dns basically in a wild card configuration that does the https record and we put in an alpn value come back to that later but certainly we're signaling that if you're looking for it you'll find an answer yes for this domain name we support quick additionally in the content header of this delivered one by one pixel we put the alt service directive which of course if you're following what i just said doesn't work because you get an ad it fetches a bunch of urls the ad stops it's a unique name no one should ever ask for that name again so when i put in a content directive saying if you ever come and visit this property again you will use quick won't you you're never going to come"
  },
  {
    "startTime": "00:24:02",
    "text": "so we had to actually alter the ad and in this particular case the ad scripts go fetch this url start a two second timer and then schedule the same fetch again so tell the browser to go refetch to see how much we could tickle by just basically doing that refresh for refetch that doesn't happen all the time in that particular case it happened around a fifth of the time or so the domain name in this case is constant it's not unique for the second fetch because we're trying to trigger it next slide so yeah i just said that next slide so there's a difference in quick whether the browser or whatever the user agent is is triggering by the dns which will happen on the first time you fetch or if it's using the content directive which will only happen on the second time because the first is yeah it's just tcp tls it's http 2 or whatever the second fetch makes a difference so here are two lines for june and july the red line is actually the second fetch and what we're seeing is around 3.5 percent of users actually use quick the second time around the lower down one is the blue line that's around one percent of users use http 3 on the first query next line next slide now you kind of think particularly if you believe apple you're all running the current version of ios and even if you're you're running chrome the nag ware is good enough now you're all running chrome what is it 100 whatever it is and it's actually quite difficult to go no i don't want to upgrade no no no no no and you find yourself typing no all the time so in theory these vendors are doing a pretty good job of getting us all up to the same release levels because the stuff that's out of date you shouldn't be running anyway so when we look at this by country population of"
  },
  {
    "startTime": "00:26:00",
    "text": "quick use next slide what you actually find on the second fetch is a pronounced sort of bias and the country at 26 or something yeah 28 is malta and even the central african republic in africa yay a massive use of quick on the second fetch um i have no idea why and i have no idea why those national variations i just don't know i don't think it's a measurement bias it's the same measurement all the way around but the relative level per country does vary a lot which is odd next slide and now we look at the first fetch now don't forget there's really only one browser that does this and one platform actually i don't know if it's a platform it's certainly safari not even sure you can get safari on linux but if you could maybe it'll do the same thing who knows um but it's safari on ios safari on macos and oddly enough maybe denmark is just in love with apple product but certainly it has the highest rate of first fetch um and this is largely european largely northern european as having the highest rates africa um much much much much much lower so again huge amounts of national variation next slide so i actually had four questions when i looked at this uh and i've sort of given you some hints already who's doing quick and why what are the mss values you know what's the connection failure rate like because putting all of our traffic over udp port 443 is not something we used to do 10 years ago and if you're using cpus or firewalls it's kind of this is crap traffic i'm going to drop it so you know how much is being dropped and last but not least the whole rationale or not the entire rationale but a strong rationale for doing this"
  },
  {
    "startTime": "00:28:02",
    "text": "amongst others was it's meant to be faster is it so next slide let's try and answer each of those who's doing it these are vertical columns don't go sideways normally the android platform is seen in about 84 percent of ads ads see android most of the time ads see mac os about one percent ads see ios iphones about five percent it's the market share of eyeballs as seen by google's ad system fair enough as far as i can see with other stats not too far off some kind of truth when we look at the first fetch almost all of the first fetches come from ios and macos and certainly none from android you know none from the others so strong correlation the platform is apples when you look at the second fetch the first fetchers are still doing it the second time the dns is working it's sticky but now android the second time around goes yep gonna do it as well so that's why the android number rises on the second pitch next slide so which user agent now this is what the browser claims it's running you know there are lies there are more lies and there's the browser string lies uh which are the best lies of all so you know with a strong grain of salt about who's reporting what you know what you actually find again is safari is first fit first fetch and no others um so the 4.1 percent of chrome probably lying who knows in the second fetch what you find is the chrome numbers come in 81 on chrome 16 on safari um firefox which was only ever 0.8 of eyeballs which is pretty low market share and it's declining very very quickly uh first fetch i don't think it's doing anything if it is doing dns it's not clear from this and on the second fetch again"
  },
  {
    "startTime": "00:30:02",
    "text": "point eight percent to one percent of share not clear what's going on next slide so who does it safari does it with the dns https query they may or may not also be sensitive to the content directive but if they're doing the dns query that's the sticky bit that's the bit that triggers it the rest is going to happen anyway but we also looked at the amount of https four times the number of safari clients asked than did you sort of scratch your head and what a little hair is left and go hang on a second if you knew enough to ask and the server goes sure why only one in four goes yeah you know it's kind of if you're going to ask why not follow up the hint um we'll go into that it's an interesting point secondly the alt service this is a low number there's a lot of chrome and if all of chrome says alt service i'm going to do it we're seeing a remarkably small capture rate it is tiny there's something going on there so that's the first question on to the next time is moving um next slide you're right uh the next question was packet size in quick you must must must must never fragment so what's the distribution of packet sizes the standard says in the first packet pad to 1200 and around 45 percent of 1200 the maximum packet size i ever saw was a tiny percentage doing a little bit over 1350 so most of quick sits in that magic thing which is somewhere between 1200 the minimum according to quick and a realistic maximum of 1400 no one's doing path mtu and extending beyond that next slide next question what's the connection loss this amazes me that i'm only seeing half"
  },
  {
    "startTime": "00:32:01",
    "text": "most of the problems we have with b6 and it's a much worse connection failure rate in v6 around two and a half percent is the packet being sent back you give me a sin i give you a synack the filters and firewalls at the front of you go v6 is evil drop the packet and so you actually see quite a visible drop rate and you would have thought or i would have these cpes sometimes were built in the paleolithic era before dinosaurs and you go udp 443 wow that's evil but interestingly if i take one day and look at some 20 million sessions there's the exact numbers there the second packet comes through in all but 46 000 attempts which is a phenomenally low failure rate of 0.24 so whatever's going on whatever reason the first packet hits me and i've no idea if the first packet never got to me because that's a problem on the other sort of direction in i can't tell if i didn't get a packet but when i got one almost always the responder gets my packet and i get the next quick packet coming in so that handshake rate is better than v6 it is amazingly good next slide is it jeff just heads up um you got about three more minutes and that's going into your i am moving so quickly yeah i know time is tight um i use the browser timer browsers not only lie in the browser string browsers line and elapsed time so taking the browser timer i get this pattern next slide um there's a definite bias in the in the measurements to say the timed amount to fetch a quick versus fetching over any other protocol it's faster a lot no but then again there's a huge variation in rtts but on the whole it's faster four how many next slide around about two-thirds of the folk record a faster performance using quick that is significant that is very significant does it work does it make it"
  },
  {
    "startTime": "00:34:00",
    "text": "faster well the browsers are reporting it does on the whole on average next slide so those are the answers i just told you that next slide these numbers are low even cloud player with their radar reports far far far higher numbers 30 next slide why i should be seeing up to ninety percent in chrome well the issue is that two second timer i'm too fast if you've ever tried to do this manually on a chrome browser you actually have to hit the sentinel again and again and again to actually make it flick too quick so it's not deterministic and it takes time so that two second fetch seems to be too fast i have to wait longer for that directive to get sort of sticky inside chrome for the next fetch to trigger so i think i was jumping the gun so that's bad and that's why the numbers are low next slide right why is the safari query rate for https so much higher than the actual fetch rate again what's going on is that i'm not giving hints i'm only telling you use http 3. i'm not saying here's the v4 address and here's the v6 address in the https record so safari has to separately go and fetch that and there's an internal race condition because if it gets an answer for the address records and doesn't get an answer for the https guess what it's going to do speed is more important at that particular point so we're now altering this measurement to actually put the hints into https to see if that will tickle the rest of the apple side to actually go down the quick path from the start i've been talking to apple as well at this point it also seems that not every https answer converts to quick anyway there's a certain amount of seeing how well it goes and i think that reaping rate of query"
  },
  {
    "startTime": "00:36:02",
    "text": "to fetch is actually being throttled somewhat by apple itself secondly why all the countries different i have no idea are there regional defaults other various pieces of browser software variant region by region that's a browser question it's not a jeff question next slide wow that was it i think i'm in under the minutes there dave there is a url down at the bottom i didn't do the qr code this stuff is being run every single day with about 20 million users every single day being enrolled as the picture changes the picture on that web page will necessarily change to reflect current reality and i'm done thank you hello brave browser thanks for this study just wondering do you take into account ad blocking at all and um you know like 35 of the web five years ago using ad blocker um ad blocking is actually an odd activity and this is the world as seen by ads it's not the world and there are certain providers and there's a mobile provider in south korea that does almost 100 ad blocking i get very little visibility oddly enough since march as you saw from the previous talk getting ads into certain parts of the world is now extremely difficult and i see very few ads in those countries yes but of the bits you see it's all the same equipment it's all the same view and does ad blocking buy us these numbers i don't think it biases them per se it's just the view as seen from the ad system ben so i can't see the rest of the control slide so you've got the cube hi ben schwartz um"
  },
  {
    "startTime": "00:38:00",
    "text": "i i had two two notes here one uh are you are you killing the quick connection from the server side before the second uh fetch is initiated that's oddly enough an nginx question we did very little to the beta version of nginx so the quick connection comes in by the look of it the two second delay happens at the instruct the browser not two seconds between subsequent fetches because browsers have more complexity than any operating system that ever got built and so the variance between in time between those two features seems to be an extraordinary amount of variance ben and it actually is a separate piece of work to understand what the true variance is just as a quick out on the way we're going to change this is that we're going to change the ad to fetch the second time wait two seconds a third time wait two seconds a fourth time and do this seven times if chrome is going to flick over at some point in those 14 seconds hopefully it's going to figure out that it can if that's to give you okay so so my feedback would be try something like http connection close the connection close header or otherwise like from the server side close that http 2 connection as soon as you've sent the response because what you want is for the client to be initiating a new socket to see should i use http 3. if the client already has an open http 2 socket to the server it might just reuse it instead of going through the delay and and complexity of opening up a new http 3 session but if if you can wipe all of your if you can close all of your connections then from scratch it's more likely to start http 3. ben that's extraordinarily helpful thank you very much we will do that this afternoon the other thing i would say is for for the https ip hints um in general ip"
  },
  {
    "startTime": "00:40:02",
    "text": "hints are only necessary if your target name is not dot so uh we can talk about that in more detail but i would i would encourage you to set your target name in the https record to dot the magic default value which means i'm not doing anything interesting in terms of redirection here uh that makes the iphone relevant again no should thank you very much we will do that any others no that's it thank you for joining us your summer yep just come up um you can request slide sharing do you want to do that yep now you should get it now you should select this like you still need to select this light try it again there you go all right so uh i'm sam i'm a phd candidate brown university uh is it better all right so yeah everyone in the room knows that web performance is important and better performance leads to better revenue and better use engagement in order to do that uh websites typically use cdns which have servers spread across the globe typically called cdn edge at the cdn edge we have protocols like http and tcp that controls the rules for request and response and rules for data transmission now an operator is required to select from among a different configuration"
  },
  {
    "startTime": "00:42:01",
    "text": "option available so for example they may have multiple constituent controls and they need to select one of those similarly initial condition windows and a lot of other tcp and http options uh now traditionally the operator selects one set of configuration that are then used homogeneously for the entire user base uh the goal here is to maximize performance uh but in this work we asked this question that uh is this approach really optimal so if you're using a single set of configurations for possibly diverse users you have to go even closer to the mic uh is this one take it off if you want okay is this one-size-fits-all approach really optimal so in practice users are not really homogeneous because they come from different regions uh they have different last-minute connections like 2g 3g 4g and they have different devices and the reason uh this makes it a challenge to select right configuration is that uh protocol performance is sensitive to all these features so assuming that we have different network paths with different delay different loss and different bandwidth properties uh the choice of optimal congestion control might be different so a consequence of this observation is that uh the one-size-fits-all approach might not be optimal when we're talking about heterogeneous connections so the goal of this work is to how to dynamically tune the networking stack so that we can maximize performance for diverse connections but before we i start talking about system uh let's go over some of the measurements that we did so we started with the review of what are the three traditional approaches that that are currently being used uh the first one is default where operators do not apply any explicit turning and they simply use the configuration that are set by default in either kernel or in servers the second is hand-picked where"
  },
  {
    "startTime": "00:44:00",
    "text": "operators run out multiple uh measurements from in different regions and based on that they see that okay these configurations are working better so we we're going to select those and the third one uh we see some evidence in literature that people are building dynamic systems where they use algorithms like business optimization or reinforcement learning to tune their configuration but they are mostly limited to either a single configuration like initialization window or a single layer like tcp so in order to test that uh we leveraged some public packet traces and we got a we got a network trace from a production cdn with billions of users across the world and we used that traces to simulate a representative network condition in a local testbed so what we did was for each of the network uh we sweep the entire configuration space so basically from the server side we set every possible configuration for tcp and http configurations and we measured page load time for alexa top on it website so once this entire sweep was complete we created an oracle that has like complete knowledge of the configuration network space and can always select the best configuration so in this figure here you see the improvement in page load time on the x-axis and we see that for the hand pick configuration there is some improvement uh but it's mostly capped by twenty percent at tail because uh hand pick configuration though being manually selected uh they're still static and they stay the same across diverse connections uh for this orange line for the tcpcc we used oracle to uh tune a single configuration which is the condition control so basically based on the type of network uh we selected the config congestion control that maximizes actually minimizes that pace load time so we see that at a tail uh improvement there's a better improvement but around the medium is still the same in the third case uh the green line uh"
  },
  {
    "startTime": "00:46:00",
    "text": "we use bayesian optimization which is a algorithm for auto tuning uh systems uh and interestingly uh the improvement uh results are not that good uh because we noticed that uh this algorithm is not really a good fit for network internet measurement case where we have lots of dynamicity we have lots of noises and it sort of derails the optimization process and finally we see the uh results for the oracle which tunes uh across the different layers and we see uh we make team observation here first uh at the tail we see up to 70 and more improvement which sort of motivates that dynamic tuning opens uh an opportunity here where we can uh optimize the page layout times second uh the gap between the orange and the red line basically motivates that we we should use uh crosslayer tuning instead of tuning just a single uh configuration like congestion control and finally the the gap between the red and the our green line uh shows us that uh the existing algorithm for autotuning are not that a good fit uh for this case so we need we need a better algorithm so basically uh to achieve these goals we built a system called confignator which optimizes the performance by systematically reconfiguring the networking stack so confignator takes into input features like website properties our user's network or the connections network and the device and it tries to find a near optimal configuration in a minimal number of such steps so that web performance can be improved so we faced a number of challenges in the design of confignator uh since we are talking about internet um into environments and cdn scale uh there's a cure associated here"
  },
  {
    "startTime": "00:48:00",
    "text": "uh if it's just a bad configuration then it's going to hurt performance and possibly revenue and further there's high dimensionality of devices and last mile connection there's network dynamics uh because network changes over time and there's noise uh so these sort of properties makes it hard to create a performance model that can accurately represent uh the performance of the configuration so that we can select the right one and finally we have some system limitations that uh we don't have the networking stacks available right now that can tune the configurations in a low overhead manner so we can use things like set socket rpt but it means that we are going we need will need to uh change application code itself and we want it to be non-invasive so basically there's two set of uh challenges some could be solved to algorithmic design and others could be solved through system design so in order to solve these challenges we use a split pin architecture for config confignator there's a central uh control plane called config manager uh which which runs in a data event manner it sort of ingests data from uh all the servers in the edge and it builds performance models through which it can know that which configuration should be used for a certain type of network and then there's a data blend component called config agent which is basically a piece of code that runs on every edge server so for uh tuning the configurations we wrote a kernel module and several callbacks through which we can tune tcp and http configurations and since this config agent is on the fast path uh it uh it caches uh configuration uh mappings that the control pin generates and it use that for real-time configuration decisions at the control point side uh it's it it's uh the workflow looks something like this so config agent with that runs on servers uh sends data about a connection feature such as network uh and performance metrics like page load and these disinformation"
  },
  {
    "startTime": "00:54:48",
    "text": "so and also the other percentage is non-zero i'm kind of confused seems at some moment like 20 of the time you get worse yes you get worse uh result what's the reason so uh we're talking about an online online search algorithm case here so definitely we're going to run into cases where while we are searching for new configuration uh if you have no context about what our network uh what works better for a network we are going to definitely run into a case where we we might be testing some configuration that have an adverse impact on the performance but the property of the algorithm that we developed was that that should be minimum so the search should be directed uh so that's why uh there is a negative impact here but we the algorithm tries to keep it to a minimum so in the paper we have experiments where we sort of try out different versions of of the algorithm and show that this is sort of the minimum that we can get right now and we have been in the remote queue hi ben schwartz uh sorry i missed a bunch of this presentation due to the the glitch but i wanted to ask if you've"
  },
  {
    "startTime": "00:56:01",
    "text": "thought about the game theoretic questions here how much of this uh how much of this gain is somebody else's loss you know is this uh is this a competition so that's a great question so in the in the paper we talked about we talked about fairness uh but we haven't actively looked into the game theory aspect yet so currently uh we are working on some future work where we are trying to uh present this problem as as you said game two between two uh two players and we are trying to see if we can find a good nash equilibrium there because like let's say in the future case 10 10 or 15 years from now if everyone is sort of running these sort of systems then they're kind of competing against each other uh because if the choice of my competition changes then my choice is also bound to change uh so yeah we don't really address the game theory uh aspect in this paper yet but we are currently looking into it more in the future work thank you uh i would say that you know i think that nash equilibrium has a name it's the ietf yeah so thanks for having you here thank you thanks and next we have marcos you request sharing yourself yeah there you go okay hi i'm marcus and together with my co-authors we investigated uh how we can use tls to fingerprint servers and find similarities among these server deployments to use it for further use cases all right um"
  },
  {
    "startTime": "00:58:00",
    "text": "[Music] it cannot it's not working try requesting again try requesting again no i didn't see it all okay then you just have to tell me when you go to the yeah i'll do yes uh so very short introduction to tls as you probably all know everyone is using it it's probably the effective standard of all the encrypted communication on the internet and it's also already quite old so this means it has been grown to a very complex ecosystem which means now that in the initial handshake the clients and servers they need to exchange a lot about a lot of information about their own capabilities such that you can find a mutual encryption base and the idea of this work was now we can collect this metadata and we can use it to fingerprint a tls stack on the server like tls stack as a combination between config implementation hardware so next slide please all right so if i'm talking about fingerprinting what does it mean it's basically just collecting characteristics about tls that you summary represent as a fingerprint and then you build a database that maps these fingerprints to something that is just not directly related but somehow useful and for example you could have see these three fingerprints here maybe one in indicates an idf web server another fingerprint might indicate an nginx docker image or even a malicious commanding control server of course these are all just indicators but they work so next slide please all right so let's have a short look at the tls 1.3 handshake and what"
  },
  {
    "startTime": "01:00:01",
    "text": "information is there that we can use for fingerprinting so as you can see like the tls works by for that a client sends a server hello to a server that initiates the handshake it contains the version session specific information cypher suits and a whole bunch of tls extensions now the server looks at it and responds with a server hello that again contains a version a cypher suit and tls extensions that are usually a response to the versions from the client and then now tls 1.3 specific the handshake gets encrypted you get these encrypted extensions certificate extensions and so on and now all this information that is written in bold somehow depends on the tls stack that is on the server so if we collect this information we can use it to fingerprint the server right continue please all right why should you need such a thing so there were three applications we thought about how this could be used uh first of all an intrusion detection system could use such a fingerprinting mechanism to just gain an additional source of information for example you could fingerprint all the servers in network flows and then just look up the fingerprints in a database of known malicious fingerprints or you could use it in intel white measurements where you really use these fingerprinting fingerprints to actively hunt for new threats or you could use it to monitor your own servers right now uh basically if the fingerprints change from your own server something happened uh this might be intended or unintended you might intend to change your software or there has even been a melbourne infection happening and somehow changing the dtls deck right next slide please all right so before i get into some results let me share a small problem we had in the beginning it was that we did this fingerprinting with some default client hellos from the library it just didn't work so it was actually because we didn't collect enough information from the server due to this question answer design of"
  },
  {
    "startTime": "01:02:00",
    "text": "tls that is intended to hide information but as you can see this is an example so um in the client hello just looking at the cypher suits in a client hello this line sends a whole bunch of cypher suits it could be hundreds of cypher suits to the server the server looks at this list and selects a single cypher suit and from this example you can see why tls fingerprinting is already quite common for clients because the client reviews a lot of information about it so the server does not so that's not a lot of information and this led us came to the conclusion that well we should not use default client hellos we need some how unusual client hellos that really trigger new behaviors from the server and we need to send multiple client hellos to the server that somehow complement each other so we learn even more and like a third point was like if we now send multiple client hellos and we want to have a scalable approach we need to somehow find a trade-off between the the amount of data we want to learn about the server and this costs of the whole fingerprinting like costs meaning the time it takes and also the impact we have on the server because we probably do not want to perform an unintentional dos attack if you take too many requests all right this led us to these three research questions so first of all how can we relate now similar deployments how can we improve the effectiveness effectiveness of our client hellos and what's not the informants of use cases so let's have a look at the first research question basically relate these servers by well fingerprinting but in a way that we extract all these handshake features from the tls handshake in a way that similar deployments have the same fingerprint and base code we did we just extracted all this information put it together in one big string so this you can see this is our format but it's of course kind of arbitrary you can see it contains the version cipher extensions and also the"
  },
  {
    "startTime": "01:04:00",
    "text": "tls alerts which are error codes in from the tls protocol because error handling is of course also implementation specific and as we send multiple requests to server well we just combined all these representations in one big fingerprint all right then let's have a look at the second research question how can we prove now the effectiveness well we did this basically had this challenge that we do not know every implementation so how should we know what's the ideal combination of client hellos we should send but what we can definitely do we can somehow optimize the effectiveness of our client hellos and we did this by doing this empirically by basically just first of all measuring effectiveness which is the metric we use the distinct number of fingerprints we were able to collect from the servers as a metric then perform the measurement with a whole bunch of randomly generated client hellos and then we just pick the combination of client hellos that maximize this metric and this way we generated 10 like scanning client hellos we used in the following analysis all right so let's have a look at the the last point does this work now um therefore we've designed a smooth study that with weekly measurements where we scan these two top lists and two block lists uh over 30 weeks we were able to collect around 100 million fingerprints so quite a lot of amount of data we can test our approach on and now the first use case we had a look at the next slide piece were cdn servers as a content delivery network servers because they were really great for us to test our approach on because well cdns are basically a single actor deploying a large amount of tls servers which is exactly what we want to be able to detect but they also provide us with a lot larger amount of data and okay but their service could also be verified"
  },
  {
    "startTime": "01:06:01",
    "text": "through other means as well so we can generate a ground truth through for example the a s or certificates they return and that's what we did we evaluated this cdn detection with this ground rule and if you're not so familiar with classification metrics so we used precision and recall so precision is basically the number of correct classifications we did and recall how many of these ct answers from the ground truth we are now able to detect so let's have a look at the results so here can you see this uh precision and recall for the four cdn's we had a look at as you can see it results for akamai alibaba cloudflare and fastly you can see that the uh like the metrics are quite high for all of them so this detection works interesting at least for us was for cloudflare and fastly it was astonishingly high so the precision was above 99 which means their gls configurations are very unique among in the internet and they're quite easy to to we were able to detect them quite easily and what's also interesting for us at least was that with this method we were able to detect also quite a lot of often at cdn servers sometimes in even unexpected places so for example for cloudflare we saw some servers but there were actually reverse proxies a third party has set up that somehow proxied all the traffic we sent to cloudflare you know why they did this but yeah we saw this all right so and uh second use case we had a look at the command control servers so where we now really are able to fingerprint or detect even potentially malicious servers to make this more realistic we just had a look at new additions to the tool list and because this uh classification wasn't that obvious anymore uh we now"
  },
  {
    "startTime": "01:08:00",
    "text": "considered like how often we saw a fingerprint from top list versus from block list to kind of generate a score how certain we are we now found a commander control server and if this score was above a certain threshold we just classified it as a cnc server all right so let's have a look at the results you can see uh now the precision recoil again for this detection just on the x-axis is now the threshold above which we classified this see the server as cnc server and you can see three different sources of input data we used so on the left you see just the t dls fingerprints we've designed and which actually works quite fine already so the precision is okay let's say the recall isn't that high especially for the higher thresholds we had a look at how to improve this and we noticed some like noticed some strange hdb server headers but they weren't really good enough to detect these servers uh but if we combine this combine both data sources uh this uh detection now worked quite well so in this case we were now able to like detect almost half of all the new additions to these block lists with the precision over 99 this is quite good and that's also how we expect people will use such a fingerprinting mechanism just as in conjunction with additional indicators all right let's let me conclude our work so in this paper we proposed a selection of handshake features and the encoding as fingerprints as a mechanism to relate tls servers we also provide a metal methodology to find new client hellos for scanning or just provide always some 10 general purpose clienteles we've made a study to really demonstrate the potential of this fingerprinting and maybe you've heard of it there's also this tool called yarn out"
  },
  {
    "startTime": "01:10:01",
    "text": "there it's also able to fingerprint tls servers it was announced one around one and a half years ago by salesforce or every showed in the paper that our mechanism of fingerprinting is actually a bit more effective and we've open sourced all our data and code if you want to try it yourself thank you sorry thanks a lot thanks a lot for coming here basically for this presentation specifically because you're very spontaneous came here and joined us i hope you had a good week yeah that's great uh we have dave in the queue marcus uh that's really interesting um i wanted to ask you for a comment on you had a slide up where you showed four cdn's and the varying precision and recall on them i maybe i missed it but how were you determining the ground truth about which cdn they were on and the reason i'm asking is what did you do with content that was multi-cdn like did that come up did you did you see content that you wanted to validate but the that content providers using multiple cdns yep we didn't investigate the multi-cdn case but how we evaluate it was basically we um we send a request to this server for example for cloudflare if you could return us to certificate for cloudflare.com and if they were able there definitely were a cloudflare server okay um any further questions then check out the chat as well there were a little bit of discussion and like also any further questions can go to the mailing list of course and we go to the next presentation um"
  },
  {
    "startTime": "01:12:01",
    "text": "that's constantine right yes i hope you can hear me we can hear you should be able to select your slides well somehow i'm not okay then can you request it again yes let's try it again no i can do it let me see where it is okay i think you can see it now right we can see you we can see the slides we can hear you we are ready to go okay so thank you for all inviting me i'm constantine i'm a phd student at rwh university in germany and i'm going to present you the results of our paper in which you took a look at the influence of resource prioritization on actual hedge of line blocking and the performance when using this with hp3 and this is joint work with ike and klaus but before getting actually into the results let me give you a short introduction i guess most of you already know that but just let me quickly repeat this so we want to load a website and for maximum performance you would like to load of course all of the resources in parallel so you would like to load the html but you would also like to load already the resources that you discovered so for example the two images the red and the blue one and with hdb1 you then just open multiple tcp connections to load these resources in parallel however this of course came with the the overheads of opening multiple tcp connections and because of that with http 2 it was introduced to use just a single tcp connection where you then multiplex the different resources in in streams and stream frames over this one tcp connection however the issue is that tcp is completely unaware of the streams so it just sees a opaque byte stream and"
  },
  {
    "startTime": "01:14:01",
    "text": "this can lead to transparent head of line blocking so let's say that for example for the blue image now one of the segments the tcp segments is lost which is just carrying the blue we saw this information and basically we could use the other information for the red and the green resources but tcp doesn't know this and just now waits for the re-transmission of its last segment so we have to wait for run round trip time and the browser does not get further information in that time with hbe3 instead quick is used and quick has multiple streams implemented on the transport layer these streams are now independent so we don't have any interest stream head of line blocking anymore so for example we now have again the case where the blue resource information is lost during the transmission however quick knows that this is only in influencing the blue resource stream here and the red and the the green information can still be forwarded to the browser however for this to work of course multiple streams have to be active and we can also get to the case where only one of the streams is active and in this case we get the same the same case that again now this this one stream is waiting for the retransmission and because basically only this one stream is active the whole connection is waiting for the retransmission and how this data is now scheduled uh with quick so which stream is actually sent in which stream frames is actually sent on the wire basically depends on the server so how the server depends uh decides how to send it and how the quick stack then decides however there's one thing this is resource prioritization which basically allows the browser to sequence the server a preferred scheduling so this can be used for example to say hey send me the html first i need to discover all the other resources first and then send me the images and this allows the browser to have different prioritization strategies and there are strategies used for example with internet explorer or the default for hdb2 which was a round robin then there's rated rod robin it has been used by safari then there's an approach by chrome which uses a sequential scheduling but they reorder"
  },
  {
    "startTime": "01:16:02",
    "text": "that important resources are sent earlier than unimportant resources and there's firefox which used with hb2 a mixture of rated round robin and sequential scheduling and because this deal depends on because this influences how data is sent this of course also influences the performance there has been some related work on that and basically this regulated work found out that for hp2 and also for hdb3 the round-robin and great round-dropping approaches are actually worst while the chrome and the firefox approach is actually the best or the better one why better because in that specific work also website specific prioritization strategies have been discussed and they found that if you have website specific knowledge for example one image is very important you get even better resource prioritization results in that regard however what we can also see here is that this sequential scheduling from chrome showed best results here although it would be worse for head of blind blocking because we would then monopolize this connection as we've seen in the example before so basically we would say okay this problem is now solved we just know there is no no influence however take this with a grain of salt because this related work on the one hand only looked at http 2 so no hdb3 no no head of line blocking free streams and the other work looked at a at a quick stack at a time where a quick boss rather that stack was rather premature and they disabled the congestion control and just sent at a constant rate and tried to avoid any loss so loss hasn't really been looked at in the related work in this regard and our idea was then to look at the the impact of prioritization on the actual head of hdb3 performance under loss and for this we then use different scenarios where we change the laws the last person the rtt and the bandwidth and then also tested different prioritization strategies and we did this to identify the head of line blocking and the performance and for this we downloaded 35 websites we replayed those websites in a test bed"
  },
  {
    "startTime": "01:18:01",
    "text": "and then measured the speed index and the head of line blocking uh so how many bytes were actually blocked during re-transmission and then tried this and then measured basically the speed index let me just skip the the testbed uh implementation in the interest of time and let's get directly to the results and for the results what we will see is always the relative median difference to chrome and we use chrome as our sequential baseline and what we can see for the head of line blocking is that for very low um that for very low bandwidth we see an improvement in head of line blocking so basically the head of line blocking is reduced but we're using a parallel strategy in comparison to chrome sequential scheduling but we can see that the differences are vanishing when we're using higher bandwidths so we can see that this this curve is always moving more to the right up to the point where um we even get a lot of overlap for example with the sequential baseline and actually those cases where we have this overlap so from in the cdf from 0.5 to 7 and 0.75 on the y-axis that's actually points where the whole website fitted into slow start because the website was very small and basically we could transmit everything of that without having any loss so that's also one point that we have to look at and for the speed index we can see in a comparable results where we see that for lower bandwidths we can see even some improvements in speed index when using parallelism on the median case so the curve is slightly moved to the left however these benefits are also vanishing with higher bandwidths this is actually due to the same case on the one hand we have fewer laws but on the other hand we have a higher bandwidth so more of our resources can be transmitted in that time and we also have a higher congestion window with higher bandwidths and that leads to the fact that sometimes the resources are just smaller than our congestion window so even when we're using sequential scheduling still multiple streams have been active because just the resources ended and the next stream could start"
  },
  {
    "startTime": "01:20:00",
    "text": "so this is the the influence of the bandwidth on its own however this is of course um introducing congestion loss so let's also have a look at at random loss and for this we looked at the two megabits per second case and then just added via net in artificial loss from zero to five percent and what we can see is that again for higher loss so where uh more packets are lost we can see that the head of line blocking is reduced which is actually as expected and this is due to the fact that loss is stopping many of the active streams for sequential scheduling while for round robin we have a lot of active streams and only a few of those are actually affected and for the speed index we can see a comparable effect it's very subtle so i added this black s-curve here but we can see that there's a growing benefit for higher loss however this benefit is is really subtle so we can see that on the left side a lot of the the data points in the red circle are below our s curve and on the right side we can see that a lot of the data points are above this so it's not as strongly as for the head of line blocking and we were wondering why this is actually the case so we then looked into the data a little closer and we found that different websites behave differently when using this and because of this we then looked into the correlation between loss and the speed index and here we can see the correlation for the speed index and head of line blocking and basically a red means that there has been a correlation which was negative so we could see that the head of line blocking has been reduced but the speed index got worse while blue means that we had a positive correlation so the speed index was also improving when the head of line blocking was improving and here we can see for example for wikipedia.org that we can see only not very strong positive correlations or even red patches so negative correlations while for newyorktimes.com we see very strong positive correlations and the interesting difference between wikipedia.org and newyorktimes.com in our data set is basically that these are two different extrema for the website size so wikipedia.org is our smallest"
  },
  {
    "startTime": "01:22:01",
    "text": "biggest website we can see that when we are looking on the left for the smaller website we can see a lot of red patches one for the right side for the bigger websites we see a lot of blue patches so very strong positive correlations and we could see that the negative effect for this matter is for the smaller websites were occurring because we could see that the head of line blocking has been reduced but only slightly because basically there hasn't been a lot of data in in on the wire in that case or in flight and in that case where we don't have a huge improvement ahead of line blocking we could see the negative effect of the parallel prioritization that also related worksaw while for the larger website we saw that the head of line blocking reduced more strongly and then the negative effect was outraged i would also like to go into the details for other loss patterns and also what the impact of the round trip time is however i cannot go into detail here but i can just tell you that the loss pattern is very important because when you have bursts around robin is again really well bad because you are then affecting a lot of the streams and for the round-trip time you can tell you that higher rtts increase the round trip time or the retransmission penalty and so in smaller rtt cases the effects are not as pronounced as we could see it here okay so time to conclude we saw that reduced head of line blocking via quick is possible however for that multiple streams need to be active in parallel and hp http prioritization influences how many streams are active and the the easy way would would be to say just use round robin however related work said round robin is detrimental for performance and we found that there is a new performance interplay between prioritization in the network ron robin can improve head of line blocking and can thus also improve performance however mainly in cases for large websites smaller bandwidths higher rtt scenarios or where rendering loss was was seen and we could also see that the new extensive prioritization scheme that has been um i think it has been a draft i'm not sure"
  },
  {
    "startTime": "01:24:00",
    "text": "if it's standardized now for http 3 um it's this new scheme we haven't seen a big difference between using the old scheme or this scheme here so all in all we can say http 3 prioritization is still website dependent which related workforce but it's now also network dependent thank you thanks for spending your friday night with us let's see if we have any questions okay but like um you can check out the chat if there are any for questions and people can put them in a chat or contact you directly read your paper send emails thank you and move on nick you're up next yeah please unmute nick and turn on your video if you like and in the best case you also request slide sharing which is the second button at the top from the left next to the hand button okay you're requesting keep screen sharing but that's okay as well i guess but you also have to enable your audio i don't think we can hear yet"
  },
  {
    "startTime": "01:26:01",
    "text": "at the top there is this kind of microphone sign you have to click as well because we can't hear yet you can ask text me in the chat window if that doesn't work for you and then we come back later to you let's do that miriah uh i i also wrote to nick asking him if his pre-flight test worked but i i'd suggest he'd rejoin and do the pre-flight test to show that your mic is working and then we should be able to go in minutes yeah please rejoin or maybe try a different browser okay we go to the next presentation that's phong are you round phone perfect oh so the next two presentations are both about um dns encryption so they should fit very well together and great to have you here from um yeah okay we try the other slides that's probably easier now you should be able to select your slides okay okay i uh so i hope everyone can uh see my slide uh just give me one second okay nick we can't see your video now but we're taking fong's presentation first you have to wait a little bit"
  },
  {
    "startTime": "01:28:00",
    "text": "longer oh okay sure no problem yeah but we can hear you and see you that's great so we take phone first anyway because you're all set we can see you we can hear you we have your your slides so you can go ahead uh i mean uh okay so uh just let me hear that i have a little problem here so okay uh hello everyone my name is bong and i'm a boston researcher at the university of chicago and today we'll be presenting our work on measuring the accessibility of domain name encryptions and its impact on internet censorship and so regardless of the expansions of https traffic plaintext domain names are the last piece of unencrypted information that is still lightly visible onto the internet so where is domain name information exposed and the slide here shows you the common places where domain name information can be monitored by any network level observer for example your internet service provider or your network administrator so this other network packet that i capture when visiting istanbul.com and the first place that you see here is uh through the next query and respond and after getting packed back the ip address of example.com the client initiated the 2s handshake to port 443 and the second place here you can see is in the server name indications where you can see sample.com domain name and the exposures of the domain name information in these two channels have led to many security and privacy problems and most network connections susceptible to domain name based uh internet filtering and so domain name uh to to address those problems many domain name encryption technologies have been introduced in in recent years including dns over tos dns over https and encrypted sni which some of"
  },
  {
    "startTime": "01:30:00",
    "text": "you know uh here that they being reported to encrypted client hello as but still being developed as an internet draft and so in the new setting the users and the dns resolver first established an encrypted channel which could be over hdbs or tos and after that the next querying responses are sent over this channel and during the dsm checks unlike in previous gms versions since version 1.3 the server name indications extension can also be encrypted and this new proposal to prevent any unpacked observer from seeing the plaintext domain name information and so you know this is clear that domain name encryption can help improving the security and privacy for internet users but it's also take away the visibility into plaintext domain name from the network traffic and so that has motivated us to investigate how domain encryptions impact internet censorship more specifically we want to know whether any sensor out there are taking a ha a step ahead to plot domain name encryption technologies and if domain encryption is not blocked which means it's accessible then can it help to circumvent traditional internet censorship technology like dns poisoning and so to that end we measured the accessibility of domain and encryption by building this system called dni based on a network of distributed vpn vantage point recruited by the vpn gay project give us the capability to conduct measurements in 85 countries around the world and we first what we do here is we take the input from many other censorship measurement platforms including uni icelab and"
  },
  {
    "startTime": "01:32:01",
    "text": "sensorplanet to see what domain that this platform has been discovered to be censored and then and also we input 71 dot and doh resolver um to this infrastructure to to conduct measurements what we do is we first do dns measurement by sending out dns uh queries for these domain names to see if you know any of them get blocked or not and then uh later on we do dns resolutions over to eh and https to see if we can properly get back to the answers that we were anticipated and finally we do while doing all this we we capture the network packet to later on uh analyze and see how in which way that sensors out there are blocking these new technologies so here is what we found from the measurement conducted by this system we could conclude that censorship based on plaintext domain names is still widespread and as dns tampering has been you know detected in many countries so here the top five countries china russia iran indonesia and india but we didn't observe any dns based locking of the domain name of major dlt lds resolver like we have dns.google or we have dns last cloudflare.com those are popular dlt us resolver but we didn't see any tambourines dns tampering when resolving those only one case in china that we found that the great fireworks timber with the resolutions of uh the of this domain name which belongs to uh hurricane electric and so um we then conducted the accessibility test for 71 dlt and uf servers by sending"
  },
  {
    "startTime": "01:34:02",
    "text": "encrypted dns queries to them from all of the vantage point we have and to better highlight the findings we compute the data of the top five not three countries when i say top five not free this classification is not done by myself that the top five not three countries classified by the freedom house um and and that they have the largest number of fellow resolutions and uh namely china russia iran saudi arabia and venezuela and it's visible on this plot that from march 2021 there's a decrease driven mostly by the blocking effort of china against dot and u.s resolution and so here i go more into detail to show you how they actually go and pluck it so this is the packet capture when i was trying to do a resolution using dns over 2s what you're seeing here is because this dns over 2s is standardized report 853 and this port is not used by any other properly popular applications and so blocking the ip and port a53 is trivial and sufficient enough to to hinder the use of dns over 2s and that's how china is documented and so this slide uh show us how they they block the uh um what you're seeing here is i i try to use the uh service of google resolver and what what have uh finished here is that i could finish the the the dns lookup for the ip address of dns.google.com right but then as soon as i i start the tcp stream to do the dns over to s uh over https um then it's blocked so the thing is the ip address of popular"
  },
  {
    "startTime": "01:36:00",
    "text": "the us resolver are widely known and therefore dropping traffic based on just the resolver ip and port 443 pairs is enough to block penis over https too although you know among our community we say if we do dns over https because it's run on port 403 then it's just a more collateral damage but just think of like what else like what other service that may run on 8.8.8.8 right so it's just obvious and so um another blocking that we observed what's in saudi arabia which is against cloudflare resolver and we observe this to be a centralized effort because we we observe the same blocking signatures in multiple asses in this country so whatever the domain name and with cloudflare.dns.com as soon as we start the ts handset we complete it we send a client hello they detect it in the client hello then there's uh they inject the reset packet to another connection and so for um the case of russia we see uh a decentralized blocking efforts against encrypted sni which means that we we don't see it everywhere in russia there and here in the countries uh that we see some efforts of blocking this uh protocol based on the two biosignatures of encrypted sni uh basically this blocking mechanism is similar with the way great firework china has been blocking it since i guess october or september of 2020 and so with that we we move on to to answer the final questions that we ask is like if all of these technologies is accessible it's not blocked or somehow we get it to work then can it help to circumvent"
  },
  {
    "startTime": "01:38:01",
    "text": "traditional censorship uh mechanisms and so we use encrypted dns when crawling sensor website and so this encrypted dns in some country i say oh china block it russia i block it iran's locker so the way we do is like we we have our old uh dns over https server running on a non-standard port and we thought that none of the country that flopped so they don't do any like fingerprinting on the traffic they just use the ip and port to block it so the takeaway here is that if we run out of dns over https server we don't get blocked and we use that to visit the website that were found censored earlier and so the finding is that a lot of them in country like russia indonesia and india you can actually defeat censorship just by using this technology but then in china and iran we couldn't um to set uh we couldn't do it successfully because a lot of this uh website they don't support encrypted sni and so you could bypass dns censorship but then at the ts handshake you still expose the domain name information and because china and brand they also have filtering at that layer so we couldn't bypass it and so the key men take away from from this 30 is that domain encryptions can help to partially circumvent internet censorship based on plaintext domain name based on plaintext dns resolutions however notorious uh sensors has taken step ahead you know to to prevent the deployment of domain name encryptions by blocking dot the us servers as well as encrypted sniper connections and to address this problem new domain name encryption protocol should be designed and deployed in a way that you know"
  },
  {
    "startTime": "01:40:00",
    "text": "plugging that traffic is not an option without causing huge amounts of collateral damage and snipes blocking is still possible as encrypted sni has not been widely adopted and uh when i say an encrypted sni now it should be encrypted client hello uh and and to tackle this problem we should really deploy this technology at a larger scale um you know and possibly like universally to discard a sensor from blanket blocking and with that i'm happy to take any questions that you you may have thanks a lot interesting results um very good for this audience let's see if there are any questions we have some time dave yeah thanks vong this is interesting um just following on to some comments in the in thread was um i think a reasonable follow-up question would be do you know of any work that tries to classify the types of censorship for instance so that you would know if the if the censorship was trying to block malware or sexually explicit content as opposed to say a political motivation uh so i um so in in the case that we found here is like most of the domain that we found to be blocked actually a lot of them are political uh motivated uh blocking rather than malware because uh this 30 is based on the block list that used by the citizen lab which is a mostly politically motivated blocked website for somewhere to send people if they were interested in classification there so that block list and maybe does only have anything that is about classifying the censorship types um it's not in this study but if you interested in uh classifications uh i"
  },
  {
    "startTime": "01:42:02",
    "text": "have a work on just the great firewall of china where i break down that they block 300 thousands website and what are the portions of that belong to business belong to pornography belong to malware or melissa's website i'm going to put the name of that it's called gfws.org that's the website you can go and see the breakdown of you know websites being blocked specifically in china thanks so much thanks patrick hello thank you for this um pat mcmanus i'm with fastly at the moment um i really like your takeaways thank you one sort of nuance i want to point out is that um you're focused mostly on the censorship case and even in these cases where there's blocking and censorship is indeed applied you still preserve the property of confidentiality of what people are looking up rather than having to say what your destination was going to be um with an encrypted dns you just can't ask that question right what's being blocked is your connection to a well-known resolver and that is a strictly better situation than you were in before of someone looking at the plain text and throwing that away so even in these situations we have like ratcheted the problem forward at least from confidentiality point of view um i guess my second note is you are making sort of a call here to back encrypted client hello and i just want to say i'm actually bullish on that i think that's going to work out the distinction you draw here of uh the old esn i and the migration to group decline hello i think all you're seeing there are those gears turning a little slowly but i don't think it's really ever exception in the marketplace so cool thank you for this thank you for the comments and uh i i totally agree on that um so these protocols are like uh i think they are of course they're not gonna go like"
  },
  {
    "startTime": "01:44:00",
    "text": "be employ and address all of the problems out there of course they will introduce new problems that we may face too with until you know how how we're gonna do the packet inspection how we do gonna do uh you know malware detections and and all of that uh but i believe these technologies are very important for our online privacy and in the long run um just like i believe like 10 years or even 15 years ago when people talking about uh moving from http to 100 https a lot of people was very like uh susceptible about that but then now you see like more than 90 percent of the web is like over https and uh just similar to that i i believe there will be a day that encrypted client hello will be deployed universally and hopefully it will help to address some of the the problem about civilian censorship thank you um yeah then we finally go on to nick you can try to join us again how about now yes we can hear you we can see you all right we're we're getting somewhere so actually it's easier if you if you don't do screen share but only slideshare because we uploaded your slide so if you oh okay uh the paper sign right next to screen share okay yeah it's open system preferences okay no yes stop that process just um hit the paper sign oh here okay in the hand and the screen share sign not a thick all right or i can't oh he wants to quit firefox"
  },
  {
    "startTime": "01:46:02",
    "text": "and reopen this no no wait wait i do it stay late uh later okay yeah let's use your slides i've i've got slides here but let's just do it your way no i selected the wrong side there's this great software called zoom that actually works um let's see uh fantastically well i can see myself behind you in the room that's kind of cool i don't know if we're gonna get slides i could go back to brave i could try that again uh no give me one second sorry this is my photo okay because they should be here we'll get there i'll just talk fast um this is let me just see if i can uh yeah did you upload them already or did you convert them already you can also do that okay yeah there's so many solutions here yeah so there it is yikes oh man okay hey look at that amazing okay um hi everyone great uh i'm going to talk a little bit and thanks to miria and dave for the invite uh to the group it's great to see a lot of familiar and friendly faces i'm going to talk about some work we've been doing to measure the availability and response times of some of the public encrypted dns resolvers"
  },
  {
    "startTime": "01:48:00",
    "text": "i think as this group probably knows very well i'm not going to spend any time on the background of encrypted dns or dns over https um as this group probably also knows pretty well uh there are some so-called mainstream resolvers i'll define what i mean by that in just a minute but um what we were interested in in sort of looking at in this work is if you go to like dns qrik proxy there's a whole bunch of other dns do dot resolvers etc that are listed on that page as you can use these and so we we wondered about that we wondered well can you actually use them and if you go to link there and there's there's a draft paper linked off of that page that's fresh you can see the full list i've i'll put some examples up in just a minute but the the the gist of this uh work is to try to really figure out how many public encrypted dns resolvers are out there that you can you can actually use that aren't some of the some of the usual suspects and credit to rania sharma who did a lot of this measurement work uh rania is actually did this work as a high school student um and she will be an undergrad a first-year undergrad at university of chicago in in the fall so hopefully we'll have a encrypted dns expert four years from now who's ready to go out into the world um so um part of this you can you can see i think from from the page as there's a is an open source tool for measuring encrypted dns performance uh that we used uh to perform these measurements you can you can find it from that page i linked um that's an ongoing and active development actually as we consider as we continue"
  },
  {
    "startTime": "01:50:00",
    "text": "uh work in this uh space um you know dig uh et cetera have added dough and dot support and so we'll we're going to be redoing a bunch of these measurements with uh with dig but some of what we've released includes not only doe lookup time measurements but also web response time measurements so using the tool that we developed um we've measured those response times using a very large list of resolvers including the mainstream resolvers which i'll show some comparisons of as well as what we call non-mainstream resolvers and then we study how the performance of these resolvers differ based on vantage point because you can imagine uh some of the some of the usual suspects they're highly replicated but some of the others that are further down on the list you know they may be deployed in a particular country or continent and so if you're going to measure that performance you probably want to measure it uh from you know from the uh nearby as well as not nearby so we did we we did our measurements from a vantage point in north america europe and and asia um we um continue to expand on this work i'll talk about that in the in the conclusion uh because we only did it from these three vantage points and it was a one-time shot but we're extending that first let me sort of talk about the context so modern browsers provide a few choices for encrypted dns resolvers uh we define those as mainstream so you can see the choices here this by the way is as of a couple months ago it's constantly changing so if you see a mistake please let me know so um the performance of these is is of course of interest in the the draft paper that i linked does"
  },
  {
    "startTime": "01:52:00",
    "text": "you know provide measurements on all those and we do comparisons against those we were also interested in like all these other doe resolvers that are supposedly running are they actually running and can you use them and so forth um so uh so yeah so we measured a bunch of different things one was availability which doe resolvers are active and responding to queries uh we also wanted to measure the round trip latency to each resolver i should say um because we want to measure our look up times against uh against i guess in the context of what that round trip latency is and then finally of course what's the query response time uh the experiment setup uh we had three global vantage points as i mentioned here they are uh this particular study we did queries to google and netflix and this is not a full list of the resolvers that we queried for that i couldn't fit them all on the slide but for that you can look at the at the paper but there are um uh i think 80 or 100 some odd uh resolvers that we did query so you can see some this is just the top of the list so you can see some usual suspects in here and you can see some perhaps less familiar faces um first thing we looked at was you know are these non-mainstream resolvers available and uh turns out that you know a lot of them uh you know we saw a fairly high failure rate as you can see uh here in a lot of cases we were not able to uh to even connect uh to the um to the resolver in some cases we were able to connect but we got like an http error code status i mean other cases we uh you know had ssl tls errors or other errors in http um so you can see basically about a you know 78 success rate um"
  },
  {
    "startTime": "01:54:01",
    "text": "which is um well let's leave it at that um good um okay so here um here what we do and i hope this is this is large enough uh for you to see but um here what we do is we look at how the mainstream resolvers perform and i'm going to walk through this uh kind of one one box plot by one box plot so these are uh box and whisker plots if you're familiar with those we're looking at distributions and um and you can see going down the list here we've got uh resolvers okay um these are sorted by median response median uh dns response time uh oh yep sort of my median dns response time uh and and uh oops and this is this is dough okay um so um for each resolver you can see the red in the red or the top of the group it's it's a grouped box and whisker you can see the ping time so that's just like icmp ping and again that's um that's a distribution so you can see a green line for each of those that shows like what's the the median ping time and you can see some of these are pretty close right if you're in north america as you sort of move uh as you sort of get to less replicated services uh or resolvers you can see some of them moving a little bit a little bit further away um bolded are what you know what we would call what we define as mainstream resolvers those are the ones that are that i showed on the previous slide and those are uh you know offered in as options in your browser um and so"
  },
  {
    "startTime": "01:56:01",
    "text": "things to pay attention to here are um you know uh the molded ones and then we've basically got three of these one per vantage point so if you want to just kind of focus on the main takeaways you could sort of start by looking at north america this is by the way um this is from i'm showing one of these the paper has has it does this three different times so you see north america local we're measuring north of this group here our north american doe resolvers um as measured from north america and we put the mainstream dough resolvers on all three because we assume they're replicated in all three places but like dracoplan9ns2.com that's sitting somewhere in north america whereas public dns iij.jp that's in japan so that's why you see that on the asia plot so a is north america to north america local b is north america to asia so that's why you see higher uh higher uh ping response times here you can see these are clearly geo-replicated um and then here we've got north america to europe okay so um a bunch of things you can take away here um certain and then as i mentioned just to repeat these are sorted by median dns encrypted dns response time so the better performing ones according to that median are or towards the top so as expected you would see those mainstream resolvers sort of closer to the top there are some surprises i think like you know for example uh or dns that he does so hurricane electric apparently runs a pretty decent um encrypted dns resolver that is replicated and also performs pretty well even though it's not a browser option um and then some of these others you know they may be reasonable options depending on"
  },
  {
    "startTime": "01:58:00",
    "text": "where you happen to be sitting in the world one of the things that we didn't do in this study i noticed i'm coming up on time that we are in the process of doing is also doing page load times this is just this is just doe response time if you presumably also care about web page loads but um i i think you know um this is pretty interesting for a number of reasons i think we expect the the the mainstream resolvers to perform pretty well but another thing that i think the ietf is considering a lot is consolidation right and um for the healthy you know for a healthy dough ecosystem it is good to have many organizations that operate uh dough resolvers that we can use uh that perform well and i think there's there's good news and there's news here um i don't know if you know i don't know if there's bad news but there's certainly information here about other resolvers that that others can use in other places to to invest um this is i think my final plot and then i'll kind of come to conclusions but that was a little trick you know that was a little bit of an eye chart and so one of the things that we've also been uh sort of looking at is um you know how do these resolvers perform with respect to to network round trip time right because that's that's the fair comparison in in some sense from like wherever we happen to be sitting where is that resolver right and then you would expect it like hopefully you know at least on your initial look up you've got a couple round trip times to set up your your tcp connection in your tls connection but then hopefully you're not adding too much latency on top of that and you can kind of see how that is if you look at sort of how's it going in north america asia and europe and you can in each point here each blue point is a doe resolver and so so i don't know what's good things should not be probably below the line so but um but you can see here that you know um how"
  },
  {
    "startTime": "02:00:00",
    "text": "we're doing as far as um you know the existence of of performant though resolvers around the world so this is all in the paper that's linked their slides are also linked from that page um so in conclusion you know i think the non-mainstream resolvers have a higher median response time than the mainstream ones uh typically speaking the mainstream ones appear to be replicated um however a local non-mainstream resolver you know sometimes actually exhibits equivalent performance as compared to some of the mainstream ones hurricane electric uh in north america and in general um all dns in europe and there's there's one in greece also that actually seems to perform pretty well even though it wasn't uh globally replicated so i think this presents some some interesting early findings some opportunities as i mentioned there's a bunch of uh ways that they're following up on these measurements and i look forward to the feedback of the map rg and again thank you so much to dave and miriam for the invite and the privilege of speaking to the group and really welcoming the feedback thank you thanks nick snick um we don't really have time for um questions anymore but yeah um and i also don't see anyone in the queue but you know how to reach nick there's this chat there's mailing this there is probably here's a website that has a link that slides to the paper and you can reach me from there too cool nick i posted that link in the chat too for people sweet yeah okay that means we're at the end of the session we're at the end of the ietf meeting i just want to say one more thing this time we only got a very few contributions and we were very lucky that we reached out to some people and they said but then it's less yes to present here and so we had a nice program um but we're depending on contributions so like let people know about this group um if anybody's doing measurements please come to us and tell us about it that's very helpful dave those of you are traveling happy travels"
  },
  {
    "startTime": "02:02:00",
    "text": "home and we will see you in the fall if not before thank you bye is guys so last minute"
  }
]
