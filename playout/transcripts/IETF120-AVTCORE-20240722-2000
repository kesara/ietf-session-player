[
  {
    "startTime": "00:00:05",
    "text": "You don't have to be experienced. It's a good way to get to know the area better, focusing on it And we have to have an update We'll wait a minute or two, but we do a fairly full agenda All right, anybody else like to we do need a volunteer to take notes. So if you have a left need a volunteer to take notes. So if you have a laptop, you just have to click on the link in the Medico, which reminds me also, if you are here in the room and you have not yet signed into the media please do so because that's how we use both do the blue show and do the cues now. So you can either use the QR code that's up on the screen or you can use the link in the online agenda If you are hearing me and you're remote, you already figured this out. Presumably And then once you are in that, there is a convenient link to the note-taking tool, which is the other thing I have people to do to please somebody volunteer to take notes and that we don't need necessarily blow-by-blow of everything, just high points and the important thing is the high points and the action items actually know everyone's names now, which is nice to have to sit in new faces Maybe some of these people would like to volunteer take notes"
  },
  {
    "startTime": "00:02:05",
    "text": "for somebody else people Anyway, let's do the business first and then we'll get to them Hopefully somebody will decide to volunteer So I guess, Bernard, next slide Okay, meeting ticks, as I mentioned, make sure to sign into the session using the media code to get there from the agenda or from the QR code. Use that to join the mic queue if you want to say some something. And if you're using the full version, please keep audio and video off for your both, you know, both pick and playback. Remote participants, obviously you'll want playback, but keep your own video off unless you're presenting or talk or talking otherwise And if you're remote, use of a headset is recommended, especially being the in-room acoustics for these things can sometimes be not the greatest, especially for me here in the front because I'm behind the microphones. So I take my mask off so I'm better in the other direction All right, so yeah, so if you are in the tool, you use the hand to the hand icon to get enter the queue. If you're remote and you want to speak you have to enable your audio. You can also enable your video, which is you useful but not required but you have to enable audio separately. They're two separate targets Okay, next Here are some links. Obviously, you can't click on them here, but you can click on them as you go to the material page and find this. Okay, next About this meeting, you're a link to the agenda, we have a link to the notes. Bernard and I are the chairs. I'm going to keep an eye on the chat, which is the Zula And as mentioned, we need a note taker and ideally a backup note taker. So please, somebody,"
  },
  {
    "startTime": "00:04:02",
    "text": "volunteer. We won't need a note taker I mean, if you want to do, if Yes, the people, oh, so Ronnie has said yes? Okay, okay, you're doing it in the online tool? Okay, Ronnie will do it in the online tool, but it'll be probably good if somebody can just keep an eye on what he does, so catch anything that he overlooks. Just have a bad war if you back up All right, so note well, various policies are in effect here at the IETF by participating you agree to follow them There's patent rolls, there's you agree to be in, you're being recorded this will be up in YouTube we have a privacy statement. A few of these have more detail comments later on Next one, participant obligations If you're doing a presentation, you must say if there's IPR related to your draft, we're commenting, you must disclose that IPR your employer controls, and there are saying available as you violate this. So A, consult with your lawyer and B, if you're commenting on something and have IPR, please say so Or bet these could happen. Also, we are under a code of conduct so please treat everyone with the condition decency, and respect. If you feel that has been any harassment or any other troubles, please talk to the ambits team All right, so we've got a number of documents Some were published. I think this is a little bit not just since the last meeting that's a little bit longer queue but you know, makes it look better Our RFC editor two is looking better than it did. Skip is an off 48 which is very nice because that took a while. Others, I think R or really should be an edit. I think two of them might be marked as ref incorrectly, so I'm going to talk to the RFC editor about that I'm pretty sure the only ref was frameworking But I will double check with the RFC editor to make sure. Next"
  },
  {
    "startTime": "00:06:02",
    "text": "We've adopted a number of drafts. I think most of these are on the agenda today and so I won't say more about them right now We have an ongoing call for adoption for Newport and region of interest dependent delivery I've only gotten, I think, two responses about that so far. So if you feel like this would be a good thing to do, please do comment to the list so that we can know that there's a sufficient community of interest interested in this work work yeah okay i think that's all all right um gethub set up we've recently created a GitHub repository We've added three drafts to it so far There's two more that could be added if the authors want Also, as I was saying, for things that are almost that are, you know, not yet adopted as working group items, but likely to be, I'm perfectly willing to have those in our organization as well so just talk to me and we'll just figure out what name to give it and you can import There's them a weekly script that updates, that sends emails to the mailing list with changes that have been. That's just to add that, that's just a repository of Mark Donningham's, where there's a good JSON file list of repositories to send, and where I send email to them so either i can do that or you wouldn't do a little bit request against him yourself if you want. But when we do that, we should when we add a repo we should also add that to that script so we make sure the mailings knows everything that's going on Next. All right, here's our agenda um as i said it's fairly full so if anybody has any comments or changes that they would like to make let us know. Otherwise, we will proceed with Magnus and closing the media types of agenda register with Magnus and closing the media type version, Magnus. Hello, yes. So this draft was just adopted and I have submitted a"
  },
  {
    "startTime": "00:08:02",
    "text": "the 0-0 version. It actually made a few, if you a few small changes, they were really minor, just to try to improve some sentences There is no open issues with the draft itself. I have one we get some earlier view on the next slide but basically I think based on this is only the digital things, etc. Unless someone has something, I think we could actually start working with block some earlier review on the next slide, but basically I think based on this is only the administrative things, et cetera, unless someone has something, I think we could actually start to work on the last call after this discussion. You have the link here to the GitHub repo for issues and PRs if you have anything so but we can go to the next slide So Ianna did a review and early review of this draft. They were asking about noted at draft Avity Core, RTP, Y2K, SCL had, is defining a payload form a media type, and included a payload media format types registry regulations So the question they were having is really, oh, if this is approved first, would we need to wait, etc cetera? I assume that we are on a hopefully on a timeline with this document that we'll go quite quickly and that we can adjust the working group documents coming out to this document if they should have it or not, depending on if they are ready or not before, if they go basically to AD before this document or not. So I think we can adopt that and adjust that so. And based on the actual publication, remove ready registrations if it's I should say, too late. So include up to the date this is approved before that that, just leave it, leave them in and after it's been approved, you can just remove it from the documents in the process"
  },
  {
    "startTime": "00:10:02",
    "text": "So that would be my suggestion suggestion um as individual i tend to agree um yeah i think probably just remove this from J2K, remove that registration from J2G as following recommendations of Magnus's draft for future and then we don't have to worry about it And so that this would not be a change to your draft. This would be a change to the other draft, right, Magnus? yes or I think it's mostly quest is saying let's just follow what comes naturally. If you actually have a draft in the lake, which is ongoing publication, yeah you should probably register until this process change has taken effect. But as soon as it takes effect, we can remove it naturally. If you actually have a draft in the late, which is ongoing publication, yeah, you should probably register until this process change has taken effect. But as soon as it takes effect, we can remove this registration request from ongoing documents I mean, I think we don't even necessarily need to wait until you actually get through publication as long as we are pretty convinced it's going to happen Yeah. Can people hear me? Lorenzo was saying my mic is low. Yeah, it's been bit low. I agree. Is this better? Yes okay good sorry about that Bernard? Yeah, I was going to suggest are there any objections to bringing this to working less grouping? less call? Otherwise, we should just put it in the notes and we can start it soon Okay, good. I see no objections. So that's what I do. So please take notes that we're going to go to work on the last long it in the notes and we can start it soon. Okay, good. I see no objection, so that's what I do. So please take notes that we're going to go to work on the last call. Okay. And also, we're at the end, of the session, we have the discussion of the J2K and I put a note in there to remove the registration Sounds good All right have the discussion of the j2k and i put a note in there to remove the registration okay then i think we're done here excellent That's good So next, I guess, Mattis, you are up for this great Next slide, please"
  },
  {
    "startTime": "00:12:02",
    "text": "Last time at the interim we discussed a pull request that we had before that interim that added some buffering for when you read a pull request that we had before that interim that added some buffering for when you receive RTP packets that have a flow ID that you have no knowledge of because you didn't do signaling before or something or waiting for its signaling still going on and we got some feedback on that and now we did two follow up, you know, one follow up pull request which adds a few more details to that and removes signaling dependencies that we had in there because the previous PR said that something must be signaled or must be negotiated out of band which is not true because you can also steadily configure stuff or maybe your endpoint is able to figure out what's the payload in that unknown flow ID even just by looking at the content without having the signaling first So we made a follow-up pull request and the details are on the next slide so yeah as I said, receivers might be able to identify what's in that stream. So it may not have to wait for signaling of that flow ID so it can just continue without knowing it and doesn't have to buffer anything. We add it again that endpoints also may close the connection using unknown flow ID which was the way to handle this before we did it and doesn't have to doff or anything. We added again that endpoints also may close the connection using unknown flow ID, which was the way to handle this before we did the change. So this is back now, back there No, the only difference is that endpoints don't have to close the connection, but they are allowed to if they want to For example, if there's no signal, only difference is that endpoints don't have to close the connection but they are allowed to if they want to for example if there's no no signaling going on or anything or the endpoint can just handle unknown flow IDs If the receiver is dependent on the signaling, and, yeah, signaling is used then we edit the sentence that should or that that says signaling should be completed before RTP packets are exchanged so that the situation that you have a flow ID that you don't know of doesn't happen but that's not always possible so we still edit or still kept the addition that we added last time that says that endpoints may buffer some amount"
  },
  {
    "startTime": "00:14:02",
    "text": "but have to limit this amount. And then it's an implementation decision to decide which parts to drop and if datagrams are dropped they can just be dropped, but for streams you can stop sending For the corresponding streams, that the endpoint decided to drop after some point time Yeah, then there's one new issue that we got I think three days ago from bernard which is about RTCP bandwidth limits that we don't say anything about in the draft yet The issue basically says that we don't have any consideration about this, but for example, retransmissions could occur if you use streams to send RTCP And that would change the ratio of how much bandwidth you are using for RTCP and I think that's also true for a few other things that are sent by Creek that are like the additional quick headers that are in there because I think are FC 3550 talks about how to calculate intervals for sending RTCP based on the amount of bandwidth that we want to use for RTCP and it includes IP headers and YouTube headers, but for quick we of course are on top of UDP so we still have these but we also have quick headers in there and other things like knowledgements and so on which could be included there too and we would like to hear what's the working group opinion under this if our draft should say something about it and what that should be joining the queue to speak as an individual I think, you know, you have, all you obviously, all you control is the input to your transport, not what your transport does underneath you So I think maybe you say, obviously, the, your arts be fractured you know, fraction of what you send to matthew quick layer is an appropriate fraction of what you send to matthew quick layer for RTP. I think that's all you can do. You might also want to say something then about what the relative priorities should be of RTP versus RTCP, because that's obviously also going to it"
  },
  {
    "startTime": "00:16:02",
    "text": "impact this if you don't have enough bandwidth. But maybe that's a different issue, but probably worth speaking about. Yeah, I think that's a good point that the transport is after you pass it to the transport, you don't have much control over what's happening Priorities, I think, depends a little bit on what your quick stack offers you in terms of how to control priority Yeah I mean, obviously you can only do what your stack does, but I have general recommendations Yeah I guess two things here, one on that priority is I've seen differences between quick implementation Some of them give priority today to grade some of them don't. So there's some differences there. But I guess one of my questions was, how useful do we think it is to try? transport RTCP over streams to begin with? You know, is this just a situation? where datagrams is simpler and if you have priority it'll just probably be the easiest way to do it or is there a legitimate reason to transport RTCP over a quick quickstream? So I think generally I would suggest to prefer datagrams over streams, but in cases where you can't use datagrams because the extension is not available or you want to send larger RTCP packets for whatever reason, then you might want to use streams And in that case, I would suggest to cancel the streams or like reset the stream when like early so that you don't have retransmissions because instead of retransmitting that RTCP packet, you probably want to send a new one instead of retransmitting it or having it retransomited by a quick quickstack Yeah, I think that makes sense. It might be useful to add some text to that effect. Yeah, that sounds good good So I'm Jahed as individual. I was just thinking like, is this something that we can retire entirely? say like well if you are using"
  },
  {
    "startTime": "00:18:02",
    "text": "RTPA work quick, you don't care about the artistic bandwidth limit I think you still care about the RTCP bandwidth, but you may not have as much control over what matthew quick step is. That's the problem That's where I think like if you don't have control especially for the stream case and all this thing so can't we just not try to have control? and say like okay this is something that not really is full. You send you, you, you prerequisite send whatever report you produce and then you put it on next to quick stack and the transmission is over there because this will completely depending on like whether it was a data gram and stream and then if in this first version like in this current effort we would like to dwell and discuss all the potential possibilities this that's a huge discussion so i was thinking like maybe we can have a easy way out not to care about this artistic bandwidth, just to focus like what are the information you would like to share trust me yeah i think that makes sense also because we try not to like change the worlds of how to calculate RTCP bandwidth and so on, or when to send RTCP, so not caring about that may be a good idea but I think I would also add what we said just before that you probably prefer to send RTCP over streams and then cancel this streams or send diagrams in the first place Thanks Yes, you have to be careful, especially if you consider that you might have missed boxes and have different legs that are interconnected to RTCP. Because you're going to have up with the situation the question of, do you have? all your timers it's based on the band that you configures on how often you can send etc and how often you time out those aspects need to be considered. So unless you ensure that you have"
  },
  {
    "startTime": "00:20:02",
    "text": "correctly configured minimal, minimal, this you configure on how often you can send, etc. and how often you time out, those aspects need to be considered. So unless you ensure that you have correctly configured minimal distance, et cetera, especially for regular non-early traffic, that you would otherwise send much more of if you could just increase the boundary So I think you will have to be careful here on how you configure your RTP profile. If you do this, just in with an AVP profile and doesn't, you would just increase your bandwidth usage You just then are regular RTCPA more often too So the retransmission would increase the bandwidth usage or what do you mean? No, yes by the regular R2C descending rules for an R2 the P stack would try to, if you tell it you have more bandwidth, it will try to use the bandit according to its rule for how often it would send regular unless you're as long as you don't have the minimal it's it depends if you're have the minimal or or if you reach the minimal interval etc so that's where you have some concerns i mean RTCP is built on that you don't have feedback about R2CB Artisip traffic going through. And this here you actually know about your artisip packet if to be been delivered etc because quick could actually tell you if an artisip packet has been delivered in all those things. But that's on R2P scheduling level, this is not knowledge it has It's also you need to remember the fact that you can, might have multiple holes and that packet will be forwarded to the next top and so that's why you can of in a multi-hop situation assume common boundaries limits and things like that and common parameters So I think you will have to think through a bit how you write this up so that okay is it a strict point to point? Do you really know that? And yes, it's only the early traffic in AVPF, for example, etc. You should know increase frequency Or you're saying you should try to have, okay, what's your target and config?"
  },
  {
    "startTime": "00:22:02",
    "text": "that for both end points. Otherwise, you will have interest in interactions here here I think, thanks for Magnus point again, I think thanks, Magnus pointing on that out. I mean, now I'm putting my Adi hat on I mean, one of the things that I would also like to understand like this is also also for Magnus pointing and that out. I mean, now I'm putting my Eddie hat on. I mean, one of the things that I would also like to understand, like this is what I've also triggered my previous individual comment was like, okay, when you are talking about RTP work week, are we talking about the whole RTP topology? or are we talking about only point to point with no media? Because if this is about, whole RTP topologies, a terminology, we use are we talking about only point to point with no media because if this is about whole RTP topologies a terminology we would like to cover with R2P work quick this would need much, much work than what we have in here. We have done lots of assumptions here and those are not valid for the end of topology that we have right now in RTP have done lots of assumptions here, and those are not valid for the end to our topology that we have right now in Art. So that would be something that also will, I would like the chairs also to keep in mind going the discussion forward, like, what is the scope of the use? on our Q? Yeah, so right now it's not clear to me we have the section earlier in the draft that talks about topologies and it basically excludes all the multicaster apologies because quick is end to end, but I think you could still have middle boxes and some parts of that use ROQ and some parts of that use ROQ and some parts of stone so it's hard to exclude all of it we have like me to think about how exactly or what exactly needs to be. Yeah, that's true. That's one that's when the R2B that's interesting yeah It's not that complicated for point to point, but it's, for multicast topology is where it gets interesting Yeah. I'm not multi-point, you know complicated all right thank you the input. I think we will try to come up with the PR and share that on the list or in the next end of ring Then we have some update on implementation status and end up tests We have two implementations in the"
  },
  {
    "startTime": "00:24:02",
    "text": "draft that are listed since the last update in our new implementation status section, which is the one from BBC, which is a couple of G stream elements implementing transport over quick and our Q. And my implementation, which is in Go, we have another implementation, which is a bit outdated, which I wrote in as a proof of concept some years ago, but this one is the current one that implements the recent draft. And then there's a third one from Lorenzo from Meetecho that we tested at the hackathon If there are other implementations, I don't know of any yet, but if there are then please let us know so we could also include them in the draft and also in interrupt tests Next slide, please We're currently doing manual interop tests between the different implementations We came up with these test cases. I think there could be more, but this is I think a good start. We tried in both directions, of course, client server and server to client, like sending media and then RTCP and both directions. We tried to send datagrams we tried to send RTP packets as a single RTP packet over one screen we try to send RTP packets over multiple RTP packets over the same stream And then something we want to try in the future is of course multiple flows and also multiplexing of RTP and RTCP, but the last two are not done in the tests that we did yet And on the next slide, I have a list of matrix of what works so far. So, of course, I think that all the implementations cover all these six test cases, which are the three that I mentioned in both directions just now within themselves So like my server to my client and BBC server to client and Lorenzo's server to client. I have a question mark here in bbc because i didn't confirm with sam but from what i saw from him, from his implementation, that is all supported. And I think he sent an update to me earlier this morning which I think also included the other two test cases that I did mention on the earlier slide with multiple flows and RTP RTCP, then we"
  },
  {
    "startTime": "00:26:02",
    "text": "did tests between Lorenzo's and my implementation during the hackathon and had some success. The Asterisk here mentioned that there were some quick interop issues between matthew quick stack he was using and matthew quick stack I'm using, so I think the issues that we had were not actually inter-up issues between RTP over quick because we like some parts of it were but then we had a problem with after key update in matthew quick stacks and then it broke So I think the problem is actually the lower layer there once we figured that out I think it should work as expected And then we also tried to start doing an interrupt test between BBC and my implementation in the last weeks, but we had some trouble setting that up properly, so I didn't include that here But I think we're going to make more progress on that in the next coming week All right. Then SDP and I think I'm going to hand over for Spencer to Spencer for this Yeah I'm just doing a quick update on Rock and SDP for Rock Let's set someone up to the queue Let me pause Sorry, about that. This is not regarding the work you have done, just your try to ask, have you ever saw something Because there are some work going with using ROQ to transmit, include the streams And then later, I just checked the UDP option part. That means almost there. So there's some proposal to put some sensible information in the UDP option field based on that IETF draft, not going to publish With ROQ, seems to me that field is not being protected by matthew quick. So have you ever saw something to do something with that? So yeah. So, so just ask some opinion it's not like challenging this one yeah i i i know what work with you"
  },
  {
    "startTime": "00:28:02",
    "text": "options and that you can put things in there to mark packets Here it will be protected, of course, because it's quick And I have not tried or done any work on it Okay, sure, thank you As I said, I'm Spencer and just provide a quick update on Rock and STP for Rock We got excellent feedback at the interim. Thank you all for that and spread over the Rock and STP ROC sessions at that at the interim. I've been through the minutes comparing them to you YouTube and we've gotten more excellent feedback from Sam Hurst and GitHub. Sam is the implementer for the other implementation that's listed in the draft right now and my focus has been on the scene between Rock and SDP Rock, there are two issues in once in rock and one is in SDP Rock. And that's what I know right now And we are getting we are getting people who are helping And that is certainly welcome We're not through and that's certainly true also Next slide, please So our next steps for ROC are continue interrupt testing and prepare for working group last call on this specification and for SDP over ROC, continue specification work. The goal is to have a relatively complete dash 00 by zero by the next AVT Corps interim that we could discuss there at Border Tail Sounds good to me. Is there a cue? Nobody is lining up to talk. And make you coming up for the next session? Okay So Magnus is not getting in line for questions and I will"
  },
  {
    "startTime": "00:30:03",
    "text": "sit down and two minutes early yeah we look forward to seeing you your doctor All right, I have another draft related to our queue which is about Q log event definitions for our Q. Next slide, please For those who don't know Q log, it's a structured logging for for network protocols that's developed in matthew quick working group It provides an extensible structure for logging of network protocols and it allows for easy sharing of the data independent of the serialization format. There are three drafts about that in matthew quick working group. The main one is matthew quick log main schema, which defines the key concepts like formats of the logging files, events and extension points and then some generic event schemas for used by additional specifications for specific protocols And the schema itself is independent of the series serialization format, so you could use CSV or something that's popular as I think JSON sequences. So you have JSON separated by a sequence marker a record marker Then there are two additional drafts which define concrete events for project One is for matthew quick protocol itself and another one for HGD3. Next slide, and similar to the one for HTTP 3, I now wrote a draft for events for QLog, for ROG This includes five events and each of these events has a few metadata that we can include there. So the first one is ROCSP stream opened, which means that a stream has been opened with the flow ID and a stream ID And these two values are included in the event And then the stream can be used for multiple RTP packets. That's why we have this event for stream opened. Then we have two events for stream packet created and stream packet parsed, which are one RTP over quick packet was put into"
  },
  {
    "startTime": "00:32:02",
    "text": "that stream, or one packet was read by the receiver And these events include a rock package which we will see on the next slide and a stream ID which is the stream ID of matthew quick stream underneath and then there are two events for datagrams which are the same but the don't have a stream ID because datagrams don't have a stream ID then the rock packet which we saw earlier for the datagram and stream packet created and past events includes the flow ID of the work flow and the length of the packet for that datagrams, that's clear from the datagram, but for stream that's part of what is being sent over that stream because of the rock format uses that length field and then there's over that stream because the rock format uses that Lange's field in front of. And then there's the type 4 rock application error which can be used in the over that stream because the rock format uses that Lange's field in front of. And then there's the type 4 rock application error which can be used in matthew quick Q log events for, for example for stream reset or so on or connection closed. And these are just the error codes that are also defined for RTP over quick next slide there are currently two issues One is to consider adding useful RTP or RTP header fields, which might be useful in debugging because that's currently not included We could either add specific fields from RTP or RTCP to the events, or we could a field that has raw info, which means that we put a byte string in there that has some privacy implications so, but it could be truncated for example to just include the header i'm not sure what's the best there, so I'm looking for input, maybe from implement or others who are interested in this. What would be useful for debugging to include from the RTP? header or RTCP header. I excluded that in the beginning because I thought maybe this should be a document called QLog event definitions for RTP but I think maybe too much effort to write QLog definitions for all the protocol and just easier to include it here But for that I would like to keep it to a minimum with what's used And then the second issue that I haven't"
  },
  {
    "startTime": "00:34:02",
    "text": "opened yet, but for which I will open a PR later is that we have to update to a new extencibility scheme, which was a introduced in the last Q-Loc version, I think, two or three weeks ago. Next slide, please so next steps These events that I present here are implemented in my work implementation I did some into up tests with tooling at the back hackathon with tooling from lucas pardue from Cloudware who was able to parse and read these Q-Locks that I produced with the implementation We didn't do any analyzing yet, but at least he was able to parse it And then, yeah, I'm looking for feedback from the working group if the working group is interested in this and then if yes, if we should have a call for adoption of this In the absence of anybody else saying anything, I think, if the people who are actually building rock stacks think this is useful to them and they agree on the formats, I mean, if it's useful to one implement I would not be so enthusiastic to implement if it's useful to multiple or all implementers, I would say yes. Let's go ahead and do it. So if you can get Lorenzo or Sam to say yes this works for me then I would just go ahead. I would say, let's do it All right. Bernard yeah I mean it Q log is really really helpful for debugging things and understanding what's going on with Quick. So I think it probably would be pretty useful to have this just for the interop testing and understanding what's going on Go ahead so I'm thinking like, okay, I mean, this is the same kind of question like how useful this is, and I mean, is this a"
  },
  {
    "startTime": "00:36:02",
    "text": "something that you really, really need for the rest of the things? happening on the rock, or this is something for, like, debugging? and interrupt testing and all these things? Because those are two different things for me because Q log is all evolving. I'm trying to push QLog to a state in the Q quick working group so that people actually make it more useful. We're happy to see, like, you are easy using this one but I'm mean, the call for adoption and all this thing, I think we can deal with this kind of letter, like, use Kilo how you want to and make a useful use of that one then when we have like understood like what are the things what are the things that we're using we're extended how useful that one, that would be then the documentation part will come saying like hey do we want to now document this one because of like some reason, right? So right now I think it's a bit premature to actually call for adoption or anything just use it and i'm very happy to see like you were using q log just for the record Bernard? I mean, just debugging things with quick, it's I think the Q log would be useful, as an example like I've seen interactions between, I frames and quick streams like at the at the window wasn't large enough, you'd see the additional delay and I was wondering why that happened, and you can get that kind of info out of Q log so I actually think there is some enduring value here. It's not just for the interrupt Anyway, so I think it is a useful thing potentially. I've actually had to use Q-Log to figure things out Good. Yeah, you're going to one one might see Q-log a bit as a new flavor of MIAB of some sort. Just for"
  },
  {
    "startTime": "00:38:02",
    "text": "active, that kind of get done with every protocol you do based upon quick so that you do have a common debugging and also operational interface that could be used for exporting for all kinds of things so that might be there may be a more a broader underlying value, surely beyond beyond interoperable Not sure whether this is a good comparison because everybody hates MIAB but yeah but Yeah, I would say, even if we don't necessarily adopt right away, I would encourage you to keep revving this document as an individual. Also, I feel like probably as you mentioned they're still finalizing their extension points in Qlog, so I'd like to have a little bit more of a stable base, so we know that we're doing the right extension as opposed to them saying, oh, no, that extension point didn't work, we're going to change it again or something like that. So maybe like when Q log hits, you know, IETF last call or something, that would be sort of that we know we have something stable to build on so they're not changing things further But yeah I think definitely this is going to be useful for the implementers, both the interrupt and debug and going forward so okay thanks Okay, this is the decision of the HEBC profile for WebRTC wanted to go over implementation status. That's most of what we'll talk about and one major open issue So we now have two implementations, one in Chrome Canary 128 and another in Safari Tech Preview 199 The Canary version is advanced considerably We now support H-265 Incode behind a flag The code is on by default. This is in WebCode And then in WebRTC, you can turn on receive and send behind a flag. And that includes support for profile ID and level discovery There have been some issues with a packet buffer"
  },
  {
    "startTime": "00:40:02",
    "text": "field trial. I won't get into that too much but basically the issue is with multiple slices and properly depacketizing that. In Safari Tech preview, there are some limitations to be aware of if you turn on lockdown mode, which is the super secure mode it blocks the encoder and decoder but the harder encode and decoder are on by default and WebRGC receive and send are on default In Safari, it's a few CLs behind Chrome. So I'll describe what that does to the STP, but basically it should be synced up in a few releases All right. So I mentioned these are the flags you use to enable both the encoder and the send and receive. It is capable of encoding temporal scalability with two layers I mentioned the issues with locked mode in Safari Tech Preview 199 There's also a bunch of other things that are coming in to Safari, which might affect any sample code you write So beware that things are still in progress there there OK, so here's the summary of where we are with WebRTC and the profile As I mentioned, there's a mission with the packet buffer field trial, not correct reassembling multiple slices and also some issues with SPS PPS caching We've discussed RPSI in handling of that That probably won't go in. Then in Safari Tech preview, basically we have it's H.O.65 is average by default. And if you have a receive-only M-line, you get some additional profiles at this point HVC is hard only on all browsers and in macOS, the hardware support is"
  },
  {
    "startTime": "00:42:02",
    "text": "very extensive, like 90% or more on Windows not so much And there are some bugs with respect to discovery of the capabilities and the profiles and so forth which is limiting the ability to successfully STP negotiate So here's kind of a summary of what we've got The show, uh, uh, hardware decode is on at least three browsers, Chrome, Edge, and Safari We do not have software decode or encode for that matter. And then hardware encode, we have a temporary scalability up to two layers in Chrome and only one layer in Safari. And then we can receive and send WebRTC in Chrome with a flag and Safari it's on by default And then if the receive only, we actually have profile one and two, so both main and high profile whereas if it's send receive it's only only main main So a little bit about the STP that comes out of Chrome Canary This is what you get with send, receive. Basically, you get main profile 3.1 which is the default And then if it's receive only, you get both main and high level 3.1 and then what's a little strange is if you turn on if you use the sendel only, you actually get both main profile 3.1 and main profile level ID 156 And I'm not sure whether this is really or not. It's a little bit odd because it's basically sending at a level ID that couldn't be received. So I'm not sure how you'd even set up an interrupt test for this It's basically even in receiving"
  },
  {
    "startTime": "00:44:02",
    "text": "mode, you're not going to be able to receive level ID 156. So this, not sure if that's a bugger a real thing And then in Safari as I mentioned there is no FMTP parameter, so it's just kind of defaulting to main profile 3 3.1. There've been some interop issue actually getting the STP negotiation to succeed It occasionally fails. That seems to be more of an implementation bug than a spec issue. But that's kind of where we are at the moment until it gets synced up to the Chrome release So the big issue we've been talking about on the list is this potential issue with receive only or send only codex And the basic concern is that if you send an offer preferring H H265 and then H265 secondary and you actually can't send H2 and then H264 is secondary and you actually can't send H265, then you could get into problems at the answer only includes H265 and the answer. So the answer, could expect H265, you can't send it, and then you fail So the alternative is to do basically receive only or send only M lines but that's not a panacea because non non-browser endpoints are likely to encounter interop issues And also we have probably some bugs with tech code off preferences. But at least at the moment, it's not clear how important this will be in practice if the HVC encode decode and the RTP send received all gets done, then probably we'll be able to accomplish things just with send receive M lines and maybe dodger a bullet here. And we won't know till we get safari synced up with all of the uh, PRs, uh, and test the SDP, uh, offer answer and make sure it all works So that's current status Any questions?"
  },
  {
    "startTime": "00:46:05",
    "text": "Um, so is it just issue 22 that blocking this document from being done as opposed to the whole process or do you want to actually have it working before you go to? last call here? Yeah, I basically want to make sure everything is functioning and there's not some spec issue or something that that we've missed So we're probably not that far away. I would expect maybe at the next interim or at worst 120 we can actually demo full RTP back and forth and then we'll kind of know that it all works works cool All right. Okay All right, hello everyone. My name is Lena Chapenier and I'm going to present the next couple of slides on RTCP messages for temporal spatial resolution I will do this on behalf of my colleague Yonghe, who is one of the co-author of the draft Next slide, please So just as a reminder of Bud Yonghe, who is one of the co-author of the draft. Next slide, please. So just as a reminder of what this draft is about, it aims to support the energy efficient media consumption, which is also known as the green metadata feature, which is specified by MPEG and in this feature the center and the receiver exchange metadata for energy-efficient decoding and coding presentation and selection of media. For instance, if the battery gets low at the receiver, the receiver can send metadata feedback to the send to the send the sender asking it to decrease the resolution for power saving And in the drive, this is achieved by specifying to artistic payload format for two new feedback messages The first message is the temporal space"
  },
  {
    "startTime": "00:48:02",
    "text": "resolution request message and this second message is the temporal spatial resolution notification message. So as ever, already mentioned, Yong He is one of the co-author and the other co-authors are Christian Herglots and Edward Francois. Next slide, please So just to summarize the history of the draft, it was initially submitted in June of 2022. After that there were some comments received on the mailing list as results of which a new version was issued with the following change First new FMT values in and 12 were assigned to the messages also there were some duplicated text from rFC RFC-4584 and 5104 that was removed Also, it was forbidden to use the message of zero for a resolution or a frame rate And finally, there was a mistake in the URL for the reference to the green metadata aspect that was corrected then in January of 2023 the draft was adopted by the working group It was later discussed during an interim meeting during which some feedback was received and as a result there was a new version that was issued where the title was changed to RTCP messages for temporal spatial resolution and this is because the draft only covers portion made a green metadata signal And then also there was a constraint added that the proposed RTCP resolution change shall not go above the resolutions that was negotiated via SDP, if available There was a further discussion on the draft during another interim meeting, and as a result there was a new version that was issued where handling of a request for temporal and spatial resolutions that is greater than what was negotiated in the sdp was added and then the last version version 3 was provided in April of this year With no change, it was just to prevent the draft"
  },
  {
    "startTime": "00:50:02",
    "text": "from expiring. Next slide, please so one of the questions we got when discussing the readiness for work room less school was whether there are papers describing impact and effectiveness of the feature And the answer is yes, there's been several papers that have been published about the energy saving relevance to the green metadata standard and the property draft and the latest of such papers was published in the IEEE Journal for transactions on circuits and systems it's titled is extended signaling method for reduced video decoder power consumption using green metadata and this paper includes a test results with experimental implementation quantifying the results in terms of energy systems with various codecs Next slide, please So another question we got was about the level of implementation and deployment. So there are some experiments implementations, such as the one that was used to collect the test results I mentioned in the previous slides Also, temporal and spatial resolution changes have been implemented and deployed in both streaming video and conferencing applications So the RTCP signaling that's proposed in the drive would further enhance the interoperability among the device also during the work on this field RTCP signalling that's proposed in the drive would further enhance the interoperability among the devices. Also during the work on this feature in Ampeg, major Sipset vendors have expressed interest in the feature and actively contributed to the work so there is interest for this in the industry Next slide, please and then the last question we got was about whether the authors have completed all required IPR disclosed so there was an IPR disclosure made by Qualcomm in 2022 on the draft And then there was another one made by Interdigital in October of 2023. And then the last co-author Christian confirmed that he doesn't have any IPR to disclose. So this has been complete"
  },
  {
    "startTime": "00:52:02",
    "text": "Next slide please. So in conclusion to the best of our understanding, all the comments received have been addressed on the draft Also, they are published papers describing the impact and the effectiveness. And then the signaling proposed in the draft would enhance the applications which are the out there and there is interest for those enhancements in the industry. And finally, all required IPR disclosures have been completed so at this point we would like to ask for working global School to be started. Thank you All right, does anybody have any comments or? Javier? Is Javier writing for asking? Yeah, so I'm a great colleague of one of the... Okay, well, raise up the microphone towards you So you can just pick it up in your hand if it's easier It's all right. Yeah. Thank you So I'm a co-author of... Sorry, I'm a colleague of one of the co-authors and I wanted to just convey that we discussed. We also agree that this is ready for last goal from our standpoint All right I sounds like the probably we should do that. If somebody has any objections, we should go ahead and do a last call on that and Bernard and I will figure out the timing of that afternoon. So make sure that's an the notes that we're going to do a last call on this talk about Thank you. Thank you Hello, I'm Hensinyang Today I will present about all"
  },
  {
    "startTime": "00:54:02",
    "text": "update information for the archipelago for haptics. Next slide please. So, um, update information for the archipelago for heptics. Next slide, please. So, this is the status of our draft. So first of all, we moved the draft on the APT core working group GitHub means that you can review and leave the comment on there and we as we announce in the last interim meeting, we added text to add aggregation parts and correct some minor typo and terminologies. Next slide, please So this is the aggregation package pellet for a parallel structure. So one in single time aggregation packet, another one is the multiple time aggregation packets Next slide, please and then we also made a minor update to terminology align some terms with V3C draft And we revise some sentences to fix typos Next slide, please So we believe that the document is ready with no plan for additional update So we are seeking further leave that the document is ready with no plan for additional update. So we are seeking further reviewer for our draft and also we think that one of the way is to elicit the review is the working Roscoe so if there's no objection so I I like to ask working law school Thank you All right. Does anybody have any? objections or concerns? Otherwise, it sounds like we should I mean, I agree that, you know, waiting for comments before the group last call is just, you know, a deadlock situation. So better to ask for working class call and if issues come out, then you deal with them That's why you have working group last call. So that's what I would be"
  },
  {
    "startTime": "00:56:02",
    "text": "inclined to say So let's go ahead and do that. We'll figure out the timing of that versus the other document so we don't have to, you know, I know this We'll have a lot of time for ABT Corps, so make sure we have, you know, don't have overwhelm people. But it sounds like we should have queue up both of these things okay thank you Okay. Thank you moving quickly here Harout. Very quickly. For both of these drafts, if you need the impact documents, talk to me. Okay, thank you Yeah, I'm probably going to be need the impact documents, talk to me. Okay, thank you. Yeah, probably when we do working group last call, we should send a a... I'll write that down there. Yeah yeah so i'm had all this us, John. And at Google, we call we'll we should send out there I'll write that down there yeah yeah so I'm had all this John and at Google we've done some experimentation with RTP header extensions. Now our with RTP header extensions. Now, RTP header extensions have this interesting property that you don't have to register them anyway, because they're identified by a URI. So we didn't have to ask anyone to do the experiments but once we're getting beyond the experiments stage and other people want to do it, well, people tend to like to have stable references stable reference okay let's see where we can get one Possibly, the right solution is to publish the specification in AVT Corps, or through AVT core in the IETF. And since everyone knows that IETF process, means that something will change at least we have a starting point Or just to indicate that you that something will change. Well, at least we have a starting point. Just to indicate that, yes, we have accepted that publishing through the IETF process means that we have to handle change control"
  },
  {
    "startTime": "00:58:02",
    "text": "Well, it's always nice to describe what the problem is before you ask people to accept the solution So the basic problem is that you get a video frame, you get an audio frame actually I get a video frame from two different places And you want to know in the world's time real world time when, where it is produced so that we can try to sync them up again I mean, having a it, if you have two clocks, you don't know what the time is. Because I always out of sync somewhat And in addition, there might be delays in the system delays like from the time you can capture the frame to the time you send the frame Network delays multiple hop delays through relays And so some of the existing identifiers seem to fulfill the purpose. So next slide The very simplest system is when you have a camera and a sender and a clock all in one system. At least they agree with each other about what the time is. Then you send across the wire to the receiving system that has a different clock now aren't it Then you send across the wire to the receiving system that has a different clock. Now, RTP and RTCP has this nice thing called S that has a different clock. Now, RTP and RTCP has this nice thing called SR, RR, whatever, which actually allows you to estimate what around trip time is. And everyone knows that every exemption is false"
  },
  {
    "startTime": "01:00:02",
    "text": "but given, taking the RTT and dividing it in half, gives you a better estimate of the one-way trip than having no estimate at all So there's no perfection. Next Now things aren't usually that simple you have a camera on a system with a clock. Tick, tick, tick, tick It passes its frames to a different system over RTP or over a wire or whatever which is a different clock which then forwards the packet to another system with a third clock and get to the receiver at the fourth clock Now, RTP RTP thing helps with the estimate of how wrong the clock is between the two last hops But the end system doesn't have any idea about what happened before that And let's tell it. Next slide So we introduce Abs capture timestamp which basically says, okay, take the NPP clock of the time that the frame was captured That's a bit of light of, of, uh, that, yes, you have to estimate this bit you have built in delays and so on. Stamp it That's a time stamp In the sender's clock. Now, you send it to the next hop The next hop estimates just how much it disagrees with what the time is and put that as in into a something called the estimated, captured clock offset"
  },
  {
    "startTime": "01:02:02",
    "text": "and then send both these values to the next system down the chain system down the chain says okay here's an absolute capture time stamp. Here's an the chain. System down the chain says, okay, here's an absolute capture time stamp. Here's how wrong he thinks the previous guy's clock is And I know what how wrong I think that guy's clock is. So I can update the estimated capture clock offset so that it's relative to my clock and stamp that and pass the package package now this goes down the chain and at the end system, you have two numbers, you have what the originator thought that the capture time was, and the accumulated estimate of how wrong that was compared to your clock So this is just a clarifying question. So just on one, I give an RTP packet only ever has one of these at the clock offset. It's not like each hot adds yet another clock offset to the right package. Okay, thanks. So the, so each, each estimates on its own. In some cases, the intermediate system might not be using our at all, or it might have different estimation algorithms so that it's perfectly legal to throw away this whole Kidd and produce a new one new offset, that says, here's what I think the originating clock was or how wrong it was And we even have a short version for the easy case where the absolute capture timestamp and the clock offset is zero so that you don't have to waste bytes on sending zeros Next slide"
  },
  {
    "startTime": "01:04:05",
    "text": "experience we had with experimenting with this We don't need to send it on every packet Usually the timestamp, clock offset, estimate and it's such an estimate anyway doesn't vary that much So, once in a while, tick, tick, tick We don't add, but we don't have adjust crock drift at all We just believe the latest estimate So we depend on regular updates once in a while Not too often, not too rarely And that's enough in our experience to get synchronization over diverse paths like this, working for our purposes. Do I have a next slide? So I didn't put in a slide of what we're going to do next So, unless I get massive feedback saying this is a dumbbody idea, you should never tell anyone that you ever considered it My intention is to put this document, this description into an internet draft and show it to the work group saying hey does this look silly And incorporate feedback, when does that happen? and then ask what to do next The alternatives are as I see it, and this is perfectly okay it's non-IETF specific You should just publish it as an informational document with a uri that has identified this extension and past This is an excellent idea and we want to change it We should adopt it as a working group document and make the changes we want to and probably change the URI"
  },
  {
    "startTime": "01:06:02",
    "text": "and then publish it as standard check or whatever or the might be an option I haven't thought of in the last 30 seconds So. Thank you to dispatch be an option I haven't thought of in the last 30 seconds. So. So. We're not going to send you. No saw the again and then get this patch There's so much that didn't make it there you sent you to dispatch. We're not going to send, no. You saw the, you saw there again and then again dispatch. There's so much that didn't make it there. But floor open Okay. So, Colin, Jax mean, I'm not sure I found your motivation for this totally compelling. I didn't quite get what you were actually doing with it, but that said ignore that. That's not a comment. I don't think we should do this It might sort of sound like that. I think there are reasonable needs where this helps make debugging. We've sort of had to experiment you know, we've sort of had, let me call them hacks that we've done this before. So I think that having this type of information in some way of sending it would be useful to do, I would prefer to see the sort of taken over as a working group document and process I assume that you'd be all right with minor changes to you know how formatting and things on this, because there's some problems there, right? Like, like, if you could send the same semantic information in something roughly like this solution would that be all be all right or would you still want to publish something that had no wire changes from what you're currently have implemented? So the nice thing about the way your eyes, the way extensions are identified is that this practice no overhead to support the old one and a new one at the same time. So have, of course, it keeps the old one and we changed the URI. I'm not proposing you reusing the URI or anything like that Yeah, having the having the IETF converge on the on a better solution is and adopting that once it's a arrived, it's perfectly acceptable. Okay"
  },
  {
    "startTime": "01:08:02",
    "text": "I'd be in favor of that sort of path and direction, and I don't think this needs to go to dispatches, clearly in this work group sure Magnus yes um of that sort of path and direction. And I don't think this needs to go to dispatches, clearly in this working group. Sure. Magnus? Yes, so my, I, I, I, I'm not certain understand in which cases normal artistic singling fails for this case, because if you have the sources, the SSR is grouped by C-name and you have the actual archa-sepe reports with the wall clock time from that system representing an actual clock that you would care about. And if you would use something like RFC 72, 75 for clock source signaling, you would know which clock that originally system had, or at least measuring that external as source towards that local clock and put it in the center report at that point, the originating combined node. I guess you have to systems here which really breaks the chain or it's primarily for estimating how long the chain is with the different transport pops? hops So you sound very much like I sounded when I, when this was first proposed to me It took me a while to get convinced by the guy who invented this, who is not here, that this was, A, needed, and B possible. Yeah. So I'm looking forward to draft, I guess, for explaining the use cases better I think. So I've taken those of needing better use case descriptions Yeah. An addition in that, I think, really get the understanding of why you do you need the absolute time rather just not the offset maybe why you need both because if you have the RTCEP report for the absolute time that maps"
  },
  {
    "startTime": "01:10:02",
    "text": "to the time stamp to absolute time on the sword I would like to understand why you just don't need the offsets That's because that's the multipot property and the need to correct timestamps that come over multiple diverse paths. Okay, so I think, yeah, you need to explain why the topology and which is one session versus another session and why you would have to do translations I think that's what comes in here. Okay, thank you Oh yeah that mostly as an individual i think i you know i've let certainly like to see the draft, but I'd like to see, you know, it doesn't necessarily need to go into a final standard, but at least for the initial drafts, explanations of, why the existing RTCP mechanism don't work and then on top of that, why this should be a header extension and not more new RTCP information Where would you put new RTCP? Well, maybe because there's no way to put them for the middle boxes to say anything, and that's fine but, you know, say so Yeah, I think the multi-tap path cases are more interesting Stefan. So thanks. I would like to see the draft two I was common. Most of what I was about to say is what magnus already said i had one more thing in MPAC we commonly have three times I was about to say is what Magnus already said. I had one more thing. In MPAC we commonly have three timestamps. We have a capture timestamp That's what you are aiming at. We have a presentation timestamp and we have a coding time stamp what what code time stem basically the time when I think the last bit of this of this frame or whatever entity it may be has been spit out by the encoder. And I think it would be good if you define a syntax, make it extensible to capture all three times be has been spit out by the encoder. And I think it would be good if you define a syntax, make it extensible to capture all three timestamps. Because that was a major to some people, especially to those which run extremely high frame"
  },
  {
    "startTime": "01:12:02",
    "text": "rate and professional applications, was a major roadblock in the past where there exists proprietary implementations, trying to both those timestamps you know, or they are sending a an impact system layer stream for the sole purpose of having those additional time stamps in the between somewhere. Hacks, dirty hacks So think about that. Thank you. Thank you I'm looking forward to having more discussion on the mailing list about understanding why you need it it I think it's a longer discussion In general, I think it's a good idea, but we have to remember that header extensions are not guaranteed to go end to end because there are middle box in the middle can drop them if they don't understand them So it's good, I think people suggested here that you also include what's the current way to do that using RTCP. Because today like in video conferencing lip sync is done using our think people suggested here that you also include what's the current way to do that using RTCP because today like in video conferencing, Lipsink is done using RTCP and RTP and in RTCP because today like in video conferencing lip sync is done using RTCP and RTP and you know in order to achieve the synchronization between the video and the audio so there are mechanism I think this mechanism is good, but you should know that why you use the and why you use the other Yes. Okay so the feedback I hear is looking forward to the drug make sure you describe the use cases and we'll come back Thank you. Thank you Thank you Next up is a you Next up is APV. No Hello, I'm presenting online. Thanks for having me a chance to present this one. This one is a first draft submitted to ABT to review the RTP pilot format for advanced video"
  },
  {
    "startTime": "01:14:02",
    "text": "Professional Video. If you go to the next page, please So I hope you guys remember that, you know, I have presented this one at the last meeting in person. Sorry for not being there in person at this time, but advanced professional video codec has been developed as a professional video codec, which you know, supposed to provide up to several games not being there in person at this time, but advanced professional video codec has been developed as a professional video codec which, you know, supposed to provide up to several gigabits, you know, throughput and very high fidelity compression, which you means that it's not really kind of in a highly compressed view but it's more like reasonably compressed pre-juring all the original quality of the video and there are several I mean, not several, there are actually many properties you know, professional video codec or mezzanine video codec available in the market. And we have tested with many, you know, popular ones in the market and in have found that, you know, this development is kind of, you know, much better than the others. And also we try to make one open standard professional video codec, which could be IPL risk for so that everybody can just use it for free And there's a plan for open the open source software for that soon in some of it organizations so that draft has been submitted for targeting information on RFC which we don't intend to bring this one into any of IETF working growth work standardization. I think, you know, it's not really kind of in a good fit for any, any of a nest, you know, any of the working group strong interested in bringing it there In the meantime, there has been a zero one version has been provided there has been a lot of various editorial improvement and, you know, there has been a kind of more detailed syntax on the metadata since, you know, we need to add HDR 10 plus support there So we are welcoming to"
  },
  {
    "startTime": "01:16:02",
    "text": "any of the view of this one as well at the same time with the RTP pilot format draft. Next page, please. Sorry, just one question is, do you mean you're submitting this to the independent series? Yep. Okay, cool, thank you Yeah, unless any of, you know, working group in IETF is strong believe this one fit to their kind of challenge or interested in their bringing their standardization agenda Honestly, we couldn't find any working group actively working on this kind of thing. So we just kind of provide it as a information RFC. That's the original yeah thank you next page please. So some kind of basic information to understand that kind of Palo format design. The basic thing is they're kind of, you know, the frame data, which include the old frame, level, you know, information in a self-contained format. So, you know, this doesn't have any kind of, you know, permit said or configuration parameter set, you know, which stays, you know once in a while for many frames some other, you know, like, you know, some other video connect does because in its many use cases for kind of a lot of intensive editing and so on so which tries to be this standard try to be kind of self-contained frame header and frame data structure. So the frames included frame header and a series of tiles then optionally metadata or filer data And then tile means, I think you may also heard about tidal in many other video codecs tile is a kind of rectangular subset of the frame, which can include serial number of Thank you macroblocks. And the microblocks are same as other video of rectangular subset of the frame, which can include serial number of macroblocks. And the microblocks are same as, you know, other video codecs. So tile can be independently decoded as long as you"
  },
  {
    "startTime": "01:18:02",
    "text": "have from header data. So that's somehow kind of parallel processing or low delay processing purpose. Next page please So since the the frame itself contained we're thinking about providing two different modes of packetization know, pecatization. One is a simple mode, so you just start from frame header, so your RTP packet payload starts with a frame header always and continues to whatever you are kind of maximum payload size meet and then just go to the next packet. So there's no rule for alignment of internal data structure of a PVB stream except the startup frame header should be always a start of payload header. Another mode we're thinking about is kind of low delay mode, which is kind of pro providing alignment with a tile style a startup payload header. Another mode we're thinking about is kind of low delay mode, which is kind of providing alignment with a tile starting points. So your tile always start with the kind of RTP payload header. No, sorry, RTP payload header So that as long as you, there's a way to get the frame header and then you have a packet getting one, uh, RTP payload start, so that as long as there's a way to get the frame header, and then you have a packet getting on tile completely, then you can just start a recording So, you know, I will explain a little bit later So if you are in the payload, I mean, low delay mode, we are considering to repeat the frame header option at the end of packet so that if you have a kind of one tire completely then you can use a kind of optional repeated frame header to decode a tile. Okay, next page please To support those for RTP packet headers, I side, we don't think there's any special need to amend any or any, any, you know packet header, you know a field we set kind of Markovie to indicate the last packet of the frame or"
  },
  {
    "startTime": "01:20:02",
    "text": "always, because it's of, you know, the packet Markovie to indicate the last packet of the frame always, because it's of, you know, packetization format, and then time span always reference and 302 bits, you know, timestamp for the kind of sampling time of the frame which could be 90 kilohertz clock later you know, similar to any other you know, parallel format. Next page, please Payload header, please remember that, you know, we have two different mode So the first thing, version number, we are considering to the 4-bit, 2-bits, you know, version number, starting with zero, as this format And operation mode will have a two different mode so a simple mode and then low-delay mode, then you know, 0-0-1-2 mode would be reached two mode will be reserved next page please Payload time we try to indicate, you know, whether this payload contains the first in the middle or the last, right? Regardless, depending on the, you know, packetization mode, it will indicate the first or last of the frame or time Next page, please Frame handling repeated means that, you know, this payload or this unit Just wanted to read the previous thing, I think if you go back to the last slide, yeah, I think you, I mean, maybe extremely unlikely given the bandwidth you're looking at, but I think, you know, you could, one one would mean it's both the first and the last and that fits the semantics of a lot of other payload types we have Basically, you're, this tile fits entirely in this packet would be one one oh you mean the uh when there is a kind of only one packet carrying entire. OK, yeah, yeah I was also thinking about that, you know, support different mean the, when there is a kind of only one packet carrying entire? OK, yeah. Yeah, I was also thinking about that whether she would support this one. I meant it's just that this is really start one bit is this is the end and yeah yeah you do that a lot of power sure sure yeah same but design, that perfectly fit things"
  },
  {
    "startTime": "01:22:02",
    "text": "Yeah, frame had repeated as I mentioned that photo kind of you know tile mode or low delay mode, you may repeat the frame header at the end of the payload that's a indicated by this H-bit, and then static frame header as I mentioned, that there's no kind of in a computer header at the end of the payload that's indicated by this hbit and then static frame header as I mentioned that there's no kind of in a configuration parameter set and so on so frame headers are repeated but you know sometimes it doesn't change any frame every frame so we just kind of have us static frame header bit indicating that we're sending the frame header, but you don't have to decode it because it's the same as before if you already have it and then frame counter is that kind of you know down counter how many packets or payload left to come the frame or tile depending on the packetation mode next page please So we are actively working on the also media type legislation and STUP parameter section in it and we've been thinking about to simplify the media, type optional parameters So we don't think we don't need anything else than profile level idea because in every frame can change their size know size and width and so on so we only indicate the profile level idea should be sufficient and STP parameters So we are also thinking that, you know, this may not be used for bi-directional communication in any case the intention of design or kind of intention of code, I guess, for professional use, like a vision in, you know, code So currently, we only have kind of, you know, one-way STB product set design there And then all the last half section, like congestion control and security will be just kind of standard normal text similar to any other"
  },
  {
    "startTime": "01:24:02",
    "text": "you know pillar format you know, internet draft. That's it for my presentation unless there are any other questions I mean, we will come for your review and any kind of, you know, comments to improve yeah I had a question by what you meant by one way. You don't mean like send only or receive only. You mean like the declarative STP without offer answer? Yeah, I mean, sender or need, I mean think it's more like you know, there's a one sender and then there's one receiver that doesn't really mean that, you know, receiver could be another center Yeah, well, that's still not declarative STP It's just an offer would send only a receive only in a, you know, an answer Oh, yeah. I mean, in that sense, it's like an offer only thing. Yeah, in your terminal. Sorry about that. Yeah. Thanks oh yeah i mean in that sense you see that i can offer on the thing yeah in your terminal sorry about that yeah yeah thanks so i think what they are looking at is, is, uh, that yeah yeah thanks so i i think what they are looking at is is using regular offer answer where it's just uh send only receive only thing Yeah, they are not declarative. Now, I just have one one thing Yong, are you sure that you have filed a single patent on the media specification? because there's no IPA declaration? out and that's a oh one draft now Yeah, we, we you there's no IPA declaration out and that's a oh one draft now i mean that yeah we yes we have not filed anyone and then we don't have a plan to file any that is very generous of you okay thank you. That was the intention and we we saw that you know why there are so many different types of formats and it each one has a kind of really small pattern attached, and we thought that should be improved You know, again, very generous"
  },
  {
    "startTime": "01:26:02",
    "text": "of you and keep it like that. I hope it stays like that it would be really a shame if a nasty surprise awaits us five years down the road. Thank you Thank you All right, so I think as a chair, it's clearly in our scope i would one to see that the ISC has actually accepted the format before we, you know, just so we know that there's a reference we can refer to or that it's published somewhere else Other than that, I think once that's happened we could do a call for adoption to make sure there's interest in it besides the authors. Well, I mean maybe even if there isn't, Stefan is shaking his head saying, I think even if they're, you know Stefan, go ahead. Yeah, thank you The format specification, which I just looked into that 50 pages or whatever it is, that thing looks is that complete already pretty much? Could you hack the codec from that spec? I think so. I mean uh unless uh i mean at least you know we have a little bit of plan to add like Babs or our Alpha a little bit later. But, you know, base codex itself is pretty much complete and then we are working on, as I mentioned, the open source implementation just based on that aspect, nothing else Okay, so my preference would be to, again, that into a you know, through some process, whatever that process may be first before we really move on the RTP payload format for it. Thank you Yeah, I think"
  },
  {
    "startTime": "01:28:02",
    "text": "as Chair, I'd like I said, I'd like to see this be being, at least in the process of being published somewhere as a stable reference but then I think once that's happened we can take a call for adoption so let's so let it so and meanwhile you can of course keep updating this, you know, both to keep in sync with any future draft and following any suggestions to both of that Thank you All right and I guess last we have J2K, is that right? Hello. This is here Can you hear me all right? Yes but there is some people doing some... Actually, can somebody in the back close the door? because of the construction outside? Thank you All right, yeah, go ahead, Pierre. All right if you just want to move to the next slide um so uh we've received some feedback Well, first, thanks for setting up the repo and so we moved the document to the AVT core repo, so that was done And since the last ID, there's been a couple of editorial improvements based on feedback from implementers, but most importantly, we removed one of the media type parameters that allowed multi-tile images to be transmitted as multiple single tile images over independent sessions and so that was a feature that nobody seems to have much interested and has not been implemented and not tested. And so it's been removed in this second this ID version 2 Again, this is just signaling at the media type level. I mean, we can always add it in the futures"
  },
  {
    "startTime": "01:30:02",
    "text": "And I think all the comments feedback has been a bit addressed and the document is ready for last call I think we'll request at this meeting All right, well, that's a nice and short presentation. Oh, um guess you have, and this is the thing we discussed at the beginning about Magnus's draft yeah I think our conclusion was that this draft should just remove that section about the registry we're closing and then because we're closing it and but then, yeah Ah. Yeah. Oh, I missed. Okay. Yeah, I was just, uh actually i was getting off my flight so let's see so there uh let's see where is this in the draft? Payload format. Okay Mm-hmm I think this? I mean, we don't need to do this online, but right, but so I see so there no more so let's see. So how do we? communicate, so you mean the media time? go ahead there's still the media type right but there's there was a separate are to be payload media format type registry, which was poorly named so so you mean the media type go ahead there's still the media type registry but there's there was a separate RTP payload media format type registry which was poorly maintained and redundant So we're closing that one down and only using the main media types registry That is the goal of the document that we discussed at the beginning of the meeting, which you can take a look at just if you're okay i'm not seeing any reference in a document to this"
  },
  {
    "startTime": "01:32:02",
    "text": "uh payload media format types registries so that's why i'm slightly maybe Magnus do you have something it the second sentence of uh section 10 you need to remove no 11 section 11 it's the second sentence then then sentence So you just need to remove the second sentence of section 11 and then you're done Magnus, do you want to just email? them the specific sentence so we don't have to try to do this? Okay, thank you that. Okay, thank you. Okay, yes. Okay All right, sounds good okay um so yeah it sounds like so sounds like let's just, let's just do a quick rev with that change, and then it sounds like we're ready for last call on this. So sounds like we have a bunch of last calls coming up, so that's exciting We're finishing work but you actually have to do it so um bernard and I will schedule that to be the other one ones All right, all right so that's everything. Well, just before we leave, maybe we should just go over all the action items make sure we've got everything. Yeah, yeah Do you want to do that? Do you have the notes up? Well, certainly we have, I think, three last calls, is that right? Yeah So J2K um, the, uh closing the media types and and and uh temporal spatial"
  },
  {
    "startTime": "01:34:02",
    "text": "yes okay so three last calls and an adoption call as well? That sounds this is why we have notes What was there? What were we adopting? Is that haptics? or? No, we adopted haptics Habtics is one of the ones a good last call on Okay. We had four last call Is that right? Sorry for not being more Okay uh Oh, yeah, I think we had four last calls and don't have an adoption Thank you than that, I think for it to be over quick they're going to keep working on it ATVC, you wanted to make sure we had everything working to make sure there's no other issues issues absolute capture time and Harold is going to write a draft APV, we wanted to wait until the code expect is done and J2K is one of the ones we're going to do a last call So I'm not sure those are all reflected in the notes as they are now, but hopefully we can remember those things Okay. All right Does anybody have any other business or?"
  },
  {
    "startTime": "01:36:02",
    "text": "oh, Javier, what do you want to say? Sorry, just I think there is an ongoing sorry, adoption call Oh, yes, there's another, yeah, there's an ongoing, I mentioned that at the beginning, but there's an ongoing adoption call for the region of interest. Is that the one? Yes, I think it is at the end of this week. Yeah Yeah, so, yeah, if anybody has any confidence, we have time, if anybody has any comments on region of interest you know just expressing um interest I guess, in that region you know you can say something now or hasn't mentioned say something to the list. Because I think we've only gotten two expressions of interest so far. I'd be a little more happy with more than that So also if you if you are you are yourself interested but also know other people who would be encourage them to send something to the list also just so be know that there's more of a community that wants this Uh I guess that's everything so we can go try to get the cookies early if you're here. I'm afraid if you're remote, you're not the cookies early if you're here. I'm afraid if you're remote, you're going to have to get your own cookies, but I encourage you to go enjoy the snack and our beverage of your choice Thank you all for Thank you, everyone. Yeah, and thank you all very much, and we will probably, as usual, schedule an interim sometime halfway between now and the next day IETF. So keep an eye on the list for that very much I love it"
  }
]
