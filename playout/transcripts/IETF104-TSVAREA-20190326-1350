[
  {
    "startTime": "00:00:34",
    "text": "with what thank you for being there you should have showed up two years ago hello everybody we\u0027re ready to start okay welcome to the tea\u0027s Vieira meeting my name is Maya diamond I\u0027m one of your 80s and I will be here for another year hi I\u0027m Spitzer Dawkins I am the outgoing transport area director and I have been "
  },
  {
    "startTime": "00:03:34",
    "text": "for a long time now and I\u0027m Magnus Weston and I start tomorrow formally but yeah I think you see me yes okay so we\u0027re ready to start I\u0027m Susan ietf session is every other so there\u0027s not Val for you same rules about participating and I hope you will all participate very much today because we have some nice topics and hopefully some nice discussions going on there um yeah that\u0027s our agenda so we start it right now we can branch the agenda if you want to and then after the agenda we will briefly talk about the situation that came up that like up from tomorrow you will have to 80s with same affiliation so we give you a chance to comment on that and then we have some technical talks here the first one is a little bit of follow up from discussion we had last time and then we have three talks which we\u0027ll talk about logging those talks came basically were motivated by quick but I hope that the discussion we will have afterwards would be more general and then if everything works well because the agenda is very crowded we will have like a few minutes for open my questions at yet any agenda fishing um yes so very much welcome and and also very big thanks to Spencer who likes surf for six years and did a great job [Applause] you just said it seemed longer so that\u0027s also kind of the usuals we have here we have a review team meeting which we SIDS rely on during reviews and they were very productive over not productive are you supportive very helpful over the last couple of month and years so that works better and better and these are very valuable reviews for us and we have three new members Olivier Gauri and Tommy so thank you everybody for serving and especially the new ones one of the big one of the biggest things that helps us is the triage team and we are we transport has a unique area review team which is we don\u0027t do all the documents we have a triage team that looks at the documents and says these are the ones they\u0027re going to need special transport attention that there is a real gift to the area directors Magnus has been performing that role for a bit more than a year he will not be performing that role anymore and we were Maria and Magnus would like "
  },
  {
    "startTime": "00:06:35",
    "text": "to replace Magnus as one of the triage team members you don\u0027t have to be a former or transport Area Director to qualify I\u0027m just saying you can\u0027t be okay then this one is easy so we do like a straight switch like Magnus will take over all of Spencer\u0027s working groups so you don\u0027t have to be completely confused about it and I will just keep the working groups I\u0027ve been responsible for so hopefully that should be easy enough so em finally I mean I\u0027m saying this since a couple of minutes now but finally I actually were close to CP in the next coming up weeks and we will also close the meeting this so if you have any last questions for the TC being people post them now yeah I mean otherwise I think I\u0027m learning you\u0027re working groups I\u0027m talking to shares etc and coming up to speed here so trying to figure out exactly what I have newest group I haven\u0027t been active before in but so don\u0027t hesitate you talking about them those groups etc provide your views etc so thank you this is also the user it\u0027s like we have sit so that\u0027s the progress we made since the last meeting we find this nice to have because it shows that we do some work but mainly it shows that you all do some work so again thank you at that point they love getting in here yeah and this is a discussion that just happened in a previous session in TC working group so there was a presentation about using h2 as a more generic transport byte stream protocol basically which is related to a discussion we had last time appears we are and therefore also a little bit related to the first presentation we\u0027ll have later on talking about other other topics that might be interesting for you later today there\u0027s also a memory meeting or later today later this week there\u0027s a memory meeting and there are a couple of talks which are very relevant for transport so keep that in mind so that\u0027s on Thursday and looking back but also coming back in some of the sessions this week they have also been a lot of presentation which were related to transport in the hot RFC session so that\u0027s an indication for us and all these things together I think that we do "
  },
  {
    "startTime": "00:09:36",
    "text": "expect more work like my feeling is that like we got we got we got over the shock we got was quick a little bit now think about like new funny things you want to do so I think that\u0027s actually a good thing because we we will and have been closing some groups so I think we have actually some capacity here think about new ideas especially if you\u0027re planning above for the next meeting come to us talk to us early we can help you we can give you feedback if you put in your buff request in the last minute chances that it will make it are less because if we don\u0027t know what you\u0027re talking about we cannot really make a decision and if you tell us early we can really help you to figure out what the right scope is for your book as well so this is like a sneak preview for the next meeting actually because that\u0027s a topic that came up from the IAB but it\u0027s also topic I actually talked to a lot of people independently this week people actually came to me and talked to me about it about like concerns that the freedom we get with implementing stuff and user space and being like much more flexible about protocols we design which is a good thing and can also take away some of the gatekeepers with respect for example to congestion control so that\u0027s a discussion that started already on the iccid mailing list so please go there and contribute to the discussion if you have thoughts but this is also topic we would like to discuss at the next meeting in Montreal because we didn\u0027t have time this time so it\u0027s it\u0027s the right time to think about it right now and then come to our central Montreal and thank you Christian way tomorrow for starting this conversation yeah Christian or Brian do you want to add anything to that point I\u0027m doing this to give you all a picture of what its gonna look like makes this coming summer so I kind of visualize that as the two area directors you will have been or talking now yeah so conflict of interest handling so the situation now is that both me and Mary are employee of Erikson\u0027s and we\u0027re actually quite close enormous issues internally so they are an increased risk for risk for conflict of interest situation now and this is something we are very aware but we will change it a little bit about how we how we see on this and how we plan to handle it so basically our basic strategy for handling cases where if there\u0027s any perceived conflict of interest is to actually hand it over to another ready "
  },
  {
    "startTime": "00:12:37",
    "text": "to do decisions or the handling of that of that situation and some examples of this would be like IP IP or issues in related to any transport document etc the de-mold ericsson IPR or employees like ADA sponsoring it document we wouldn\u0027t do that for an Ericsson or three that was something would have to handover if we end up in situations where the working group as difficult and agreeing or they chairs disagree or leave the consensus decision or call for the issue two babies that happens occasionally that will also be if that involves anything with Ericsson that also really is something you would refuse from if we have all if we have working of shared Erikson a working group all working shares I would say and that\u0027s something you can avoid having but if it if the situation occurs some reason it might be that the exodus is Sharon only laughs things like that so and in case of calm complaints against the working group shot this is Erickson person so one situation I want to stress that we don\u0027t consider really being in the normal situation be an issue is that some author is from Eric zone for all the working group consensus document because there\u0027s several authors there\u0027s working of shares and there\u0027s consensus from the from the working group on this document to process it so in those cases unless someone requests that they feel that is a sensitive issue etc or if it is are some other additional issues around this document we will we will handle those according to our normal working group assignments the area or so any comments on this mr. Dawkins just just mentioning that this is copy fairly closely from the the plan that the routing area directed routing area used when Lea and Adrian were both funded by the same same funder as well so this is actually this should work and the it will work better if everyone helps the area directors make it work it\u0027s also it\u0027s really not in a problem to hand over any kind of things or whatever to a different ad from a different area we do this from time to time for like various reasons so we\u0027re all good for that one and we will be very sensitive to to try to figure out if there\u0027s any conflict but more important is also if you feel that there is a conflict please come and talk to us and tell us : Perkins speaking it as an individual when I get close enough to the microphone so I think this is a very "
  },
  {
    "startTime": "00:15:37",
    "text": "sensible plan I I would have to suggest that in cases where the that there is a preponderance of Erickson people for example if in the case where all the offers are the documents are also Erickson yeah we have a very effective transport review team that could do fancy check on the documents yeah that\u0027s a good death suggestion thank you lousy idea I don\u0027t I don\u0027t see a problem with this is a good approach and thanks for writing it down so would I be correct in summarizing this is so even if an area where you have two different affiliations like like we have right now there are cases where the ad responsible for something would hand that over because of conflict of interest and and now you\u0027re basically handing it over except you\u0027re handing it outside the area yes that\u0027s roughly what you\u0027re doing here Yeah right that makes total sense just to respond to lures I myself have shepherded a routing area document for this you know very reason the thing that we picked up in the last two or three years three years ago probably was the ability to move an entire working group responsibility to an area director in another area but leave the working group in the right area with their peers there was something that we got when Benoit was doing yang and several other area directors picked up his groups I\u0027m a completely different from completely different area but they stayed as Ops groups they just had an area director that was outside of ops all right let\u0027s go um yeah all seems fine to me the only thing I would question if if thinking about this from the point of view of someone who feels there\u0027s a conflict of interest they may not want to come to you to convince you there\u0027s a conflict of interest you say we will hand it over no no yeah that\u0027s not what I meant so if you feel there\u0027s a convict you can talk to us directly if you want to but probably the best to talk to it somebody else in the is G or the IETF chair or your chairs and like everybody is aware of the situation and I think we all are aware that we should handle it carefully yes yeah and I think that needs to be documented so that people who you know we\u0027re all your mates we know we tell you but but someone who feels outside of the system so I did send an email to the community about weeks ago and in this in this email I did actually explicitly say come to ask come to the is G or the Florin babushka Broadcom my question to you I mean it may be okay however is there any binding document detailing these details once a meeting it is done in our see that documents this case the behavior we should have in "
  },
  {
    "startTime": "00:18:37",
    "text": "this case excuse me if you mean an hour see that document so actually I mean this is what last said this is not like you can always have a conflict of interest and we behave in the same way as we would with every conflict of interest just like because this is like a situation where a conflict of interest can be could be happening more easily we will just be more careful about watching it again if I might continue as I have flexi multiple as the O\u0027s as the end of effect actually I was about to say something that you you\u0027re you\u0027re moving right in the direction of what I was going to say it\u0027s so what I was going to say was important remember that this s do we all participate as individuals so what we have here that other SEO s don\u0027t have is more running code about this if you think about the number of router vendors that have provided leadership to this organization for a period of decades we you know we\u0027ve had to as a culture deal with this issue very you know very deeply so this is something that this is something that\u0027s come up a lot over a period of decades having said that you all are doing exactly the right thing and providing feedback to the new area directors about the way you expect things to work please continue I\u0027m just saying don\u0027t look for a lot of documents about this because there\u0027s been in the culture for decades there would be my answer again at least from our perspective we would like to see more clarification and maybe it\u0027s a good time to take a step forward and clearly stated I mean I don\u0027t have the reference right now but I believe there\u0027s more text about conflict of is tendering in general however if you feel it\u0027s not sufficient you\u0027re proud of this community like we are happy to take some input and have more discussion about it I was hi Brent ramble I\u0027m just going to say that yeah a few paragraphs updating 2026 if people in the community feel that\u0027s necessary it\u0027s not that hard to write an ID lifecycle so um I would be interested to learn it well if there\u0027s anything particularly that you feel needs to be clarified here um I I\u0027m I mean obviously the the the NomCom rules try to avoid the situation we\u0027re in however right um the the slate was such that there was no other good option and so we have two employees from the same affiliation and and that\u0027s not the first time does this happen is there anything that that you think is missing here or yes so again even the fact that we do have this conversation right now it shows that maybe you would be better like also a previous speaker said including a couple of paragraphs detailing whatever behavior should be expected to be good so we\u0027re we\u0027re I "
  },
  {
    "startTime": "00:21:40",
    "text": "would hit with that is if there are things that are specific to the transport area that that\u0027s something that the transport area would be in charge of providing paragraphs about but if we\u0027re talking about something a way that the ietf in general across areas should behave that that that\u0027s a conversation that we need to have with the larger community and remember that all of our BCP process BCPs came from somewhere so they\u0027re not perfect and they can all be changed by the community I could see a general level is gief white statement on unconfident was being being useful I\u0027m not sure if we need to be very specific about this particular case which is like one example right um also I want to point out having been a realtor before right the the spotlight is on you in general and the spotlight will be on manga Samaria in particular and and there\u0027s a well-defined process for you know how to get rid of a narrow director and you feel that they have overstepped the boundaries and and that is well defined and can be executed right and everybody\u0027s well aware of that so the the quickest way to limit your term as an air director is by you know not being careful about moving on so a little bit which it\u0027s actually comes back to continue the transport era in general and and how our staffing situation I want like a little perspective on this situation how it how it arose and why it was hard to avoid even a twist so I was the only running candidate when signed out from I think it was around August he went in to call for nomination gave it went out the point where it was likely but not final that mean yeah we would be hired by action was somewhere in December if there\u0027d been a good candidate at a point I I could I would have had an optional step down if they were candidate otherwise I would have to reset noncom state if I called on comm that I don\u0027t anyone do it because we might hire or is a it\u0027s likely but not final hi Amelia I figured Nam Kham I really irritated at the point but yeah they\u0027ve done their work and replace any probably know it\u0027s late but that could be done but and if it was and it was final that we hired me I asked before an oncoming I\u0027ll Smith went out so the thing I I do like to tell future years is that even if you think you have a great candidate please run anyway because these situations can occur it could even have been a family emergency or something for me it\u0027s a saying no I can\u0027t run anymore and and then the non-common process "
  },
  {
    "startTime": "00:24:40",
    "text": "wouldn\u0027t have been as far as way to select him and he had said replacement etc so don\u0027t hesitate to run against people you think is good etc you can provide feedback to the home come saying that\u0027s yeah I rather see that other person doing but I\u0027m here if you if you among come feels that\u0027s the right person great thing to do so at two points a one is running through the process can actually be an interesting experience say yeah in many ways but you know doing having some kind of a pre her so before you actually want to do it it might be an option for you and and then because we had this discussion yesterday I for my experience I\u0027ve never been in this situation but if you actually end up in a situation where you\u0027re the only ad for an area it\u0027s doable but it\u0027s it\u0027s a hard situation because you always come or you all over ever never again come and execute the situation where you have to make a decision it helps really to have somebody else you can talk to and you can also has the expertise and you can decide together in these kind of things so don\u0027t put anybody in this community in that situation if you can if you can have our disease yeah so and then it\u0027s this call to arms so to say so Emmaus term ends in March I plan to only do one single term so my put ends in March 2021 noncom will ask for typically ask phenomena surrounding us September timeframe so it\u0027s a great chance here run this year run if you didn\u0027t make it or if you come from this year run the next year so and if you have any questions of what this actually means to be an ad please go ahead and ask us so Tom so my impression of being NAB is it\u0027s a lot of time like almost a full time job can you comment on that because telling us to run is great but yeah you need some backing but it\u0027s it\u0027s there\u0027s different way of running this actually because I would say there\u0027s if if you select offload not a maximum amount of work and all the focus on the most important things of which you can\u0027t offload there might be some potential for doing this seem like you I would say one maybe one to two days a week that\u0027s about what you but we\u0027re trying to do right yeah keeping my time very much to 40% which is I was really looking for that not not any more next year I can do more work but it is possible and it\u0027s another reason why it\u0027s important to have a second ad there because you all have a backup so even if you like go on holidays or whatever you miss you miss one of the teller checks you miss reviewing some of document you have a bag up there say it is possible "
  },
  {
    "startTime": "00:27:42",
    "text": "but it also means you need the more time you have the more you can participate in the things you want to participate in and the next time you have you like have to do the Bailey today you didn\u0027t business right but yeah it\u0027s I mean one of these tasks are actually like looking at the other data documents that comes through I mean those part of those tasks can really be offloaded exam to review teams etc and if you trust them doing the right thing you can basically ballot based on their input I mean I think I def here does that basically fully on based on your not so okay yeah all right thank you good afternoon everyone my name is David skinned Ozzy I work at Google and I\u0027m here to talk about masks so first of all apologies for the very convoluted acronym but turns out of all the cool kids are having cool acronym these days so why not so in terms of like where this is at this is a very early thought experiment I put it in draft form because that\u0027s the best way to get ITF entities to read anything but like my goal is not to publish this in its current shape in any way shape or form it\u0027s more to kind of ping people on the concepts and see if a is there interest in this kind of work and B am i is this completely crazy or am i doing it horribly wrong so I already presented this yesterday in second dispatch to really focus on the security aspects because apparently according to them following cryptographers on twitter doesn\u0027t make me an expert so it\u0027s worth getting them to check and conversely following transport experts on twitter doesn\u0027t make me an expert either so that\u0027s why I\u0027m here to make sure I\u0027m not gonna break the internet as we\u0027re saying these days all right so what is mask about as I\u0027m sure a lot of you have been following the news internet censorship is definitely on the rise and either state actors or company product companies providing services for state actors are becoming more and more resourceful and clever about the ways they prevent people from accessing content so in some cases we can think that ethically that\u0027s not great and I personally feel that there should be a way for some people to access things that maybe they\u0027re not allowed to in "
  },
  {
    "startTime": "00:30:44",
    "text": "particular these state actors have been very effective at blocking domains so they their specific content that they don\u0027t want people to connect to or they want to log if they connect to it so what\u0027s been happening a lot recently is looking at the s and I in TLS because that there\u0027s more encryption on the internet that is the part that still really sticks out but they\u0027ve been also very actively blocking any kind of technology that allows you to circumvent that mainly VPNs or yes and I which is encrypting the SI similarly doe dns or yes is being blocked as well and the kind of fundamental properties is anytime there\u0027s traffic that doesn\u0027t look like regular web they block it and the reason for that is the web is still a huge huge place there\u0027s a great many number of websites we want to keep it that way but also makes it untenable to have a whitelist for government because there\u0027s always going to be a perfectly fine website that they\u0027d haven\u0027t heard of so they\u0027re relying on blacklist to specific things that aren\u0027t allowed and then heuristics so that\u0027s kind of our in here of using the fact that my personal website is probably on though not on any blacklist yet and maybe I could hide a VPN on my personal website I hope at the end of this talk my personal website doesn\u0027t end up on a blacklist but if I were to run like v2 IPSec for example on it that\u0027s noticeable that\u0027s why I end up on the blacklist so what masques does is to make it so that my https website which exists today can also be used by me or maybe say my friends there\u0027s a VPN in a way that doesn\u0027t stick out so terms of threat model we have an attacker that\u0027s really powerful so not only can they watch everything that\u0027s going bye-bye they can also attack so send active probes there\u0027s prior art showing that some of these networks will see connections go by and then probe the server at us saying oh do you speak this VPN protocol and if the server says oh yes I do then they add them to the blacklist so we want to protect against that so your list of requirements for what mask needs to do to achieve its goals so the first one is kind of from the passive perspective this looks like HTTP 3 quick it doesn\u0027t stick out its the same sni as the website it\u0027s the same LP n no funky just client extensions or quick transfer parameters since all those are sent in the clear another one is you can\u0027t detect the server by probing yet so if you send it like a regular HTTP request you\u0027ll get the webpage but if you send it any kind of VPN message without the keys then it just says oh I don\u0027t know what you\u0027re talking about I don\u0027t have that swept page or I don\u0027t speak this protocol and another one is because more and more "
  },
  {
    "startTime": "00:33:46",
    "text": "like lot of these networks blocked quick and UDP we need to be able to fall back to HTTP to over TLS which is still getting through the intranet today in those scenarios your VPN performance is not going to be great but that\u0027s something we have to live with all right so the authentication mechanism I\u0027m going to kind of gloss over but see the presentation from yesterday but basically the client sends a request to the server with a special signature on a TLS key to exporter and that gives you the property that the first message for the client-server authenticates the client without requiring a prior kind of requirements and a nonce on the server and we also rely on just a regular web PKI TLS search for the other side of the authentication then once you\u0027ve established that so indeed I am David talking to David server then you can negotiate mask features so in particular what you want to do the most common one is an HTTP connected proxy though I want to talk to a bunch of other web servers and so you negotiate that feature you can both go there Lars clarifying question yeah if you want to tell me to wait that\u0027s fine so I was wondering a little bit what the previous slides we talked about that properties of the system you\u0027re proposing so it seems to me at least not having thought about as much if if I would like to detect something like this I could simply look at spikes and traffic to servers like I\u0027m guessing at your server my server don\u0027t get a lot of traffic and if they\u0027re now hosting a VPN no matter how right that net volume is going up so is this meant for servers that are busy enough so that the the increment that mask would put on them is in detectable or so that that\u0027s one option otherwise what I personally had more thought of is that the math server would be in a different jurisdiction so for example let\u0027s say the government of fake guns fake country is stan is being really bad to its citizens the math server is say here in the US back home in the US and I\u0027m sorry it\u0027s still jet lagged the government be able to tell that all of a sudden this URL that isn\u0027t local it\u0027s getting a lot more traffic than it didn\u0027t like last week and no so the idea is to have so sorry I guess yeah I completely forgot to say that in the introduction it would be to make this very like small localized deployment so for example I can put on my personal web server give it to like four people and so on and so far so like small condos like this or maybe a big content provider could provide that service before the argue next to theirs but then if it becomes kind of public let\u0027s say this big CDN is providing this they might get blocked so I was kind of hoping to you know fly under the radar of that aspect of detectability I think somebody who is on the transfer person needs to figure out a bit more seems "
  },
  {
    "startTime": "00:36:48",
    "text": "like you might still be detectable simply by the by the change in volume towards some of these domains true but you would also have a for example if someone writes a blog post about quick is how quick is gonna blow up break the internet there\u0027s gonna be all sudden increase in uh in traffic so I think that might that might be okay is Dave David black calmed I hope you got me talk to security folks watch out for that fallback mechanism security gremlins work there and that\u0027s a topic for for another session app absolutely and that I\u0027ll show you is a really common one between the fallback between HTTP three and HTTP 2 so that\u0027s not specific to mask off compared to telecom the point or is that has been raised about statistic analysis of encrypted traffic is quite real it has been used to unlock voice over IP traffic that I have some subsequent slide about that so where was I oh yes feature so connect proxy so there you can use it to talk to any other web server on the internet so the main use case would be usin HTTP connect request for port for three server creates a tcp there and then you do TLS end-to-end because an important property is the mast server doesn\u0027t see your clear text bytes if i want to offer this service as to some friends to help them i don\u0027t want to get their passwords but also that works for any tcp protocol so the client can access any tcp server another one is do-- less can say hey I support doe so in part of this tunnel you can just also make each yes where she PS requests another one is UDP proxying so this is starting to get more into in a transport world most with the exception of DNS most udp-based transports on the internet today send a lot of packets in the same connection or session meaning for the same 5-tuple in that case the optimization here is you negotiate with the mass service saying it\u0027s think of it like Sox V Phi of UDP its I wanna I\u0027m gonna send a lot of packets to this IP and port and the master says alright I\u0027m establishing a flow for you there and then you can send quick data grabs with a slow identifier and anytime the server sees them it sends them over there and vice versa so that allows you to run quick and to end but also web RTC DTLS any UDP kind of connection based as opposed to responsible quality NSS but any connection based protocol for this and then for any protocol that is not covered by any of the previous mechanisms you can have a full-blown VPN here or you just send send quick datagrams with just a full on IP header and then the processing is exactly the same as like the inner IP address ESP payload for IPSec for example and then "
  },
  {
    "startTime": "00:39:48",
    "text": "on the server side you can either send them through or not them to kind of hide the client so absolutely traffic analysis is a big problem like can\u0027t just and wave it away but I am no expert there and with it when it comes to privacy it\u0027s impossible to come up with a solution that solves like everything there are no silver bullets so what I\u0027m focusing on with this work is at first to kind of kill all the things that are clear text that are really like easy to detect today to really raise the cost of mounting an attack to raise the cost of how much processing power how much money it is for this state actor to detect this traffic and also one of the great things about quic is that you can put a bunch of streamer Datagram frames in the same packet or you can also add a bunch of padding to packets so that allows you to have for example if you have a pattern of how you know your traffic is gonna look like you can feed that into let\u0027s say the the math server and it just doles out packet to kind of follow that shape so but that I haven\u0027t done I\u0027m no expert there and I\u0027m hoping it can be some mitigation for traffic analysis another cool idea that someone mentioned right after my talk yesterday which I thought was really cool is that if you have multiple mask servers and you have an end-to-end quick connection to an end server up there you can use quick connection migration to switch between the mask servers so mid connection you end up swapping from the service perspective oh you just had a night rebinding you\u0027re just over here now everything keeps working but from a network attacker assuming that the mask servers are outside of their control and their administration they have a much harder time doing traffic analysis because they just see kind of slightly less correlate about traffic again not a silver bullet but the goal here is to keep making it harder and harder then a problem that Rosa came up for this yes Collin question yeah question on the previous hi Colin Perkins so obviously this this affects the timing or potentially affects the timing and some of the Dex chrome applications you mentioned are real time applications you may want to consider separating Datagram in real time in traffic so you can do the OB obfuscation differently for the two cases perhaps trade off real time behavior for easier to detect behavior which would of like allow you to know this is not real time so you can obfuscate typing so just to clarify you\u0027re saying that like some traffic that is less time sensitive we allow it to be delayed and hidden better whereas "
  },
  {
    "startTime": "00:42:49",
    "text": "the one that really is time sensitive we take the privacy risk but still have it kind of invisible or you you at least give the applications the ability to make that trade-off rather than enforcing one particular behavior which would then be suboptimal for certain types of application absolutely then it becomes actually the bigger question for this group is how does the application talk to this is there an API from the service perspective the server doesn\u0027t even know that mask is involved it\u0027s just a it\u0027s just a middle box just a friendly one from the client perspective if it\u0027s behind like VPN software that\u0027s in on the device they might not know either so that might be I do agree that that would be great but actually if people have great ideas for how to do that that would be helpful yes pop all right Oprah\u0027s go when you\u0027re when you\u0027ve got going clearly all the the requests the URLs and all that\u0027s written can be different within what\u0027s being requested and then that that\u0027s difficult to see but I\u0027m thinking of someone looking in the middle of the path but traffic and sorry just in the middle is on the client side of the mask so on the other side on the evil the attacker yeah yes and a sub point I don\u0027t think you should call it a state actor because you can\u0027t just define the only bad people as state actors because other bad people can do things as well anyway absolutely and not all states are bad actors yes not all bad people of states anyway the point is if I if I attempt to start off the same way as mask but without the mask you know I just accessed the same website as some other traffic I will be able to tell that there\u0027s a different amount of traffic coming back then in a simple request and in the mast request so and so be actually I would because we have more stuff want to disclose right I would take like the detailed traffic analysis question maybe offline at this point thanks it let\u0027s chat after and but the one-word answer is padding maybe not good enough yes all right so one of the issues here is that familiar with any kind of tunnel or VPN is overhead which can cause MTU issues so again we don\u0027t we still don\u0027t have really good ways to do path MTU always over the Internet so hopefully the two peers can kind of communicate and we have some awesome mechanisms for that on what is there so "
  },
  {
    "startTime": "00:45:49",
    "text": "they don\u0027t kind of overwhelm the tunnel yes I did it um Tony owns and we do have a good mechanism for doing path MTU discovery for tunnel endpoints it\u0027s called DP rpm tud so we can do it across the tunnel it\u0027s the stuff you\u0027re tunneling what is the problem but yeah that\u0027s something to talk about one absolutely yeah no but I agree for the tunnel itself yeah that that is great oh and then kind of actually a little bit what colin was saying the probably if you run it like it should be connect and you do TCP between the end server and mask and then quick between my and the client you have conditioned controllers one against the other everything\u0027s fine but if you unclick over mask then you have one kadesha controller on top of the other and there\u0027s no easy way around that because by design quick hides all the cognition control information inside the encryption boundary so that\u0027ll be probably like one of the rising challenges of this and many other proposals I think hey Cohen Perkins there\u0027s an easy way around it but this grouping are like kids so I\u0027m disabled just control on the tunnel that means it\u0027s implemented in user space right absolutely and I\u0027m gonna use that to plug game to not plug something never mind anyway there are discussions on quick datagrams and how they interact with code gesture control that is a topic being actually researched right now because it\u0027s not trivial what the correct answer is if it blocked basically on a second Collins remarks both that just having one congestion probe is much easier to figure out how to get to to interact and it is gonna be really really tricky to get sufficient assurance that this actually actually a higher level in higher level congestion control loop operating absolutely thanks Andrew McGregor at some point someone is going to have to since solve the mystic indicial control problem there have been some recent math papers published which actually give me some hope that the problem is solvable but it\u0027s myself yet could I ask you to share those math papers I\u0027m generally curious or I suppose the list is as well certainly I can track them down and post some ones Thanks it brings me to another question where do you want to have the discussion continuing actually which is perfect segue into my next slide so yesterday at the end of sec dispatch Venkata security ad suggested that maybe having an IETF mailing list for this particular topic would be interesting and they seem to be interest in the room so could I take a quick poll of the room if we were to create a mailing list there who would be interested in joining raise your hand Oh awesome thanks yeah I think "
  },
  {
    "startTime": "00:48:51",
    "text": "that sounds like a good next step because this is very early I and again please 120 25 no thanks so yes I\u0027ll take the action item of making sure this lists happen and I will announce it on TSV area but yeah if you find this interesting please come and reach out to me or if you think I\u0027m a terrible person and I\u0027m doing it wrong please also come tell me that\u0027s even better all right Aaron and now we\u0027re open for any kind of questions this is very quick I think this is a really interesting idea I just wanted to let you know that um BBN had several folks working on this I think under like a department state contract and this it predates quick and doe and so their solutions are probably pretty different so but I\u0027m trying to get some links if there\u0027s anything they published and I\u0027ll send those to you in case there\u0027s stuff that you can use Thanks that would be incredibly helpful mark Nottingham I would encourage you in this work this is a little deja vu for me because we had a very similar proposal for http/2 at the end of its lifetime and and the threat model and the requirements were very similar no no discriminators in the wire being able to you know have plausible deniability and that didn\u0027t go anywhere but the I guess the the higher of it is that there was a community that was very interested in that capability and I still get emails about that occasionally so there\u0027s definitely an audience for this I don\u0027t think it has to be deployed on big CD ends or huge websites I think the the property you\u0027re talking about or I can put it on my web server for my friends is really cool and I think there\u0027s definitely an audience out there for this so so I\u0027ve encouraged to continue having said that although you\u0027re talking a lot about quicken about transport you are creating an HTTP extension please engage in that community to make sure you do that doing that well and we\u0027re member that to work well this needs to be implemented in a webserver and in commonly deployed home grade web servers not just gee whatever it is today so yeah absolutely my ideal scenario here is that there are packages for all the open-source web servers you can just easily install and then send your friends some keys and a nice little clients from my iPhone and from my desktop fact if you cook could ask you to send me or the list a link to that the work that wasn\u0027t it should be too yeah yeah it was a thought experiment it wasn\u0027t really serious but there was based on the response to it it was interesting also and there could be good ideas in there too I doubt it but yeah okay thanks hey there bloody mural tunnel so HTTP has the protocol upgrade functionality maybe we could use that to upgrade the HTTP to Sox and that would kind of take care of some of your use "
  },
  {
    "startTime": "00:51:51",
    "text": "cases so actually this is literally how this works it\u0027s an HTTP connect with protocol thing so it\u0027s the same way that WebSockets or HTTP 2 works hello Alexei did you already made aware of pluggable transports which the protocol is using and because they also have some mechanisms to hide these or hide the Onion Routing traffic as HTTP traffic I think you approach is new as it\u0027s touching new protocols like quick but but they already had some prior work through this that I am not aware that could I ask you to send me a link please yeah sure thank you so much all right thanks everyone and apologies for going over time right stirs good so the intent of this is to start a wider discussion about logging in the ITF comes with a bit of a disclaimer I\u0027m very very new here I mainly do hb2 and quick stuff so I\u0027m probably going to make some mistakes here I\u0027m very much looking forward to your pointing out those mistakes at the end presentation interrupt you for one sec so we have three presentations in the same space so we were running over time already even but so if you have clarifying questions um if you have like want to start a broader discussion we should do it at the very end I think yeah so in the beginning there was HTTP - and its core proposal is that you can now multiplex different resources of a single TCP connection to be able to do that you need some kind of a scheduler and the RFC specifies to just use round-robin for that which is also on the slide you could also imagine doing something purely sequential or maybe a mix of two so we started looking at age two implementations to find out what they\u0027re actually doing and for that we were using Wireshark and it should come as a surprise to absolutely no-one here that that got quite tedious quite fast so what we did was take the peak apps out of there and make this kind of a visualization so this is a timeline where each of the rows is an individual HTTP resource and the blue squares indicate when data is being sent for that stream so here we can very clearly see number one gets a little bit of bandwidth then number two number three all the way down we go back up again all the way down again very clear example of "
  },
  {
    "startTime": "00:54:51",
    "text": "a round-robin scheduler HP - this is done using what they call a dependency tree where the nodes in the tree represents the resources and siblings share bandwidth based on a very simple waiting mechanism so this is quite straightforward but this mechanism allows also more complex setups so we also have this visualization this is what Firefox is doing by the way you can see this is again a timeline because this tree is not known up front it is built nodes are added when the browser discovers new resources and are removed when those files are fully downloaded that\u0027s kind of what our problems in because hb2 only sends on the wire when nodes are supposed to be added not when they are removed so there is no full state sync to keep this tree up-to-date on two sides so previous visualization kinda has to hope that the server follows the spec the problem is that the spec literally says it doesn\u0027t have to borrow ties Asians are more like guidelines not rules for good reasons but so to actually try to deduce what server is doing you have to fall back to the first time line and try to manually assess what that does and this problem became very painfully obvious just a couple of months ago when a more generally usable tool set integrated this so this is webpage test and they updated their waterfall view and the opaque bits here now clearly identify when hb2 data comes in using this usable tool people then started looking at what our CBN\u0027s and hosting providers actually doing and the results are actually quite terrible and if you can start the video maybe we can see what actually what it looks like if they do it wrongly so these are both Firefox but different servers and I think we can very clearly agree that the right side the correct side is a lot better for the end-user experience than the erroneous left side of the thing so this is kind of the state this is kind of the state of HP - about three years after standardization which i think is kind of terrible my tsys is that this would not have been the case if this kind of tool would have been usable at the moment of implementation at the moment of deployment people might have been more rigorous in testing these cases instead of deploying this kind of behavior so have you learned from edge to the wire image itself usually doesn\u0027t contain all the information you might want to have for debugging and this kind of tooling is actually kind of useful in practice so that\u0027s a ch2 and then of course this happens and I\u0027m only like half joking here because quick is exceptionally complex and not just that and ice is that what "
  },
  {
    "startTime": "00:57:51",
    "text": "what they really said is you know we\u0027re going to take all this complexity and implement it from scratch you know believe it or not there is even an idiot doing a quick implementation in JavaScript so we quickly identify this you know this is going to be a problem so we started porting our visualization tools over to quick as well only this time we\u0027re not using the peak apps because there\u0027s a lacking information we are now using endpoint logs directly so we updated the timeline it\u0027s now very easy to compare different implementation behaviors so if you had three different implementations the same test case one of the streams is being blocked by flow control the top implementation does not care just keeps on sending the second implementation uses quick feedback mechanism using a stream blocks frame to try to get more flow control allowance but it\u0027s exceptionally aggressive in sending the feedback that\u0027s our one just doesn\u0027t do anything it\u0027s just it\u0027s okay I\u0027m blocked I will just wait around and see what happens no feedback so this obviously should not happen but this kind of tool really helps identify what\u0027s going wrong with different implementations a new tool at me Anna was a sequence diagram quite special here is is that we actually combine two locks from two Fanta spots if both the client and the server log this allows us to very accurately display things like latency we know exactly what latency was on the network but also the links he introduced by processing at the software stack this also allows us to show things like reordering very easily you just look for crossing lines in the sequence diagram it also allows you to very easily see things like wherever packets Ashley lost and then also how are those lost packets we transmit it now in TCP this is relatively easy not so in quick and quick at least what happens is you change the packet number Kairi transmit the worst thing that happens is the packet is completely broken down into smaller parts less parts can be retransmitted in different packets later so if you want to try and debug that and keep track of that you really really need those endpoint locks and the good visualization to be able to do that last one that I\u0027m going to talk about it\u0027s too complex to go over here old ones just focus on a big red arrow because you were also logging things like congestion window and bytes in flight again things very useful for debugging but typically not visible on the wire so what have we learned from quick using multiple vantage points very interesting I\u0027ve shown you now clients and server but you can definitely imagine having several in-network measurements as well let\u0027s say a load balancer a proxy server that kind of stuff to get a full end-to-end overview in this single tool the problem with this was we are basing ourselves on these endpoint logging formats how that was in practice is we wrote custom parsers for four different quick implementations and I\u0027m going to "
  },
  {
    "startTime": "01:00:52",
    "text": "show you a quote of one of the students that helped me with this and he\u0027s right yeah even within the same tool there are inconsistencies so this is one of the quick implementations six lines the top view of our ecv which means receive then you have our X which also means receive and then you have our CV which very predictably means recovery all right so try to strike that so that\u0027s the point where we said okay I don\u0027t want to do this anymore that\u0027s try to make something that people can we use so we defined like a proposal for a standard logging for a quick in the idea that we can then just have all the implementations give us the same format we can store this in a database and then very easily create tools to just work on this single format that makes both the data in the logs and the tools very easy to share between implementers and stakeholders I\u0027m going to talk a bit about this format but I\u0027m not going to focus on a quick specific stuff I want to take more generic concepts behind it hopes that they are more broadly applicable so the first thing you have to do if you define a new format is the format and we could talk about this for the whole rest of the session probably but my opinion is it doesn\u0027t really matter which exact format you choose because it\u0027s quite trivial to write transformers that go from one of the format\u0027s to yell yeah I had yang on that first I took it out because I knew the line would be right so let\u0027s get this let\u0027s go to the interesting stuff as far as I can see there are two main types of logging that people were doing summary and event based so summary one is kind of interesting because it doesn\u0027t log anything until you request its logs so the moment you request a log it just sends you like a snapshot of the current application state and if you want to do more fine-grained logging you just up the interval with which you request these state updates this is actually what was presented for HTTP two in the beginning there is a nice draft about that that never really made it to its standard but most of the h2 servers are implementing this sadly there aren\u0027t many tools that also support this format the second up performant is what most people are used to it\u0027s a chronological log of events that are happening the simplest form of that is just a packet log this is for example what chromium outputs for the network stack and also the quick trace format so there\u0027s a second quick warning formats from Google that will be discussed in the talk after this one and they use this approach so our format is called Q log we chose JSON just because we are "
  },
  {
    "startTime": "01:03:56",
    "text": "creating web-based tools and that integrates quite nicely with JavaScript and we chose the event based type streaming because we want as much flexibility as possible to be able to do our debugging news cases now don\u0027t get too hung up about exactly what this is saying that\u0027s for the quick working group just three things that are more generic one we like to namespace the events with a separate category this makes it very easy to say I\u0027m not interested in for example the HTTP stuff I can just very easily filter it out or just not log that at all second very interesting thing is a fourth column there which we have called trigger but some other people are calling reason or calls the basic idea there is that you can have the same event but it can be triggered by various different things for example here you have packet was determined as lost and is being to retransmitted in quick that can have multiple causes why this packet was deemed lost and so usually you can infer which of these it was from context of the rest of the log but it would be interesting if you have more explicit indication of that as well interestingly cue log and quick trace the Google format were developed in tandem without us knowing anything about each other and still both of the proposals have the same concepts of a trigger or a reason which i think is a very clear indication that google should hire me but also that it\u0027s an interesting concept that we might explore a bit more the final thing fantasy the final thing is the actual per event metadata we like to keep flexible as possible so we just keep it as a normal key value based JSON object or we do like to keep the keys even though it has a little bit more overhead but it\u0027s a lot more explicit so I\u0027ve talked about event based logging and you there are kind of different granularities that you can go into it into for that so the top one is what you\u0027re probably used to it\u0027s a simple packet lock and you log everything that\u0027s in the packet or the packet header the one below that shows the exact same data but it extracts a new type of event from that so here in quick you have a connection ID that\u0027s in almost every packet it doesn\u0027t change all that often so it makes sense to extract it into a separate event I\u0027m kind of hoping at the quick people in the room have started noticing this but this is actually a log of a buggy implementation in quick the clients proposes a connection ID server usually overrides that with its own connection ID and the client is expected to immediately switch to the server\u0027s connection ID as soon as possible that\u0027s not what\u0027s happening here the client is only switching to that new connection ID after the during the handshake face not during the initial phase just to make that more "
  },
  {
    "startTime": "01:06:56",
    "text": "insightful the bottom one is actually what you expect you expect this change to happen at the third event not at the fifth one and this might seem like a bit of a strange example but I included it here because this is literally what I encountered a couple of weeks ago so I am the guy doing the JavaScript implementation and apparently we had this bug in our implementation of quite a while and just by adding this kind of more fine-grained event based logging I was immediately able to see well this new connection ID event is happening way later than I would have expected I immediately found a bug because of that so this has a lot of advantages it also has disadvantages in quick packets are raised up over the smaller frames you can imagine implementation creating those frames upfront putting them in some kind of a temporary buffer and then only taking them out when it\u0027s actually time to create the actual packets on the wire that means you have a kind of a disconnect between frame creation and packet creation so the question becomes which frames are actually in which packet it\u0027s almost impossible to see from this side of log you could say here we look at the size that doesn\u0027t really scale what you could do is log a frame splice which isn\u0027t very efficient but you could do is not slog the frames when they create it\u0027s only when they are being sent on the wire which is what quick raised us which you lose a little bit of the buffering concept but you have more insight into the network you can also just keep it as this this is what chromium does in its net log you keep more insight in how for example memory is used less on how to network so this is kind of a different balancing act depends on your use case and I\u0027m not quite sure yet what the best approach for this is is don\u0027t open question for me so one of the key tenets of Q log is to be flexibility I really want to see I use usable that people can also add their own type of events their own categories of events as well that it can fully replace what they currently have is a logging solution which is quite trivial if you don\u0027t want to share or use these logs in other ways it\u0027s very easy to just rip out those custom categories but the foreman also allows is it\u0027s easy to combine different logs so if we step away from quick for a second we can imagine a kernel TCP stack logging we want to combine that with http information from the user space level this should make it relatively trivial to integrate those two together one of the consequences there is the tools should keep this in mind they can\u0027t expect logs to always have all the information they want conversely what the tools can do is say you know I will only work correctly if I have these categories these type of events in this type of metadata you can even validate that upfront when you\u0027re given a file so you keep a lot of flexibility and at the same time qbv very explicit and what certain tools will do which i think is a very nice combination of things so we "
  },
  {
    "startTime": "01:09:59",
    "text": "have these nice fantastic event based flexible logs where are we going to get them for actual processing and visualization one of the things I really like about HP - proposal is that they said let\u0027s use a well-known URL so they said you go to this URL and just get the logs for the current connection that you are on I propose to extend that to also be able to get the logs from all the connections that are currently on the server or at least maybe the most recent ones that\u0027s just on the server go also on the browser side this would again allow tools like webpagetest to go like I do a run I automatically fetch the client side find its point the server side combined - into a single log and present this to the visualizer it\u0027s also scales very well to something like a interactive debugging concept or maybe you have a server that you are tweaking some parameters with you can just stream all these events as they happen over a speed based link you can have a very nice visualization coupled to that as well now I can see some of the security minded people in the room squirming a bit on their seats because exposing all of this interesting laug state at predictable URLs is not the best idea I\u0027m definitely no security expert but I can see that there are several ways that we might make this practice practical in practice to be used but not be completely safe it might not be usable in actual large-scale production environments but especially there I think enough options to make this safe enough to make it usable in practice so in summary what I think when we do logging nowadays we mostly stay be above that conceptual line I think everything below the line is definitely very interesting as well especially with something as complex as what we\u0027re doing nowadays so we should be adding this kind of stuff as well especially talking about quick we have some inter up between the current quick implementations it\u0027s my opinion that there will be large issues trying to actually bring the current implementations into actual production settings I think the people doing that will eventually succeed because they\u0027re very smart but I think it might be a lot faster and a lot easier for them if you would have a standardized logging and the tooling toolset I\u0027m also currently running a survey on quick which are all cordially invited to fill out and which we asked which of the quick features are most important for your specific use case one of the features we asked about is standardized logging you can see that a lot of people seem to agree that this is an important aspect continuing with quick final slide I promise what I think we can do in ITF is create recommendations say these are the types of logging that you might be doing and this is the situations there it might be they might be interesting this is the way you could expose them for automatic "
  },
  {
    "startTime": "01:13:00",
    "text": "processing and how to keep that secure maybe we can even make like a sort of high level schema for people to match their own things and I don\u0027t think it\u0027s very useful to go super low level in the schema and then have like you have to register new categories invent types witch Ayana or something like that I don\u0027t think that\u0027s workable in practice what do you think is that the IDF should say you know if you are starting work on a new protocol or protocol extension you were expected to have a logging plan you are expected to have a logging document and early implementers are expected to implement this type of logging at least to some degree so that when you\u0027re finally done with all the work you have kind of a sort of basic tool set and interoperable implementations that you can then start to debug with each other Excellus yeah the instruments do you have clarification questions discussion we take off to the next presentation all right that was it for me yeah thank you first this was a great presentation a lot of good points yeah so if you have if you have actually questions that would be great if you have comments you might just want to save them and Victor can you come up front Oh ready we have no clarification questions however we\u0027re just gonna go ahead and stay in line it will be another half an hour you have management accepts the risk actually while those lights are going up I did have a clarification question I thought Robin you said you did not want to talk about yang but your last light sources suggest exactly that request sure okay thank you very much that was a great presentation you might just come up front again later on for the rest of the discussion hello everyone my name is Victor Vasilyev I work at Google on quick congestion control and I was asked to give a presentation about what we use for tracing at Google and I intended for this to be a very big long presentation about all of the free logging formas would have and how I\u0027m only responsible for two of them instead of all free however fortunately for everyone here I got sick sometime in the middle of writing so instead of giant presentation I will only talk about the most important points answer about how quick tracing differs for TCP and those are our two points I want you to take away "
  },
  {
    "startTime": "01:16:01",
    "text": "but anyways let\u0027s start with this talking about what TCP does and like so why do we collect traces so the first question is why do we need traces and there are lots and lots of answers for all depends on who you talk to and my perspective is as a transport stack developer it is important for me to see information about when I send and receive packet to the about congestion control you can do much more with traces other than the bucket with version control you can debug flow control you can debug cases where you think you should be sending acts but you are not sending acts or cases when you are sending too many acts and just taking up all of your CPU but my perspective is I work on congestion control so everything I care about is going to be from that perspective there are many forms in which you can write traces but the main point of traces is Robin already pointed out is you\u0027re recording events that is something happens you write it down you write details about it and then you move on with your life until the next event happens in Europe and and there are many many layers on which you record events or to the reported connection level events you should record like opening closing connection and then those are two the main two different kinds of traces people are typically interested in are either stream level traces what happens when you write on one stream or other stream and why do you choose to write that particular stream at that time and this is important when you have a complex priority scheme and you want to debug that however G quick doesn\u0027t really have a priority team so I don\u0027t care about that so we\u0027re going to talk about packet level events that is events which are related to packets there are two okay there are four main types of events related to packets one packet can be sent to packet can be act and this is from perspective of sender free packet can be lost or retransmitted and we\u0027ll talk about the difference between those two and the number for event which nobody ever writes the sender can run out of data that is the sender can discover that there is nothing to send that event is surprisingly important "
  },
  {
    "startTime": "01:19:04",
    "text": "I\u0027ll talk more later about why so there are traces there are many ways to collect traces you can collect them at sender you can collect them as a receiver you can even try to collect them in the middle of the network you want gets much useful if you\u0027re debugging congestion control like me you\u0027re connected collecting them at sender because congestion is all something you do at sender so all traces I\u0027m going to show you are from the sender\u0027s perspective so in TCP you usually the way you start your tracing is you just take it you run TCP dump you get a peek at file you optionally remove actual data central wire because you presumably don\u0027t care if you\u0027re debugging TCP and this is how it looks like I\u0027m how many people in the room have seen this wonderful screen okay so some people can read this I can\u0027t nobody actually reads this in this format usually what you do is you draw a graph for this and there are many graphs you can draw you can draw a throughput you can throw good but which is different from sort but you can draw our TTE you can draw a loss rate you can\u0027t really draw your each sip window or you can draw a sinkhole 10 sequence graph and 10 sequence graph is actually test always the formation you need including all the preceding and is the only graph or actually concerned it with which is good so the way time sequence graph works is a test and x axis which is time that\u0027s easy to understand y axis is the TCP sequence number hopefully the tool you are using have subtracted the scenes TCP same sequence number so you can actually figure out some tools won\u0027t do that so you\u0027ll have to figure out where you\u0027re in the connection and so you draw so you draw a line where you send the packet and you can draw sent packet and you can draw acknowledged packets with two lines and those lines effectively tell you when you send and when you believe we got an acknowledgment from peers that thinks you\u0027ve sent were received and then sometimes you can draw a selective acknowledgments there are a lot of various ways in which you can draw selective acknowledgments our internal tool Google tourism in a very interesting way which keeps crashing my browser especially if they\u0027re like the worst pattern is when you receive a packet and then all even packets are missing but all odds\u0027 "
  },
  {
    "startTime": "01:22:05",
    "text": "packets are there then it definitely starts behaving very very poorly anyway so this is the most canonical way to draw a TCP transfer this is me uploading a file to Google Drive yellow line is receive window which is not important here for our purposes the grade line is ax and white dots are sent and you can\u0027t actually see them apart because we\u0027re zoomed out too far you can make wires make Wireshark tools if they are same diagram here if you zoom in you can actually see those bars or to send packets and the Green Line is the cumulative acknowledgment line okay now there\u0027s just an actually good idealize diagram of how to read that time sequence plot so the two important facts to notice about this plot is that so the slope of the line is the rate is the bandwidth for SEM line it\u0027s the rate at which you\u0027re sending your paging rate or even if you don\u0027t have do paging your sent rate say green line is your cumulative good boot ie the rate at which you\u0027re actually receiving data it\u0027s usable by application the horizontal distances are TT it\u0027s the distance between the time you sent in to ten years it and acknowledgement and say vertical line is your effective congestion window at that moment it\u0027s well it\u0027s not even the congestion window it\u0027s an estimate of your bandwidth delay product which is I guess the same thing it\u0027s your congestion control works well so how many people are familiar under have seen such graph and like and resemble thing okay good because I\u0027m going to talk about how quick oh and before we go further so this is what happens when you lose stuff you lose stuff you have to at time T we lose we receive a selective acknowledgement which effectively tells us it works as a duplicate a kid tells us which would rapidly returns me it\u0027s all dated is an SA and SB and this diagram is important because the quick diagram will look a little bit different so here you can see the cumulative acknowledgement stops at the point where we\u0027re lost and then you have to wait an extra round trip to returns me at all upset data to make use of SB to SC okay "
  },
  {
    "startTime": "01:25:13",
    "text": "so in quick the big problem is that we don\u0027t have a sequence number we have packet numbers and in quick we can take all data and we transmit it as new data and we do not returns with package one for one the way it usually works you declare data lost and then when you decide when the moment comes for you to decide what to write you first look whether you have data to retransmit emergence in the data there\u0027s a data and only after that you transmit new data so but we still can simulate this approach without velocity in and it will look exactly the same and situation without losses so the way you do it is you whenever you send data in a packet you look at all the stream frames inside the packet and USA in a sequence number which is not a real sequence number two every piece of data you return you you send so in case of retransmissions it\u0027s actually becomes more complicated and there are two things you can do one is whenever you retransmit data you go in the past you look okay when did I send the data and which sequence number I assigned to that data that I lost and decided to return it and you draw that accordingly and that looks like that which is actually just the same diagram and there are many problems so there are nice things about this the most important nice thing is this looks exactly like TCP the not nice thing is number one in quake you\u0027re allowed to not return speed data that you have lost so there will be situations when like data is never retransmitted because it was sent on a stream that got reset and once you\u0027re set a stream you no longer transmit data on that stream even if it were lost and our old tool we used at Google it was a TCP based tool it had a lot of trouble whenever things like that with reset streams happened the tool just dropped the drawing say at line like Jack line was just stuck flat at the middle of the connection for the rest of the connection so that\u0027s one of the reasons this doesn\u0027t work so there is a "
  },
  {
    "startTime": "01:28:14",
    "text": "second approach is that you just treat retransmissions as new data and actually the conclusion here the way the way you look at this situation is that every data is either ignore alleged or lost and once its acknowledge or loss there is no need to follow up with retransmission because so so this is this diagram of the CCP worldview and this is the same diagram in proposed quick world view note that there are no retransmissions the data gets sent and it gets lost and then some data gets sent again and you can see there it\u0027s wonderful pointer data may be ever transmitted here because ultimately is there if you think about this from quick world to you there is no difference between you retransmitting old data and sending new data because it\u0027s all just data and you can which allows you to pick priorities between those two it allows you to like decide in the middle the connections as that high priority stream is actually low priority and you don\u0027t even want to return smooth data that you sent once and I feel like this is so this is a important takeaway number one I want everyone here to takeaway is that in quick there is there isn\u0027t really such thing as a retransmission from congestion control perspective the event you care about is data being lost because as soon as the data is lost all of the congestion control implications of the losing data happen like you remove it from the all bytes you have in flight you have a loss event which tells you to scale your congestion window down or whatever your congestion controller tells you okay so the second important message is a you should whenever you do logging you should try to write down as match as much information for the actual congestion controller as you can and I will give you with couple of stories about why is this as good it\u0027s just as important and you should do this what information I\u0027m talking about the information so the most important information you can write down is your congestion window at least for Reno cubic and window based algorithms if you\u0027re doing DPR you also really want to "
  },
  {
    "startTime": "01:31:14",
    "text": "write down your pacing rate because pprs rate based you want to write down your bytes in flight because that number is very important for congestion control and it can be different from what you expect and it is very important to for all those numbers to be exactly what you expect because if they\u0027re not what you\u0027re expect you\u0027ll have bugs and very weird performance issues speaking of weird performance issues okay let\u0027s let me go and tell some stories about congestion control box were found and the most important and the most famous one is a cubic bug so the cubic bug is there was a bug in quick cubic implementation which was also a bug in Linux TCP cubic implementation which has existed for 80 years and nobody found it and the way we found it is so I was working as an intern at Google and I was trying to add rich logging to our log infrastructure and one day I not only managed to ruin security for that but I actually managed to run a production server for YouTube with set logging on and also very very first trace I\u0027ve ever pulled in I just we read through the trace and discovered that the congestion window at certain point of the trace jumps up to obscene amounts without any apparent reason so the underlying bug was that in a cubic cubic tries to brtt independence so the cubic equation is written in terms of congestion with though as a function of time and it is written with the assumptions that you\u0027re sending your data continuously however if you ever stop sending and then you wait for like five seconds and the new resumes ending what will happen is you will not in original cubic implementation you will be stuck at the point where cubic will saying that it has been successful is sending data for all those five seconds and it will be at the point where so a cubic curve cubic works is that it starts at the very bottom it tries to reach a plateau it spends some time it\u0027s at water and then it just decides that it\u0027s done and it\u0027s time to probe up and then adjust "
  },
  {
    "startTime": "01:34:14",
    "text": "skyrockets its congestion window and in cubic bag that part in the middle was skipped and it just jumped at skyrocket congestion window part and the only way we found it is we took that table and it was obvious in the very first race and it was at a dramatically positive in effect on both Linux TCP and especially on quick because in Linux there was a safeguard for against she went rising too fast and the quick version didn\u0027t so we\u0027ve got dramatic improvements in our transmission rate and you can see there is a blog post blog financing I the way I learned about that bug actually being fixed was I was no longer an intern and that\u0027s what suppose they read on the front page of hacker news and that\u0027s how I learned that the bug we found was actually fixed and was actually important the other success story is during development of beauty are we wrote I wrote codes to log almost every single parameter that VBR has inside of it in logs and that was very handy because bbr unless you know the state the trace will tell you very different story depending on which PPR mode you\u0027re on and even\u0027s a tcp bbr version so it doesn\u0027t so there is no way to do a rich logging in Linux kernel TCP but I know for a fact that TCP VB our team has similar tool and I think they have print halves into kernel logs which logs the current state and that\u0027s the ways they\u0027re tooling works because they don\u0027t have anything better but that\u0027s the second takeaway I want everyone to see is that you should put as much reach logging detailed congestion control information in your traces as possible because that\u0027s the way you find bugs all right so thanks very much I think that\u0027s a similar message like Rome was given us that like considered at the same time time I think and Brian we have one more short presentation I need to stretch my legs anyway I don\u0027t have any "
  },
  {
    "startTime": "01:37:18",
    "text": "okay so my name is Jericho and today with my colleague marker salar we\u0027ve been working on this from one particular angle and wanted to come here and talk about this and you know maybe together looking at a problem like logging from different perspectives who will help us end up in the right place on overall solutions and this is gonna be pretty quick so I have just a few pieces of background information like where are we coming from why are we thinking about this and from what perspective and then I have one slide about some recommendations on how to approach on this space and the first item is that Marx and I have been working on a piece of open source software that is initially was like measuring the quick spin bit behavior and was able to determine RTP from from those connections but also grew into a tool that you can use to measure all kinds of different protocols and their behavior RTT and some other parameters it\u0027s basically an in-network tool that sitting somewhere in the network node and observing traffic passing by and you can use it to determine some of this parameters like round-trip delays and you can used for network network debugging you could use it for research like you know thus you know this type of traffic behave well or you know what impacts of some some new algorithm or you could also use for operations like perhaps even raising alarm when some of the parameters are behaving oddly the other piece of background is that we are usually thinking about things in terms of a distributed system so so first of all we\u0027re obviously not thinking about endpoints or months we think about networks but you could also think about endpoints and network nodes together about but in any case of this like multiple places where you can get information about the particular situation and and you can combine that information in some fashion together and perhaps get more data than just looking at from one one data source basically what Robin was also saying the third piece of background is that like what have you actually been doing in concrete sense in terms of logging and such and that\u0027s really like the if you look at the piece of software that we wrote spin dump has three things to talk about one is how do you deliver stuff somewhere secondly what is the format of your data and finally what is so the semantics of the data or what what nature of the data has for our case when we do measurements somewhere we we either you know things can scroll on the screen or you can store it on a file for your research analysis or whatever we can also deliver it to a server over HTTP or HTTPS "
  },
  {
    "startTime": "01:40:20",
    "text": "basically posting to to particular URL and then the the format question so we started out with human readable texts and Jason are possibly adding binary format in the coming months or so and and on the screen you will see that it says in very end of this and we have like we track multiple different kinds of events we talked about event based mode earlier and this for us this multiple types of events like one is like now there\u0027s a new connection on quick or TCP or whatever it is and then this measurement events and and so on and so forth and then finally like the nature of the data it\u0027s not just about like individual packets necessarily you could also consider that like you deliver this batch of events like you give it a one event or batch of events or you could even aggregate information let\u0027s say over time and and then inform some receivers as well during the last second we received 1 million packets and average RTT on these types of connections was was let\u0027s say 12 milliseconds so there\u0027s lots of possibilities here and just not only the question of like what what actual format looks like so that\u0027s the background and then to my observations I want to make basically five statements and this has been arrested before by Robin and others that unification in logging our approaches and formats would be useful really useful for for interoperability and our ability to actually debug things for instance that\u0027s really essential so I flew support that the other thing I want to say is that let\u0027s consider different uses it\u0027s not just about debugging or not just looking at your consistent control algorithm or some other specific aspect there are many things that we could do with data from either in network or endpoints I mean in different situations whether it\u0027s doing some research on some some type of traffic network optimization debugging or you know many many different possible goals so let\u0027s consider that the third thing is that indeed it will be useful to combine information from multiple sources we\u0027d be very happy to do things that were we kidding for some reason purpose is to combine data from endpoints to with in network nodes and then the fourth point is that it would be like it was tempting at the beginning to think about okay let\u0027s optimize I want to have C bar instead of JSON and or you know protobufs or whatnot and that was very tempting but it on purpose held back a little bit because there\u0027s more to be gained by thinking about like depending on what you do like "
  },
  {
    "startTime": "01:43:21",
    "text": "think about it from the semantics perspective that are you delivering you know a million events or one event and let\u0027s optimize that first and then then figure out what that would be actual format this so so we\u0027ve tried to focus more on the bigger questions than the details and and finally particularly since we are looking at this from a network perspective and to begin with we don\u0027t have a lot of information it\u0027s it\u0027s you know all the keys and anaconda and so forth is hidden as it should be but but there is some informations there like IP addresses and so forth so we actually also want to think things like an immunization so our approaches that we can wherever we\u0027re measuring we can analyze the information already at that point and deliver that an anonymized data somewhere and then therefore there isn\u0027t like this huge data base anywhere that that would have ability to track like what is what did this IP address do and so forth so find that very useful and yeah so this is pretty much it so I think I\u0027ll do the rest of the time for discussion thank you very much yeah we open the floor now hi Brian Trammell um I want to thank the the presenters the area directors very much this was one of the better boss I\u0027ve been to in a while it feels a lot like a Boff and I\u0027m wondering if this is the point at which if which we can hum for the formation this working group because I am all about this uh it\u0027s a little bit of a joke but not really Oh awesome well let\u0027s just do it then no I\u0027m serious um I think you need I think I mean you do it or do you want Magnus to do it do I get it earlier if you do it okay no I think we actually I think that I think that I would be very interested in I don\u0027t even like ask her hands from the floor but I would be very interested in knowing who would be interested to do work on this I would be very interested in doing work on this I think this is something that\u0027s that\u0027s necessary for going forward in the future this is a good a good way to replace in a lot of the context that we\u0027ve been worried about a lot of the visibility that we\u0027re going to be losing when we\u0027re going too quick I will make an observation an observation anonymization is not helpful from research it is absolutely imperative anonymization is maybe not so much maybe not not not wait hold on I can\u0027t even triple negative that can i anonymization is also useful in debugging because when you\u0027re talking about investigating a problem with a piece of code um you might not want to say okay well only the people who can help me on this or people who are in the same authorization domain for access to potentially personally I didn\u0027t file information and so on I think that anonymization and how you do access control in this is actually something that will be key to having impact with us in a working group going forth and "
  },
  {
    "startTime": "01:46:22",
    "text": "I\u0027m actually answering all these questions if they\u0027re both questions uh the other thing that I would say is that um I think I see a lot of synergy between the type of architecture that URI is working on and what Victor and and Robin are working on I think that yeah it\u0027s not an either/or it\u0027s not just logging or just observation like one of these things is observability you know the system tells you what\u0027s going on inside it one of those measurability you can derive metrics from the packets as they fly past and I\u0027m really interested in the possibilities of of being able to unify these and sort of a unified view of things so I\u0027m super excited about this and yes I think we should form this working group and we should be not real Thank You Jenna and good so I\u0027m I want to call the sentiment that I\u0027m very grateful to the eighties and and to the speakers to for having come here and done these presentations one of the biggest concerns I\u0027ve had for quite a while now is is around tooling for quick because we all know that performance work requires good tooling and it\u0027s one thing that people are building in various forms in ways but it\u0027s really difficult for everybody to build really good tooling around this so having having some some actually combined effort and and joint work go into building tooling is super helpful I don\u0027t need actually happened yet but at least the fact that there\u0027s so much work going into tooling now is very very good to see just in terms of the importance of this for those who haven\u0027t really been looking at using tooling yet and note that as soon as we started using tooling in quickly for example we caught a bunch of bugs immediately and that\u0027s when I say tooling I\u0027m talking specifically about we integrated the trace for example and we were able to catch a bunch of bugs and still haven\u0027t got everything but it\u0027s it\u0027s super super helpful and for for getting good performance it\u0027s going to be absolutely critical and that\u0027s where a lot of quicks winds are because the promise of quic is in delivering better performance then you would get with HTTP 2 over TCP and to get there we need to have super good touring so yes I\u0027m totally on board as well and then I\u0027ve been talking to both Victor are in trouble and I\u0027m very happy to help with moving this forward into some sort of sanitized log format so that we can actually have implementations right to that and hopefully not yang Tom Herbert so I agree this has really been a very good presentation I do hope this work goes forward in some regard so that being said as a protocol developer I think this is fantastic it\u0027s obviously very powerful tools and we can make proto protocol is better as an end user this "
  },
  {
    "startTime": "01:49:24",
    "text": "is terrifying collecting data at clients at servers in the network being able to correlate them that\u0027s exactly what an attacker does so the page one of any anything like this should be what are the security and privacy implications of logging and collecting this data and if you cannot answer that question substantially insufficiently none of the rest of this matters so as an end user I am not willing to trade any privacy or security for the ability to help debugging or network operations so we can get past that I think it\u0027s great so obviously that\u0027s I think the core should be a core issue here Erik Kinnear Apple I just wanted to say that this is both very interesting and excellent presentations and as an implementer this is something that would be very helpful for debugging prior to deployment and I\u0027d be very interested in adopting to to make some of that happen whatever form the sense of taking to that end once we\u0027re talking about deployment I think comes back to a lot of what Brian was saying around how do you do anonymous ation and make sure that you don\u0027t have to compromise so I would be very much willing to participate in that and and try to help find a way where we don\u0027t have to make compromises for the security of privacy of the actual end users and Roberta firstly the privacy issues just have to be solved because this data exists anyway can be made to exist by instrumenting and implementation whether or not the original developer put it in there so it\u0027s just got to be done yeah I basically got up this exactly that I think a Malaysian is super important then we should totally do it but today the information that you can get at the endpoints with TCP dump is basically what you can get here for quick and so it\u0027s not it\u0027s not any different than Oscar for Owen had a question on this I have actually another topic of our internal um we had three presentations now about instrumenting quick um that\u0027s you know that Transfer Protocol that were is that the forefront of our minds right now some of them were like focused on maybe h3 over quick I\u0027d say it makes sense not just to look at h3 but quick as a generalized transport as well one question that we have to go into in the working group I don\u0027t have an acronym for you that we\u0027re forming right now is the to what extent with these logging formats need to be sort of like transport general right and I think a good thing to look into would be let us presume that TCP had been designed with a wire image that looks like quicks "
  },
  {
    "startTime": "01:52:24",
    "text": "great and huh you call it to the list but we need to get a list so Spencer can you give us a list oh we need an acronym no ppm the three of us are here all week so at least two of us at any moment will be able to approve that so Aaron Falk this is a little bit of a trivial comment and I don\u0027t know if anybody other than say Christophe will appreciate this but you know looking back at sort of the evolution of performance measurement I remember Tim Shepard presenting TCP plot and Matt Mathis talking about the web 100 kernel and way it really feels like we\u0027re living in the future here that this is so much more expressive you know and things have progressed so fast so you guys can complain all you want but things are a lot harder back in the old days I think this so this is my way of saying I think this is a really interesting and important work and in you know youth usual caveats of like trying to figure out what we should do in the ITF versus what people should do elsewhere seems like I\u0027m in favor of it okay thank you very much so so that was actually an honest comment that you don\u0027t need it well to get a working group right so I think what I really hear is that you want a way to continue this discussion with meeting this in the first place but then if you want also a venue like working group to talk about this then I think you have like we all together have to consider what the starting point is in which card which aspects are should be part of this working group I start at least denying that I I won\u0027t gently push back against that I think there\u0027s a lot of good work going on right now and I think a working group might have the exact counter effect of what you really want right now I think what you want right now is agility I think what you want right now is better tooling and integration with various implementations I think we want to drive work that\u0027s that\u0027s already happening we want to sort of give it a boost but I don\u0027t think there\u0027s a lot of standardization work that we need to do yet so to that extent I mean I think that that\u0027s the only work in here that we may want to do is integrating the the login formats or having a unified login format so that implementations do not have to spit out 15 different form of logs and that\u0027s something that at least for the first run is basically a draft it\u0027s not a working good so I I\u0027m gonna push back against that just because that that delays things but that\u0027s what about gory first and yeah I "
  },
  {
    "startTime": "01:55:24",
    "text": "don\u0027t think we have a charter so we don\u0027t have a working group we have an intention to do something so I bike Jana let\u0027s find space the ice you have to talk about this and let\u0027s find a draft it\u0027s what I wanted to see Ronnie Evan I like the presentation but there was some difference between the first two and the re presentation in terms of this scope and what it was covering and I think we need to to look at the what we want to achieve in the logging whether it\u0027s a general tool whether it\u0027s both of us specific around to deliver that information and I think we need some students ization on that Robyn marks I want to give a bit of pushback against Jana there I think the the quick specific use case can be split up can we kept agile and working next to a potential working group the working group can go broader it\u0027s exactly what I think you had in mind as well Nia by doing a more general presentation for me so we can maybe view the quick work as kind of an interesting segue and to get quickly it to get some experience of what we want to do as a starting point for discussion in a bolder working group but I\u0027m not sure and that\u0027s something I\u0027m not one to hear from other people is have how much potential do you see for this for things other than quick is it actually something that people want to see David wark wanted to support the idea of doing a structured log format of marginal assisted men\u0027s space the log formats are not all that good we have these wonderful tools called log scrapers sometimes this came up what you want sometimes they don\u0027t so I think just the log format would be incredibly useful I also like the sense I\u0027m hearing let\u0027s go solve the problem for quick and when we figure out how well it works and what what were good ideas versus not-so-good ideas the time then then generalize okay and before Spencer is allowed to run off this room I want to open the floor for like more general open my questions to the 80s if there are any and I will wait for like 30 seconds or maybe less okay then I have enough time to thank Spencer again and thank you everybody for the session and see you next time thank you all [Music] [Laughter] [Laughter] "
  },
  {
    "startTime": "01:58:30",
    "text": "[Music] I\u0027d have liked "
  }
]