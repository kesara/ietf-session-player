[
  {
    "startTime": "00:00:22",
    "text": "it. that's Hello, sir. You're absorbing. I'm sure there's something disturbing about that, but Oh, So We're you know, That's not a supported scenario. No. Why? No. to Some people have more than one computing device I've heard. there. Oh, probably. I think it's time. It is ready to start. Now let's go anyways."
  },
  {
    "startTime": "00:02:00",
    "text": "this is really sensitive. Wow. Look at all this transcribing that's going on. Yeah. Okay. So Welcome to the Jose Working Group. IETF 117. I think we're going to have a pretty concise and non controversial agenda, First, as a reminder, this is the IETF The note well applies. If you When you registered for this meeting, you agree to abide by all of our policies and seizures and rules. If you have any questions about any of these, please see. any of your co chairs or our area director? Our area director is going to be a little bit late to this meeting, but he is following belong, Just a couple admin notes I wanted to make. 1st of all, We didn't ask specifically for a scribe There is a notes page that's linked from data tracker Do we have anybody who's willing to be the primary person dropping notes in there? For small group, can anybody take notes for us? Thank you. Also, I will note that it would anybody can actually follow along and please contribute to ensure accuracy and completeness. I I have developed a new appreciation for this tool because last time, we've apparently forgot to submit our minutes, and I didn't realize it until we were doing the meeting time was super easy to go back and find the notes page and just upload them. So It's linked from data tracker. If you don't know how to find it, please shout, shout, shout, Second thing is, please I mean, I know we're a pretty small group. But if we could use the q tool, that would be great."
  },
  {
    "startTime": "00:04:05",
    "text": "please be clear, concise, and respectful, and please remember to act according to the IETF code of conduct. Are there any oh, and one last thing. Those of you who are old enough to remember Blue Sheets, Because you either need to scan the QR code here Or you need to or you need to scan this QR code and join the meeting. This is the equivalent of signing a blue sheet to sign into the meetings. And it's very important that we have the attendance of everybody in the room, both for the intellectual property aspects of an open standards group and also for room capacity for future meetings, although I don't think that's going to be So I'm gonna pass this around, please. If if you sign it to me, that doesn't that If you if you sign in a mid echo, yeah, Sign in to meet Echo either on your laptop Or use scanning the QR code. if everyone doesn't sign in next time we get assigned a telephone booth. So But but they have decided that in the secretariat in doing room counts, has observed that the number of people in rooms is greater than the number of meet echo counts that we have for each room, and that's why they have gone back to passing around a blue sheet. Next, This is our draft agenda for this meeting. agenda bashing, which is what we're currently doing, then we'll have we'll talk about the three drafts that have been accepted as working group drafts and have been uploaded to data tracker, then we have a new individual submission. then we have the rumor of an individual submission coming. and then any other business. Is there any agenda bashing? Nope. Nope, and then we will welcome David."
  },
  {
    "startTime": "00:06:00",
    "text": "So let me get your slides up. to share This is your web proof updates. Okay? and This is my first time presenting at an IETF. So I look forward to being in front of a jury of my peers. So I'm gonna give an update on the the set of JSON web proof oriented drafts we have. the adjacent web proof, proof algorithms, and proof token. at You won't be able to point it towards this one. Oh, yeah. Yeah. Yeah. That doesn't mean that it will actually work, but Yes. But we tested it a minute ago. My experience with these things is they have not reliably worked. next slide, please. So between 1 We had some editorial cleanups, things that weren't. Things that weren't quite coming out of tooling correctly. We've also pointed to the latest BBS work that's going on in the CFRG may very well be talking about it right now over there. We have been getting a little bit more editorial and feedback and comments on GitHub, which has been nice. Also, I've been working on the next postal, proposal, proposal, as an option to restructure things a bit. changes for 02. So we're now that the BBS Signature 3 is published. we're looking to fully embrace that. So the and Current text uses kind of a"
  },
  {
    "startTime": "00:08:01",
    "text": "Java Skip, JavaScript library based invocation for the the older crypto, that has changed since. both in how it's described and what it does under the covers. So we're updating the text to that. We also had you know, a programmatic generation of all the examples from text fixtures, those have kind of been hard coated for a while. So part of this effort is also to make sure that the examples are generated and correct. following other people's lead, we will probably also publish any secrets or public keys needed for people to verify those in the spec itself. Next slide. Things we're working on after a to multi payload stuff I'm gonna present. What are the resolution of that is incorporating 5 or 5 those changes, One of the possibilities there is in JWP that we structure, the presentation form to actually use that as well. We're still tracking the BBS work. It's one of the primary algorithms that we have used to describe that's But appropriate for our space. that isn't a, you know, commercial product, etcetera. They have a new work that's proposed, which is refound, so that current text, I believe, fuses a secret that you don't disclose. You do a proof of knowledge of that. to basically carry the message forward. This would be based on a a private key."
  },
  {
    "startTime": "00:10:01",
    "text": "And, also, there's been some interest and Alright. Please talk to me about because of equivalence. of this work and getting that started. this remote side. So not too much to update on. any questions? Just a quick question. how many here have reviewed the latest drafts? Okay. Is there a lot of activity on the GitHub repository for them? I know Brent posted a couple of comments that we already accepted. the GitHub repository as part of migrating. I also want to at triage existing issues. It's been there for a while, and I wanna be a little bit more around get a little bit stricter about triaging issues. Okay. I I was just curious about getting some momentum to get this moving because mailing list is pretty quiet and There's not been a lot of changes, but where I I personally would like to see once we have BBS described using draft 3, is to start seeing some application of this Just like with yeah, signatures and encryption. They're it's really describing stuff that's part of a larger application, part of that use. So we really need to start understanding how people would like use this. and make sure that we're building the right shape boat. Okay, thank you. Any other questions? Okay. Then we can move to your next presentation."
  },
  {
    "startTime": "00:12:02",
    "text": "Okay. JWS multi payload option. Thanks, Lee. So Jason, what proves today? describe a a syntax where there's multiple payloads Limited by Tilda. This is using the same one extra character we have in the Uralsafe alphabet. that's used by the basixty 4 slash unencoded payload option in more classic JWS It's also being used to augment JD Best messages for SDJobs in JWP, you have a protected header, and then you have multiple payloads that are limited by total characters, and then the the proof at the end. So this allows applications to represent multiple payloads. they don't have to necessarily compose it into something like a JSON message if it say one of the payloads is low resolution JPEG. They don't have to be a 64 encoded. in order to put it into another container or define a binary container. Proof algorithms works are the group algorithms in general want multiple payloads because they wanna have payloads be the unit that they operate on for things like selective disclosure, E EVENTUALLY PREDIC IT PROVES. which would be not releasing someone's birthday, but that they're over a particular agent. a point in time. application still have to describe what's in those individual payloads. And there's another JSON proof tokens that starts to give one possibility of A starting point for applications same as JOTS did for JT Gus and JWV."
  },
  {
    "startTime": "00:14:06",
    "text": "So the idea of multi payload option is to try to break that piece out of JWP and propose a way that all the existing database algorithms can leverage that to the limited syntax. So It's also an opportunity to more fully describe how that works. in that sort of situation. So it describes both the contact serialization and the JSON serialization. it describes how JDS signing output or signing input works for those classic algorithms. but it also starts to describe what we call a multi payload aware signature algorithm. which doesn't take in the JWS signing input, the basically the As a whole, it takes the constituent pieces. So the expect attempts to describe interactions with things patch payloads, that it doesn't really work or that it works interesting moving with unencoded payloads. and basically promoted greater reuse. between JWTUS And JWT. Here's an example. probably looks like a lot of examples you've seen, but non base 64 encoded header, with a multi payload true value saying that it's critical. the 3 payloads delivered by 2 Tildas. I put them on new lines. AND A signature at the end."
  },
  {
    "startTime": "00:16:06",
    "text": "Oh, the next will be on there. So there's not really that much new here. If you've read the existing JDP draft. since we're defining payloads as a a new key for this realization. that part's relatively straightforward, So the idea behind the multi k little wear algorithms is that I'm not taking those individual pieces as as octets, and operating on them. So this provides a bit of bridging layer between signature algorithms. that don't don't have additional operations and proof algorithms, which extend districtive. the older additional capabilities. for controlling the information disclosure. So the underpinnings of how it interacts, And I'd love feedback from very simple manners on this. So it depends on new multi payload predictive header It's similar to how base 64 coat false for unencoded. affect the validity of the overall complex serialization, for a algorithm that's find as being multi payload aware, the ideas that it's mandated to be true and thus can be admitted And the reason this works is because a existing implementation if it"
  },
  {
    "startTime": "00:18:00",
    "text": "doesn't understand multi people to wear algorithms. won't recognize the algorithm. that's being specified there. That's a unique strength. there's backward compatibility described as well. So the idea here is if I actually put get their backwards. Yeah. If I do base 64 and put it, falls, for running for the payload. than the signing input between the multi payload and the uncoated payload are the same, their Right? Provide identical? So an existing JPS library will be able to Take that data if you describe to crack your messages this way. and the payload with total delimiters would actually get passed up to you parallel. higher level for the implementer to deal with. So there's a a bit of a callout for backward compatibility using existing algorithms, like, say, e s 256, And we also describe how this works with attach payloads, and it's in particular, they need to be fully detached. So don't have a mixed mode where One payload is in the message, and the other 9 are are separate the applications expected to deal with all the payloads. They're not crafting a a serialization with merbation. So, primarily, the motivation is the the proof stuff isn't really leveraging the existing Jose stuff as much as I'd like. It's leveraging keys. It's leveraging I've protected headers and some concepts. and it'd be really nice to have the the two blended together. So as I said,"
  },
  {
    "startTime": "00:20:00",
    "text": "the proofs become multi pay a little rare algorithms just with extra capabilities as defined by adjacent group algorithms, and JWP describes how to present new forms basically to meet new application needs. Excellent. Some of this as well is making sure we don't have deep dependency graph. it was not to talked about excellent work, but it was mentioned earlier today that the SD JWT work there is a desire to not have it be jawed only. even though it's built on top of but have jot JSON payload to be something that's understood in 1st class because after all, it's really defining a a redaction system for JSON and how to reconstitute JSON. other than describing a couple of keys and that the base is an object. it's not really putting a lot of restrictions on the actual JSON body. I would hate to see people say, JSON proof tokens or something else that we've built on top of all is great. But internally, I don't need that. I just need it traditional signature or an HVAC This isn't even going to a holder, this is just data storage. and but I can't use any of this stuff because it all assumes I'm using an algorithm like BBS. Yep. Yep. Oh. So if this is adopted, this changed the structure of the existing document. So this would describe the forms. This would describe the concept of these multipayload to wear algorithms while"
  },
  {
    "startTime": "00:22:00",
    "text": "Jason White Cruz would start to describe the roles and capabilities of the the new proof based systems, the idea of issuance of presentation, Others are serialized how applications are expected to use them. Proof algorithms would describe these new multi halo to wear algorithms when they're proofs. So if someone wants to have a JWS just straight up signature that's multiply a little rare. don't need to use proof algorithms but this would describe how you know, what is selective disclosure, what is unlinkability what our predicate proves. The various different properties that individual algorithms that that we know they can have describe the security and considerations and privacy situations around those algorithms. with those particular property is. and describe algorithms that we know of that we we think are broadly applicable. and and stable for people to use for proofs. Next. Isn't that next? up there. whereas JSON proof tokens actually gets dropped down and just becomes basically a multi payload token format somewhat parallel with drops. So I can work with JWS or JWP. We're not riving how it works with JWE unless people find that interesting, interesting, interesting, interesting, interesting, interesting, interesting, interesting, interesting, interesting, And So we'll have similarities with jots for hope. but not yet. So it'll have similarities with JOTS"
  },
  {
    "startTime": "00:24:03",
    "text": "hopefully be able to reuse claim names for appropriate. There may be cases where it deviates And describe the various properties that with JWS. While, say, it's only really to talk about JWT. think that's would love to get feedback on this as a individual submission. It's very new. ask some of people saw it for the first time, when I submitted a couple weeks ago, some of them heard about it, this week, So feedback on what people think on kind of this proposed restructuring whether that seems appropriate, and then see if we can get working group adoption. Okay. or or Hi. Oresteel. So just on the topic of Jason proof tokens, Mhmm. of the things that's been sort of difficult about SDJOT is, like, the compact serialization, the JSON serialization, the structured suffix is Ford, just as a sort of a comment for this work, would be nice to be able to upfront know that we're gonna have support for adjacent serializations. We're gonna have support for compact serializations there's gonna be consistency around structured suffixes So they it fits into the same sort of ecosystem as the work that's been progressing for SDJot so that folks who are taking advantage of, for example, the JSON serialization SD JOT has that normal JOT does not have. are kind of aware that yeah, you got selective disclosure. now you can get unlinkability and you don't have to lose your chasing serialization, when you, you know, move to token format that that builds on this."
  },
  {
    "startTime": "00:26:02",
    "text": "just keeping them all in in mind. I'm not sure if that's in currently, but it's a request for it to be in. I'm happy to leave comments on the document. things like media type aren't there, there's definitely already lessons learned of the the checklist of things that we need to make sure we accommodate it for. and it is still primarily meant Most of this is still primarily meant for usage with group algorithms, things like VBS. ZK Stark Space approaches. We don't wanna preclude it from working with traditional algorithm. What's your It's great. It's the best thing ever, and it's not wasteful. No. It's am. We are already with JWS and JV have things like unencoded headers, headers, We have extensions where It is really nice sometimes to not have to figure out how toggle things together with dots until this So there could very well be scenarios, Going forward, as well where applications say complex serialization is great, but it doesn't. fit my data I'm not a huge fan of it. I wouldn't choose it, and a people 5555 But It is there. and it it's there for people to use. Go ahead. Michael? like to point out to Mike Jones if that's the proper use of the queue."
  },
  {
    "startTime": "00:28:01",
    "text": "Thanks. Blake Paroc here. dotdiane laughing here. There's some yeah. Exactly. There's some confusion net. Yes. Yes. We're seeing replace Peak WIP or whatever we're calling it these days. The no. I just wanted to comment on some of the unencoded stuff and where I particularly seen some interesting use cases coming up for that. and there's 2 different areas. 1 is in embedding material that's accessible from a structured data or otherwise standpoint for search engine retrieval. where you can verify that signatures are there and things like that, and that's just something that has coming up, and that we're seeing that more and more build a lot of crawlers. We're we actually are encountering that kind of in the wild, not just in images where we previously were seeing that stuff. The other area that that stuff has come up in terms of seeing unencoded data is in similar cases, but in terms of, like, product listings and plays. Right? So as we're seeing things around particularly carbon or product passport type language, having the ability to rep present in a well defined way. This is signed data signed by me. Here's some potential proof or information around it around, say, a certification that this has. does help meet certain regulatory needs. So definitely liking the direction the going, I'm glad you haven't precluded those cases of saying here's these on encoded JSON things. I'm not the biggest fan of JSON in general, but it has definite uses. So Yeah. And I actually have the same issue with unencoded payloads. in the Jose case. and it's more along the lines that There's not enough. application guidance of what's appropriate. So the You don't want it to become an envelope for I want to make a Document structure, I wanted to be because that was my requirement."
  },
  {
    "startTime": "00:30:02",
    "text": "and, oh, I can cram all this stuff in without bothering to sign it. there's the limits of how you should or should not use young unencoded headers, it it gets a little frightening sometimes when you hear someone. has used them and say, Oh, I hope they use them in a good way. But you can't really say I hope they use them in the right way. So you use them in a good way. there's a difference between unencoded payload AND UNPROTECTED HEADERS. Sounds like we might be mixing them up a bit here. Unprotected headers are really great for smuggling or kinds of information along with the integrity protected information including information that is protected in different mechanisms. So for example, in the cozy use cases, counter signatures go in the unprotected header. In the skit use cases, proofs of inclusion for verifiable data structures go in the unprotected headers. if your base secured serial serialization doesn't have a unprotected header bucket. than those other sort of extension points a protocol person is looking for are are not you're not able to sort of pair them up and it leads to the sort of issue of, like, well, I'm not gonna call what I'm doing a Jason Webtoken because I have no unprotected header to put my extra. favorite stuff in. And so my comment, you know, before was just I I like the unencoded payload stuff because you do want to sign you know, images you wanna sign, you know, arbitrary. And I don't wanna base 64, you know, your own code things, just assign them. But I"
  },
  {
    "startTime": "00:32:01",
    "text": "also really like having this unprotected header bucket with caveat of, like, be super careful what you put in there. Like, make sure you're using it consistently with the other ways that you can put information there and You guys just gotta be super careful with it. Right. And Yeah. You're right. I may have misunderstood the two parts there. So Uncoated payloads, basically for false with this, aren't really something I thought it was appropriate to support. because it's multiple payloads. because people might say, well, I want a mix So instead, My motivation was more to push people towards easing patch payloads for those kinds of scenarios and say, similar to how STJOT said, well, here's my own thing. say you don't have to have everything in our format. if you have special needs that we don't accommodate on. we have detached payloads. You can use this just as the protected header and and the signature. My goal with the unprotected headers, is I really don't want to have GDP have algorithms set require them to be used for, like, inclusion groups. I I wanna make sure Like, if I'm partially disclosing a miracle tree, I don't want unprotected headers to be at the place that you might put that data I wanna make sure that it's properly structured in the the overall serialization. But, yeah, I've I think to for the un the unprotected headers we're probably missing some guidance. And if people have guidance, that'd be great as that's kind of a global JWS, JWT, and this work,"
  },
  {
    "startTime": "00:34:01",
    "text": "You can find comments in the first text. Okay. Any other questions at the mic? Thanks. Thanks. Thanks. Thanks. Oh, wait. Go ahead, Brian. the on the unprotected headers, there was was someone that was a suggestion to do the SD Jot Disclosures in the unprotected headers But they When you have multiple signatures, the unprotected headers occur at that level rather than at the payload level. So it kinda, like, doesn't match up very well. I don't know if that helps you at all, but it came to mind there. more generally, and this is not gonna be particularly helpful. I JWS is already painfully overloaded as a signature A JSON Web. signature, ACTUALLY CAN BE A SIGNATURE in the classical sense Hmac, which is not a signature. we call it that. and no signature at all, which is also not a signature. I I'm I'm still really nervous about further overloading JWS with even more semantics about being different things. and that Yeah. Well, you know -- Kinda go on record with that. Yeah. I don't know what else to do. But -- Yeah. Yeah. Well, But but continuing to propagate mistakes by making it more and more more things. It can now be that makes me nervous. Right? in the context of multi payload. It's still signing that. It's it's a different therapy but understood. you know, the debate for none. rolls on. forever,"
  },
  {
    "startTime": "00:36:08",
    "text": "Thanks for sharing So would multiple none now be Yeah. Multi none. Multi none. It's all or not. Yeah. I don't see why none wouldn't be multi payload aware. It's the most thing. Some people will build down, but Musk We might wanna say, that you shouldn't use none with multi payload. Did you? Everyone says that now. I will soon. So so I I feel it sort of as my duty to remind people that we do have remote participants. And if you're gonna speak, please go to the microphone. Have a lovely chat at the microphone, but use it. So something that caught my eye is m p false, and stuff about algorithms. It looks a bit ugly and non orthogonal. And my miss whether you have considered having the inverse sense of the flag like like Single payload. false Which would have backward compatibility in one place instead of 2. Sure. Multipaylit false was there so that you could assume false with the default. we inverted then true would be the default. So if if I had a If I have a database implementation that supports this and it doesn't see the multi payload header has a traditional algorithm they were just the same. It was false. but but back and flip it. Yeah. Yeah. Because if you flip it,"
  },
  {
    "startTime": "00:38:05",
    "text": "you don't have to rely on applications failing on algorithm Fence which is which is you said, the detected header. If I have it as a a critical to understand header, which I did in the earlier example, and they don't understand it either way they'll fail. If I don't mark it that way -- Okay. -- then either way, they wouldn't succeed. So it was more saying, for Forward use with proves. you don't have to have a MP True in the ticket header for all of these because those algorithms. already make the assumption that they're going to be bad, the individual payloads and the protected header so you're you're not controlling it to understand one way or another. for traditional algorithms they need to understand how to deal with the tilde's in the payload and how to generate JWS signing text. So that's the Purpose of that header. is to control the behavior of the existing algorithms. But, yeah, if we can talk more about whether it makes sense for it to be default, true, default false. Yeah. indicate current or backward compatible behavior because the base 64 header, for instance, the unencoded behavior is false. Okay. Any last questions? So if I could ask a favor, if you could send a link to the document to the mailing list and ask for discussion and any comments there in addition to link to the repository can put comments there as well."
  },
  {
    "startTime": "00:40:00",
    "text": "mailing list, we can consider whether there's we can do a call for adoption if that seems appropriate. Sounds great. Okay. We see it. okay with you? Mike, Hello. I'm Mike Jones. I'm going to do something that I've never done before, at an IETF presentation which I'm going to talk about a draft I haven't written yet. This is a proposal for a draft. Hence, they're not being a draft identifier where it says proposed specification. Nonetheless, there's ideas here that I wanted to float by you and let's roll. Next slide. There's 2 kinds of algorithms registered in the Jose and Jose algorithm registries. along a particular dimension, which I'll describe here. There's probably other dimensions in which case that's also true. There's algorithms which I'm calling fully specified. that If you know the algorithm of identifier, you know what cryptographic operations have to be in your library in order to use the algorithm. There's others that I'm gonna call polymorphic. which don't completely describe cryptographic operations that you would need to support to use them. So here's some examples. So the RSAA shah 256"
  },
  {
    "startTime": "00:42:03",
    "text": "algorithm identifiers in both Jose and Jose are fully specified. Yes. 256 k, which uses the Bitcoin curve. is fully specified. es 256 in Jose, is fully specified. It says that you're using NIST P256 Curve. However, in It says you must support it with the nest p 256 Curve. and you may use it with other curves. such as the brain pool curves with chatch out polly and other things that may come down the road. The other big example is EDTSA, which was the 1st polymorphic algorithm identifier registered for Jose. which I admit I reviewed it, and I didn't catch it. that you need to know the curve associated with the key such as 8025519. or ED448, in order to know what the EDDSA algorithm identifier actually refers to cryptographically. This has consequences. Let's look at it on the next slide. Yeah. If you wanna take a question, like -- knock yourself out. -- Go ahead, Brian. The ECDS, JW e algorithms where would you put them? in this classification? That's a fair question. They"
  },
  {
    "startTime": "00:44:01",
    "text": "bring with them the ephemeral key in the parameter set And so You know at runtime, where you stand, but it's a fair point. is the receiver you do. because you have the key on the algorithm. But as a sender, You don't. necessarily. I don't No. You're rating a great question. So as as a sender in encrypting to the receiver, you know, theoretically, you you know what their public key is. So I mean, I'd be hard to encrypt to a curve that I didn't understand. with ECDHES. this is a good discussion, and we should keep having it if we consider this draft. at a minimum, whatever the draft becomes that absolutely needs to be discussed. Why does it matter? the OAuth specs The open ID connect specs the Webauth n spec in the w 3 c, the 502 specs, made the assumption that if you have an algorithm identifier, It's sufficient to negotiate between 2 parties that are gonna interact cryptographically Whether they support a common set of Cypher suites and can interoperate. The AS metadata RFC includes This example,"
  },
  {
    "startTime": "00:46:01",
    "text": "token endpoint auth signing out values supported, say that five times fast. with examples of RSI shot 256 and You see DSA. Shah 256 with the p 256 curve. Those are fully specified. It's meaningful then for the other party to know what they need to do to use that token endpoint. And, indeed, this actually started with open ID connect an OSborrowed at, that there's a bunch of places we have supported parameters that say alg values supported or ANC values supported. for this and that. kind of cryptographic operation. And this is continued, you know, for, I believe, things like token introspection endpoints. and other things that have happened since that Let's go to the CASE side of the house. and EDTSA. Minersate, is polymorphic. it can be used with 8825519. it can be used with e d448. It can probably use with other Edwards curves should they get registered. I think it was 1 John Bradley, who noticed in the webauth end context that you know, we had this minus 8 value, and people were using it with 25519. But if people came to the table and wanted an authenticator with ED448 signing, there wasn't a way to say so. not using the negotiation framework that we have And, indeed, the line here"
  },
  {
    "startTime": "00:48:01",
    "text": "It's a quote from the approved weapon level 2 spec, which just declares. that if you're saying EDDSA, you actually mean EDDSA with 8825519. Were you going to talk, John? yeah, that person was actually the person who was using it was me, So, essentially, because we had painted ourselves in the corner with web auth in and and c tap We either have to fix the algorithms or change the webauth and protocol to basically send a curve as an or parameter to try and get around this problem. And I would rather fix the algorithms, then train wedging a new parameter. John, you're way ahead of me. Next slide. I have a proposed solution. which is register new algorithm identifiers that are fully specified for all the things that people wanna do with the registered polymorphic. algorithm identifiers. So for instance, in the Jose space, I might propose creating an identifier which we could bike shed the identifier if we want, but let's not. Not. called ES25519. whose definition is Edward's curved digital signature with AD25519curve. and we could have its animal friend with the 4 48 curve. and we could have Jose numbers associated with those rhythms that are likewise unambiguous. for Jose, where ECDSA was polymorphic or is polymorphic."
  },
  {
    "startTime": "00:50:02",
    "text": "We a could do similar trick. We could register a number, which I'm giving a name for the moment. which is ECDSA using p 256 and char 256. And we could do the same with 34 and with 521 with shot 512, and there's other examples which those of you who know the specs well and particularly those of you who had written code using them, know what they are. That's my proposed solution. I think Tobias is on the queue. There's several on the queue. Yeah. So in general, support of reducing work you know, creating more easy to follow guidelines for people willing to or wishing to register algorithms to not do that in a polymorphic way. I think that's a a really useful thing to have documented. I just wanted to come back to the Cozy 1 because recently. and Mike and I have discussed this. This the cozay usage actually came up with ISO 8n013part5 usage of it, right now, they they specify using e s 256. with the brancorp curves and just just reading the section because I don't think this text is absolutely clear, but my interpretation of it at least is that it is not allowed because and I'll read from the draft. You you're reading from the Jose I'm I'm reading from the reference standard that the iron registry points to this document defines ECDSA is working only with the curves p 25638 4521. The document requires the KFC2, implementations need to check that the key types and curves are correct when creating and verifying signatures future documents may define it to work with other curves in key types in future."
  },
  {
    "startTime": "00:52:04",
    "text": "I take that to mean those other documents would register other algorithmic identifiers. Right? So e s 256 is That would be the hope, but I don't think that's what it means. Really? Okay. Michael. Oh, wait. So that that doesn't mean that if Somebody wants to use the bring pool curve with ECDSA, we can't accommodate them by registering a new algorithm. which would be the less brain exploding portion of that. Yeah. Mike Mike Carrock. Thank you, Michael, for putting the strap idea together, concept. am broadly supportive. We had the post quantum, use in protocols or whatever that is now since we can't seem to get a name rolls off the tongue over there. Right. Yeah. Anyways, right before this. And it was actually a good session. we're talking about the variety of drafts across the board. But one of the things there's a couple of things coming out on that Side 1 is a great draft. The deals with naming of hybrid schemes and things like that that are coming about. Obviously, a topic that will be important. In general, if I think about the challenges we've had just with getting folks to understand that lettuces are not curves. and this would have helped quite a bit there. Right? And so having this clarity, especially as we are seeing new and many and varied post quantum approaches. much less before we get into hybrid signature scheme. which unfortunately are happening whether we like it or not. usually not. So it's just something we should be aware of, and bad things will"
  },
  {
    "startTime": "00:54:00",
    "text": "happen eventually because someone will take combinations that are really improper together if we don't provide this ability to register very clearly what we mean when we say it. So I think this is a great step in the right direction. not without challenges to go through and break some things out, but I broadly supportive and willing to review and contribute. So the other snark I just wanted to add is, are you sure we don't need to put your names in these things for win week coin. Oh, for sit out. So taking the prerogative of being at the mic, I'm gonna something that might per rock, just said. and something John said a few minutes ago, which is John said, you know, we could maybe fix this by augmenting web ought then to maybe, for instance, pass a curve parameter. And Mike just said, there are things other than curves. There are lattices. There's HPke parameter sets, which are not all curves, and Cryptography is a big bad world, and none of us maybe some of you are photographers. I'm not Justin Richards. So two two parts to this. one one positive and 11 negative. positive is that when we started working on HTTP sig HTTP signatures, which has its own algorithm registry, kind of things like that. We actually went and had a conversation with CFRG about this. and the overwhelming feedback that we got was make sure that all of the code points, fully specify every single variable part of this algorithm. And so that has been encoded in the HP sig draft of if you are defining an algorithm, whether it's registered in Ayanna or you're just using it locally because you're allowed to do that with that spec. It's a it's a little bit different world."
  },
  {
    "startTime": "00:56:02",
    "text": "you have to lock every single thing down, your hashes, your padding generation function if you've got one in Your PDF. Yes. Absolutely. Anything that could vary has to be locked down and understood and defined by the application and you're using one of the interoperable code points that's in the registry, The text that defines that absolutely has to do that. including bytes in and bytes out in order to actually make this thing work. So Yes. I absolutely agree with with this approach. This is this is not a place where where polymorphism is polymorphism is particularly hell full. Like, you you don't want variability here. That said, This work would Would make things a little extra weird, because without an additional I for working with these various algorithms. Because without sort of an additional flag or identifier or indicator or something I now have algorithm values, which could land me in the same space in two different ways by meaning 2 slightly different things. So I have 2 ways to pass the same information. And when you're talking about registered values, that's usually a bug Now if we had started where this where this was, like, how everything went in and the guidance going in was you know, like what CFRG. suggested, then we we wouldn't be having this conversation, obviously. But we live in a reality where That does exist. And so I think part of this work would be questioning should there be a deprecation of the underspecified algorithms. in favor of these. I know. I there's oofs coming from the audience for the remote participants. and and some cheers. But, I mean, it's it would be painful"
  },
  {
    "startTime": "00:58:01",
    "text": "to do, but also might be the right thing to do. I'm I'm not sure. -- touch upon that on the next slide a little bit. Alright. Thank you. Excellent. Thank you. Or just in general, how how would we handle this reality where we have these things that mean 2 really kind of different things where the whole point of a registry is you get one thing and it means one thing. Hi. I'm Dhey's Kajitoni. and the I don't hedge date. I I I don't just like our preliminary algorithm. But I don't have any any reason to approach this proposal. Yeah. But I think it is relatively easy for signing algorithm. but it is are are I think it's very difficult for ECDH. since since And I So I I have a question. We did also include our encryption algorithm for ECDH. I think you You want to include the carbon information, but I I want to ask you are you want to include their there subsequent encryption algorithm. into algorithm ID. Do you understand I do understand the question. I think may somebody else maybe Ori asked that question, and Brian just asked the question about ECTHES. I have not fully thought it through, and I would welcome those"
  },
  {
    "startTime": "01:00:02",
    "text": "who care and those who have informed opinions to be part of that conversation because I do want us to do a thorough job, but not overcomplicate things. Mhmm. Thank you. Sorry. And this may not be accurate, but Ori and I were I was and our father was about ECDH. Yes. Specifically, I think that question also involved whether the actual symmetric content encryption algorithm would be part of the construct, which is a even bigger issue or question. that I don't have an answer for. But -- It is the case. that Jose and Jose, do split things up so that there's 2 parameters. There's the key establishment algorithm, which is ALG. which may be ECDS or some other things. may be direct. and then there's the content encryption algorithm which is specified as ENC. And I would like ENC to be as fully specified, as I'm saying, I want ALK to be for the same reasons. ECD HES, you know, key agreement is an interesting space, and I think it we should do a good job of this because I don't wanna leave a mess that Other people will have to clean up some years from now of, like, I'm attempting to clean this up with your help. Awesome. Yeah. So I I think that I just heard Sam's cross has been answered. And I I just wanted to say of the registries. I think it's great to have registries that"
  },
  {
    "startTime": "01:02:02",
    "text": "are so fine, Grain, that you can very clearly identify each individual concept independently. But that doesn't necessarily mean that, you know, that's a good idea to expose that kind of registry in an envelope protocol, environment, depending on the scenario. And so I'm I'm supportive of of this, but I'm also sort supportive of some of the other registries that we've discussed. I mean, we've talked about this a lot in the context of HPT and this concept of hey. Should, you know, Was it a mistake to have Algan and Andy separate? We could have made a single identifier that communicated both those concepts. We didn't originally Should we put them together? You know, you could. I think those are the kinds of conversations that's good to have it's easier to have that conversation when you can point at each of them individually somewhere. but that doesn't mean that you need to always be pointing at them you know, in that in that way. So I I think and just some commentary on hallway conversations I've had with folks about this sort of experience in this particular, the CFRG comments you know, My summary of or my my sense from folks who work within CFRG is that they think it's good to fully specify these things and communicate intention, with as much simplicity as you can possibly muster into the experience. And that is a design constraint that that runs against some of the sort of registry maintenance design considerations, or agility design considerations that you might have So you have to balance these these issues. But from my personal perspective regarding the IETF and this registration process, the debate that time that it takes to write a draft and update a registry entry"
  },
  {
    "startTime": "01:04:04",
    "text": "for to add a new capability is probably shorter than the debate time it takes to support a fully prioritized protocol. That's it. k. couple of non chair observations. The So we also need to consider Edward's encryption x25519. needs to go into that list. For encryption on the wire, it's less of a problem, I think, because you always have the context of the you know who you're encrypting to so you have the certificate. It's where we're trying to do capability negotiations. So in OAuth server configuration when I say I support a a particularly, you know, ECDSA. p s 256. -- p s 256. that that kind of works. So we So I think that we need to figure out encryption is perhaps we have to go through on a case by case basis, figure out whether or not it's what we're doing. But I think that we still want to be able even if it's not a run time problem with ECDH, we should make sure that how we do configuration files is going to be clear. Maybe adding an extra parameter saying, yes. It's ECDH with these curves or But if you wanna use a brain pool curve, what have you. don't laugh, Mike. I knew it was coming. I didn't know they had done it."
  },
  {
    "startTime": "01:06:00",
    "text": "Okay. Next slide. So should we do this and should it get approved, a result would be that this would add updated by references to some of the existing RFCs. In particular, 8037 that registered the EDDSA identifiers for Jose. it would add an updated by to the because the algorithms draft. Justin asked the deprecating question And that's a question that would come up, and I'm not taking a position. I would Be happy if we deprecate it. I am stand it may not be practical. But that's a discussion to have once we have a working group draft and an intent to go down this road. But at least we would be doing updates so that implementers who put on notice that there's been some updates to the way that things are done here. Next, The other thing that I would propose to update the instructions to the designated experts. for both Jose and Jose, saying, please don't register anymore polymorphic out rhythms. Let's not make the existing problem worse. and so that's a section that I would right. Justin's on the queue. Yeah. But if you're almost done, I'd rather you. Okay. One more slide. Go for it. next A question somebody else asked me that I hadn't thought of, but it was a good question. Is should this be a BCP document where it codifies the best current practice as described in"
  },
  {
    "startTime": "01:08:03",
    "text": "the conversations with the CFRG, like, Make everything unambiguous, that that's the best practice. And then that would be the core message of the draft. And a consequence of that is the rest of the draft with registers some specific algorithms. I am not taking a position here, This is part of the thought space, and this presentation is about exploring the thoughts space. with all of you great great people. I am done. Justin Richard, I have feelings about this last one, but that that's something that needs to be discussed. The the thing I wanted to bring up though in it it was relevant to the last few slides is that one of the tools that we do have available to us as as a working group. is updating the structure of an we can add columns, and we can specify values for previously registered things. in those columns. We can remove columns. We can we can restructure stuff that was already set up there by by previous RFCs. And I think a a lot of times the fact that that is allowable. It it it gets it gets forgotten as a tool. that that we have at our disposal. like adding the polymorphic nonpolymorphic identifier column. Exactly so. And and so that that would possibly side stuff be deprecating all the polymorphic question, Although that might also be something it's it's I agree with Mike that that's a conversation that needs we had in context of this work. Yes. Absolutely. but that might be in a in a scale patch. I am I am not an expert at how to do I've I've done a Iana Registries. I mean, ask Roman. But But this is something that I that I think that is absolutely lou tractable. Okay. just one second. I just wanted to"
  },
  {
    "startTime": "01:10:01",
    "text": "point out Carsten has provided a draft, in the chat, that about the deprecation, he says to read that draft. us. need to take a look at that. in case you're not -- Yeah. I've typing because it's usually hard to to influence an in room discussion. So if she want to hear what I have to say. Please look at the chat. Thank you. And, Yiran, can you pull that draft reference out of the chat and put it in the minutes? Place We're sorry else. Brent Zundell just wanted to say in from what I have heard, this sounds like a really good idea. I really like what Justin just said about adding columns at least as an interim step toward cleaning up the polymorphic things. and would be very supportive of reading the draft. Thank you, Brent. Yeah. Mike Parikh again. Just a quick follow-up. I I think Justin's heading down possibly a really good direction here. In particular, we could possibly do see do things similar to what we see with RFCs where we say updated by, etcetera. so we can approach similarly, right, where we can say this, you know, use of polymorphic existing is updated by this or you should you know, replaced by. Right? There might be similar language to figure out to point people the right direction. going forward for new implementations. I would also note that there might be 2 separate right items here. One might be guidance broader for writing specs around cryptography we are seeing things like that come out of CFRG out of the Post Quantum groups as well. So there we've might wanna look towards Roman and others to maybe coordinate some of those efforts don't duplicate there. And all of this validates why I'm glad I gave this talk about a draft that doesn't exist yet because you all have context"
  },
  {
    "startTime": "01:12:01",
    "text": "that I don't. and I'm really glad to get all of this input. Any other questions? Okay. So your next steps are write a draft, circulate it to the mailing list. Excellent. Okay. With that, we are at the end of the agenda. Does anybody have anything else? Alright. You have A little bit of oh, wait. I see hands. Go ahead. Roman. If I'm out of bounds, tell me so. But I I remember, like, offhand comment that that maybe you were gonna think about making sure that we're chartered such that we can do Jose maintenance activities. I think that was also Like, we dropped the ball on that. Didn't you you replied to the chairs, didn't you? Yeah. Yeah. Go ahead. Yes. As we left the conversation in IETF, Florida on 17th. So, like, at 16th, the last time we met, there was ambiguity on whether maintenance was kind of in scope. I looked at it, maintenance does not appear to be in scope, and that seems like a massive oversight. I think we can this with kinda one sentence, but to do that, we need to just formally re charter that. And the chairs and I got talked, and there was a proposal for what that one sentence would look like and so we should run the traps. quickly, in my opinion, to put it in there and, you know, we should obviously do the normal consensus process. Thank you. Right? Yeah. I was trying to decide whether to mention it or not, and I decided not to, but Mike. Mike. If you have substance, know I do. Go ahead, Ari. So just a brief comment about some recent"
  },
  {
    "startTime": "01:14:02",
    "text": "documents that I think are relevant to the conversation we're having about, you know, We're talking about algorithm, you know, identifiers here. but they show up in envelopes and key formats, and I would like to direct the attention towards the key formats that are supposed to rep represent a capability for post quantum capabilities. So in particular, the key formats and deskuk has worked on for HBKE. how to express the HPK parameters, and look and look thinking about key formats for some of these newer capabilities and also key formats that support hybrid schemes in both hybrid signatures and hybrid chems. Just there are some some documents that have been posted to the list, you know, right before IT have started. And you should if you care about KeyForm just go take a look at them because have some interesting Jason representation and some new keys you might be excited to use in the future if you have comments. I'm sure the authors would love your your feedback on them. I'll have to have to look them up. But, yes, Or or the notes actually, the notes page would be great. Alright. Go ahead, Michael. Yeah. Just one qualifier to add on to Ori's comments, which I think were great, and I agree with all everything he just said, but there's one note that I think folks that aren't working in the space don't necessarily think of. in relation to how we specify hybrids in the post quantum side, which is the combiners also have to be very clearly specified and they may have their own parameters, and they're not necessarily what we would think of like a signature speed or something like that. So there is this kind of additional class of things that have to be specified to know what you're doing. So Okay. Are there any other questions or comments? As I mentioned at the top, please review the notes page to ensure that they are complete and accurate because we'll pretty much"
  },
  {
    "startTime": "01:16:00",
    "text": "copy that into the minutes for the meeting. And with that, you have 14 extra minutes in your day. things. So this thing does. And it's the same problem I had on that. Same problem I had on Sunday. it works some of the time, and it because I was playing with it, and it does work. And then it doesn't work. It's like there's a certain amount of time you have hold it down. Just playing with you. That would be funny. Like, hey, I don't know. It's just not reliable. Alright. Well, that's"
  }
]
