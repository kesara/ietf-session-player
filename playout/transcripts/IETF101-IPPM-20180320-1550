[
  {
    "startTime": "00:00:05",
    "text": "all right so again please yeah I was just saying that the HDMI cables should be - one is already connected to the laptop that is top right corner on your desk you should stay there this is for the cue the other one should be close to the mics that are their own desk I\u0027m plugged into it I\u0027m plugged into it that\u0027s the one I\u0027m plugged into it plugged into a four-way splitter and I\u0027ve got no projection okay so we\u0027ve come there okay thanks so yeah for everyone coming in we are awaiting an AV fix as you can see this is the note well um this is an IETF the working group status is we have submitted somebody drops to the iesg in the past couple of days that they have blue screened our meeting there\u0027s only so many blue screen jokes you can do in a row so I am Brian I\u0027ll have your all week um actually I do think I can start running through on some of this stuff I can put the I can put the note well off in a moment so our working group status we\u0027ve published two RFC\u0027s um oh actually I don\u0027t have the up way too updated chair slides here that\u0027s unfortunate because we\u0027ve published um 8321 um IETF icbm Altmark has now been published and eighty-three 37 s looked at the last draft from our Orlando charter in March of 2013 forty thirteen thirteen okay yeah it\u0027s our happy 5th birthday to RFC 83 37 on drop by ATF I ppm model-based metrics so that is done we have also submitted 2330 ipv6 so even though it\u0027s on the agenda I have no idea why do you want to talk for a couple of seconds about what you did okay good and twelve yang um sorry t ramp Toa yang zero six "
  },
  {
    "startTime": "00:03:11",
    "text": "has also been submitted so we\u0027ve got two and cue thank you to the IES chain for reading these so should i unplug I think I\u0027m connected and on the agenda today we have ten minutes of fixing AV problems followed by actually ll you didn\u0027t have slides for 2330 ipv6 did you no no can you come and go ahead and we\u0027ll just sort of do the things we can do without slides and I also didn\u0027t get slides for party run test yeah okay cool so you can do the two things that you\u0027re gonna do without slides well generally agenda around a little bit excellent hi everybody I\u0027m we need a bigger room next time it looks like I\u0027m al Morton and a co-author of two drafts and I\u0027m about to talk about it\u0027s good thing I brought my machine so one of them is the update of our framework for ipv6 testing and that that is now basically done as far as the working group is concerned but we had to update it a bit and and the reason we did that was because the ipv6 updated drafts in their large series dropped in the 8000k range so we had to update I guess Nalini noticed that so thank you know we need for running the you know the the knits checker to find that problem and then we then we actually revised the text that refers to the references so that took a little time and then Neville who\u0027s here Neville our document shepherd found the same problems unfortunately we had a working version like ready to go to fix those and Yocum Fubini did most of the updates to the xml and then once we all agreed to it we submitted it so and that\u0027s so that\u0027s why that one was updated and is now on its way good so then so basically the last time we talked about so now another draft one i\u0027m co-authoring with greg mirskiy who\u0027s here in the front it\u0027s the draft IETF IP p.m. port T WAMP test that is a draft where we\u0027re moving a a UDP well known port from an assignment to the tea WAMP control protocol control protocol to the "
  },
  {
    "startTime": "00:06:13",
    "text": "to the test protocol and and we believe this is done it\u0027s the combination of two individual drafts and so that\u0027s this this should really be on its way to and we\u0027ve done what we can to accommodate it in the yang model I think I would have liked to have done more but it was it was tricky that yang stuff is tricky so anyway thank you very much for the stats thank you out any questions on those two here\u0027s microphone might be easier to come to this I just looked at that draft just before coming to the meeting and I think there\u0027s a mistake the port the last one you talked about the changing of the UDP port 862 I think there\u0027s a mistake in the table the bottom that tells what Diana should do it says I believe it says 861 1 1 2 instead 861 861 861 861 in that Ayana please define this way it says it has 200 arms 280 ramps yeah and it and it switched to them around so alright I\u0027ll check thank you thank you for reading the drafts so so we actually we need to check on note takers roni are you taking notes maybe um can we get maybe a backup note-taker in um maneet your pad he\u0027s known to you if you\u0027re bad we got somebody on the ether pad can you can you login E if you\u0027re bad ok can you back up on ether pad Thank You Tommy I\u0027m jabber scribe huh oh cool thank you too birria for jabber scribing um good so this is our actually why did I make you sit down al you\u0027re up here for like the entire so the next so let me see we got we got right here ok 20 to 30 a 56 we\u0027re done with 40 um tests we have you\u0027re gonna have a quick look at what\u0027s going on um then we have the metric registry initial registry and then routing and then we switch from the elm Orton show to the Greg murski show and he\u0027ll talk about stamp and the yang models and then we\u0027ll go to the IOM portion of this evenings entertainment there are there\u0027s Frank good ok good and then we go to the lightning talks um quick question um Carson Norris and hobo are you here excellent I did not get slides from you so there\u0027s nothing to report ok cool "
  },
  {
    "startTime": "00:09:13",
    "text": "multiple good cool so then we can just write that off the list for somebody else that explains why I didn\u0027t get slides ok good thank you very much so um route or whichever you find first registry registry it is obviously we\u0027ve been doing this a long time and so I\u0027m actually gonna concentrate on the contents of the registry first although there\u0027s a next slide please yeah right so this is the yeah so this is the contents draft and this is the registry that we\u0027re trying to put the contents in and that\u0027s a pretty long one too so we\u0027re trying to oh the concept here is that we\u0027re trying to specify with precision metrics and methods of measurement so that folks can make these measurements all the same and we\u0027re going to provide unique IDs and so forth detailed exposition so that these things can be done the same way everywhere this is a general description of the registry concept each registry entry is a row no surprise lots of things that you can read there I\u0027ll just hesitate for a moment so the next slide shows the category and column headings and so we have a summary metric definition method of measurement the output administrative info and the full history in the comments lots of detail there it\u0027s the same for passive and active measurements also hybrid measurements so they should all fit in here when they when they matter so here\u0027s the updates for both graphs so we\u0027ve revised the passive TCP metric which was added in 13 we\u0027ve added a handshake metric this was previously the the TCP syn ACK metric but I generalized this to be called handshake because that that kind of future proof sit for the the days when we\u0027re trying to do something like this with quick if we get there and and it\u0027s not going to be quick so so there\u0027s the name round-trip delay passive IP TCP - HS that\u0027s a new naming element for handshake and that\u0027s the one we can reuse and then I\u0027ll note I\u0027ll note down there at the bottom that that we\u0027ve also added quick to the naming elements so when a qualified and corresponding packets are a TCP syn and they see peace in ACK that\u0027s when we get the round-trip delay in the forward direction we\u0027re assuming and an observation point sort of in the middle between the two endpoints and you get basically two halves or the round-trip delay the RTD forward RTP reverse put them together you\u0027ve got the total alright so um oh I went back sorry "
  },
  {
    "startTime": "00:12:17",
    "text": "oh it\u0027s the same slide all right now wait a minute wait a minute yeah okay there we go sorry about that so registry and metric drafts update the future here\u0027s the future now we we really need look at them at the heuristics for the methods of measurement in the TCP passive work I I said right here at hackathon 101 we had a good discussion about the heuristics in general and we examined sort of ourselves how the TCP heuristics would change when we look at TCB I\u0027m sorry quick with a spin bit implementation a spin bit basically means for those who haven\u0027t become familiar with it it basically means that you get one sample of round-trip time sort of per window let\u0027s say for per total round-trip time you don\u0027t get a round-trip time for every packet so that means that it that when when we have a when Brian has used in the past a round-trip time window for evaluating round-trip time samples for TCP now we\u0027re not going to be able to do that we need a larger window to do that brian\u0027s at the mike i\u0027m an already in line keep going okay so i\u0027ve got a lot of items here which we which we recorded I want to thank Emil Stefan and Alex his colleague for going through a lot of this with me I think we collected a lot of good stuff here and ways that we can improve both the metrics the heuristics we\u0027ve got for the methods of measurement and the future ok so comment from Brian before comment from Brian um on this so there\u0027s the discussion on this bin bit is basically on the whole scheduled agenda for Thursday morning and quick on if you are interested in this please come by the method here is not really necessarily quick specific right it actually looks kind of like an alternate marking method but it\u0027s an alternate marking method where the alternate marking is dependent on transport state because of how the how the spin algorithm works we did some experimentation with this at ETH and found that it actually gives you better RTT measurement then you get inside the crypto in certain cases because of just the frequency of acts when you have a unidirectional traffic so the spin bit actually gets you more edges than you get RTT samples just looking at the extreme Wow when you\u0027re coalescing acts so this is we\u0027re doing this work for quick and we\u0027re doing this metric work in quick and if the spin bit doesn\u0027t end "
  },
  {
    "startTime": "00:15:17",
    "text": "up in quick then it\u0027s probably not extremely useful to put it in this registry but the the two different spin mechanisms one is a one bit spin and one is a three bits been that we were looking at um are kind of general of mechanisms right you could add them to you could put them on an extra bit and I mean I we have many many extra bits in the ipv4 header obviously we just grab one of those you could um have a you know a gigantic destination option for your little three bit thing which use incredibly wasteful but I mean like so the general marking mechanisms are generic so it might make sense to nail this down a little bit more regardless of what happens on Thursday I\u0027m cautiously optimistic but um well I wasn\u0027t actually proposing that we take on quick in this initial rest recon okay but you need to make sure that the registry definition would allow us to come back and do it right because if we suddenly move 90% of the pass of our TT measurement in the world to the quick spin bit then we get we\u0027d actually need a new metric you need internet rec yeah because of the naming rights exactly yeah yeah well in the end the the the measurement methodology is completely different rightly so the estate you have to keep the thing that you\u0027re looking for the signal that you\u0027re using it\u0027s all different so and the yeah the three bit spin is actually kind of it\u0027s kind of weird and designed it\u0027s designed to solve a specific problem that runs that you run into when you\u0027re using a one bit signal in a environment where you have Lawson reordering right great okay so it\u0027s not that weird but I mean it\u0027s a fundamental problem you have to deal with in a packet switch network so but yeah so that all of the stuff for the registry for whatever ends up and quick and other things that are parts of this sort of single bit explicit passive measurement signaling that\u0027s actually its hybrid measurement rate because yes it\u0027s a bit that\u0027s put in every packet for the purpose of passive measurement all of that is well I mean we\u0027ll have to basically do spoke stuff for the registry to make that happen yeah yeah good thanks for your comments huh so like I said I\u0027m not going to go through all this in detail but you\u0027re welcome to read it and appreciate it more updates so this one we didn\u0027t act on yet Brian but we we wanted to improve the DNS measurement methodology at the last meeting you mentioned that there\u0027s an interesting method for DNS measurement by encoding information in the query itself we currently only have measurement for a specific RR we could do more and also I got an email from Fred Baker from basically from the root server and a service a root server "
  },
  {
    "startTime": "00:18:18",
    "text": "Service Advisory Committee our sasak and they need metrics to support recommendations to root server providers so kind of SLA like and so it would help them if we did if we did more in this space it may be beyond the scope like I said future there it may be beyond the scope of what we\u0027re trying to accomplish here now but but that\u0027s that\u0027s something worthwhile noting all right so next steps we really need this TCP section section 10 reviewed we\u0027ve I\u0027d like to see DNS response time and loss also reviewed because I\u0027ve got that quad at symbol there we have to look at two methods in order to be able to measure loss and sort of the final thing is that on Thursday I\u0027ve been asked to come and talk to the XR block group it\u0027s late Thursday afternoon and they want to provide input to the registry this was kind of a surprise to me but glad to get it I mean actually we had yet some folks from X our block comment on the rtcp X our metric last time so it\u0027s not completely unexpected but it did come kind of as a surprise yeah Rachel yeah yeah actually yeah that\u0027s me Brittany\u0027s work too as a POC and I think things are saying yeah I\u0027m so today we are going to discuss whether this over this metrics should be you know including whether it\u0027s a buck should do this work or and if we do what kind of a metric is repeating could yeah yes so and and and I mean there\u0027s there\u0027s a lot of ways this could proceed we hold up the initial draft to try to get those metrics in or we just have a follow-up draft that puts in the rtcp X our metrics that that you guys are interested in always to doing yeah let\u0027s talk about that yeah and and will promise to feedback to the group okay that\u0027s it oh yeah I wanted to mention this one so now that we\u0027ve got our RFC a pardon me the what\u0027s the action item okay who\u0027d like to review okay yakov tcp section yeah yeah anybody no no no you know you\u0027re you\u0027re you\u0027re in there and yeah and anybody for dns really needed somebody anybody know anybody who knows Ignacio good thank you all right so this so this is this is one that we really ought to sort of pick up and get going again now that we\u0027ve got an RFC I think "
  },
  {
    "startTime": "00:21:19",
    "text": "and Matt and I will we\u0027ll work that in our copious spare time and that\u0027s my last thought on on this thank you Oh Matt this document and actually the general problem of extensibility for the registry has suddenly become worried to me it feels like we\u0027re gonna grease a huge population of tiny RFC\u0027s to essentially add one line in a registry and it feels to me like a lot of those in many cases belong as a separate section in the base document and it\u0027s future based documents what I don\u0027t understand it does does this register you require Ayana action does other fields that need to be registered to be unique that might accidentally collide so they need to be coordinated yeah yeah and and have you I mean and you\u0027ve looked at this registry entry it\u0027s not small it\u0027s not I mean a one-line entry has a lot of detail and I Anna\u0027s ready to deal with that it\u0027s not going to be an enormous table that you can\u0027t really use on your screen it\u0027s gonna be like a text file in which case it warrants being a doc so each but that but then they\u0027re not one line RFC\u0027s either right like this this is this is cutting out of one line RFC to route so they\u0027re there\u0027s four of us doing the the now interestingly named Ora draft advanced unidirectional route assessment I can say the names from memory yeah Ignacio I was here in the front al Morton Yoakam Fubini and Carlos pignataro well I\u0027m not sure who\u0027s here this time I don\u0027t think he is I haven\u0027t seen him yet yeah so um so so we\u0027re doing it and um okay so that often back on so I\u0027ll just start with the background we we introduced this draft kind of a year after meeting Ignacio and in Buenos Aires and got some good comments from r√ºdiger gibe and Frank Bachner we had a strong strongly informed scope discussion at IETF 100 we had proposals from Carlos to cover more than IP basically to start to look at other layers and and and so forth what we agreed was that we could make the definitions of a hop and a host identity and so forth I\u0027ll get to those in a minute we can make them more general but we have to we will consider what work is "
  },
  {
    "startTime": "00:24:19",
    "text": "applicable at other layers as needed and as I said we at Carlos so here\u0027s how we\u0027ve generalized the definitions so the for the for the true scope it\u0027s the internet and hosts communicating on IP that\u0027s where this is directly applicable but we\u0027re saying it\u0027s applicable to other network domains if desired its current wording so now we\u0027ve generalized terms like host identity so that they remove IP from the first sentence and then make it specific for IP so that makes it generalizable Jose and any the unique address for hosts communicating within the network domaine it\u0027s a globally routable IP address for IP this is the address that they use for normal communications and error communications that error part is important for discoverable hosts it\u0027s host to convey their host identity according to the requirements of the network domains such as when error conditions are detected and that that would be important when ICMP sends a time and exceeded message when discarding packets and it means it complies with 1122 and 1812 so we\u0027re jet so now we\u0027re still generalizing the definitions and more a cooperating host it must respond and it should provide other info and that\u0027s a this is me this is the interrogation kind of protocol we\u0027ll hear more about that later from other authors but this is where you\u0027re we\u0027re being explicitly asked what\u0027s your address what let\u0027s see so in the remainder of section 3 we\u0027ve really cleaned up all sorts of things like the fact that the IP address and TTL and other terms appeared in various parameters we\u0027ve generalized those four hop member route and route ensemble that\u0027s kind of the hierarchy of of things that we\u0027ll measure and report here so here\u0027s questions for the working group something we can discuss so we can we add an appendix to illustrate applicability beyond IP last at the last meeting Spencer who\u0027s reading his phone said that we should so consider first whether work needs to be done and and one way to do that is to kind of look at how it might be done in this context so we think a candidate for for an appendix that shows the applicability beyond IP would be based on MPLS ping and traceroute would use RC a 29 can be applied to IP because it\u0027s already being sort of done in a v6 datacenter and last time greg mirskiy suggested 63 74 for loss and delay measurement in this space "
  },
  {
    "startTime": "00:27:21",
    "text": "so so that\u0027s sort of one topic to talk about any feedback on that yakov you have all the mechanisms to measure it has unique addresses there\u0027s obviously om they can do this things for you so if you I think that\u0027s even better than MPLS Ethernet better than MPLS you heard it here folks all right anything else on that okay so reporting the metric one point that Carlos asked me to make at this point was that we don\u0027t want to sort of fix a something rigorous format wise here that when we make the measurement there can be multiple ways to report this we might have multiple options here but we\u0027ve looked at this on various times in various places and seeking some wise and experienced input on on this particular topic hi Brian Trammell is individual so one comment there\u0027s actually an RFC for a stored format for trace routes yes I don\u0027t think we want to do that right anyone who wants to understand why I say that go read the first couple of pages of it um one thing that I think whatever format we have for this should capture is that you never from any of the methods that we know how to do for for route connectivity um you never get an assertion that no Dax is connected to node Y right you get an assertion that at acts of protocol you got a packet back from this interface which is attached to device X and then something and then that one TTL down from there a few seconds later you got a packet back from interface Y which is attached to some other device which might be the same I mean so like there\u0027s the the standard thing that people do with traceroute to say okay every hop is a link and I make them a graph because that\u0027s cool and we have tools for dealing with it and it\u0027s pretty much always wrong so the we should somehow capture in the V in the format that we\u0027re not talking about hops we\u0027re talking about measurements that at a certain distance at this point in time we saw this right and then you can infer what you want to from that but we don\u0027t to repeat the "
  },
  {
    "startTime": "00:30:22",
    "text": "inaccuracy here there are there\u0027s recent academic work in inferring interconnection among entities from priests route data okay and BGP data it turns out you need both so there is anti-aliasing so there\u0027s a thing called map it and a thing called border map and you can actually glue them together and they they work nicely together but that gives you a more in a s level interconnection graph and not a IP layer interconnection graph which is what we and I don\u0027t think we want to do a s level interconnection in this document we want to stay at the IP level but we need to be very explicit about the fact that we don\u0027t have a way to actually measure whether we want to measure it\u0027s everything we\u0027re measuring as a proxy and and but one of the side effects of MPLS is what you just said okay now I\u0027m going to take that even at versus MPLS hump um yeah so Ignacio was raising his hand to comment on the two sort of BGP based methods so please I mean Nasser always a mile in touch fellow from the IETF well from the point of view of traceroute specific at traceroute at IP level normally we try to use some kind of useful tools that try to do the best to look forward the same path every time but it\u0027s not always the same you normally 99 percent of the time you can got the forward time the same forward time and not always the hop n and the hop and plus one are being connected physically there are several things for instance and pedis tunnels opportunist you cannot detect normally you can got several hops in the middle and several things in the middle and there are a lot of issues to make maps using trace route this is one of the thing that i normally do if you are talking about BGP this is different things but normally you can got some more more information because just to map the IPS to the prefix and traffic to the IES number you can got some connections on real connections and but normally you got less connections then you see the BCP tables attribute project because you more or less you got "
  },
  {
    "startTime": "00:33:24",
    "text": "a lot of information there and sometime there are some informant routes that they are not being used because you have not problems or because another things there for you if you want to make him up it\u0027s quite difficult this is the best we can do it\u0027s not but it\u0027s not perfect there are some bias again yeah so we need a sentence right up front this isn\u0027t perfect thanks alright I got it here so we still have a sort of a low Ruettiger yeah on one remark if you work on on MPLS or an Ethernet this would delay your draft I guess because you need the expertise and that needs to be sober and it will be different from what you write on IP because um in order to make sure that packet passes the same link on MPLS you do something completely different than you do on IPs suggested by Ignacio so maybe you should only write one could do that for MPLS and then this will be another document yeah okay we wanted to ask thanks for the input all right so we still have lots of things to do that a lot of them were suggested by Carlos when he was a commenter and not a co-author one by Frank bottners there and and then we skip that last one so we\u0027ll keep those in mind got to get those solved for another discussion area it\u0027s the temporal composition for route metrics passed measurements influence current results this is pretty well understood if you measure something now and it\u0027s doesn\u0027t change it\u0027ll be the same route so can we spot check past measurements at critical hops where they have sort of diverged into you know multiple parallel paths and and that way reduced the measurement load and a time that\u0027s something I think we should think about I\u0027d like to sort of hear from folks in their route measurement experience you know whether they found you know how much stability they found in their little corner of the internet because as Matt pointed out rightly in the last meeting what what what you\u0027ve seen of the Internet is different from what everybody else has seen so so you really have to ask the question in the broad context of this of this crowd here so there\u0027s other things that we should probably develop I like the idea that the hop and route concepts they sort of treat a class of packets what we call Class C we treat them equally they all get you know routed on "
  },
  {
    "startTime": "00:36:25",
    "text": "the same path typically it\u0027s useful to know it\u0027s a concept from a couple of RFC\u0027s that we\u0027ve that we\u0027ve had in the past they\u0027re all the way back to 2330 and and the newer 77 to 99 but I think that\u0027s that\u0027s sort of worth thinking about and doing more with here so let me leave those errors or areas they\u0027re so complete the do\u0027s and continued development and discussion items but here\u0027s where thanks to Ronnie\u0027s good reminder from last time let\u0027s try to line up some reviewers for the draft especially sections 4 5 \u0026 6 which are ignacio\u0027s main contributions to this work and which talk about the methods of measurement talk about that the tools that can make these measurements and the delay analysis so that should be fun should be a good read who would like to volunteer to read sections five six and or four five and six who in the room done um work with trace routes Jason Jason has been raised Jason wheel and crazier out stop so he\u0027ll take a look that\u0027s okay go look okay alright that\u0027s a start Jason Jaso and w wo w e IL yeah good good thank you alright I think that does it and the only other thing I wanted to talk about is I go away was this hop count tool that you and yari and and someone else are putting together yeah I think that\u0027s worth talking about as a methodology in here I\u0027m not sure yet okay um that\u0027s really research II stuff okay so for um so I shouldn\u0027t say too much because some of this will be discussed tomorrow during the plenary but a side project off aside project was a yari primarily is putting together sort of as a as I project a tool to figure out what the efficiently figure out what the path distance between two points on the Internet is so it\u0027s basically like priests route but it tries to send fewer than a traceroute worth of packets and you know what caches things remember stuff and so on and so forth so so hot distance is an interesting like not the actual Hopsin entries route but the number of hops new "
  },
  {
    "startTime": "00:39:25",
    "text": "trace route is an interesting secondary metric for doing classification of primary metrics so um for example there was this this thing that I did for the quick RTT design team looking at how how private see sensitive location information was coming off of our key keys and it turned out that if you had in from if you were getting information from previous routes and you how far away something was the lower the hop count the more likely you were to have better fit between distance and delay soon as there are fewer points at which you\u0027re gonna have processing delay right you and your points are what you could have queuing delay so as an as a metric it\u0027s kind of interesting I don\u0027t know that we really need to cover it now yet because it\u0027s kind of just a little pet project but okay okay well I think we\u0027ll be working on this road and yeah and I know you work fast so thank you Brian thanks everybody for your attention Ignacio you guys it\u0027s just a little comment about the last one when you do some measurements using TCP or quick or whatsoever and the difference is the way that you are gathering the information with traceroute you say okay I will gather every second or every fixed time deterministic time and this is different you you got less resolution you got much more resolution in the other case but from the statistic point of view you are not doing exactly the same and this is a special point okay this is a combined deck for stamp based model and data yang data model of a base specification is it not okay so since we already discussed what was became zero version in Singapore I only give you a diff we welcome Richard foodie you know him mr. fuller he provided very good comments and helped us to advance this version so we expanded introductions section did update on the terminology to make it more I goofed to make it more familiar those who work with t1 and make it less "
  },
  {
    "startTime": "00:42:29",
    "text": "Sdn centric so that to point out that control of stamp entity can be provided from OSS BSS proprietary COI or as the end using neck and yank and clarified use of Z field of error estimate field that based on RFC that we have to support TTP format how interoperates we discussed among offers and decided so to make this document leaner and enable faster progress of the document to spawn stamp extension document and stamp extension document will be presented in the widening section and we added section on interoperability over t with 81 white so in interoperability with t1 part we consider two scenarios obviously it\u0027s a heterogeneous system when we have stamp session sender and session reflector on t1 white and conversely a to my session sender and stamp sessions reflector we document how it works and what can be used and I just don\u0027t want to read it I appreciate if you can take a look at their published document and send your comments so what we see is in open issues is security encrypted authenticated mode what we want to support in stamp because as we discussed in the previous meetings the goal the requirement we set for the staff is to be compatible with the T WAMP in unto gated mode we think that achieving compatibility on a wire with the T WAMP encrypted authenticated mode it\u0027s too high requirement because of the way how encryption and authentication negotiated in 81 control protocol so input suggestions your thoughts on security are greatly appreciated yeah yeah kufstein number one I think that\u0027s fine because the use of the authentication "
  },
  {
    "startTime": "00:45:30",
    "text": "and encryption in the field is actually relatively limited the encryption I personally never understood why anyone would want secrecy on a test packet anyway the authentication makes sense but as I said before it\u0027s really not that used so losing the ability to inter work with the system which really is not that much in the field I don\u0027t think is a major loss okay thank you but what we want to do and how much we want to do we want to do both methods or one where we\u0027ll be fine with one of them because the difference is that whether their third thing or actually their information collected by the reflector on ingress to send in the clear text or to be in protected as well so that\u0027s the only difference between two modes yes understood as I say for I\u0027d really like to see someone explain a threat model why we need encryption on this contest packet we did a similar thing on kind Packers in tik-tok and no one really came up with a credit credible combination okay authentication absolutely it could be either service stealing of this or doing bad things and I understand but encryption it doesn\u0027t I don\u0027t understand the use case and therefore I think you can just you know forget about it if someone really says they may need that put something in it doesn\u0027t have to be compatible with anything right okay so okay we agree on that compatibility may not be a requirement is a non requirement I think that the only possible scenario is that because now monitoring SOA becomes a part of why cycle orchestration and failing of out of SLA may become some event that system will react so man-in-the-middle mingling with your measurement results can affect your view of quality of the service which would not be objective because it will be skewed and I think actually your career or actually giving a good proof of the opposite because if you\u0027re going to look at an LS oh monitoring system if it\u0027s encrypted packets then you don\u0027t really know how to monitor unless you push the keys into the middle of the network which sort of is creating a problem that probably says that the encryption is a bad idea so yeah I understand what you\u0027re saying about you can read it the other way as well so on doing is a with you that right now it\u0027s a non objective and I think it\u0027s your your suggestion was fine okay so but again then our call to the community is to "
  },
  {
    "startTime": "00:48:33",
    "text": "look at current document because we just effectively replicated the format of the packet as it is integral so is it something that we want to carry on just knowing that this package would not be compatible with the tea womp in encrypted authenticated mode because what we would like to do is we would like to progress this document as rapidly as possible I believe that if you look where it\u0027s going to be hard and to update previous or existing legacy reflectors the hardware reflectors as far as I know none of them support of indication or encryption the ones which are software can be upgraded so once again I think it\u0027s fine okay update on a Yank model again in in synced with their terminology update we had in the base model we provided this update we changed their stem security to stamp authentication vice versa step security replaced stem authentication and define new timestamp formats to be used in connection with their use of the flag in a estimate field and provided some extension for the stem session reflector in order to take advantage of default values and minimize the necessary configuration for the reflector and that we added configuration examples to demonstrate how the default configuration will look on our minimum configuration on the stand and default configuration on a reflector question no not a question just a comment once again because of my not having been in several ITF so I missed this document and until you told me about it and I just wanted to say how impressed I was with the yang the company I work for we have a proprietary yang for similar purposes and this is much more complete it was really impressed with it and I really liked the idea of having another timestamp format for those who like similar to what what was done in other places in the past I think it\u0027s a great idea and to allow both the NTP kind of format and the PTP kind of format for those who need it yeah so I think both thing ID number one great document number two that\u0027s a good idea okay Thank You Jakob but again I regret that you missed that we do have RFC for this timestamp PTP timestamp so "
  },
  {
    "startTime": "00:51:35",
    "text": "basically it\u0027s not really that no idea it\u0027s just taking advantage of existing I understand it\u0027s not now I mentioned that this has been done in the past and I think was a good idea then and and borrowing that technology and bringing it here is a good idea fine okay thank you and you understand why I think it\u0027s a good idea not because of the problem of round off the problem of leap seconds is the problem yeah okay so again it\u0027s too small script I cannot read it from here I have to acknowledge that but yes please read the document and or you can do a deep with the zero version one to zero and take a look on unlived ifs and review there what we\u0027ve changed and common that it whether you like it or not on yes we split a little bit different we introduced for the reflector we introduced that reflector can take that it will take the session on any port and from any IP address so that really it was a suggestion from footer and it really made the reflector configuration in the default mode much simpler of course that creates a security concern so because then the stamp does not filter incoming stem test packets but that can be mitigated by using ACLs so outside of the step it\u0027s just a matter of preference you can use ACLs to filter our traffic that it\u0027s destined the step and especially that is easier because if you use a well known port 862 that we make and a default for reflector then it makes it much easier to put up ACLs and then make reflector configuration minimum as possible just a comment on that yes you can look at this as being an ACL kind of problem and therefore handle it that way I think however that there is a good reason to think of sessions even in t1 plight or stamp in this case and when you think of it as a session with session parameters it\u0027s not an ACL problem anymore and the most important parameter of a session is who the sender is so therefore I understand it can be done but I think it\u0027s the wrong way of looking at things it\u0027s sort of looking at a reflector who doesn\u0027t know what it\u0027s doing has no concept of a session in your ACL in it I think that\u0027s yeah it\u0027ll work but I think philosophically it\u0027s wrong ok I can I can pour into BB FTR 390 which has a similar idea as you know I thought it "
  },
  {
    "startTime": "00:54:36",
    "text": "was wrong there as well okay I don\u0027t argue but again III want to stress that this is optional so this is not the only way to do reflector yes you can do it very explicit configure identity of the senders on the reflector of course in same way you don\u0027t have to use 862 UDP port on the reflector you can pick up any port from the dynamic range so that again provides the backward compatibility with the t1 right sender or t1 sender in a another gated mode okay so again we can discuss whether the choice of default is reasonable that using any as a default setting for sender port and address on a reflector from the point of the default once again going back to security from the security point of view I believe that even a quote unquote dumb reflector should have the concept of a session otherwise you can overwhelm it by sending in this case port 862 added from unknown places and just overwhelm it and then you don\u0027t get response from it here\u0027s a security problem do it the right way I agree you have a point ok so that\u0027s an example of sessions that are configuration I on purpose are we on purpose left everything which will go away because it\u0027s basically default just to demonstrate that and you can did you so we can just produce the real configuration how a small configuration would be if we use the default settings so this is and this is reflector and effectively in the reflector if we use actually if we move the problem of security to ACL then it\u0027s only enabling the functionality and default is 862 so that\u0027s it we welcome comments questions and we would like help from chairs to get there early young doctor review all right I\u0027ll note that down and make that thank you more safe time we\u0027re actually way ahead this is pretty cool but I don\u0027t I have yeah yeah you\u0027re all going talk guys I don\u0027t I I can\u0027t remember when we\u0027ve been this far not behind um at this point in an IP p.m. meeting um Frank ate all right so update on the IOM "
  },
  {
    "startTime": "00:58:02",
    "text": "data fields draft I\u0027m sorry for that I tended to go and copy that title slide it\u0027s it\u0027s corrected on the draft by the way so the draft has even David\u0027s new headers so sorry for that good catch well I\u0027ll correct that for the Montreal meeting so there is I think two main changes to the draft as it stood the first thing is and we have quite a debate in Singapore on that timestamps again that we had well a need for more than one time Stan format some people argued for 1588 some people argued for MTP there is been more recently even argument for positive time a POSIX timestamps and people not only wanted to use the time stamps for hop-by-hop but they also wanted so for tracing but they also wanted to use it in an end-to-end way so and we wanted to harmonize that instead of having multiple things flying around that\u0027s something that we\u0027ve done that the second thing was something that we learned from writing a series of different encapsulation drafts and that it helps go and harmonize the data structures here to go and allow us for an easier way to encapsulate saying things and then well we did a load of clean up and so on the IOM type thing that\u0027s apparently something that from a problem perspective Brian brought to us and Bryant started writing and encapsulation draft for GRE and well then he started doing that and he found out that with the original approach how data was structured we had a OM type field for the two versions of tracing incremental tracing and pre-allocated tracing what we didn\u0027t have is a code point in the iom data draft for and to end options or proof of transit options which means from a parent protocol perspective you need it three code points one for tracing with the suit two subtypes then one for proof of transit and one for edge-to-edge now he went to the I Triple E and said well guys I need three either types for that and the I Triple E guys said no fucking why okay hmm problem right so that pointed to an "
  },
  {
    "startTime": "01:01:02",
    "text": "inconsistency that we had from how we did typing in our IOM data draft and well that was the the incentive to go and clean that up so we Fitz expanded the type now to go and cover all four cases that we have and well that leaves room for additional types in the future so that we have a dedicated type for pre-allocated trace for incremental choice saying for approve of translate and for edge-to-edge and well there is now room for multiple additional types if we ever come up with us in the future and the other benefit is that we have a single code point from a requirements perspective when we ever ask a parent protocol go and go and encapsulate and we\u0027ll see that in a sequence of additional things later on so I think that\u0027s the benefit that we can go and harmonize single code point from upstream and that obviously solves the problem with the GRE draft immediately we only need single either type so there\u0027s a question just a comment I\u0027m glad you have made this extensible because I have another option here having to do with proof of transport or but you know P ot as personally defined does not check order just that it goes through the different points and I have made an extension to that which also checks the same time order and once again not right now bringing it to the IDF but at some point I will be in with me another point so just as an FYI for you so the current P ot draft that we have has two ways to go and do proof of transit one is based on Shamir secret sharing right which doesn\u0027t allow you to go and change the ordering onion right the second thing is based on the second option that is mentioned in that draft is basically based on nested encryption which I will say routing right which which allows you to go and I can write I can do it based on secret sharing but with order it\u0027s a slight change of the polynomial okay The Onion Routing way of doing is much heavier from the point of your cards right so that\u0027s an interesting so let\u0027s chat offline because so far we had that trade-off discussion and P ot like if you do crypto then you need typically hot vs. to do that in an efficient way on every single packet if you do shimmy your secret sharing the vanilla way like we did it then well you lose that particular attribute of being able to check sequence and okay well let\u0027s chat offline because that might be the perfect middle way because people have been arguing over proof of transit two options not great options are awful because it leads to duplication in "
  },
  {
    "startTime": "01:04:02",
    "text": "implementation so that might be a good option to go and explore us as a kind of solution option so well that\u0027s what we\u0027ve done so far so from a clean up perspective encapsulation now as far smoother and you\u0027ll see that later on so the basic asks for every single encapsulation for every single upstream protocol that we have is for a single core point the second thing goes to the timestamp format what we\u0027ve been harmonizing is there is now a single section that discusses timestamps and so we\u0027ve been farming out the text that was kind of scattered around in incremental tracing in pre-allocated tracing in the edge to edge option and we found that out into a dedicated into a dedicated section and in that dedicated section we cover now well the three typical uses of time from a format perspective be it NTP POSIX time or p TP 1588 there is two fields for that seconds and well something that could be seconds and something that is less than a second which could be nanoseconds or fractions of seconds or I think the last thing with POSIX it\u0027s not really microseconds but the way how these fields in two are interpreted is up to the choice of one of the three and it\u0027s up to the operator to decide which interpretation to go for what we allow for these three and now all these sections that we had prior are now referencing this one new section that defines timestamps and that way well I think we harmonized anything time in that document and hopefully it\u0027s cleaner by now because that cost confusion in the last meeting and finally we\u0027ve been getting a lot of help from mickey mickey\u0027s online thanks Mickey cleaning up the language and money crisis that\u0027s kind of the English thing because of me being German and we also cleaned up things that typically confuse people you know that IOM had a little bit of from an implementation perspective heritage from ipv6 so we use doctors left mmm not too great because it started to confuse people so those things became their own nomenclature now we\u0027re using things like the remaining length to important voice potential confusing confusion with upstream other protocols that\u0027s basically what we\u0027ve done on the data draft any questions whatever so that "
  },
  {
    "startTime": "01:07:03",
    "text": "leads me maybe to the last slide so well please continue to shoot your comments trying to get this thing stable it\u0027s starting to really look clean by now there\u0027s two areas that need clima cleanup the Security section needs a load of additional love hoping to get that filled in over the course of the next couple of weeks same goes for the manageability section and we have a section on IOM data export there that I\u0027m about to go kill because Mickey with a couple of other guys including myself wrote a draft that covers a very very very simple way to do export of iom data which basically kind of takes the IOM data wraps that into an IP fix frame without additional interpretation so we\u0027re not really doing formatting inference into fields it\u0027s it\u0027s one I II or so sorry all right and we just farmed that out into a dedicated document so we probably don\u0027t need that thing in this particular document anymore so clarification question on that document it\u0027s basically just there\u0027s a or you have a new I II and IV fix that says here\u0027s a giant chunk of IOM data or correct okay he Bush he just published that we couldn\u0027t get her prior to the deadline so he just published that don\u0027t want to discuss it right now just make make um everybody um talk to me is an information element expert about that at some point we should have that discussion yeah I think we this makes the call for two or three additional allocations that we need from I Anna it\u0027s an informational document to kind of frame the discussion a little so that we don\u0027t really have it in the data draft because it doesn\u0027t belong into the data draft yeah we\u0027re running 15 minutes a hand that\u0027s cool great questions so I have a chair question um you say targeting a stable document by IETF 102 does that mean you want to start the working group last call in Montreal let\u0027s see whether we can go and get okay okay yeah we have a little bit of homework there and okay so that Turkey have the homework done by then turnings Table Talk is in is an aspirational statement not a promise is an aspiration yeah so if we can get that done yeah that\u0027ll be nice if we can\u0027t get it done yeah all right so next I think we go into lightning talks and that\u0027s still you right well I don\u0027t know the order but could be me would make sense yes that\u0027s touching yeah very point that I just made about nine ten eleven getting "
  },
  {
    "startTime": "01:10:04",
    "text": "to a single point per error the possibility below a single code point and again gosh again the same title slide yes still not acknowledged anyway so let\u0027s skip about across that real quick so Greg Greg yeah so baseline what we want from a from an overall encapsulation perspective is people will do and do this already in hardware so there is running code in hardware today and that means whatever we do from an encapsulation perspective if the protocol the upstream protocol allows for choice let\u0027s not make their life - or let\u0027s not make the the implementers life in Hardware too hard so that\u0027s one of the mantras that we\u0027ve been in being preached so avoid nested structures wherever possible because pointer lookups in hardware are difficult and challenging because you need to do that at high speed the other thing is what we learn and I already talked about that is make sure or you can only in many cases use a single code point from upstream well we\u0027ve been evolving the data draft for doing that so with that we can pretty much have an encapsulation approach for all the protocols that is very consistent because all we need is a single upstream code point the question is only what is the upstream code point in certain cases there is choice the one area where we have choices pretty much the debate that we have tomorrow which is in nsh where you can either go do next protocol or use teo base here i think it\u0027s even simpler with the protocols that we\u0027re discussing here the other thing is that io am is not expected to alter really the forwarding behavior off the packet more than it needs to and that means whenever we encapsulate into a protocol we don\u0027t want the traffic to be flagged as OAM traffic because it\u0027s customer traffic we\u0027re just adding additional metadata to customer traffic as opposed to we are creating OAM traffic this is not probe traffic just because we suddenly add the iom and form a and that means well we want to make sure that well that distinction is is is clearly in there because many protocols have a notion of Oh am traffic and that\u0027s not that nothing that we already want to go do and the other thing is that we want to go and keep I um of what "
  },
  {
    "startTime": "01:13:04",
    "text": "it does relatively separated from the parent protocol right so the semantics that I um has don\u0027t necessarily need to be known and vice-versa off the parent protocol because people might want to go and do the I um up operation in a blow-up so all you do is well you hunt for the IOM information in the packet and then do the stuff on the IOM data because the IOM data is defined it\u0027s with its own namespace and largely independent of what the parent protocol does so Brian do you want to go do that because I\u0027ve been keeping come on ok well I\u0027m probably wise I still had a use case for the end case with Giri and so I ended up inheriting a draft as it goes so though that became useful which and that did help us I think understand how to clean up the encapsulations a little bit from what was there just to eat just because it was a something that we finally had to really focus on so this is really simple there\u0027s this one new code point is Franco saying which is that says this is IOM packet and then there\u0027s a shim that defines the IOM what they\u0027re going to happen next in Giri and then you immediately go to what\u0027s defined in the data grafter after that so there was an intention here of not redefining whatever was in the data draft but point to the namespace I think we\u0027ve gotten there very nicely and okay so we really just defined one little shame yes yes hi Greg mercy City okay I I think that I can just give this question it\u0027s applicable to all three drafts to be presented in a whitening strike so not to repeat it are you familiar with the overlay om design team om header draft I am NOT okay okay so it proposed exactly the similar solution it\u0027s just fields and size a little bit different but idea is absolutely same and this draft will be presented tomorrow and called for adoption and if you familiar with this work I wonder why it\u0027s not even referenced in the document yeah absolutely and again why have three documents and why have these documents at all if we have one draft that already will be presented and adopted possibly in NV or three working group well I wasn\u0027t aware of it so I can\u0027t answer the "
  },
  {
    "startTime": "01:16:04",
    "text": "question we\u0027ll look at it this is the only any other questions yeah because the idea of and actually the Charter of overlay design team was to produce om that can be used in different overlay networks and so we have that and we came up with one single document and now we have three different document that proposed the same construct whereas their construct is the same which is not surprised to me because I know that it can be same so I just wonder why need for three different documents to begin with and then why not to use om header or comment on it make it more suitable for your needs when we have already document so um we are not so that if you read through the documents right so the endcap looks similar but it\u0027s not entire the sign that means you have to go and come up with something that little shim that is protocol-specific right and I think we\u0027re repeating maybe we just go and quickly skim through that that was the GRE shim where you using next protocol you need something that gives you the IOM type and the overall length of this body right that\u0027s what you do in a GRE if you are in V X lon and using the shim header there you end up again using next protocol and you need a shim that encapsulate your IOM data right it\u0027s slightly different the approach is the same but I think there is no that no such thing that you can use a generic header for all those protocols right you very easily can because if you not limit yourself we struggled with this when we try to hit it in four octaves but when you go in for example four eight octants okay what we\u0027re trying to avoid why it\u0027s four octet come on we have you we had a lengthy discussion about easier actually your solution is limited because you limit yourself only to 1k of IOM data okay so if you have more than one kom data what you want to transport you are in the same problem you have with the teo v with the limited length okay so why to offer limited solution when you can get another throw another for octaves and then the sky\u0027s the limit "
  },
  {
    "startTime": "01:19:05",
    "text": "you have all the flexibility you need you even have reserved fill you have a versioning you have everything yeah I think that\u0027s the that\u0027s the debate that we are internally so what I would like to have this bate in India three working which is well we\u0027ll come in here right we want that debate um so we\u0027ve been arguing this for for quite some time from an efficiency perspective so Gregg is in the I want it in the most clean way as possible can we can also argue the thing from let\u0027s do it in the leanest possible way camp way originally why did we arrive at using not a single code point from upstream but three originally why was it that way because we try to go do it as kind of condense as possible so if you\u0027re able to steal stuff from upstream you don\u0027t have to go and define it yourself which ended up being more efficient on the wire here well we\u0027re trying to go and walk this fine line between cleanness and efficiency yes we can spend another four bytes but we already know even today that certain lookup engines are relatively constrained how far they can go and look into the pocket certain lookup engines today from an IOM perspective only support say time stamping for instance why because they\u0027re limited in their lookup depth if you\u0027re looking at use cases that are just caring about end-to-end time stamps and you just want to go slot that in and certain use cases do that Ryan right then well this lookup that becomes a constraint so people wanted to go and have it dense if we find consensus that well we want to go and spend extra bytes for getting more flexibility I\u0027m all for that if we can get well the entire party behind that because here with VX LAN yeah fine we go with the next protocol approach but if you fast forward to gen√®ve it\u0027s getting even worse right Geneva is a real headache for me because if you do G gen√®ve well you can\u0027t really do next protocol because that thing doesn\u0027t exist with gen√®ve what does that mean you\u0027re using the T of the approach engine Eve and then you\u0027re limited because of the five bits to a length of MUX maximum 128 that\u0027s far less than 1 K right right it\u0027s significantly lessened might be too few for a load of generic use cases so it is a concern can we solve it yeah we can solve it with more bits our people ready to go there well I think that\u0027s what we\u0027re trying to find out here so we so far we\u0027re in the camp to save bits and not to add flexibility ok I would like to ask a question so you propose to discuss data plane encapsulation of the "
  },
  {
    "startTime": "01:22:07",
    "text": "packet that defined by other working groups so why this discussion would be in this group and not this appropriate groups that own this encapsulation that\u0027s a recommendation by the chair of this working group the chair of this working group can speak up on that one so the recommendation here is that we have basically this is in parallel to the process we used with the six-man are about the v6 PDM do this was a destination option it was designed for use for passive hybrid measurement in IP PM the proponents took that to six-man the ipv6 people looked at it and said I don\u0027t really get the use case so no they came over here I mean the original idea was okay we\u0027re gonna do the encapsulation over there and we\u0027re gonna do what how you can measure things with this over here do you want a 80 interrupt okay clarify the process so it really depends on the protocol for v6 men they actually you can be like believe they say it in the Charter they say we don\u0027t have to write look at all the options if you have a use case you can define a new option right right so far the protocols you really have to check the Charter of the respective working group all right can you do that homework check the chart of the respective working group yeah yeah yeah we can do that okay so yeah I suggested that they come over here to talk about them because exactly for this particular problem right the different cat relations have different limitations on the applicability of the data and like so it\u0027s you know it is interesting to know that this proposal for gen√®ve for example limits what you can do with IOM right so there\u0027s there there are restrictions on thee and that is feed into the sort of the process of you know how we define that measure methodologies metrics based on this so yeah the I clearly the idea here is not an end run right the idea is that things come in here we discussed the the impacts but the owning working groups obviously have to ratify any any change if they own that but if the charters of those working groups say that any chain any additional code point within the protocol defined by this working group must be your working group item then you have to do it that way because I just wonder what will be the situation if there overlay om header becomes the working group document so it\u0027s obviously on it\u0027s not extremely efficient in terms of documents if we have two different encapsulation methods but if what I\u0027m "
  },
  {
    "startTime": "01:25:08",
    "text": "hearing from IO am here is that that overlay protocol does not meet their needs I just suggest to work together yeah and you know let\u0027s take the rest of this conversation to end vo3 tomorrow yep and that\u0027s also I why we took it here because well you have the people in the room that care about the data that we carry as opposed to you go to a Wiccan group that just says well we basically one room for a container and well what is in the container people don\u0027t really care about right because it\u0027s the semantics of what is in the container the upstream protocol not necessary I would not misrepresent the position of other groups please I\u0027m sorry didn\u0027t get that let\u0027s take this one and vo3 please this come okay my watch tells me this conversation is over next is the process it\u0027s good practice to discuss it here first find agreement in this room and then bring it to the working group that could that might be responsible for standardization okay thank you and we got our answer and actually we were basically told by we were told by the six man people yeah you can actually do it over there like so even I don\u0027t even thing it was a six man people I think it was Brian Haberman as as in Terry he\u0027s like yeah just we don\u0027t care but you might um next up is Greg huh right in the notes this conversation will continue in nvo 3 yeah all scream okay so as I mentioned we split their document that was adopted by the working group and into two documents the base specification which defines the base format of a stamp test packet and extensions the extensions that we are proposed to use govt type length value format and some of this extensions already been the part of stem document it\u0027s heading location times information to provide to communicate or characterize their synchronization source and time stamping method I personally believe that the idea of error estimate was to provide this information and somehow we haven\u0027t finished the job of quantifying what is what so if somebody believes that it\u0027s "
  },
  {
    "startTime": "01:28:11",
    "text": "better to finish the work with an error estimate to characterize the sources timestamp and method of obtaining the time value like whether it\u0027s whether how close its hardware it\u0027s a software or not then this might be an alternative that we\u0027re planning to work on coercive service coercive service it\u0027s just has two options weather just reflector reports of DC p-value and ECM value as packet been received and puts it as a sender DCP and a CN value or there is an extension to that that sender includes the value of the ACP to be used on the reflected packet so that allows you to run DCP testing because you can especially in multi service wireless backhaul when you have different services 2g 3G and 4G you often have to manipulate with the acquiescence of service marking and sometimes this configuration is manual it\u0027s very easy to miss configure and that leads and very difficult scenarios that it\u0027s hard to troubleshoot and identify the problem so this mode been seen as a way of very easy test of the network to verify that their handling of these CP values in both directions is as expected hi I\u0027m Brian trommel\u0027s an individual clarification question as I recall there was a RFC a little while ago that out of this Tootsie lamp right so this basically taking that functionality from teenagers okay yes yes we only add it to the monitoring that we have RFC to the do monitoring got it okay yep but there is an extension to do testing yes we use existing functionality and we take a next step which i think is logical step yeah Christine um do I understand that you\u0027re going to be or at least allow changing let\u0027s say dscp on a packet by packet basis in other words have a jump around like that creating a crazy way once again the obvious idea of having a session as in t ramp then you in it per session basis you could do that but here you\u0027re you\u0027re doing something which is just no packets yes you\u0027re right that that\u0027s idea to allow to do DCP test session this is no session this is in the packet so you could do this one packet has this dscp annex back there\u0027s another one right yes and okay you\u0027re allowing that maybe your wait we should "
  },
  {
    "startTime": "01:31:12",
    "text": "put in wording that you shouldn\u0027t use it but if you do use it what you expect to happen do you expect everything along the way to be stateless mmm well again if if there is some cost remapping in the path then we want to expose it that\u0027s idea of it it\u0027s a test how this path handles DCP of particular value weather because again it\u0027s hard to say whether remapping is appropriate or erroneous by sending packets with a set of determinated DCP values we have certain expectations how that has to arrive to reflector and if sent from reflector to the sender how that has to arrive to the sender so it\u0027s a controlled environment I actually is thought of an interesting test that I didn\u0027t think of before if you have values like this you could just start increasing the dscp then see all of a sudden the rate changes you could it could be an interesting diagnostic with it thinking about none with not sure I like no no the thing is a CP is that it\u0027s not contiguous space it\u0027s a cold point ok so basically the idea is that you it\u0027s it\u0027s not PCP and Ethernet like I would be used to but you could probably think of other things that that that you could change on a packet by packet basis which might make sense I don\u0027t know we\u0027re open to suggestions but the idea is here is that if operator has a notion of certain behavior they want to system to produce in terms in regard to the DHCP so you can have a test sample which is subset of your code points depending of how you that what\u0027s enabled in the network but but why don\u0027t you do this in your yang set it up as a session and do the dscp that way you have it reflected in a certain way and not push push it into the pack because we don\u0027t want it to do it it configure a packet by packet with the yang go exactly I\u0027m saying so you are thinking of the that\u0027s the inherent part of this you\u0027re going to change it right but we can do it on there in the sender and the reflector will just follow whatever it\u0027s taught you know we don\u0027t want to complicate yang model on a reflector ok because reflector it should not be aware of it reflector should follow instruction given by the sender sender anyway we\u0027ll be analyzing processing or sending this data for the post processing somewhere and the same for size of reflected packet for the asymmetric a lesson it\u0027s one and then we\u0027ll go on this is a footer with Nokia I think the the general general comment of a packet by packet each correct me if I read this wrong in the draft but each "
  },
  {
    "startTime": "01:34:12",
    "text": "packet that relates to this session from the sender is going to have a consistent diffserv code point if you\u0027re using this on the reflector for congestion notification some along the passo it\u0027s a packet by packet but if the session sender launches each packet in the session with the same diffserv code point then it is by sent by session right it\u0027s just an action on the reflector right okay and direct measurement so we actually direct measurement is the idea is similar to well-known Ethernet loss measurement where you have a definition of what is in profile frames so that for layer three it will be in definition of in profile packets the exact definition is obviously outside of this specification but there are service that we provide we just collect counters from the sender reflector in one trip of packets similar to Ethernet LM LM mo elimar so next again we welcome comments and we kind of hope that it might be grandfathered because it\u0027s used to be a part of adopted working group document so I appreciate the consideration we don\u0027t need an answer now and you\u0027re okay it\u0027s not I I know it\u0027s okay yeah we got plenty of times so not confuse the list this is a next step for the alternate marking methodology so a generalization of the alternate marking for any cast any type of unique as flow in general multi-point to multi-point paths this is just a recap slide so you know that as my unmentioned before the FEC 8321 has been just published and there are also some use cases some application within ITF in particular directory documents that define how to use two too long two bits long field to perform the marking methodology nets in bare SFC I\u0027m your dream and also in MPLS to perform the an improvement of the RFC 63 74 with the use of the synonymous flow level and then we have also recently and alternate "
  },
  {
    "startTime": "01:37:12",
    "text": "marking variation in quick like you know so what isn\u0027t what our next steps there are some performance measurement where a lot of flows and nodes can be involved so this is a big data problem for example the idea is to generalize this kind of methodology so RFC 8321 works very well for point-to-point flow but what happened if I have a point-to-multipoint pot or I have a multi-point to multi-point part so we have to formalize how to take the counter and how to make the performance monitoring more flexible so this framework is about multi-point alternate marking we want to add flexibility to performance measurement so we can reduce the order of magnitude of the counters if needed and this can allow also a flexible orchestration because the orchestration the orchestrator can calibrate and can manage the performance measurement in virtual networks so the first idea is to introduce the clustered pocket rows so if we were if you have if we have a nut and large network we can identify a portion of the network so a group go to group segment that we call the cluster and so the definition is that the clusters are the smallest sub networks maintaining the packet loss properties packet rows property means that the number of incoming packets are equal to the number of about going packets so there is a very simple algorithm that I show you in the next slide is to step out do it but in general the cluster can be also combined and so we can perform a partition of the networks at different level depending on the detail we want to achieve this slide to show you a simple algorithm the cluster partition the first step if we have for example this is in this slide we have a point-to-multipoint but the first rap we collect and when we group all the links with the same starting node with same a node V node C node and so on in second step we combine the link group ID in the first step with at least one ending node in common so for example we can build in this way for clusters partition for the figure so the second and the third links group add in the first step combined it because have the you know the increment so this is just an example but we apply this algorithm also on more complex networks another important point that is included in this document is about the delay measurement in a "
  },
  {
    "startTime": "01:40:12",
    "text": "multi-point part so we know that in our FAC 8321 we introduced the double marking methodology to perform the delay measurement but double marking meter does not work in case of multi pointin parts so what is the solution the solution is that we can consider we can consider a single packet delay measurement by using an acid-base selection of the packet so that is detail in a in a older FSE RFC 5475 that combined with the alternate marking method makes the delay measurement more flexible because you can use two alternatives a basic cash hour a dynamic cash the basic cash the alternate marking split the continuous frozen batch and so the the batch saw packets and the marking variation permitted to anchor the samples that are selected with the acid-base selection this is a use case for is a multi-point alternate marking scenario so as I mentioned before we add flexibility so and as the end controller can perform a flow filtering or a cluster zooming depending on the use case depending on the level of detail we will level of detail we want to achieve so we can start with without examining so yeah let\u0027s take let\u0027s take discussion on this one to the list and woah okay go ahead finish off this slide but we won\u0027t take any discussion yeah the last sentence is about the controller that can calibrate so we can start without X I mean independent case of problem we can detail the cluster we can make a cluster zooming and we can perform also pepperflow alternate marking perform at but just in case we have problem so please read and comment on the list and maybe we can bring this and in Montreal cool thank you right right yep and go okay these are the draft is also on same technology alternate marking methodology but at the point of view is different so now the scope of the of the current draft is to make an analysis of officiate 321 methods to introduce new methods that with low overhead so single bit also what we can use if we have zero bits for marking and so in the end of the scope of this document is to understand what is the most useful method we can we can use if we have zero bit one bit or two bits available so the "
  },
  {
    "startTime": "01:43:14",
    "text": "black background the F SAT 321 okay the packet loss measurement is well known but we can discuss about how to perform the delay in their facility 321 that is the single marking method where first and last packet have been used as a time reference for the delay calculation the min delay and double mark this draft introduce an additional variation that is the multiplex ad marking so we can have the same resolution of double marking map but we can use the opposite bit of the current from the current batch in order to perform it just one bit or so the delay measurement so the time stamp it is opposite to the bit of the current batch so in this way we can use just one bit to perform a double marking math the double marking meet oh yeah it\u0027s almost another alternative that is introduced in in this draft is about the use of the acid-base election in particular if we don\u0027t have be some bit to perform ultimate marking method how we can perform performance measurement so so we call zero mark English we use the ashen base selection to select packet bot for loss and for delay measurement otherwise we have the same methodology that I mentioned before for the multi-point so we can combine the I should base selection together with the alternate marking so this combination is very cool because you can anchor the number of samples within a marking batch okay in this slide mention before that this document makes a summary of the marking methods technology and in particular this is a table that is in the draft and show you with the focus on delay measurement what are the difference with the difference technology in particular the last two the last two roll show rows show you that the single marking edge could be the most complete method because there is the there is the t\u0027s resilient to reordering to packet drops and it is also multi-point compatible that is also a good point so it is very similar to double marking but it is it can be considered better if you want to perform multi point measurement so as a next so the Documenta lights the market meet of strength and weakness or it complete the officiate 321 experiments so in "
  },
  {
    "startTime": "01:46:14",
    "text": "particularly it you can understand we wish methodology you can use if you have zero beat one beat or two be good all right as always please take comments on this to the list and again hopefully we can see this one again in Montreal with some improvement so this is Greg again yes I know we have one more on young models for IOM and then actually because we have we still have time to step a if if you and agnostic I want to get up and go back to the conversation that you were going to have on the previous draft because we have a little bit time and trying to hold the lightning talks to five minutes Oh keep it okay so this is new proposal I think I kind look in the phone there nice catchy phrase a hybrid two-step measurement method so what\u0027s the problem we see are the quality of measurements in the world\u0027s degree depends on consistency of taking the measurement and in our t month extension that\u0027s one of things that were employing that the method of taking the timestamp so we\u0027re the time step is taking that\u0027s a directly affects the consistency because if the timestamp is not taking when they\u0027re transmission or reception of the packet physically begins then the packet may experience unbound delay and that will affect the quality of the measurement so closer to the hardware we take the timestamp avoiding our any queuing then the better the more consistent the measurement would be and that\u0027s applicable to obtaining values of counters and other metrics so and another is that the measurement information the telemetry should be secured and based on that if we transporting the telemetry in clear-text then we\u0027re opening it possibility to the man in the middle attack skewing it and that\u0027s affecting the scenario that we discussed earlier with Yaakov discussing their security levels of the stamp okay because now we pay attention to SLA and it affects how the system being mapped and if somebody can misrepresent the real picture of their class of service a class of experience present then it will be unnecessary changes in a service allocation and resources or might be something will be missed and that will produce unhappy customer "
  },
  {
    "startTime": "01:49:16",
    "text": "and yes hi clarifying is just quickly perk up you don\u0027t need to to encrypt but you need to signature right right I made a just a proposition to clock synchronization in in tick tock yeah right well we\u0027re not talking about what kind of security mechanism we are just saying it has to be secure yes so solution if we take a look at RFC 81 69 residence time measurement in MPLS networks it has defined two modes of operation for our TM capable OS are one step a 2 step so the 1 step is as it\u0027s suggested by its name puts the timestamp in the packet that carries p TP control message and the 2 step produces the message which has characteristic information that identifies or refers it to the message with a bt p control message and then transports only and collects residence time so it collects the residence time on our TM capable nodes throughout the path and that provides on path support for p TP synchronization which improves the quality of clock synchronization what we want to take from this RFC is idea of the two step method so that the measurement can be not not necessarily to be transported on a packet itself because then it allows us to read values and then transport them in a separate secure packet with a characteristic information which will associate to their packet that triggered this collection so that\u0027s ensured the idea of the two step method so we improve consistency and we provide security of the data just a comment and that this didn\u0027t wasn\u0027t invented for MPLS this is obviously in the original 1588 spec the idea of a two-step right uh.okay 1588 has a follow-up messages but when we did it and basically what we did for MPLS we included PTP message where the original or follow-up inner ACH encapsulation and then we have a scramble to collect to accumulate residence time across the path understood I\u0027m just commenting on your comment that the idea of no no I\u0027m just referring to something local to ITF which has a easy reference point now it\u0027s again yes "
  },
  {
    "startTime": "01:52:18",
    "text": "PTP has a similar okay okay cool all right uh thank you very much as usual please read the draft comment on the list and maybe we\u0027ll see this again in Montreal so last is yank data model for IOM there you go it kind of works one here I would like to propose yonder the model for the Institute and the idea is simple we organize the IOM model with as a list of profiles and each profile were associates one flow with the corresponding IOM information we use the filter to identify a flow and there are four sub profiles each of them well relates to one IOM encapsulation type and according to the ion the data specification the multiple I want data types can be encapsulated into the same IOM header and the the sub profiles includes the pre-allocated a tracing profile as described here and also the incremental tracing profile and also the proof of transit profile right now that this this profile is imported from the proof of transit document later I would suggest to integrate it into this young model directly and also the edge to edge profile that\u0027s all for the lighting talk okay I have a question can we roll to the original so if you have a profile and this profiles are optional as I understand why not to make our base yang model is very lean enable and then everything else is mounted mountable that\u0027s also a good suggestion make sense thank you and we hope this can be adopted as the starting point for the island configurations cool so let\u0027s discuss that on the list and reconsider in Montreal okay all right thank you very much you\u0027re separated you want to come back up and do the 35 seconds that I cut you off there because we do have a little bit of extra time wait which was this this was this one and we will go to "
  },
  {
    "startTime": "01:55:19",
    "text": "here we were here right yeah and actually Ignacio if you had a question we can do that to you because holding to the five minute rule but we have a little bit extra time so and my question is how do you plan to collect information and okay you put some nice idea to separate in in the different cluster and so on but how do you collect the information and and why is so important to determine if the in the previous slide the the basic harsh dynamic harsh way is so important I I didn\u0027t catch from your presentation okay I mean the Asha Base erection of the the pocket okay for the collection okay you have the reference of the marking batch so as in double marking approach you know the number of packets that can be selected within a marking gauge so it\u0027s the same if you want to the problem is that in bicycle shops just you you have one one collective point isn\u0027t it everyone is sending information the collected information to one point yes and then you process over there yeah isn\u0027t it no this is not clear this is the ultimate marking method does not specify how the measurement results being exported it only specifies the triggers that being measured export of data can be done in IP fix and GRP see in any transport and the direction configuration of data collector is orthogonal to alternate marking method yes and an important issue on this point is about the number the only problem that you can have with the acid-base selection is the number of pocket within a marking batch because you cannot control the ash in selection as you can control a double marking approach so but in this way there is a dynamic ad shop in the dynamic ash approach where you can there is an iterative algorithm that is detailed with in the draft where you can start to make a selection based on ash but you can discard the samples in order to occur almost an almost constant number of pockets within a marking batch but this this can be detailed this is this is detailed within the draft that if I can describe you more in the next presentation if I can have a more time "
  },
  {
    "startTime": "01:58:21",
    "text": "for sort of for the present to do that okay good all right thank you very much that concludes IP p.m. for IETF 101 year in London we will see you all in Montreal thanks a lot yes what does grandfathering mean "
  }
]