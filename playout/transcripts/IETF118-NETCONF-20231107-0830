[
  {
    "startTime": "00:00:01",
    "text": "Live. Yeah. But I I don't know if we wanna do that because that would get heavily into a working session. Yeah. Okay. So I don't know how you wanna drive. What would you do? What would what would be the general thing, just so to say that is maybe set up a side meeting in the meantime and say announce it. Okay. On the Netcon mailing list, we have a site meeting too. Discuss anyway, we should get started. It's fine to Okay. Good morning. Wanting. Alright. This is the networking group meeting for IETF 118. Oh, yes. You all should be, familiar with the note well. If you're not as a participant, remember, you agree to follow the idea of cross seasons policies. By participating, in this meeting And if I want more details, there are some BCPs that the list on there at the bottom for you to go through. We also have a code of conduct. We rely on your cooperation. And encourage diversity and discussion. And, of course, mutual respect for him. Everyone in that is attending this meeting. We hope not to have to intervene, but we will, if need be. Medical. I guess, I hope you have, by now, you have had some interface within the some exposure to the new interface. Of me take up. We are also trying to get used to it. But, hope there are no major issues with that"
  },
  {
    "startTime": "00:02:04",
    "text": "There is, of course, the remote and on-site to, so choose whichever one works for you. There is, of course, the chat window for comments, And by the way, you can make it a separate window if need be. And there is also a zillow link if you just wanna if you prefer to just use Zulu, we have a 2 hour slot And the agenda is fairly full, but we still have some time at the end for any other additional items. The queue management by now should be fairly familiar to all of you. It'll be managed by meet echoes of Please raise your hand in mid echo before you speak. On the microphone or remotely. And do remember to remove yourself from the queue once you're done. There is a notes page on the meet echo tool, we highly encourage folks to contribute to the notes and the minutes of the meeting. Better, more people that contribute, the better the notes come out to be at the end. And the status of the drafts of the HTTPS node have draft has been in, ISG for some time. It was it had some issues with aina considerations that we have finally worked through. Thanks, Rob, for that. We do have some remaining comments in this discusses that we need to kind of work through. Which we'll do probably after this meeting. The claim service suite of drives. We're working through the 80 reviews on them."
  },
  {
    "startTime": "00:04:02",
    "text": "As part of there are 9 drafts where we hope to at least push out 3 of them soon enough. I'll let Kent comment on that. And we do have a broadband, at least on statement to talk about. Right? I was about to mention there was a liaison request that came in from BBS. On the, client service bid drafts more than just the 3 the first three that we discussed. They also want TCP and TLS, I think. So we'll prioritize all those and maybe, we don't try to get those through first. Now I guess we need, the composer response To that liaison state. Okay. And, but but talk work with AD. Work with Rob on the response, send it to the working group, for confirmation. And then send it on. Yes. I think so because I think, if I remember correctly, I was asking about maturities stability of the draft. So I think the ones that we're about to get out the door, we can say these ones are where they are, I don't think I don't think I necessarily say that much about how stable they are because we don't know we could warn them things to say this while they're on the process. Actually, I think they're quite stable because they've been deployed in production environments. That I'm aware of, in 2 different applications that I'm aware of. So what I was trying to say is you don't know what the comp's gonna come back to the ISG review or or itaFLOT. So that's the thing we can't guarantee, but I think otherwise I agree the other working group stage there, they're done, I think, pretty much. K. Alright. The TLS 1, the 3 draft has been submitted to, IC for review. I don't think so. We need a presentation for it here. The European note of draft, is working progress. Will be presented in this meeting. The same is true for a distributed note of transaction ID less pagination, and the newly minted and adopted"
  },
  {
    "startTime": "00:06:00",
    "text": "private candidate draft. And finally, the burgeoning and yang notification, is also work in progress. We'll be discussed at this meeting. So here's the agenda for the for today, we have a whole list of chartered items that we need to get through And then, of course, we also have a few contributions in terms of non chartered items including, a paper I guess that we'll discuss, at the end of So in terms of agenda, anything else anyone wants to talk about our secretary, per had us thought to present, yang sorry, not yangers, but and and and the neck off next. Just to resurface those discussions topics for, interests. So I think at the very end, there'll be some discussion about and perhaps, a get together later this week. Alright. If there are no other comments or questions, we can move to the first item on the agenda, which is private candidate. At Sorry. Good morning. This is an update on the private candidate's draft. And I'm delighted to have my co author, James, also here in the meeting. Next slide, please. Brilliant."
  },
  {
    "startTime": "00:08:01",
    "text": "Just as a very brief recap of the problem that the draft trying to solve. So it addresses issues around the existing shared candidate data store, for example, when you have multiple making changes to that single shared candidate. And then one session commits, and that commits all of the changes by all all of the sessions and also different sessions where their changes overlap and trade on each other. The draft introduces a private candidate data store, which is tied to a particular Netcon session or to a particular restaurant request? It defines what a conflict is and how an implementation resolves it it provides a solution both for NMDA aware implementations but, the authors also wanted to allow non NMDA wearing tations to opt into this private candidate, data store. The draft describes exist, extensions to existing NetComm Operations to describe how they work with the private candidate data store. And it also adds a new update operation. Since the last meeting, the draft has been adopted by the working group, and James and I have subsequently published a new version of the draft that addresses, comments mainly from Kifang, thank you, Kifang, In particular, we've removed the link between the private candidate and the candidate capability for m and aware implementations. So if your NMDA aware implementation supports the private candidate data store, you just advertise that capability, and that's the end of it. For non NNGA aware implementations, we still require that if you have advertise private candidate, you also advertise candidate the reason for that is in the non NMGA case, the way that a client accesses the private candidate data store is by treating it as if it was the candidate. We've also added an eye on a section to to request allocation of this private candidate capability The draft is more explicit about the life cycle of a private candidate"
  },
  {
    "startTime": "00:10:04",
    "text": "In particular, a private candidate is created for the first time you reference it example, the first time you do an edit config operation against the the private candidate, and it lasts for the duration of the Netcon session or for the duration of the best comp request. The draft also I suppose normalizes the locking behavior. So now when you do a lock operation against the private candidate. It just locks the private candidates This is not a useful operation because only your session can to private candidate anyway, so there's no point in locking it. But there's also no reason to preclude it and this behavior makes the private candidate data store behave like any other data store in the context of looking The strand of thought, for private candidates is the overlap with transaction ID the authors have sort of considered this in some detail. Ands. Our view is that if an implementation supports transaction ID, then it would be it would be useful if the implementation could could use that that method of detecting changes to the data store to support the conflict detection and resolution mess mechanism of private candidates. But we didn't want an implementation to have to implement transaction ID in order to support private candidates. That's the end of my updates, and I welcome any questions. Alright. So I'll go first with the point that you just mentioned. So even though you kind of separated the transaction ID from private candidate could that be a should or main"
  },
  {
    "startTime": "00:12:00",
    "text": "or May for some for an implementation that is implementing transaction ID. Could the conflict resolution be still be used I think I think I think I think we would Yes. We would like that to be the case. I think that may require a bit more thought to make sure that that is the case. We are on talking with Jan later in the week. And I will send an updates to the list about the outcome of those discussions K. I'll go second. Kent as a contributor. Can you say some more about the rest comp support? And especially with regards to the a destruction point Yes. Fundamentally, Fund fundamentally, in my opinion, private candidates are not particularly useful in the context of rest comp because because the date store only lasts for for the duration of that of that response request. It's not not sort of a long lasting data store. The main sort of behavioral change in the rest con context is currently with rest comp if the implementation advertises the candidate capability, then when you do a rest conflict, it will commit the it will, it will, it will, it will, it will, it will, it will, it will, copy the candidate data store to the running configuration. So you still have the problem where if if other sessions, like the net over Netconcessions have changed the candidate data store then that rest conflict will also commit those changes. So the main behavioral change for rest calls is that if an implementation supports private candidate, then, then, a rest comp. Session can't commit other sessions changes. Okay. So I think I understand that the RESCOMF is actually not supported in terms of having private candidate like like like And I mean, you're saying it's session based, right, with for neck off."
  },
  {
    "startTime": "00:14:02",
    "text": "The NetComm session actually has to be destroyed, but but even for Netcon clients, just because they do a commit. Doesn't mean they actually closed their Netcon session. So we may wanna rethink parts of this. I think so I actually, I don't I don't follow your point. With the Netcoff, did you say that, the private candidate gets created upon first at a config. Yes. And when does it get destroyed? And when the Netcon session closes, that's what I thought I heard. Yeah. Yeah. So but but NetComm clients don't typically close their NetComm sessions because they do commit Yep. That's the change in behavior. For many management systems, they will have long live NetComm sessions. That will last days or weeks. Yep. And they're not gonna disconnect just because they can get it commit commit and And so why is that a problem? And what's the incompatibility? Then they won't be able to use this mechanism. To if the require having one of the account sessions then. Yeah. Because you seem to, get give given the impression that the response any edits that come in conflict that anything that net concession is trying to do at that point. Well, I'm saying 2 different things. I pivot my pivot is I started with rest now I'm doing things in the net net half. Because you're saying that the commit for NetComm happens when the NetComm session closes. And I'm suggesting we're stating that many management systems, they don't close in the concession. To to clarify it. If if if a in that concession, can can do a commit, and that will commit the private candidate at that point in time. Okay. So then it's not really tied to the closing of the net concession. Yeah. I think you misstated earlier than gate can fix, Sorry for the confusion. But still there's an open issue, I think, with restcom. The support for rest of them. I would like it but more if it'll be possible to for rest clients to also be able to have private candidate distrust."
  },
  {
    "startTime": "00:16:10",
    "text": "What we'll think. I just cut just to comment on this discussion. So, as a contributor, So I think the net conformer, I don't see why there's an issue there because it just means that your private candidate store stays open for a longer period of time. So to why that because, I still have to unsale your point. There was a misunderstanding. But it actually isn't when the conversation closes eprom It's when the commit happens as the private candidate Oh, and then you recreate a new one afterwards to a new letter config would create a new private candidate. Just leave some At the at the point, can you pull up that diagram? I believe there was bag them in the slide deck. Yep. That's James Carmen from Nokia. As a co author. So, the session remains open. And the, candidate configuration, private candidate configuration remains when you do a commit, it is synced with the running configuration, but remains open. So it doesn't get destroyed and recreated. So it is a long lived thing. It is continually updated, so it doesn't cause an issue with any management systems from that perspective. And so that's from a from a Netcon's perspective. That's the plan. And you can see in the diagram. Let's use the top one here of private candidate 1. We make a bunch of edits. Do a commit. Which does an implicit update or an explicit update behind the scenes. And then that is basically your you know, where you where you currently live in the tree. And that remains until the session gets closed. The restaurant side is different. Sure. And then I think, know, Rob was trying to articulate, I think, that It's it's maybe less useful in the rest point environment. Given the the short lived kind of, activities that happen with each individual transaction. But it was placed in as you know, from from some feedback from the group, So, yeah, if you"
  },
  {
    "startTime": "00:18:02",
    "text": "if you could take a good look at the the restaurant side of things and and make sure that we have it correct. And that it's still valuable, then that would be very useful. Feedback. Thanks for the clarification. The neck outside looks brilliant. Just the restaurant side. I'd like to see some ability for the support to be there as well. And, and just a quick comment on the Rescon side, I think the thing interesting is I think you can create the date store. You'd have to give it like a random name probably a random ID. And then that is is the how would you stop anyone else from editing that same one coming in for another request and want to edit same data store. Is interesting, but I think it's an interesting problem. I also agree with Kent. It'd be nice to have a solution with the rest cave, might full private candidate beyond the single request. It could be tied to the authenticated confuse her name. Okay. That makes sense. Kent's got some good ideas here, I think. Sorry, Jan, for jumping the queue on you. So go ahead. Give johnname.cisco. So I really value this private candidate initiative. I think that's a valuable functionality. I would definitely want to use that in our products. There are some, aspects of this that I don't particularly think is wealthy. So we had, for example, you have this many different modes and stuff, it's too many modes for an efficient implementation and ability. If if you have 6 different modes since some service would have to support all 6 and clients several. It it becomes a testing matrix problem. So if we could reuse the number of modes, I think that would be a good one of these modes is about, how you update things as to when things change in the in the rest of the world, you have this, what do you call it? Also updates? Oh, auto update something more. Right? If you're if you're a survey implementer, you always have to keep running in the database at all times. Right? There's no way around that. You have to keep"
  },
  {
    "startTime": "00:20:00",
    "text": "running. Updated. Private candidates can be implemented as either snapshots of the whole running. Or as, delt us towards running or something like that. So you have to keep track of what's differences they are in running. And the if you're not using this auto update then you have to do this. And the if if you're running as big, that becomes a scaling problem. So in the you have a single medium sized router, I don't think that's maybe a big problem, but if you are have a much larger configuration to care about. That's that's a problem, a real problem. And I would really like is probably kind of this concept to work also in the large scale systems. So that's an important point for me. And there, as we have discussed a little bit earlier, and we will discuss more this later this week. There are some changes we can do to this to fix that, I think, And also as the author of the transaction ID draft, I think there's lots functionality that's could be reused here, in my opinion, that would fit very well in here. I understand also the sentiment that you don't wanna force people to implement transaction ID, but So maybe we can, at the core of this is the concept of what the conflict is. And I think if we can agree on what that is, we can even separate that into a separate draft that we both reference, browse from the pre can, or whatever. But I think we need to agree there so that we don't have to implement 2 different conflicts resolution mechanism for each draft, that would be a nightmare. Thank you, Jan. Just to address these points, very quickly. First of all, to clarify, sorry, in the draft, it's not referred to as heard is referred to as continuous rebase, you know, just to clarify. That was my mistake. I Yes. I agree, that the I I certainly hear what you're saying about the having lots of different modes I think it would be good if the working group looked at those modes and we could reach some consensus, you know, about whether those can be reduced"
  },
  {
    "startTime": "00:22:00",
    "text": "and I also note your comments about, making this work in in the large scale with respect to the the update made. And yes, it would be it would be nice if we could agree on a definition conflict so that that concept could be reused. And I will make sure I update the list with the outcome of any discussions later in the week. Excellent. Excellent. So Hi. It's it's too far. You mentioned that you have resolved or just the comments I have read all of the my comments has been resolved. For example, I read the comment that you extend the Natcalf operations to allows the private candidate to be accepted as a target that store. But and you also, define a new RPC called update, but you don't have the young tech model defining that. I think this is missed in the document. Yes. You're absolutely right. The document doesn't yet define the Yang Data model. That that is something that the authors will work Yes. Thank you. We've locked the queue. James, I know you're in the queue, so you can still come, but, how far are you into your presentation? We that's that's it. And next steps, address the comments in the room, and Yeah. I think there's been been, a lot of useful feedback here. And, are you I think there'll be some discussion on the list about this which will feed into the next version of the draft for sure. Thank you. Thank you. Yes. Transaction ID. Thank you."
  },
  {
    "startTime": "00:24:04",
    "text": "Johnny, and I wanna talk about the transaction ID and the trace draft. All at once. It's now at version, 0 2 And what's really happened since one is, one major thing. It's We've implemented this transaction history concept that we discussed in the last act. Yes. And as far as most people in the room wanted that was an interesting idea. Let's let's do that. And I will, most of what I would present here today is how that works. And, with that, after this update, I don't have any more feedback that I'm aware of or I or ideas from anybody about what go in here. So I think, unless we hear from the audience here within the next until the next ad. Yeah. So what needs to change your updates? I would be asking the shares for, last call or Sounds good. I also added, one more extensions, yang extensions. So that's authors that have interested in implementing this can mark which nodes in the yang tree that will have this, transaction ID, notes or attributes attached. If, as an optional feature. I didn't want to just point it. It does Alright. We might have to move Sure. The Okay. I need to do is Oh, right. So here's how this works. We have a client here that has now, information about what the configuration is on the server, server hits, of course, it has its 3. Then you can do a get config and you get the whole tree. That's That's how net conference. Right? Note though that this free. And of course, it can be the root of the entire tree, but it has to be a sub tree somewhere deep boundary. And and and somewhere. It does not need to be the whole config or even at the the feet. The feet. Can be anywhere"
  },
  {
    "startTime": "00:26:00",
    "text": "Next slide. Yeah. Yeah. Okay. I don't know what you're saying. No. No. No. It it works. It's a META co bug, I believe. I'm on a different screen. I'm doing a show of hand pull and or preparing it. And, apparently, while I'm doing that, it won't allow you to slides. So I'll increment it for you. There you go. And Go ahead. Yeah. Another, the new thing here is that you can calls, basically say, I want to go know what happened since a particular transaction ID, in this case, the green collar represent a particular 1919 This is the latest known transaction ID that line has. And it's asking you, sir, what happens since degree? Empty response back. No. Otherwise, in today, you would have to ask for all of it. Get the whole thing there and compare and finally see, oh, that was actually nothing new So that's, significant savings and if you're on the client side here. And even for the server to not send all this data It's a heavy operation to collect all this information and send it down just to see that it's no change. Thanks, please. Okay. So then here's now another case where the server has I see the change. The yellow notes are new coming from somebody some other manager or operator, maybe? So we do the same operation again. Get conflict since green. And then we get back exactly these three notes. With the pri previous versions of the transaction ID specification, might have gotten a few extra notes, like another green down here because it was difficult to express exactly what you wanted. But now we have this transaction history concept you can get exactly what has changed. And you see this I'm in the corner here, reflecting what the server thinks is the transaction ID. It knows it was green, earlier, and the latest one is now yellow. And the, of course, the server can implement this transaction history in different ways. If it's chooses to use"
  },
  {
    "startTime": "00:28:00",
    "text": "straight integers monotonically increasing integers or something like that. History is pretty simple because you can easily compare which integers are smaller and larger here's more complicated case, and we have an edit config. The client says I wanna change these three notes here. Shadow it one up on the on the top. So in then it sends those 3 down to just as usual, but can it also say If the latest one is yellow, So it's conditionally making this at a contact and feeds the server. Thinks that the latest transaction ID is yellow, If you go and implement that, implement them, give it back a new transaction ID blue So that's a client says, okay. To don't hear our blue, and we'll mark those with that transaction ID down down here. If the client is also using Yang Push, And the subscribing to changes at this part of the tree, it will get an echo. This is a normal thing today. Whenever you describe the things that you're changing yourself, you will get an update telling you what has changed. And then the, it's difficult for a client to know Is this my echo, or did somebody else do something similar to what I did? It's about the same time. Don't know. You have to actually read it all compares. It happened there with my echo. But now this is marked with a transaction ID So we declined to say, oh, this is my stuff. I don't need to care about Of course, still some ways because the server generated the message that we don't want. But this is how subscriptions work, and we haven't changed that in this graph. At least we quickly realized that this data was not interesting. And here's the other case then. We are doing similar change. We wanna change these three notes. Sending them over to the server if late is this blue, but now Data is not blue anymore. So, a change has happened by some other manager or operator in the meantime. So the, on the service side, the transaction ID is red. And in this case, the server would just come back and say, no, can't do this"
  },
  {
    "startTime": "00:30:02",
    "text": "your expectations about the world looks like are not true. We reject it. And that's exactly what the client's hoping for. If somebody has been tampering with dealing with this, I wanna know. So I can re rethink what I want to happen on So that's basically what is transaction ID mechanism is all about. There's, of course, a lot more details in the draft itself. But if you get this sort of level and think this is interesting, go read the draft the little question marks here are supposed to be checkboxes. So we have some implementation experience of this, we have a prototype implementation of this mechanism, and it seems to work. We added this, transaction history concept is for second line is time to say. We added this young extension so that you can mark in your yang tree. This is one of these notes that have a transaction ID associated with If you don't want to know exactly what that means, go read the draft and see the details. So these are the things that all that were on the to do list in the last meeting, and they are done. Of course, we need further implementation experience, both in our own products and teams, but, I would value if anybody else would want to take a look at this. Now it's a good time. And with that, we'll move over to the trace context So before you Alright. Do you wanna ask any questions on this particular part of the presentation for now. Fernando, Francisco. Thank you for a very nice draft. I sent a mail on the list a while back ago. Regarding the e tags, together with Rescomb. So, the The transaction ID is, tags are UTF 8 in this draft. E tagging HTTP is a US ASCII I believe."
  },
  {
    "startTime": "00:32:01",
    "text": "So, that would be earning compatibility. That needs to be sorted out. Because you also mentioned that you, you recommend that different APIs like Rescom and Netcom should implement the same transaction ID, and in in HTTP, the e tags are per encoding. So so that the matching works And but you can select to have a strong attack or a weak one So if you have a weak one, you can have the same, exactly the same item to find, or data in in the attack across everything. But if you want to have a strong matching, you instead need to have a separate encoding. I think that's a very good point. You are quite right. We need to update the exact, format of these tags a little bit. It doesn't change the mechanics of anything, but it's just conform better to HTTP documents. Thank you. Thank you. So we had a quick poll that we wanted to conduct so maybe maybe maybe So if you could respond to that poll. We pads You have to be logged in to meet echo to be able to participate in both Yeah."
  },
  {
    "startTime": "00:34:05",
    "text": "Many no opinions. It seems like people need more time to read the draft and internalize it and and respond on the list. Last call will assess the sale quickly, I think. No. No. I I didn't want to ask for that call now, but I said for the next meeting, I would be discussing with you about last call. That's my plan plan plan cap. At least I'm happy to see that no, but it really, again, just a quick one on the call. I'll just note that often actually the other polls I've seen that's happened this again, there's been a large number of no fees. So there might be towards in the room who don't know and hence in it, so don't skew it too much. And I think I guess one thought Yeah. So I think it's approaching last fall. So if you wanna read is something that's reasonably stable, I think, and, it's good times feedback. For for divided please do greet if you have anything to say about this. Can I just make So one other comment on the actual? I haven't read the latest version of the draft, but one thing I think will be good to get resolved or have discussion about is this overlapping transaction IDs and private candidates at all. So it'd be nice to know there should be any change of direction there, before last call. Is that sense for things just to have a discussion there. Mhmm. Okay. So I will move over to the quick to the next topic, just one minute here. In the interest of time. We have a couple of other drafts. There's a transfer trace ID. And, they were adopted before this meeting, and there were no updates since last ICF meeting in this And basically what they do is they're taking some worldwide web consortium says Dee headers. Or rest headers, and mapping them in one case to NetComm. So it's a very simple mapping, taking exactly initiatives from W3C. Making them into XML attributes. And the second draft is saying, basically, take exactly what's"
  },
  {
    "startTime": "00:36:03",
    "text": "a conversation says and turn them into rest headers. That's all there is. If there's, literally half page or text for each one, So We don't think there needs to be done anything else for this. We would just want these concepts from a well rated consortium to fit into the rest then confirm. Because it So for those last two drafts, it seems time for do an adoption pull. They are adopted, I think. Oh, okay. I don't know if you have Are they free? officially announced it, but, we are come far on those. Okay. There it is. At maybe we should talk a little bit more about error. No. We have these are also check We have talked about air handling. We published them as, should, And now we need some implementation experience. And there's more W3C, predicted contents that is that is related to this package that we should be monitoring. And maybe to similar drafts for. I think that's it for me. Okay. Thank you. And interest of time, we'll move the next presentation right away. For for for Yeah. Name is Piran Deshong. I'm from Sysco. Unbagged others. I'm I'm running to present the recognition mechanisms for, medical records. We're now at 2, version of the draft. Yes. So, And, overview is that there's a one draft defining the mechanisms, filtering, etcetera. For lists and leaflets. And and then one protocol draft each for netconf and restconf defining the how it works for them. The current status is that, curses curse of pagination that has been discussed before, is finalized now in the draft."
  },
  {
    "startTime": "00:38:02",
    "text": "There's a snapshot support for it, conflict falls. Added so you can, indicate support in total per node and, in the system capabilities, model, or 3 and then, enable it per request. Also added is local aware collating or sorting, you can possibly now select which, locally you want to use. And then signal the server can signal back and what, was used to one claim. And then there's, some tutorials that has been made, missing definitions. And things trying to find error entities that have been discussed and and and and I also added this Yang security considerations template text I don't know if it should be added or not. The moriarty draft. Cursors based, pagination then, the graph, it's to find that a service should support, cursor based pagination. You can off list, and you can offset a list then not only by a number of, elements, but by a key so this means that it's only a conformance list and not leaflets And, currently, is augmented in the system capabilities. Tree that curs with the cursor supported leave. So it's now opt n but perhaps it should be hoped out. So this is what it would look like. Have a cursor, some base 64 encoded thing. And the limit of the elements, and then you get back this annotation with the previous time mix. Courses that you can, package So I would like to poll, the room if it's possible."
  },
  {
    "startTime": "00:40:02",
    "text": "If, cursor based technicians should be opt in or opt out, if it's possible. Otherwise, we can take it on list. Looking for moving to the ball. So as an individual contributor, I would, it's now defined as opt out I would actually suggest that it should be popped in because that would be, Niceer to have it's sort of expected if you work with databases. So what, I don't know what yes or no means now, but, say, when do we do it? So we'll redo it. Should So do you just make either of yes or no be obtained or opt out doesn't matter. A bun or just So, yes, it's now but it should be up then. Okay. I think we can continue this. We don't need to So, can if someone just can note that, it the room thought it was obtained because I'm be part of the So pagination with snapshots, and it's defined now that the server may support snapshots,"
  },
  {
    "startTime": "00:42:00",
    "text": "you augment, system capabilities with the snapshot leaf. Team to get sport, for the targeted, config false list node. And you have the snapshot query parameter to signal that you want to take a snapshot for this pagination. Yeah. So you can enable snapshots per request. The law of values are true and false, both for lists and leaflets. And, if the snapshots are not supported, you get back this a error error identity. Or the error app tag is populated with snuff. So snapshot will not support Moving on to local aware sorting, server support, is must for config drillists, should for config faults, and, you may disable it for config false lists. In the constraint system capabilities done. So, reading our slides. Yes. So code points can be collated, differently depending on on locale. I have extra slides if anyone wants this clarified. User account, select locale I have for their for their sorting collating, pagination, and being informed of what the server actually used references to relevant documents, Yes. So the user can use the sort locale collate. Query parameter, where the is a free form string, but should be a language sub tag defined in RFC 5646. If this is omitted, the server chooses local, if it's on if the look supplied locale is unknown or invalid you get back, this unknown locale error and the server signals the metadata value and the response, what location was used when it's working. If the node was not constrained. So this is what it will look like."
  },
  {
    "startTime": "00:44:00",
    "text": "You have the request here with social calculate to be sent in for the Swedish locale get back a sorking, and then the or the collating and then the what the server actually used. That's a metadata Yes. Some editorials should we use this Yang security considerations template or not. Can take it on lists or on your view. So the next steps, fix these editorials, And then I think It's pretty much done so we could go for a working group last call. Questions? Okay. Oh, okay. Well, while we're waiting for Sean to step up, to go ahead. Well, just very quickly, I just wanted to ask as chair. How many people have implemented this draft? Is or anyone has anyone implemented this draft Yes. I assume you have. We we have, customers, not of everything and I've implemented, 3 5ths of it, I think. Is anyone else implemented? I think there's one more that I've heard of. Something like it, but I don't know Okay. And that's over or is that your competition Which one? That's okay. That's not mine. So there's a third one. Okay, but still, that's pretty good for a draft that hasn't last called yet. Sub Thank you. So I I have got some confusion about the snapshot parameter. I think define a snapshot parameter, but I don't really understand how did the client know whether to use that parameter or not? Or what's the difference between using that parameter or do not use that. You clarify a little bit more because So if the client sends in the the To take a snapshot when you're packing it in, you have to send it in Yes. So then the pegymianian would be"
  },
  {
    "startTime": "00:46:02",
    "text": "The retrieval will the reroute will be returned best on that snapshot without yet, but how would Clyde know whether to use it or not? Mean, you you like to recommend the client to use it for some highly dynamically changing it's totally up to what the user expects. There is. However, I I recognize now, missing point, how do you do with subsequent requests? Tag anything that's Okay. Thank you. So that was me. I think Actually, can take it offline. I think. Okay. Might be able to answer a little bit of that, which is I don't think shots are very useful for config through. Notes. You already have all the configuration. You can iterate over them yourself. So it rose just for config posts. And I would imagine, it's probably highly dependent on the implementation of the database. Yeah. And also the application, I would guess. What what you, expect it to be I mean, the size of the data data Okay. Thank you. Hello. I am Alex, from Insaleon. Presenting an update on the UDP notice draft. So since the last eight year, we have had a lively discussion on the mailing list. So we would to thank George and Andy Hans Benoit Kent for this feedback And so far, and today, I I would like to go through to different issues, I have listed So"
  },
  {
    "startTime": "00:48:00",
    "text": "Let's go so first, there were some concerns about the packet lost given that UDP notif is based on UDP. There is an applicability section stating that UDP notif must be used when This is not a concern. For unchanged notifications, we would expect to use are reliable, transports such as, HTTPS Notive. And so far, within this iteration, we have moved up only, the section stating that, yeah, that 2 g p not if it's more for counters and things like that, that are not, that for packet loss is not a concern. Basically. I don't know if we want to raise the questions during the issues or at the end, hear us. I'll take continue until steps on Okay. Yet. The second use issue was regarding the segmentation implementation within the draft, the there was, the race that the cementation was too similar to the IP fragmentation implementation. And therefore, why? Do it at the UDP 90 level and not use the API layer. Here, we want, to to state that we are using the UDP usage guidelines, in RFC 8085. That state that, UDP application should not use the, fragmentation, and that's why we, also, give that implementation UDP native level. And also on during a hackathon in 110, sometime ago now, we also did some tests in in performance, and we noticed actually that"
  },
  {
    "startTime": "00:50:00",
    "text": "when the packet was fragmented at IP level, and there is a big drop in performance in Dinos. So that's why. And on this iteration, we have aligned totally to the RFC 80 85. So we have I put the mask into a shirt since in the UDP usage guidelines, they in the state that it's recommended, but, not mandatory. Also, We were raised that the version number the definition of the version number of the protocol was not clear or So in this case, we have just predefined it we have put also, the link to the Ayanna registry so that it's it's clearer And then, last, some editorial changes based on the, on the feedback. So the first one was regarding the message length. It is was it was not clear within the draft that when the message was submitted, segmented using, UDP Notive if this message lens was for the entire message or only the UDP data. So we have clarified that. And also aligning with the distributed noteiftraft or using the observation domain ID, ID, so this definition has moved to a mess So to identify your help is moved to message permission ID. The goal of, observation domain ID was taking the definition from ip fix, but we have noticed that, it raise more confusion than anything. So we have changed that name. And then some other editorial, changes on the DTLSX based on the feedback from Hans, nothing big"
  },
  {
    "startTime": "00:52:00",
    "text": "always stating that we are using DTLS but not extending to d d D TLS protocol tool. To encode our to encrypt, UDP native messages. So what's next, so far we have We believe that we have solve all those issues. Please if, you feel that, there is a still issues raised them on the mailing list or doing the working group meeting. We suggest to the charts up up to you to, reach out to the trans portfolio directory, directorate, for an early review. That might be, useful for for clearing all of these concerns maybe, but up to pictures. And, of course, on the next iteration on we are planning to remove the generic UDP client and UDP client groupings, students, we've got interest from the working group that, it should be in a dedicated draft for usage in other protocol stacks. This draft will be presented and later on. So Alright. Speaking as a contributor So Oh, sorry. 1st as a chair, we have sent a request to the transport services group to get their feedback. We're still waiting for that. To your I think it was your first point, point, point, which was about, the fact that you're now recommending that the size be no more than, I guess, 64 k No. One case. Sorry. Which which issue is was the 7th. Yeah. Confidence of what No. The second pointed that into users. So are you"
  },
  {
    "startTime": "00:54:01",
    "text": "So your your recommendation is that it'd be, I mean, we we are we are not recommending any size of data. We are saying that, when there is a packet loss, when, when, when there could be a packet loss within the network, udp notif, should not be used. And, of course, within the configuration, you have so the MTU and you you are able to set the parameters for cementing on based on on your capacity of your network Yeah. I think that should is probably a fairly strong indication that you don't want the implementation to exceed That's science. Ideally, of course. Alright. But for sure, you don't know whether the message is pretty big or pretty small, and it's with young push, it is actually variable depending on on on the young module you are subscribing to. So so we are only giving the mechanism to do it ideally, it should not, be used but, of course, also using the guidelines of, UDP applications. Arps. Yeah. I think it would help to be clear that either you wanna support it And, that you highly recommend that everyone limit the size with a packet Okay? So I I did not statement saying that, that, it should be supported that ideally, the package should be Yes. Okay. Okay. Robleton. So, going back to, I think, your first issued the previous one to this, I don't have concerns so much about packet loss, but I think in when UDP's being used often in ISG reviews, they want to see something about"
  },
  {
    "startTime": "00:56:04",
    "text": "congestion control. So I think that's something that we discussed with chairs and things like that. So I'm not sure what the answer is here. The answer might effectively be, say, you should only employer in in scenarios where congestion control is not an issue. So that might be one solution. It's it's coming up through management networking and guarantee there's enough provisioning or the device that's receiving at the country, the collectors very close by, you may not matter. There definitely need to be some text here about congestion control, Whether that's sufficient, I don't know. There is actually a text, and there is a subsection on the applicability section of what congestion control That really covers this. Yep. Maybe that's sufficient, but, hopefully the TSB review when it if it's gone to them, I'll I'll definitely flag that and say that because this is gonna be good enough whether that even helps it on it. And then Kent has a contributor. Okay. You made a good point about how it was just count it doesn't very much matter if you lose a packet or not. I think it's difficult for the applications to know how large the size of the messages will be because as say, yank pushes variable. But I also recall that in yank push configuration, it is, on a person's the transport that should be used. Yes. And I think that then it's possible that, you could say, well, give me notification for everything, that's not data plane, you know, high throughput data plane specific using HTTP. But then just for the data plane high throughput, information UDP notice. And so there maybe could be some guidance that could be had or put into the draft to make those recommendations, if that's possible, and then taking it one step further, maybe there's something in the configuration that could be said. Only send over UDP if it's besides the messages as a certain size. You know, whatever my MTU for my network is, otherwise use HTTP Notive. Just tonight. That's the last part of this discussion, a recommendation."
  },
  {
    "startTime": "00:58:00",
    "text": "I don't like the idea to like choose the transport based on the size. I believe that it it it is up to the user to choose which transport, right, And, and, of course, it's always experience. So I don't like the idea personally, to add that. Having a statement that it is recommended that when the packet is very big, use HTTPS native. I don't have issue with that. But I wouldn't go that far. But Agreed. I'm in interest of time, I think we'll move on. Are you done? Is is Okay. Thank you. Case. Yep. It's morning, everybody. So subscription to distribute notifications Oh, I was in a different tat tracking. Okay? Okay? Sure. I gave you 10 minutes for both presentations. No worries. Okay. So from IPF, 117. We had 1 remaining, item is reviewing the observation domain ID terminology We got some input from, from Benoit that, the domain observation ID we took from, from IP fix because it it is very similar and the problem. It is it is very similar, but they're not exactly the same so that was was was more, raising confusion than actually helping. So we decided, in, this version that we are addressing this by changing the terminology to, message publisher ID. So we don't have any ambiguity with IP fix anymore."
  },
  {
    "startTime": "01:00:04",
    "text": "We hope, that addresses the concerns and requesting feedback for, from the mailing list And, other than that, we don't have any other remaining, points. And, we believe it's ready for the last group last call together with the UDP notice class. That's Okay. To chair the UDP note of draft, I think, current the depends on the new UDP client server groupings draft. Right? Which is not yet adopted. So we could possibly progress this draft, but then it'd be stuck in a misref state with the editor I think we should discuss that when the draft is being presented and Okay. Any questions or comments, then we can move to the next Good. I'm gonna write I had to go to the next place. Exactly. Sorry. Support of versioning in Yang notification. So description, just as a reminder, what is the the scope of the draft you see on the left hand side, the additions on the the subscription, notifications so we are adding the, basically, the module name, the revision, and also the revision label. So that in the subscription state change notification message, we understand for configured subscription, what"
  },
  {
    "startTime": "01:02:00",
    "text": "module has been subscribed to and also what revision and, semantic in this module has. We got 2 feedbacks for my, yeah, the IPF 117 from and one is the the arrow handling. So we extended the data store selection section out describing the, the new errors identities for, revision unsupported, revision label unsupported, and incompatible evasion and revision label. And in the operational sections, that's the input from, from Rob. We gave some context towards the yank package, how it offers a complimentary information by describing how one specific module revision is part offer set of, young modules. Requesting feedback. I hope it addresses, your concern. And I like to state that in the afternoon, at researching at the Palmaovka 12. We have a site meeting regarding the yanked to Kafka. And message poker integration. Okay. It's good. I I think Okay. There is no comments? Okay. Good. Mix. 2, Tomas, you're presenting this one as well. Are you not?"
  },
  {
    "startTime": "01:04:00",
    "text": "Good. One lot to go. Supportive host event sequencing in, young notifications. So here, shortly, cap, what is about. So, currently the notification had a only has, the event times of when the message is being published, published, we're heading now, 2, 3 further items One is the host name of the exporting router and also we are adding so called, message publisher ID. You just heard from the, distributed notice draft I was presenting before and the the sequence number. And, the goal of, this draft is basically today. Network operators, when they are receiving young push messages from the network, in order to, to forward those match messages to a time series database, they need at midpoint, add actual, or at the data collection, they need to add this information. So that actually that the end system is able to understand from which note this message is actually coming from And that poses a problem that we are changing now the semantics at midpoint And, since now, the the Samantha validation, especially when you do that into a big data chain integration is relevant. We do not want that, so that's why we are putting that at the point where the message is being generated at, the young push publication. So we introduced this stuff that IPF on the 16. There was a Paul, which showed a much interesting the net converting group in this, version, we changed terminology, coming from the distributed notice draft from domain observation ID to message publisher ID"
  },
  {
    "startTime": "01:06:03",
    "text": "And, currently, there are no open points and, we are requesting working group adoption. Yeah? Yeah. So I understand very well the need for this host identification somehow. But, how do you foresee host would know how it is known. I mean, it's the the clients of this information or the interprets of this data, somewhere far away in a chain may not look upon the host name the same way as the host itself or something. So that name that he wants to know and the other ights, needs to be transported back into And did you think about that? Something? Right. So we try to be as close as possible to the auto network telemetry protocols So that's why we were using this name if you look at what the BMP RFC in the initiation message, that is his name being fine. And also, it's actually not coming from, BMP itself. BMP is also relating to a SNMP where this is actually being coming from. So I believe you are very well aligned and at the end, Yeah. Host name needs to be configured on the host. So we believe that the network network management system, should know that this, this network node has has this whole thing. Thank you. Sure. So this, I might ask this question later on also, but I believe that a combination of at there's another draft that follows this, I think, which is about this time. Is there any reason why we're splitting this into 2 separate drafts because these are fairly small changes. Could they be combined as into a single draft? The reason why we sec separated to 2 is here we are extending the notification header"
  },
  {
    "startTime": "01:08:02",
    "text": "and the second draft is extending the young push header. With the domain ops, with the, with the timestamp. When the matrix was being observed, So here in the notification header, we have a timestamp which this defining when the message was being generated or sent. The other one is but I'm open. Yeah. Of course. So he's just doing a quick for Sure. Sure. It's Right. But there's tuner sites. Wait. Wait until after. Okay. Right. Then let me see that 2 more slides. Okay. Okay. No. K. I'm gonna go ahead and close the poll. So I think it's largely hasn't, not many people have read it at this point, so maybe Let's continue the discussion on the mailing list woke up."
  },
  {
    "startTime": "01:10:11",
    "text": "Yes. So I'm Alex again. I and I am presenting an update on young model for net even notifications. So for to give you a bit of context, yam push was based on the implementation of, netconf even notifications the orange header was defined within an XML schema within RFC 5277. And then, the Jamposh header was wrapped within this notification. YAN push also allows you to encode the YAN push notification message in other encodings than XML. So when we are using young gs or young seaboard, we are not able to validate the message since the these schema is defining XML only. So that that's, what this trust tries to solve So what we propose within this draft is only solving this gap. So it is a very, very short draft defining the structure of the notification within a young module, it updates RFC 57. And uses the same netconfigure and notifications. Also, the Even time is camel case because on the x ML on the finishing, it is camel case. So the whole, definition of this, module is, in the draft, and it's very short. Current status, we have had some editorial changes based on as a feedback from Andy and Tom,"
  },
  {
    "startTime": "01:12:04",
    "text": "from the mailing list, we have extended the abstract explaining which issues we are trying to solve. We have fixed the references and explained also why, the young URI and the is the same as the XML URI defined in another traffic. There there there has been a bunch of questions about how the this draft and the net of notification messages are, in linked are, are common. So we have added a section explaining the difference, for that. And then at the end, we have added some examples of how, this encoded message, should look like on the keyboard encoded So, current issues long time ago, I I've had the feedback that was not right for this young module. I have no problem in changing, this, graphics and also, and erase that, this should request severseit. I am currently discussing with the core working group for that. How it should be managed. So I am suggesting to to wait for the CRC to be and let's see how all these discussions with the co working group coast. So, what's next? So to to summary, this draft is a very short draft, very simple one. But also very crucial, to validate the Yahoo's notification header. It is something, that is, used for example, in the young, to Kafka project to validate the whole thing based on the different young dependencies."
  },
  {
    "startTime": "01:14:03",
    "text": "So in my opinion, it's a very important one. We would like to request more feedback, from the working group and maybe a working group adoption if, there is an actual interest on So, I'll go first and more like the chair hat on. I believe you had a slide which is comparing that Yes. Message is Right? So first thing that kind of jumps out for me is that's a workgroup document. And has a definition for message time. But they call message time. So we have a duplicate definition in a work group document Yes. And understand that you want bad for your purposes, but we can't have 2 documents trying to define the same thing. Mhmm. So Have you talked to the authors of notification messages to see Either work with them k. To to move that draft, if that works for you, giving other data notes also, but it gives you at least the what you want from an event time perspective. So could you, for example, if that progresses Could that be used by by you also. So The thing is that they define, new structure to bundle the, multiple notifications within the same, yampoos notification. And, in my young module, I am defining only the gap Right? So in my opinion, both your modules, soft Well, they they are actually, focus on implementing new features. So getting a bunch of application within the same. And, the younger expects to only fill the gap on RFC 277. So I what I would expect is that the second draft,"
  },
  {
    "startTime": "01:16:01",
    "text": "depends on the young module I defined. So Hi, Alex. I just wanted to do, you had a slide on the civil state allocation, I think, And so just the status of that document, it's it's an IT It's an ISG review at the moment, and this call will discuss blocking that document. But that was discussed this week, and I think those are gonna clear. I think we now have a path forward. So my expectation is that should then exit ISG reviews. Speak to the microphone, please. I thought I was, and now I am. Sorry. So the I was saying the civil sit draft, I think that's now clearing ISG review. And so, think issues have been resolved, so hence, and then progress. Hence, I think it's probably is worth getting, single SIP range allocated and maybe generating a SIP file for this. Fair enough. I I've this discuss with the working group chairs, to see, what they were focusing on and also to see if they were having guidelines for these allocations. They have not. So I would expect that What what I want, with the SIVOR SIT allocation is that Okay. I'm okay implementing them within the draft, but then, I would like to have guidelines for next people implementing to also allocate them. Right? Because otherwise, I would only have the Jamposh header with the seaboard seat and the rest with with the c bar the normal circle. So for me, having only this draft is useless. But that we need some guidelines on how should notifications be defined? And how this silver sits"
  },
  {
    "startTime": "01:18:01",
    "text": "should be allocated So they So that's my only, concern. So the civil seed draft, it should have, document effectively how you allocate seed for existing RFC. So one RFCs that would have young ones published there's a plan for generating cifols for those. So that would solve that problem. The one interesting thing for this though is it's obviously more efficient if you can compress and allocate the IDs close together. This might be a case where you want to try and tweak things so that the the numbers you're using for the parent Yankpur structure, and this one are quite closely aligned. Because as far as far as I understood is that what you would have within the whole network is, you either encode the messaging c bar in normal c bar or in So to actually use the CRC, you would need the allocation of this seed range. For all the young, dependent Yes. Exactly. So that's something I would like, I don't mind doing it. But then I would like the working group to push other people also to, allocate these seats. Right? You you may not need to just by doing your draft, maybe the forcing function is required to get the other ones allocated. Is it? Yeah. So this Okay. You mean the the automatically allocation from There's been 2 discussions on that. 1 is whether when you publish an RFC that has a seed file, that if the is to be it depends on other young models. I don't have to files. They'll get generated automatically. I was pushing for them to actually just generate the civil survey published RFC. Yeah. Not every pop sharps into the Yang model. And so it solves it either way, but I don't think you need to worry about it here. Okay. Okay. Yeah. Next, Kent, I think with all hats on, I just wanna thank you for this I I I really appreciate it when people"
  },
  {
    "startTime": "01:20:01",
    "text": "bring, drafts to the IETF that are trying to fill gaps that, you know, this is like something that hasn't been defined for how many years. So thank you. Thomas Gaff Swisscom. So speaking for a network operator and looking at, current industry, we have Basically, all the major vendors have being implementing proprietary and push solutions So, we are aware of many implementations, implementations, which are coming up. And, therefore, in this context, I'll as a as a co auto. Think it's important that we are progressing with this stuff very quickly because it's a gap currently within, a young push. And if you can resolve that quickly, that would lead to, cricut option in the industry. Thanks. So as a chair, I would like to fast track this adoption as well. So we'll discuss this Thank you There's one more, I'm in. I'm in. Alright. Yep. I'm here. I'm at Swisscom. So, just a question to the authors here. The whole premise of this draft is to provide a description that you could use to validate the messages that are coming from the routers. Right? I'm wondering first how why use truck subscribe this. And second, have you does the existing tooling provide this validation, or we have to validate it with a new tooling. On top of this. I haven't heard the the the first question. About the second question, so far, there is no tooling for that. We are trying to use, Yankee a young kid, they have implemented the support for this header. And the first question was, why use tracks? Structures for that. Because, the notification in young is defined as a"
  },
  {
    "startTime": "01:22:00",
    "text": "statement as a keyword. And therefore, you cannot define it as a simple container. Okay. So, basically, when you define, for example, in, young push, the push up the notification is defined as a type And this type, the notification type is not defined. That's the issue. So here, since from what I implied from your answer to my second question that there is special requirements to use this track to validate I would like to see this because the standard tooling would not work. So there must be some implementation section to tell you how you would validate the messages, like, using the same, using the structure that you provided because it deviates from the standard, the end, at this point. So Kent as a contributor, I've have software that validates SS Structures. And what I do is I quickly rewrite the yang module to be inside of a structure to container. And then I validate it that way. It said cheap, but it works with all those standard tools. Yeah. But, I mean, we have to document this somehow. I mean, it's the heck that you came with you're right. Okay. X, the next presentation. So here, I I am presenting the a new draft about, generic young groupings for UDP clients and UDP servers. So the context, it was from the last eight years that I got, some feedback about"
  },
  {
    "startTime": "01:24:00",
    "text": "these definitions within its within the UDP notice draft and that there were some interest on having them in a dedicated draft. So so far, the scope of this draft is having, generic groupings for UDP clients and servers and also including the DTLS implementation. So this, is to be used as standalone or, with in combination with other protocol tax such as, for example, the UTP notify No surprises. So for the client they were already implemented in UDP Notifraft. So I've only extracted those and put it in, in a teardrop. The IP address is the fine as IP address now zone, from the feedback on, UDP. The D TLS container, I am using the ATF TLS client generic grouping, to implement it. And since, we are focusing on the TLS 1 dot 3, we have 3 most from the fee, we have removed the details from the 2, bits from the young module. And also, the feature statement of DTLS. So it's also defined within this yeah, module. Same for the server, but instead off, using the the client ones. I am using the server ones. And So, yeah, I would like to request more feedback or more contributions to this work, I understood that it could be interesting for the quick working group. So I will send out an email to them, so so that they are aware of this work"
  },
  {
    "startTime": "01:26:01",
    "text": "And, as I stated before, since it becomes dependency for UDP, notif, I would like to request, working group adoption. Yeah. Okay. So I'll go first. Kent in the queue as a contributor and also co art holder, I believe. But I and I mentioned this once before, I think this draft maybe only needs to define the UDP client and UDP Server groupings. And not do the detail less extensions. Okay. The reason why is because those extensions are currently using, using, the TLS, it's, groupings from the TLS client server drafts and, and therefore, they don't need to be redefined in this draft, but and any consumer who wishes to define a detail less spec can, use the UDP like client grouping and also the TLS client grouping and compose the equivalent stack themselves. Okay. So this draft will be dramatically simpler. You don't actually have to have the detail less plan or the details of the server parts in it. Okay. And just leverage all of that from the existing TLS client server address. Okay. I implemented those because, from an email from from my You you were interested in in those. So I guess guess guess just, I mean, I I probably must have suggested it because I thought it, it's just the one grouping that needs to be included in used insight. Right? But in all the, other client server, drafts that stack of them. This is always the case that they need to be used as well. But they don't redefine them themselves. They they just simply refer or use the grouping that's being defined in the other drafts. 7. Okay. Then, yeah, if the worker group is okay, I will remove them from from the draft. Yes. That makes and that makes this draft even smaller and quicker to get through. Yeah. Thomas Garth from Swisscom, maybe can you go to the slide where you showed, yeah, Exactly. Mahesh was already, raising that basically by moving out that information and"
  },
  {
    "startTime": "01:28:00",
    "text": "to another draft document. We are creating a dependency. And as I said before, the industry is moving forward, we we are looking very forward to the adoption of yang push and that's another puzzle piece, which is needed. So therefore, and if I recall also correctly from, Rob's comment, in previous that, we would welcome that this is being also fast tracked as well. Okay. Benoit. So There's always a novel goal to have groupings. Right? So, If I look at the history of what we're trying to do, the series of draft is and TLS and client server. Looked up the timeline there. So, okay, I won't I will mention here, but My point is that since there are dependencies, is there a way that we could send this working group if it didn't go through in a year, or something like that or whatever ex meeting then we go without the grouping. Because of dependencies. Because my fear is that I mean, I witnessed the experience of the series of draft that you have can't, right, client server, GTP TLS, It wasn't many, many years. Right? So can we just say maybe with GAD there. If not done, within that time frame. We forget about that. Because we need those dependency now. Well, I mean, in terms of, think the chair is still in agreement that since this is a dependency to an existing working group document that we need to progress. This become a working group document quickly as possible. So We would also fast track this. Okay. Thanks. Okay. Thank you."
  },
  {
    "startTime": "01:30:20",
    "text": "Alright. You can go ahead Okay. Who do this Right. Okay. So my name is Jocelyn, and I'm from Echolobaltenic and I'm presenting the project team push integration into Apache Capka today. Which is the internship project that I've done, in Huawei. I research center. I work on the Libyan push parts that handle the push messages and yamdo, yamodel registration to schema registry. And next slide, please. And stay on bringing an introduction to the value of this project and the issues that we wish is to, discuss along with the solution we have chosen in the library and with we proposed a draft to solve one of the issues Next slide, please. Nowadays when we talk about network management, we're talking about the 3 steps of issue detection, identification, and corrections. And with the demands of bringing this process into automation in greater, a great basis for this is the reliable telemetric data which guarantees that the issue detection results is complete and accurate. And in terms of the completeness, we need the metrics from 3 plings management plan, theater plan, and up operational plan, And in this project, we will use the yam push method to collect the operational metrics which is the YAM data. And in terms of the data click"
  },
  {
    "startTime": "01:32:00",
    "text": "correctness, we need to make sure that the metrics collected using this method. We will be clear instead of being misleading. And next slide, please. I think you can progress the slides yourself now. Sorry? Are you able to use the arrow keys to progress the slides yourself now? I'm not sure. Let me check. Oh, Okay. So I see you're asking to share screen. I'll just I'll do it I'm sorry. I did pass the slide it didn't work, I guess. Okay. So next slide, please. And in the classical natural telemetric framework we're using to date, it's not possible to directly apply the push method into this framework because of missing semantics due to the fact that the model that metrics are collected from, is never communicated from the browser to the operator database. And next slide please. We are proposing they did data mesh systems, which introduce a schema 3 in between the router and the operator database. In order to keep records of the year model of each data we received, so that, problem of missing semantics can be solved. And to implement that, the is needed between the schema registry and the data collector PMACCCD to clarify which your model is used by the data and to get it from the router by sending gets schema requests and register it's in schema 3, and that's the job of the library, Libyan push. Next slide, please. And this is an overview of the Libyan push and current states for the library, it has been an open source library in it up. And as for the schema registries, there is there is a working example of the"
  },
  {
    "startTime": "01:34:00",
    "text": "plugable schema registry, but it's not open source yet. Next slide, please next one. Thank you. We have found the following issues when implementing this library, which includes how store the young models in schema registry and how to know the young model of each date each each data and how to obtain the YAM model in its dependencies. Next slide, please. And in terms of the first problems, we need to how to store the models in schema registry. First of all, we need to make sure that it can simulate the data structure. With the following sense, the schema contents can correspond the young source code, and the schema reference correspond to the young model pandencies relationship. Of course, it needs to add the functionality of young validations. And next slide, please. As for the second problem, how to load the subscribe module. There are two ways that we can do it according to our research, for the first solution is to pass the links basis in the first young push messages, we, we we received because the module links is always, recorded as the in the data store content. And this solution also facilitate to find the augmentations, reverse dependence, which is a reverse dependency because its modeling is also in the value as a prefix. The second solution is to use the ITFP unsubscribe notification model to get the subscription information by sending a guest request to that model, and pass the data store expect future or the subtree future. And then we can find the subscribe path and path by passing that path can know the subscription model And in the library, we have chosen the solution to Next slide, please."
  },
  {
    "startTime": "01:36:04",
    "text": "In terms of the last problem, how to obtain the model and its dependencies. And since here, we're not when we talk about obtaining the module, we're not only talking about sending a single get schema request to the router because we also need register all of its dependencies, which could be a lot. And therefore, one single gets schema request is not enough. And here, we propose on demand downloading and get those schema. The first solution first solutions, we do by directly passing the young source codes, to get them. And in terms of the reverse dependencies, we send a get request to the ITFPN Library and model. To to get the deviation list and the augmentation list But since the augmentation list is not there yet, so we did not follow with this solution, instead features to get all schema, which is to gets all the schemas from the browser at the connection beginning at at the connection establishments and stored in this In that way, we manipulate the entire model and so that we know all of the relationship of each year models. And we have chose to use the GaOS schema in the library. Next slide, please. And we have designed a TFS salaries for finding all of the dependency of 1 models by, switched will traverse the entire young tree Next slide, please. And here is an usage example of the a solution we have chosen and this, has been presented before in the less IETF mitty. Next slide, please. Next one, please."
  },
  {
    "startTime": "01:38:05",
    "text": "And in the end, we would like to propose, to augment the ITSM library and model to also provide the augmentation list In the sense that, if the the the solution get us schema is does not work in the long run because it does not facilitated usage with real device, because there are a lot more, yam models in there downloading all of them would take a long time. And in that case, the on month downloading will be more applicable, but only if that's the deviation list and the augmentation lists are both provided in the ITFPN Library. So is reasonable to also have the documentation list, and the draft has already been post it's it's Next slide please. The link for Lipian Push, Lipian Push is, opposed it in the last slide, and It's already open sourced. Thank you for listening. Thank you. Any comments? Questions. Right? Rob, just enter the queue. Rob Walton as as a contributor. So one concern I have with adding the augmentation list into Yang libraries, if effectively almost gives you, like, a duplicate of information. So there's information that's already specified in the yang modules, and you're now also providing that same information in a different mechanism. And so there is a risk there whenever you provide the same information in 2 different ways that it becomes out of sync. And you have to then trust which you're going to use. I guess the answer is that you'd always rely on what's in the yan model incorrect. So that's one potential downside of doing this That's fair."
  },
  {
    "startTime": "01:40:00",
    "text": "Benoit, so I think it's not different than the deviation right, that you've got in the young libraries. The thing here is actually a timing issue If you want to use young push and we're going to receive exactly if I make a comparison with IP fix, we're going to receive yank push. UDP based from multiple routers all the time. The question is do we want to lose the time to get to get all which could take a long time from every single new device that we have or device type or device with iOS or device with a specific line count set. So this is the issue here. It's real time timing of telemetry. And somehow, this is small cost to get it directly. It was a very us into that def the young library. Robleton. Yes. So I acknowledge that deviations also have the same thing. So by thinking young packages, we did took deviations out to remove that sort of duplication. We're going the other direction with young packages. Yeah. Yeah. Agree with Rob that this information is already available elsewhere. So I'm not seeing that this whole thing depends on this, but I don't think it hurts too much either to have this in there. Simplifies for some clients to have it in there already pre computed. That's kinda nice as long as it's not become too larger mean, I don't think it's complicating things too much. Alright. And as long as you're standing up, you hear the last presenter. Thank you. So the the previous presentation is a very good introduction to what I'm about to talk here is, pretty much the same area. So we have also been working with, telemetry and time series database is a bit is supposed to be a checkbox."
  },
  {
    "startTime": "01:42:06",
    "text": "I mean, you have already you have already seen probably a lot of these graphs, coming out of your networks and stuff like that. Yeah. Yeah. We have a line here. It's now showing it is that we wanna be showing, the and much of this telemetry generation that's called based on the Yang cable systems. So we are taking yank functionality and bringing it out in graphs like this. My point is that's in at least in in certain cases, we are certainly getting really nice graphs. But in many cases, we don't really know what we are measuring. I'm a as many of you know, I'm a climate buff. So I want to do, read about energy assumption and those are are the those sort of things. And when I look as we see many graphs that are showing how much CO2 or energy or something that that is being used in my network. But as soon as I ask, alright. So is the cooling cost included in this number here? The guy that's showing me this graph is John King, And usually, you don't get an answer because this is hidden somewhere. You don't know what we are measuring really when you get up to this level, on the collection aggregation, have lost track of what it is that we are really aggregating in And so we are lacking, traceability. We can't see what we are measuring. We don't know even what units is there's any sort of precision guarantees about this So if this is if this is, the important thing is to show a graph and make somebody impressed we are already there. Yes. But if we are to make decisions based on this should we move the traffic to from data center a to data center b? That a good idea? Will I save something on doing that? Then we need to be, pretty sure about the data. We need to know where it's coming from and it's dependable. And I don't think we are there quite yet. So, I'm proposing I just posted a draft called this the fill out list framework because fillet list are all about collecting the time stamps,"
  },
  {
    "startTime": "01:44:03",
    "text": "timestamp data. So there's a very similar to what you just saw in the previous presentation. You have collectors, you know, providers, aggregators, that are bringing this whole, and I'm not really going to focus on that in this position right now. But just to give you an idea, the thing is that we are collecting things from both Yan capable devices as well as something that's totally had never heard about yang. Like, from red feed sources about CPU temperatures, and I know what else that has no yang modules today. But we are making sure that it's landing all data is landing in time series database. And that every day that it's in the database here, has a yang description associated with it. And the log with metadata like the precision, the units, and is cooling included or not. All of these things should be metadata as with this data. And then we are providing it, aggregating this data from multiple such sources with time series, data into yet other times here's data because you are aggregating this, taking all of these and adding the cooling stuff and getting this into time to state this, like, here. But one of the things that I think particular relevant to this room and this group is Okay. So we have data that's on the left side. That's all described in Yang, and we have data in here. That's in the times of your database format. How do we make that leap? Well, we need a way of finding out what do we call the object in the time search database So we know which young leaves they come from. So that's why we have this Christian Lars and I'm presenting this on behalf of Christian. Who has made a proposal on how you take Yang Pass and, including the keys and the holding things and map them into the sort of target form at the time series database is used. So we have this rendering style. We have you start with the model and you get everything falling out with the model. You don't have to have any assumptions, a special you you can be implementing this particular model, but you have that that"
  },
  {
    "startTime": "01:46:00",
    "text": "model driven infrastructure for Pampers databases as well. And this is what it looks like. Basically, we're replacing the slashes with underscores taking out of the keys and setting them as labels because that's how the time switch databases work. They have this readings and a lot of labels to say, okay. So which server or which interface or which whatever what's this about? We think it is very important that, all the data that's in the times of your database is described by Yang because the Yang is providing a lot of the information and context and There's no it's not possible for us to go out to every device in the world and say that you have to implement our special kind of power measurements, yang models, It's gonna take 10 years. We don't have the 10 years. So we have to be able to work with there. But then augment with a metadata and descriptions of of this in Yang And since, Since we're doing this, mapping, we don't call it it's it's, I mean, we have, yang to XML, and we have yang to j matter or encodings, really, but this is not an encoding because it is not doing everything possible that you can do in Yang into time such databases. You're only focusing on the use cases where you want to use it at times of database. So we call it the mapping. We are taking explaining how you take a yang model and translate in that into the times your database things, for the parts of Yang that, they make sense there. And, based on this, you can get a query into typical timeshare databases like this. Where you use these names coming from the yangmalls directly So that's that's how we propose that we work with time to use data. Based on yanks. Thank you. Any comments? Yes. Thomas Kaff, Swisscom. It's amazing."
  },
  {
    "startTime": "01:48:02",
    "text": "Because what you're just describing and, looking through your draft, basically what probably currently, network operator does and consuming the young messages from the network and what processing steps are needed to actually make it work end to end. I have a few comments, like, first like on slide 5, you write on the transport. On the transferred format, just one class would be nice to have there. Something we just preserving semantics because today, we are losing semantics already in, in the transport. And and basically render the the the let's say, preserving, that the information makes it difficult. then, on section 3.2 in your And draft document, you know, nicely describe basically how the the the the subscription needs to be maintained on the on the network notes and how it's need needs to be managed. Here, maybe one additional thought is, I mean, to, like, the data mesh architecture where basically data products needs to be managed. So, data products have like SLIs and SLO. So we need to have quality in our metrics. So we need to understand whenever we are subscribing on something that actually We are also getting the data, and we are not losing data because we are in the business of real time streaming data. So that could be maybe an interesting addition in in there, all in the Section 33 where you talk about process and aggregate the components of using the terms streams and flows. Yeah. Yep."
  },
  {
    "startTime": "01:50:01",
    "text": "Can call them other things. I just, invented those terms in the context of these documents. But what's really nice is actually, There are terminologies, basically, like in, for is in Kafka, we call them topics and subjects are basically how you channel and basically do the semantics and then Last one of these, if you go into the outlook what could be very interesting is basically that right now, you're describing basically when you flatten the data, when you're, do the chasing explosion. You need to change the the dimension names in the times there is database. Right? So we are in contact with the time series database vendors and saying, Hey, At the end, what we want is actually support of yang in a time series database, and I think optimal really the industry benefit is that we're setting some requirements and saying, if a time series database would would need to support Yang these are the requirements. We have to support that And until that, this is what the network operator needs to do to make it end to end work. Very good. I mean, the reason we I'm wrote draft was to make this conversation happen, and I'm very happy that you are bringing this up. And the the the work with this draft is never giving me, such a strong imposter syndrome as anything before. I know that some people in this room have worked a decade about with professionally with this, sort of temporary collection for every week that I have spent on this. So it's, it's very intimidating stand here and propose how things should be done. But I I agree. It's it's very nice to be to get like this, and we will I very much like to cooperate around this Absolutely. Thanks a lot. Right? Oh, yeah. And the Go ahead, Herman. Alright. So Ahmed from Swisscom. I would like to add my voice to Thomas and say this is very important because"
  },
  {
    "startTime": "01:52:04",
    "text": "this point, most operators are hacking their way around to get the data into, It's a time series databases, two notes one that Thomas elaborated to is 1 it's important always to keep the semantics. I see that, there is a mapping here, but we need to be very aware that we don't lose semantic It's not about drawing graphs. It's about actually providing insights the end of the day. The second thing I see the draft is taking the approach of mapping the end to existing time series databases, and I would like to see a more two way conversation to have a bit more ideal solution than just mapping to what services there. So let's try to think about what kind requirements we need from the time series databases and what kind of, things that we can reach a way that is, let's say, best for both words, not just mapping what we have to time times a stated basis. And as Thomas said, We have seen a lot of interest from time series databases vendors to actually adopt Yang because you see a lot of potential there. So, let's let's make a two way conversation other than just mapping our stuff to their stuff. If you can help us with that conversations, those conversations nobody will be more happy than I'm Definitely. It was great to see all the interest in this work. Thank you. Okay. So I think that completes the list of scheduled presentations, as I mentioned in the beginning of the session, Per was hoping to, maybe have a discussion about a neck off next, and rest of the next. Did you want to k. Maybe you could share from on the a contract So there's, on the Netcon"
  },
  {
    "startTime": "01:54:00",
    "text": "working group there's 2 projects, 2 repositories. 1 called ResConF Next and 1 called Netcon Next. There's about, 10 to 20 issues on each of them. And, since we, have loads of time left, the Netspend Group. I thought, now whenever all the work is becoming finalized, we can take on that bird package. So maybe if you can share So, what do you so let me just quickly indicate then. So what is the objective? Yes. So the objective would be to, maybe if people are interested. To, do a a side meeting and start looking at what could be done now without the new without new versions of protocol. Protocol. Protocol. What needs a new, protocol version, what is interesting, what is uninteresting, I mean, it it's not, that many issues. So It should be possible to do what requires, for instance, young next, etcetera. So if people are interested just a quick show of hands. The people that are not interested, raise your hand, Great. No one is not interested. So everyone stays here. Afterwards. And we'll schedule a side meeting. No. But if, for real, if is anyone interested in spinning or fixing stuff with netconferencing. Yeah. Yeah. So, quarter of the room or some such So, then, just over here afterwards, and we'll try to schedule either a side meeting or just some, ad hoc meeting in the Yeah. I would suggest that, you set up a side meeting and send the information out on the mailing list saying"
  },
  {
    "startTime": "01:56:00",
    "text": "when and where to meet Yes. Thank you. I am presenting, the NetCon issues that currently that they're 22 ish ish And then, I also have Rescom. I think I think just to just switch up. Yeah. 12 issues in rest now. So these are relatively small number of issues. I mean, there's over, I think, a 100 issues for Yangmax. So comparatively less effort Okay. Well, We finished early. Thank you. And did you want to say something more? Thanks for coming. That pretty much concludes the session. Cravot Yeah. I should press this button to, oh no, doesn't work."
  }
]
