[
  {
    "startTime": "00:02:22",
    "text": "Okay. Oh no. That. Is that raise hand. What's test test."
  },
  {
    "startTime": "00:05:41",
    "text": "Okay. Well welcome everybody? This is the I open meeting at Four one six in Yokohama. My name is Colin Perkins. I'm the rt f chair. Let's to check that everything's working for the remote people."
  },
  {
    "startTime": "00:06:03",
    "text": "I'm very quiet. Is that better? Alright. Okay. So as I said, my name is calling perkins on the I f chair. This is the I open meeting. So I went to starts with the usual reminders of the higher Policies at the intellectual intellectual property policy and and so on. So first of all, I reminder in the We follow the the same Disclosure rules as the I etf does. And by participating in this meeting, you agree to follow those procedures. In particular if you're aware of any intellectual property on your your talk or your contribution at the microphone. Then you need to disclose disclose that fact. And the precise rules for this are listed on the slide so on In addition, a reminder that we make audio video recordings of these sessions available at this session in particular is being streamed live and going out on Youtube and the recording will be on Youtube afterwards. And there's also a photographer here. So if you're wearing a... One of the reds do not fit graph then you'll be you will avoid the first photographs. But if you speak at the microphones or if you're giving a presentation, you you will be recorded on the coatings will go on my. We also have a a code of conduct please do pay attention to the rules about critical conduct and the anti harassment procedures, please do behave professionally and appropriately. And I'm sure that everybody is welcome in this meeting and in the I and the and in the In general."
  },
  {
    "startTime": "00:08:04",
    "text": "I reminder also that any personal Day give will be handled in accordance with the premise policy. If you a remote participant. Please remember to turn off your audio and video unless you're actively asking questions. If you're a local participant, please do sign in by scanning the Qr code so we have a record of who is attending. Also, if you're asking questions, use the... Please use the the the meter tool leave at the on site tool if you're in the room of the full full tool if your remote. We're running a unified queue for questions. So please do use the tool rather and just going straight up to the microphone to put yourself into the queue. If you have any questions with this and how the tools work the the that the url on slide has has some further information. Also a reminder that as a covid safety measure in person participants in this meeting in the Controlled rooms are required to wear an F p two mask or equivalent the only exceptions that are the people actively presenting and the chair when they're actively speaking. Participants asking questions from the floor expected to remain masked. Alright. So as I said, this is the Iot open meeting. The Iot itself is the a parallel organization to the ie etf, which focuses on some of the longer research issues, which affects the internet. It's so much a research organization. We're not here to conduct standards development, we're not here to"
  },
  {
    "startTime": "00:10:01",
    "text": "reduced standards. And while the the I can publish informational or experimental rf the primary outputs of the research groups is expected be understanding and research papers. Okay. Vertical specifications and and rf. The Iot is organized as a number of research groups those listed in I'm s in dark blue on the slide a meeting later this week. Computation in the network research group, c met this morning. And we have two two groups which are not meeting that the network coding research group is essentially finished with its work and will be expected to close relatively shortly. And the thing to finger research group is having a a a meeting in a few weeks I'm like, and all the other groups are meeting later this week. We also have two new research groups to to new proposed research groups, which are meeting for the first time later this week. We'll hear more about these in in a few minutes. First of these is the usable formal methods research group which is Chad by Jonathan H, H and Steven Farrell. The gold harris is to bring together the the the critical standards community in the Was the academic research community, which is studying formal methods for protocol specification. There day being to to exchange some next experience and and ideas. I'm trying and understand whether and how formal methods can be employed to improve the way we specify protocols and to improve the correctness of the protocols that are being specified in the. And to pass back experience on what's useful for for professional protocol designers to the academic community developing such such tooling. And that group will be meeting on Wednesday, I believe."
  },
  {
    "startTime": "00:12:04",
    "text": "Other new research group is the research and analysis of standard setting processes proposed research group, which will be meeting on thursday. The chest for this Ig castro and neil turnover, And this group is focused on understanding the standard setting process itself. Focused on understanding the community is diversity, the impacts that the set of participants in that community have on the process by which we develop standards, the impact of of how changes in that community affects the standards which are being developed. It's focusing on understanding the decision making process in internet standards understanding the interactions between the different parts of the, the participants in the And the And other standard setting communities. As I say, we'll hear more about these in a few minutes. And please do consider going along to there to their first meetings later this week. So as I said, the primary focus of the Ihs is on producing understanding and research and most of the are in the form of papers. We do have a publish Occasionally and the Ihs has published two Rf since the last meeting. First of those was the Cc info draft which came out of the information centric networking research group. Which is an Rf published in February this year. And I think just last week, the quantum internet research group published its first draft first On the architectural principles for quantum. And the quantum Internet group is meeting in the slots immediately following this one. So if you're interested in that topic, please do go on to that meeting. In addition to the"
  },
  {
    "startTime": "00:14:01",
    "text": "research groups And and the the research we we we do in those research groups We also organized the applied networking research price. This is organized in cooperation with the Internet society with sponsorship from Comcast and Nbc universal. It's here to recognize some of the best research results in applied networking, some new research that has potential relevance to the the Internet standards community. And perhaps to recognize upcoming people who who are likely to have an impact on the internet standards and and technologies going forward. I'm very pleased to announce that we have two and what presentations today. The words go to the the awards for this meeting go to boris as many for his work on novel offload architectures for for mix. And to after seller jacob for his work on evaluating machine learning for network security. So as I said the main focus of this meeting will be these presentations, the papers in the awards. Sorry, the papers and the slides are all online on websites and please do congratulate the two what for for the awards. In addition, the final activity we organizing in the is the applied networking research workshop. The workshop is a forum for the research community, the vendors, the operators in in the eye the Standards community to present and discuss emerging results in the applied networking research. It with the July Meeting. Would be in San Francisco this year. And I'm pleased to announce that the shares of this meeting of"
  },
  {
    "startTime": "00:16:04",
    "text": "this workshop will be Francis young from Microsoft, and Maria the lack from Princeton. Both of whom previous A n, he went So I'm I'm very pleased to have them on board and running this workshop. Paper submissions for the workshop for be you twelfth of me and you should look out for the the detailed call for papers any day now. Finally, I'd like to highlight that we do offer travel grants to attend the I ihs meetings we offer diversity travel grants to support early career academics and Phd students from underrepresented groups. I'm we offer for travel grants to attend the applied networking research workshop. The f dot dot slash travel grants site will include information about those you can expect the call for travel grants for the July meeting your life later till this month. So click please do do look out for that in the next couple of weeks. That's essentially all I have to say. Our agenda for the rest of today we starting with a couple of short talks introducing the two new proposed research groups Jonathan will talk about the the usable formal methods group next. And that be followed by Ig who'll be talking about the the recession analysis of standard setting processes group. And then following that's the majority of the meeting will be devoted to the award talks starting with Boris talking about autonomous nick, and then After we'll be talking about Ai a machine learning for network security. If there any questions, if not, Jonathan, I guess your first."
  },
  {
    "startTime": "00:18:14",
    "text": "Want me to request the. I'm just doing it. You should have control. Yeah. Okay. Good. Afternoon. Good afternoon, everybody. So I'd like to introduce the usable formal methods research group. And before I do that, you probably want to know what I mean by formal methods. And the standard definition would be the use of mathematical techniques and fl to assist in the specified vacation design analysis implementation of in this case, protocols. But that's not really a very easily digestible definition. And so the real question is can we bring mathematical rigor to our work with price calls. Can we say this protocol is secure and I can prove it. So a very, very history of formal methods I am going to try and compress approximately seventy years of history into one slide Yes, there are lots of things missing. But basically, work in the fifties and sixties, that mostly dealt with safety, and whether mechanical processes would fail And over time, that was applied more and more to digital processes. And nowadays, we use it to analyze protocols. And certainly initially,"
  },
  {
    "startTime": "00:20:00",
    "text": "The proof techniques links were really quite limited. We had to make these very strange assumptions or we couldn't even analyze some things that were beyond our tools and they required huge amounts of manual work. Hundreds and hundreds of pages of by Handwritten and Algebra. And so over time, we eventually invented tools and techniques that helps with this process. And allowed us to do more interesting things. And eventually, the tools were sufficiently mature and usable. That the formal methods community became deeply involved in the development and specification of what became Tls one point three. And just to give you the way I think about this you can very roughly compose decompose formal methods into two rough camps, There are lots of things that don't really fit into this categorization, but roughly, you would say formal analysis is the set of techniques which we use to say Is this specification design correct? So you can ignoring anything that we care about the implementation is the design if implemented perfectly Correct. Does it do what we think it does? And then as the second half, which is formal verification, which says does this piece of code do what we think it does. Does this piece of code say compute the right value. And the formal methods research group will try and look at both of these. Just to give you go back briefly to the Tls design process. Happened with Tls one three was from the beginning, academics, were doing formal analyses of the protocol design they was saying, does this design"
  },
  {
    "startTime": "00:22:00",
    "text": "achieve the effects we wanted to. And actually, there were three or four major floors that were found in the protocol design at various stages of it's development that eventually what removed while they were removed. And There were proofs written that say this version of the protocol secure. This especially the price call meets its my. I sorry me specification requirements. And that is where I first came involved in the. So you might think, oh, okay. Well, we've already used this tool. We know how to do it. Great. Problem solved. Problem is Okay. The problem is formal methods not very user friendly. The proofs can be immensely long. So we used a automated tool to do a proof of Tls one three and the proof runs to seven hundred and fifty thousand lines. And you could in theory go through line by line and check each one of those. But most people don't want to. And you... So you basically have to choose a tool that checks each line and eventually gets to the end. The alternative procedure that people use rather than trying to use one of these tools is to write by hand proofs. Literally long form proofs. And quite often. I will be asked. Can you review this paper? Here is twenty six pages of Algebra you have two days to review this paper. And unsurprisingly, It's very very difficult to actually check whether the proof is actually a proof. And so there are a couple of issues, but mostly, the proofs are hard to understand, verify just everything. And Academics have mostly been doing this work. And a problem with this work is it's very high risk and very low reward."
  },
  {
    "startTime": "00:24:00",
    "text": "Because quite often what happens is you analyze a protocol, and you say, Great. It's secure. No problems at all. And then you go to get it published and everyone's like who thought it wasn't secure? You just have written a very boring paper. And so unless you're like, I'm pretty sure this is broken. You're not gonna invest the potentially years it would take to check. And so enter the... Usable formal methods research group. Proposed. How can we solve these problems? How can we take this technique that we finally got a point where we can actually use it. How do we make it so that anyone can use it? And I think the initial steps that will be really good for the. It's gonna provide a place for experts gather. And it will be a pool of knowledge that other working groups can come to and say, we can't make this work. We we don't know how to do this. Can you advise And If we then start building up a tower training materials. Because at the moment, it's very easy to analyze a very tiny protocol as examples and And then the moment you want to go slightly more complicated you're on your own. And They're there we can also provide feedback to tool designers. So a lot of the tools are not actually used necessarily by people who want to analyze have protocols, they used in Academia. So we can go some and say we need this feature. Hopefully, because the I f does do some publishing, we'll have a place to publish these negative results. Pub pace to publish. Here is a proof of security, and we'll have a place to store"
  },
  {
    "startTime": "00:26:04",
    "text": "all the proofs and the checking tools you need to check the proof. So a couple of non goals. Very important long goal is to not try and change the Etf process. So Maybe the I etf processes do need to change. But that's not what we're interested in. That's no auto. It's an I rt f group. And if we manage the way we can check whether we have succeeded in making formal methods usable is if people use them? If we say you have to use them, we we don't know whether we've succeeded. And very much, we don't want to be an obstacle we want to provide useful tools. We're meeting on Wednesday at nine thirty. Please come and join us. Thank you. Any questions. Alright. Thank you. So they don't have any questions. Alright. I guess I won the the online water either. I've got the really low mic. Alright. So maybe this is a question for when you have the session later in the week, but my very, very limited understanding of formal methods is that One of the challenges with them is anytime you're doing a proof, you're always dependent on a certain set of lemma or a certain set of assumptions. So the big question is whether or not those are valid. There's not fit within the of what you're planning I'm working on? So absolutely. There are some very standard assumptions that we make. Which we know aren't true For example, we assume"
  },
  {
    "startTime": "00:28:00",
    "text": "that, say, asymmetric crypto, is just a magic perfect black box and that it always works. And yes, we will definitely need people who do crypto analysis to continue doing their work. The goal of these proofs is to say If we assume that we have a valid or secure asymmetric crypto algorithm. We can then swap that out with any other algorithm that we think is secure of the day. And it doesn't change the proof. The proof says if you have a secure algorithm, you can build this thing. Thanks. And sorry colin introduced me forgot to say my name at the beginning for the record Broadband van meter. Hello. A Just a question because looking at... When coming here, I was assuming that well the former methods were going to one second. No it's fine. Yes. No. I was I was a understanding that we're talking about formal methods in general for proper protocols and for verifying fine approving whatever the properties it seems that you are focusing it very much on security is his So that security property is my background. But it's certainly not the only scope of the. Mh. The proposed dodgy. You know, one where one of the first things we're planning to do is try and come up with some examples that people can look at that aren't security related, you know, deadlock related, live related. But yes, That's certainly in our scope. Yes, my my background on security. So what I think about. And just we do have any idea the background that the planning because I remember a long time ago, this used to work with this communication communicating process things like that Csp. Yeah. Exactly. It's or or or we talking about something a little bit ahead of that."
  },
  {
    "startTime": "00:30:02",
    "text": "Definitely a little bit ahead of Csp. Csp is Ninety two ninety three. Yeah. Well you right. Even before, I will tell you. Yes. So, yeah. We're we're we're looking at things from several decades later that But so how based on related the purchase of dial. So the underlying tool is usually either patent natural schemes, oh higher order repercussions schemes. Okay. Any other questions? More questions. Alright. Thank you. Thank you very much and come to my audrey. Come to the. Yes. That comes my ballpark Right. Great. Alright. So next up his Ig who'll be talking about the ras a reminder while I matthew is getting set up, if you're in the this room you need to wear a mask. If you are not willing to wear a mask, you need to leave this route. Alright I here to you. Thanks Colin. Hello hello, everybody? Telling you about our new research group proposal search group, which is about research and so far standard setting processes. And I'm turning together with Neil. Next slide, please. So what is About well, the name says it always is about understanding better things that we do here. Not only at the idea, but mostly at the Idea point is not to judge whether the Is the best thing since sliced, and the it is not the point is just to analyze what we do and people might make judgments on that, but that's not really the point of this research group. Point say data than judgment. Types of output that we expect joint reports paper. Database says, for example, we are now labeling email discussions for agreement this disagreement, so we can understand better consensus information processes, tools, and software,"
  },
  {
    "startTime": "00:32:02",
    "text": "where, for example, making a little tool to make recommendations for Cross review by comparing they content of the email say of the people with draft that might require review. The way to do it well, similar to many other research groups, collaboration many different people from many different areas that are interested in this sort of stuff. Organizing word concessions, and prevent there are different people that has been working in different ways around this. And mostly produce evidence space and reproducible work. Visa the charter Please subscribe to the male list interesting come to the system tomorrow We do a lot of different things. Slide, please. Just to give a glance like this, for example is from one of the papers that we have being working on, and this is the call for Sip graph, you can see how It's a group of people that write a lot of drops together. Can see also some points in the middle, you can maybe why that's happening. Again, that judgment, next slide? That's the interaction graph of the working group. You can see how things class are nicely around different areas. And this just to give you glimpse, but we do many other things and if you have next slide, please. If you have questions or you ideas Or do you want us to look into something? Please drop by And this is what we do, but we don't. Is to make article comparisons between which which on the second organization is better or similar to what jonathan fiancee say define how operational process of the Apps would work. Those people is welcome to use the data that we might to make those judgments. Right so, but that's not all. Next slide? So please by on Thursday, we have believe Fabric was going from eth to large language models in under funding the idea, and please come to agree this reports or just discuss"
  },
  {
    "startTime": "00:34:00",
    "text": "their search group are starting. So if you're gonna have say, on things that we should be looking at, are all ears. You very much. Alright. I can ask you any questions. Yes. Not. Let's see any online. Ask go for questions. Okay. Well, if you are interested in understanding how the Works, please go along to the meeting on thursday. Thank you. Alright. So and again, a reminder that we have a masking policy and this if you're in this room you need to wear a face mask. If you are sitting next to someone who is not wearing a face mask please remind them and if you're not willing to do that, you need to leave the room. Hi Leon. And my name is Menu. Hang hang Just one second. Alright. So Can what do you now have control of slides? Okay. So I'm very pleased to introduce the the first of the applied booking research price first of our applied networking research prize winners for this meeting. Speaker here is boris many, or is Phd students at the technique tech computer science department in Israel. It's currently vest Ep l. And he also employed by Nvidia as a software architect."
  },
  {
    "startTime": "00:36:00",
    "text": "His research is focused on improving system for performance by enhancing nick controller hardware. Then recent Near worked on accelerating quick with Udp segmentation. Me see so offload. Also worked on accelerating encryption for Quick Tls and Ip. His talk today is on Autonomous nick. And it's a paper that was originally presented at the plus conference in twenty twenty one if I correctly. Yes. Alright. So congratulations again to Boris. I'm over it to you. Thank you. And Okay. So thanks for the introduction calling. This paypal is autonomous? It describes It describes soft architecture that enables sn to accelerate l five political computations. To soft Tcp ip. So we're going to focus on l five protocols of Tcp. Here some examples. Specifically we're going to focus on the Tls protocol and it's encryption decryption and authentication digest as it's called here. In the paper, we also Nvme and it's digest and copy of flow and the combination of the two. So I belief overview of Steel do we probably no better than deny about this protocol most popular way to include tcp traffic has two stages, handshake and data transfer, the data intensive portion is the data transfer so so we focus on that and we can assume that the handshake has been completed for the rest of the talk. Okay. So next we're going to explore the design space of l five protocol acceleration using Tls an example, listen."
  },
  {
    "startTime": "00:38:00",
    "text": "So the first approach to accelerate Tls is in soft, full instance can tls less is a software optimization. That requires no additional huddle and we little a bit more detail how it optimize steal, but essentially the blake some obstruction to make it mobile performed The problem is that as long as we're using software we can't avoid the overhead of data intensive computations. So the next approach is to use How. Such as the on cpu acceleration available in intel Cp called A I, So so this is very efficient. It uses and cash family has relatively low oval overhead, but nevertheless cpu doing Tls can consume more than fifty percent of the call on just encryption. So looking for, we can consider an enough Cpu accelerator such as a Pci Call does encryption like the quicker Sys The benefit is that the Cpu overhead is independent of the data being encrypted, but the problem is that significant power is required to outperform the Cpu acceleration. And this can be problematic and sometimes applications need to be designed to make use of looking forward, we can place the encryption on the surface data needs to those the nick anyway. The problem is let's current approaches to do this they depend on Tcp Ip routing in quality of service essentially, the turn internet will stuck into the hard and this introduces a lot of complexity, security problems and has does shown itself to be undesirable and impractical. So"
  },
  {
    "startTime": "00:40:00",
    "text": "So our approach is to move the encryption to the nic, while still keeping the network stack. In software, including Tcp ip etcetera. The problem with our p that we introduce an additional overhead on recovery as I'll explained next. So before we dive into how autonomous Works. We build our solution on top of Canal. So I'm going to explain how can works. So tls is a form of a software specialization So on tls list what we had is we have a baseline application, which using the Tls library. It calls the line with its data. The liability eclipse the date. I put it in a tls circled. And then the record moves to the counter will Tcp sends it. So we have an encryption test and and in copy paste. Once when passing from the application to Tls and And the copy is when passing from tls to Okay. And the copy from passing from tcp. So what does it it combines the encryption and the copy pass into single pass. And so it could be more efficient additionally enable optimizations such a. Finally, in Tls, the Tls layout can communicate directly with the nic driver and this is what will require for autonomous software communication allows us to make some optimizations. So with the autonomous tms, what we have is that we need the encryption pass from software and we move it into the hollow. So when the application sends it data using"
  },
  {
    "startTime": "00:42:02",
    "text": "cannot tls less. We just do a copy with don't do the encryption. But we still create the called. But this time, we can compute some parts of the called for instance, the mac authentication it remains zero because we can compute it. And we pass this data to Tcp and and Tcp will add its and segment as it deserves. And eventually data passes to the network, the cooling clip the data is it passes flow. So nutshell this is the solution I will get into how we implement The offload road starting from the transmit side. So In order to offload data that is in sequence, We don't want to do much because the mid uses statement incrementally is updated and we simply send the packet with an indication and how will will perform population include the data. Then it uses two context to accomplish the civilization, static state, which is relatively constant full connection. For example, the encryption is and the dynamic state that is updated bucket. And it holds the state for the next expected Tcp sequence. So it turns the huddle how to include the next dc second stumble position. And holds things like the message officer message size and Iv and the authentication again. Okay. So the problem is we want to send something that is out of sequence. For example. Assume that we sent back one flight and then software decides to mid packet five."
  },
  {
    "startTime": "00:44:04",
    "text": "So the hud doesn't have the correct state to accomplish that because it expects bucket nine. And it needs to transmit packet five. So what happens is that the driver identifies this problem, it compares the sequence numbers. Between the dynamic state. It has shadow off and the packet that's been closed meeting. And it's going to perform a flow which we call the cover. Week five. So in the the recovery flow, what we need to do is we need to pass the Tls local be of Tcp bucket five, which is marketing in the dash lines. On the figure. And after passing this information to nick caldwell, we can send packet five because the state would be adjusted full packet five. And to accomplish this, the driver will communicate with the Tls layout directly asking it for this Tls local prefix. And and the Tls layer, it holds this mapping which which allows it to provide this information. The only problem is that the Tls needs to hold this information all the time, and we can't release this data once packets are acknowledged because we may least pound of So we hold the next, fill all the packets that that combined into a and but at least there is only when the entire Tls level is acknowledged. So that's sig path moving to to do safe path. So again, the The sequence flow is. How will the clips incrementally spark go through? And indicates for each packet, whether it was the clip to authenticated successfully. Now problems begin when we have out of all transmissions"
  },
  {
    "startTime": "00:46:02",
    "text": "full instance. In this example, we will see packets want to flee fall and then I can do again. So packet to transmission and and then bucket five. So what will happen is the how will skip the collection of pocket to identify that it it was received before because it expects bucket five. The benefit here is that Hubble continues doing its acceleration for packet five and onwards, and it doesn't stop because of bucket two. And a little problem that me, Is a tls data here what behind is the bucket two. Is not received well it is expected. And instead buckets fall and five alive and only then bucket to her lives. So bucket was essentially received. What happens in this situation is that using the length field of the Tls liquid handle we identified that the next local huddle will appeal in pocket. And so when packet fl received, the hud will synchronize itself to be ready to the clips record that starts in bucket flow and so packets four five get decrypt and the offload and the acceleration will continue for future packets, and then packet two is considered to build the transmission in this case. Now, the little problem happens when on the safe path, we get handling all. So the Tls select handle is the huddle can't use this slick will it lies on the length field of the Tls select handle to tell the position of of the of the next level because after little six bucket fall it knows you didn't see pocket flea and pockets"
  },
  {
    "startTime": "00:48:02",
    "text": "all can have any number of potential Tls circles. And as a result. It's it's stops off loading until it is recovered until they hubble state is couple. Just a little slow, I think. Okay. So to to solve this problem, we can just let's software to notify how every time Tls panel because packets make continue coming all the time. And and as a result we will always have displays condition between software and how will keeps receiving new packets. So we moved some solution that is not pure soft. To to solve this problem, full streaming Tcp. And the solution we propose the device is soft huddle collaboration well fills... So suppose we have Tls And what hud does it will speculative search for what we call magic pattern for instance less it's this hacks seventeen o. Which represents the type in the building. And once hud identifies this pattern in the Tcp bytes stream, it will ask software. Is this tls handle or or is it something else? And meanwhile packets continue to live. And the huddle we click where it expects to see subsequent Tls like called handles based on the length field again. So he'll, we first found the heavily bucket five. And then in packet seven,"
  },
  {
    "startTime": "00:50:02",
    "text": "we check and verify again the the header team. If it's not out. We continue... We go back to step one because it was done. But if if hud was correct, in this speculation, eventually software will be able to confirm that indeed packet five contained a tls circle handle in the position that the the the nick asked about And this this will allow Hud to synchronize and resume its acceleration from which whichever point it is currently tracking. So this is essentially how we solve the recovery problem on the. Okay. So taking a step back. Taking a step back, we ask yourself protocols in computations are autonomously flow. And to define the p and that make them such and we find that most computations and protocols all but not all. Looking at the that make computations autonomously affordable, we start by identifying it on the transmit side, the computation must be size preserving And this preclude acceleration of completion and in encapsulation. For instance, we have here an example, we didn't relation to explain the intuition behind this. So suppose we took... We have two hosts, host and Host b. Communicating v and host a uses inflate the message say it's tls handles or something of that so just one slip. Okay. So Jose sends the fills packet and the nick"
  },
  {
    "startTime": "00:52:00",
    "text": "accelerate it by en it. And by doing so it adds some additional payload bytes, And as a result to additional pocket is well because the Mt is seated. So two packets will send on the wire instead of one. So host the received those two and sends x but the second act is lost. And as a result, what we got is that host a thinks that all the data is sent has been successful received because it got an act for the one hundred fifty bytes cent. But in fact, some data was lost and the nick needs to be responsible for the transmission. But the transmissions and Tcp logic is what we wanted to avoid placing in the neck. And this is why we consider this undesirable. And in a couple that is required. Next we'll require that the computation is on Tcp packets of any size. So it can't require by from future packets. And this includes some block cycles such as As Cbc, which operates some blocks blocks of sixteen bytes, because some packets may not contain the all of those sixteen bytes and we need to pass them on. We don't want to start installing packets in Hand to perform the civilization. Next to to do the recovery will quite the state the required to compute the population is of constant in size. And is message independent, up to maybe metadata such as sequence numbers. And it can depend on all slim payload on on future bytes. And we find that most and hill entities."
  },
  {
    "startTime": "00:54:04",
    "text": "So indeed many computations fit in these requirements and this include"
  },
  {
    "startTime": "00:56:10",
    "text": "Is it copy? To offload with zero. And Https, which is just using open cell. And what what we can see in the figure for this instance starting from the left figure with the is that the yellow line and blue the is the same. And and the yellow line is is an Http p is the best we can hope when doing https offload and we see the that the gap is a very small. And the numbers below show the comparison on the return, Https and offload with seal copy. So left point on proof phones by almost twice And on the right point with one hundred and twenty eight thousand connections, it's by improved by fifty three percent Okay. So finally, this this result is so to to one fix show using. With the same hydro they're working down and doing this eight hundred gigabytes and this is On public, you can look it up. And That's it conclusion autonomous sneaker floats is framework for accelerating five protocol computations efficiently while cooperating with tcp ip stack it is applicable to most and computations and evaluation should that we can by flip and you prioritization by up to sixty percent and latency by up to thirty percent Thank you."
  },
  {
    "startTime": "00:58:02",
    "text": "Okay. Thank you. So other there any questions? Surely someone must have a question. Alright. So I have a question. So so honestly, this this approach in certain properties. Of the protocols you know, as soon as I say preserving increments fully have constant states and so And you know, obviously, these fit some protocols were not necessarily all of the protocols. To to what extent of these fundamental limitations of the approach of versus sort limitations of of the current work that might potentially be be resolved in in a future iteration of the the ideas and and the the approach. So so almost all of them fundamental, the only one that can be somewhat softened is the requirement for Cbc. Well, it's possible to to think of a solution that stole some bytes to to enable and this offload the power block the one that doesn't have the full Ads block But this would be more complicated and see is. So is not much interest. Okay. Thank you. Dave. Hi. Dev wren mit. Do the trade offs change at all of you of a user mode Tcp stack as you work with Db or something like that? Not at all. Thank you. Any other questions anyone on the remotes maybe have a question."
  },
  {
    "startTime": "01:00:09",
    "text": "Okay. So one other thing... I mean, obviously, this is an Meeting you're presenting it. Is is there any of guidance or any some issues to can to the that the Should be paying attention to when designing future protocols to make this type of approach or or similar approaches. So what better? Yes. Actually, that's a great question. So this approach also works for tls one point three, which was finally more or less when we will finalizing the hud. And one of the things that happened in Tls one point three is that the trailer was starting to use the little location type and and when using an such as dc, it created some problems for instance So in general, it worked well because the formats of the la remain the same. So keeping the formatting of records the same is helpful. But what one problem to appeal these that... Until we clip the entire record we don't know if it's an... Really an application data or something else. And this becomes a problem when we want to combine this with something fingers else. Suppose inside Tls, we have some protocol that we pulse and we use to do data placement So to do data placement we need to to assume its application data, but if it's a handshake then it's bogus, and this creates quite a lot of complexity. That we didn't anticipate that doesn't exist with Tls one point two. So this is somewhat unfortunate. Similarly padding is also makes things more complicated than it could been."
  },
  {
    "startTime": "01:02:05",
    "text": "Okay. Thank you. So so it sounds like there's may be some lessons that can be here. What learned from the the way the protocol called design changed to make it's simplify loading. I'm not sure that the Wants to stand days according. To to the way hud works, but it would have been desirable of course. But but it perhaps helps if there are multiple ways of designing approach on some easier to float than others. Yeah. Definitely. Alright. I see rat on Meter. Yeah. Roger Carey University. Looks like really good work. Thank you. A it's an interesting presentation and and I think it important topic. This might be kind of an extension of collins question, But to what extent is this work The value of this work sort of a characteristic of this particular point in time relative to the technology. Is this a future proof technique where we still be able to use what what you've been doing. Ten years from now, twenty years from now it's the you continues to evolve. Know, for example, if somebody sort of a corollary question is if somebody offers you one parameter change to the system that might might get better. How would that affect your your performance, you know, somebody offers you double bandwidth with or prices many cores or something. That's a great question. So these are the early of this technology in particular, so it's how to predict what's going to happen in the future. Right now we'll see solid adoption, but it's not like everybody needs to do eight hundred gigabit Tls. So so it's not obvious it's applicable to to all use cases. Yeah. There are impressive numbers. Yeah. The the numbers great, but everybody needs those numbers. So those the trade of and making the most out of coils quite a lot of work software. I think the performance in today. Somewhat better than linux because the net fixed guy really did a lot of more to make it. So... And"
  },
  {
    "startTime": "01:04:04",
    "text": "I think we'll see of time how to the twenties that Cpus are not getting much faster when mix are getting very fast it makes sense to move as much data intensive computation over the payload to the nick is possible. And as long as we're using Tcp, and think military is going to the main relevant of it. Thanks. Right. Thank you. Are there any final questions? Alright. Congratulations once again. Thank you, boris. Next up is. So this you control and then Okay. So the final top today, is the other applied networking research prize winning top is by Alpha seller jacobs. Arthur has a a Phd in computer science from the federal University rio grande do sell in Brazil. And he works with Jennifer Rex group in Princeton and with Walter William. His research interests include Network management in intent based networking, natural language processing for network management. Software driving networks, programmable networks. And artificial intelligence and it's applications for networks and security."
  },
  {
    "startTime": "01:06:03",
    "text": "He's worked working currently, is a senior software engineer no health. I believe. And his papers today is entitled the Ai and machine learning for network networks security. The emperor has no clue. And I believe this was originally presented that the Ac sem communication security conference in November twenty twenty two. Yes. Okay. You should have control it for the slides. So you. Go ahead. Thank you. Thanks, for calling. Can I pull this up maybe? That's better. Is it... Yep. Okay. Right into the mic. Right into the mic. Okay. Thanks calling for the introduction. Hi everybody. My name is Arthur. And I'm here today to present to you our work entitled I for network security, the emperor has no close. So in recent years, we've seen exciting and advances machine learning in Ai in fields such as facial recognition recommendation systems or even spend detection among many other areas of computer science and other areas in But let's take a look at what's causing all that excitement. And what we call the traditional Ai development pipeline. Usually, if you wanna develop a new machine learning model. You start by collect some data and selecting which model you wanna use. You didn't use that data to train your selected model and evaluated using traditional evaluation metrics such as precision, call our score. Then if you have a high enough iphone score, that usually means your job is done, you can claim your model works deployed in the network production in a production. And you move on. Otherwise, you go back, you collect more data or you collect better data,"
  },
  {
    "startTime": "01:08:00",
    "text": "and reevaluate your model selection. No we claim that this sort of traditional Ai pipeline is good enough for low stakes decision making such as recommendation systems, or spam detection. What about high stakes decision making scenarios, such as self driving cars or network security. In which a wrong decision can have direct impact on people's lives or companies companies revenues and reputation. In this scenarios. We argue that we need to be able to claiming that a model works is not good enough. We need to be able to tell why model of works and when does them all not work? Considered especially, especially considered that is it there's well the command documented that machine learning models can suffer from under specification issues such charter learning but the model take shortcuts to classify the data, rather than actually learning to solve the problem. Order their a model myself from out of distribution samples or even that the model is simply over fitted just for your correlation in the data. And not learning anything. Consider this example, we trained a forest classifier fire on the popular datasets seek Twenty seventeen for network security. And achieved a f score of point ninety nine. In this example, if we revisit the questions, we have before, we quickly realize that the traditional high metal pipeline gives us no answer to them. So In this in this specific scenario, would you be able to trust this model? When trust in this model actually means handing over control for that model to make its decisions. So to help developers and researchers Answer that question, we propose trustee. Christie, is a novel explain... Explain way technique that produces global explanations from any machine learning black box model in the form of low fidelity Sorry. Fidelity and low complexity this is increased."
  },
  {
    "startTime": "01:10:02",
    "text": "Trustee augment the traditional Ai pipeline with two new steps. The first one to extract a decision tree from any black box model and the second one. To analyze that decision tree for any issues that might impact been pairing the model to make correct classifications. Let's focus first on this step explanation. When does design, we had four major requirements in mind. The first one for it to be more agnostic for it to be able to work and explain any given machine learning model and not a specific type of machine model. The second one was for Trustee to be able to produce high fidelity explanations. That is decision trees that makes the same decision as the black box model. The third one insists this decision tree meant for a human to be able to parts and understand we needed the decision trees to be low complexity enough. That a human can actually parse it Finally, our last requirement was for To be able to produce stable explanations. That is produced roughly the same explanation for the same input on multiple executions. So Because algorithm starts receiving as input to a dataset set and a black box machine learning model. It then starts by splitting that dataset into training and testing datasets using a given split such as seventy and thirty percent. It then uses that black box model to as a oracle to produce the expected output for the training data which will then be used to guide the training of the decision trees. Notice that Since any machine learning model can be used to produce the expected output we achieved our our first design requirement of m. Then, Trusty selects an M number of samples from this training dataset expected output, and further splits it into a training and testing set. This"
  },
  {
    "startTime": "01:12:01",
    "text": "training said is then used to produce a decision tree using the traditional algorithm cart called classification regression trees. And then evaluated using the test datasets sets to produce an explanation output which we can then use to measure the fidelity of the of the produced explanation with the expected output This process is repeated another time and and then number of times with different samples from the training dataset, in which we call trusty inner inner loop. That runs and then number of times. This inner loop produces output. The decision tree with the highest fidelity achieved on our iterations. Achieving our second design requirement of high fidelity. Then one thing to to notice here is that it is not in uncommon, for cards algorithm to produce decision trees of hundreds or thousands of notes. And for for human to be able to parse it this needs to be much much smaller. So the size of the explanation here matters. To to circumvent this problem, we propose a new algorithm, we like we call top key pruning. Top keep pruning is based on the observation that if you rank the branches of a decision tree based on the number of samples that it covers you get diminished returns in terms in terms of fidelity. So we we prune the outcome explanation by simply selecting the top gay most important branches from a decision tree should give you the most fidelity for it. Achieving our third design our our third requirement of low complexity. Now finally, given that trusty use subs sample of data to train decision trees. It is possible that with multiple institutions, different decision trees will be generated. And so to"
  },
  {
    "startTime": "01:14:03",
    "text": "mitigate that issue. We added an another loop to trustee that runs the inner loop for an nest s number of times and calculates the pair wise agreement of the decision trees the decision tree produced. That is trusting measures whether or not to produce the decision trees make agree on the decisions made for the same samples. And then returns the decision for you with the highest main agreement amongst all of them. Achieving our last design requirement of stability. This decision tree is also the final output of trustees algorithm. Which is then presented for an operator or or developer that's using trustee. Now for the second step of the augmented does it development pipeline? We introduced a novel another method we call trust reports. Trust reports basically automate part of the analysis process to try to identify the three un specification issues that I'd mentioned before. That shorter learning other distribution samples and inspire relations. Basically the trust report summarizes important information the decision tree explanations such as the size of decision fee, the depth the number of input features from the model that were actually used to classify the data the fidelity amongst many other things and and small experiments to see how much the explanation is to the actual black box. On top of that, the the trust report produces useful plots on the on the decision tree explanations such as the number of samples class fight at each level of the decision tree, for optimal pruning, the number of... The number the number of samples and classes that is specific branch class. And then the number of samples that each feature is responsible in the decision tree classification."
  },
  {
    "startTime": "01:16:03",
    "text": "Now it is important to notice though. Sorry. That the trust report does not automatically tell you which issue your model suffer from is still require a human to look at them and I try to identify it this this under specification issues are ultimately domain dependent. So it's really hard to automate. We did try. Now to illustrate how trustee can be used to sc machine learning models. I brought you three use cases I like to to discuss. The first one, All of these use cases, by the way are are from selected publications with artifacts available. So the first one is a one dimensional convolutional neural network used to classify data between Vpn crypto traffic and non Vpn traffic. Dismal model, uses the first... Features as the first seven hundred and eighty for raw bytes from each p file analyzed. And actually and reported an score of point nine. We were able to reproduce something close to that of point ninety six. We didn't use this model. To extract a decision tree out of it using Trustee. With a fidelity of one precisely, and no pruning it was required. Since he only had seven notes that you can see here on the screen Now as you can see, this decision trees is telling us that the model uses is using bytes forty nine, forty three and forty seven. From the input bytes to make rec classification between Vpn traffic and non. Fig. Now to understand what this decision, we need to first understand the data that it's coming from. So If you go when we when we dove deep into the p caps that were being used. We quickly noticed that there was a split in the data that is all the non be traffic ups head Ethernet headers on them, while the Vpn p ups traffic ups"
  },
  {
    "startTime": "01:18:03",
    "text": "did not have internet has held around them. This created a mismatch this created a mismatch of the alignment of the features. That the model was looking because for non Traffic, the model was looking at source and destination mac headers. While for Vpn traffic, it was is it was looking at total length flag offset set and protocol from the Ip headers. So we've met technology in mind. We can go back to the decision tree and see that the first decision that this this model is looking at is basically comparing whether or not for Vpn traffic, it it is using the ...Udp p or Tcp protocols value six six and seventeen of the Ip four protocol against a random bite from a source Mac address which in this case is always larger than seventy for the data. So that basically splits almost all of the data perfectly. The second level of the decision fee is basically showing that to eat readout the remaining few samples that do not follow those rules, like one percent the the model is picking up on different headers such as the fragment offset against a random bike from the from the source Mac address. Than one for Vpn on right side. And on the left side, is looking at the destination mac address, which is already zero. So With that in mind, we set out to produce validation data set to validate the definition output And we did that by tampering with the pack headers from the original pickups. Specifically heather's forty three forty seven and forty nine. And as you can see, that had no impact at all precision recall. The reason for that and using our trust report, we were able to identify that is that If you go back to the data, you could you quickly realized that the developers of the model didn't remove the pickup metadata from the from the peak before"
  },
  {
    "startTime": "01:20:02",
    "text": "reading of the features. So they're actually reading features feature values from the p metadata for the first forty bytes. Which includes a lot of potential potential shortcuts for the model, including by thirty twenty three. Indicates whether or not Internet header is present or not in the pic. So from the first few bytes, the Model had plenty of opportunities of to take shortcuts to pac the data rather than actually learned classify between Vpn and all Traffic. So we've that with danny mind, we start out to tamper with ranges of feature values rather individual features from thirty two to sixty three to zero to sixty three into zero to one twenty seven. Until we reach an score of point three ninety eight which is basically worse than a coin flip. So is that this model is suffering from late and short of learning and didn't learn to classify the data at all. And simply picking up on shortcuts put in the future in the future values. Now For the second use case, I wanna revisit the random forest example that I showed before We selected many, many papers we saw many penny paper that relied on the seek Twenty seventeen dataset for classification. This data set is really popular. This data contains traffic from thirteen different types of attacks aside from benign traffic, including port skins, ddos and hard. In this... And this dataset comes with reset of seventy eight pre computed features from flow statistics such as flow duration meaning to arrival time, number of packets sent and receive in each flow. And a lot of most of the publications that we we found used the dataset reported f score numbers of point ninety nine which were very easily able to reproduce with a random forest classifier."
  },
  {
    "startTime": "01:22:00",
    "text": "We then use trustee to extract the decision tree from this model, which gives us point nine nine fidelity of which you're seeing here the top three pruning of it which only has six notes. Now aside from the obvious problem of using destination ports, to to classify F ftp and Ssh attacks. I wanna focus here On this specific branch that classified all of the heartbeat samples in this dataset by simply looking at the maximum length of the response back maximum single have for response packet at size flow. By simply looking whether or not, the maximum response the maximum length of response packet size is bigger or or smaller than twelve k. This model is able to determine whether it's a heartbeat to tech or not. The reason for that and using this distribution plots from the trust report, we can see that this feature specifically, perfectly splits the entire hard lead flows from all of the rest because the response back size for hot flows or is always bigger than twelve k, and it's always smaller than twelve k for all of the other classes. And we can see that same behavior in other features such as the inter arrival time response to arrival time almost perfectly splits hard from all of all of the classes. Now to understand why this happens, we need to first understand how the heartbeat that works. A heartbeat of deck and I feel like this is preaching to the choir, but Heartbeat tech works. Happens when a in a malicious actor sends an Hd Eps heartbeat message with a to a vulnerable server, with a value in the size field bigger than the actual package. So basically, you can send a sixteen k byte package and specify it as sixty four bytes for the server... A vulnerable server will respond with a message"
  },
  {
    "startTime": "01:24:00",
    "text": "we've with have a heartbeat response of the same size as the incoming impacted by copying the context of the incoming package, into the into the response packet. So but since the pack incoming impact only has sixteen k kilobytes the response package will have forty eight k forty eight k kilobytes from the server memory, which may include credit card information, usernames, passwords, that sort of thing. No. In the c two twenty seventeen data specifically, we notice that for the thirty minutes duration of the hot fleet the heart tax generated, they didn't close the connections once. We generated huge numbers for future values related to response packet sizes and arrival times in those flows. Which made it abundantly easy for the for the model to pick up on those values. So With that in mind, we set out to generated validation data or explanation, consisting of a thousand new heartbeat flows who out of distribution values in which we simply close the connection of the of the H connection after every heartbeat message sent. This generated feature values related to response packet sizes and arrival time much similar to benign traffic. And as expected, the forest plus was unable to identify a single one of those new thousand hard lead flows. As hot. So the takeaway for this specific use case, is that this model is clearly over fitted to training data and suffers and fails to identify any simple changes or simple out of distribution samples. No Third use case, unless... I don't wanna show is another example of a paper that uses the seek Thousand seventeen dataset. This paper was published in Ccs twenty twenty and proposes a and print. This paper uses an auto and now model for intrusion detection system. Users four thousand four hundred and eighty features"
  },
  {
    "startTime": "01:26:04",
    "text": "with values minus one, zero or one, which goes to a stable bit representation from the the packet we reestablish protocol headers read from the five first packets of each flow. Basically, if a header is present, in the in the half is not present in the in the packets. The value set to minus one, and it's set zero or one, depending on the value that is adding up in the packets. This model achieved an f score of point ninety nine, which will read easily able to reproduce their rep art artifacts. And then we use Trustee to extract the decision free explanation out of it with a fidelity of point nine again, And as you can see here, the stop four pruning of it and we has eight nodes from that tree. Now there's a couple of different interesting things to focus here. The first one of which which is that the first decision of this the decision increase is making is basically looking at D detail of the first package and checking whether the third bit from the T tl is one or zero. The reason for that is that because In this dataset, all of the attack traffic was generated announced from an outside computer, one hop away from the measurement point. And so this is basically checking whether the the attack was inside the network benign or outside the network, which is malicious. So it's basically able to tell the difference based on that. Most of the attack traffic was generating using cal which is initial value is sixty four. Minus one hop sixty three, third bit one. And then you get just split all the benign traffic from the from the rest Now the second decision is also looking at D detail but it's splitting all of the d ddos attacks were generated using Windows. We know eight point one to be specific which has an initial value of one and twenty eight"
  },
  {
    "startTime": "01:28:02",
    "text": "one minus one hop one twenty seven, so let's look at the second bit of the second package, it could be the first package. So yeah, whether it's one or zero, and then it's able to fight all of the ddos. Samples in this dataset. Now the third decision that here is also interesting because as you... If you notice this is the the the Decision tree is tracking whether not the value is negative or not. That means that the value... The the model is checking weather No problem. This means that the model is checking whether, there is a second package or not in the in the flow that's observed. As most of you probably know? Port scans are usually not responded to by an attack by by a victim. So all of the ports can flows in this dataset, only had one package. So basically, the model was able to check whether or not it will support can by the number of checking... The number by checking the number of packets in the flow. And finally, this is our last observation we noticed that this decision relied heavily on random bits from the Tcp options headers in the in the flows. And using the using the... Sorry. And using the trophy report, we removed features from this dataset until there was only Tcp options fields for this model to pick up on. And still This model reported an one score of point ninety nine using only Tcp options bits So this this was very interesting to us and indicated that this is actually this model was not learning anything, but was picking up on Spur correlations in the data. We set out to validate this explanation by accumulating creating a balanced dataset set of four thousand and forty seven flows from real world traffic from Network. And use to cut ideas"
  },
  {
    "startTime": "01:30:01",
    "text": "to label those flows between benign, distribution of service attacks and Port scans which were the three classes that we were able to collect from the short spend that we collected. As you can see when we used en printer M model to classify that data, he was unable to identify single one of the distribution of service attacks, the denial of service text, Sorry. And it was able to identify very few of the port candidates. The reason for that is because as I mentioned before, uc also didn't respond to port attacks. So the So we was able to pick up on a few of those attacks based on the number of packets in that flow. But as you can see, it failed when put under minimal stress of reward traffic So our takeaway for this is that this model suffer from spur correlations in the training data. And the reason for that is that because of an initial called curse of dimensional. This feature this this this model has a so large number of features that is not able that the training data is not able to cover all of the possible feature values in that data. Making it a abundantly easy for the model to up on various correlations in the data. Like this. So Aside from this three dataset set three use cases that are presented, we looked at four other different use cases with diff with artifacts available and found issues in all of them. Including Kit soon and ensemble of neural. For anomaly detection, reinforcement learning model for adaptive trade selection. In the paper, You also find an algorithm description of trustee. An ablation study on all of the design requirements that I presented and more information as well as the user guide on the trust report that I am that I mentioned before for."
  },
  {
    "startTime": "01:32:00",
    "text": "Trustee was also packaged into a python package can be downloaded today. It's available for anyone to use. And has received surprisingly number of mode of down of already. Finally, Machine learning high stakes scenarios requires a level of trust that the traditional Pipeline pipelines simply cannot give us, But trustee helps by improving the trust and providing high fidelity and local complexity explanations in the forum decision trees. Trustee can be used today by anyone and be download in that website or using pit And yeah, so just download the package go analyze. So yeah, thank you. Thank you. Alright. Thank you very much Excellent talk. Anyone have any questions for Steve carla... Yeah. I read the paper it's a really good paper. Thanks something... I I enjoyed it. I'd say, I enjoyed reading the paper when I towards the end. The beginning was a little bit harder work for me because it's something my field. The end actually was was very good for you used with the case studies. So I was wondering All of this depends on having access to the training data, essentially. Right? If you don't, and perhaps in real world cases, you won't that's a vendor is making some claims or something is there any way to kind of en that you could extend this to handle cases where you don't have access the training data? Yeah. So you technically don't need the x like training data to produce an explanation using trustee just get better insights using the training data. If you have access to the model saved for an Api that makes a classification and you have data to to that you are able to use to test it, you can produce explanations for that data."
  },
  {
    "startTime": "01:34:01",
    "text": "For using that model. But it I... That is a hard challenge because not everyone makes it model available. Like that. To an Api. For example. And so the the follow on and could you en that there could be any recommendations you could make to people who are claiming that their models are are super good. Things that they could make available that would allow saw some kind of validation like this. Let's so so maybe make an Api available or, you know, Yes. So this is part of what I mentioned before a lot. We tried to automate this analysis as much as possible, but it's really hard because it it's hard to tell whether or not the model is actually suffering from shorter learning for example, or the problem might be super easy and not need machine learning at all. So it's hard to make that call unless you actually familiar with the domain. But based... We did have, like, a bunch of guidelines based on the values we we produce on the trust report that could indicate whether or not there might be some going on with the model. So for instance, if you if your model has four thousand features and you're using one or two percent of it to make a perfect classification using a decision. That is probably an indication up that there's some problem going on. We can say for sure, but that's an indication. We can tell. A recommendation for people to check. Great. Thanks again. And it's nice to see somebody being skeptical to go. Thanks. Alright. Doug my montgomery, is is there some notion that you're resulting decision tree model is unique or optimal in some way or there that is a good question. So It's not I I would say it's not unique. And probably not optimal. It's... We optimized for fidelity. But there are different decision trees that might result in the same fidelity. When we achieve the best possible fidelity for the use cases we analyzed,"
  },
  {
    "startTime": "01:36:01",
    "text": "But if you have correlated features in the dataset, you could generate this of the same fidelity with using different features for instance. So we chose not to tap that information basically by adding that outlook to trust to produce a decision tree. That's roughly stable. But one of the things that we discussed while developing is that there is knowledge in the different decision trees that you may produced. The the express exclusivity of a decision tree is naturally lower than neural network for instance. A neural network has more power express power than a decision three. ...And that's the reason we moved away from season trees in the first place. So you can produce different decision trees explanation for the same neural network. And they all might be true. It's hard to say. It's it's hard to say which one is the the the one true this treating probably there isn't one. It's mission of all of them. And that's something we're kind of working on trying to tap on that the information of different decision trees that might be produced. Because there... They they can be there can be valuable information there to explain how the neural network might be working for instance. Does that answer your question? Yes. I had a quick second question. Just just to be sure, right? When you produce these curated datasets, you are retraining. On them. Right? No. No. No. We are evaluating the the model strained originally. On the curated datasets. See how they would perform. Okay. Okay. I I see a brilliant tram I think his remote. Back out of the queue. Oh wait That was myself ends of people I am hi. I'm Brian T. Good morning from Zurich."
  },
  {
    "startTime": "01:38:03",
    "text": "So I noticed something in... Thanks a lot for the for the talk. This was great unlike Steven. I haven't read the but I'm going to fix that this week. Noticed something in all of your examples were basically you went into the decision tree and we're essentially doing an analysis based on fairly deep domain knowledge of how the sender in the network Right? This is something I think that's missing from at least a lot of the Bm ml literature on applying to network security in the past. So so thanks a lot for that. Is it accurate to characterize the work that you've done here is basically automation assisted analysis of of these decision for Right? Like, So the the... What trustee gets you is over the first time to point out, hey, you should look here for an over fitting or over classification. Is that is that an accurate have I understood that correctly? So so one of the things that that Yeah. Most of okay. head when Steven was talking and and this might be something to look at in sort of future work for looking at being able to do verification without training data is you can essentially generate synthetic network data. Based on your knowledge of how these facts work. Right? Like, so the set that you have to explorer if you're trying to extract something from an Api, is significantly reduced. From this at you. And even just in in the examples that you have here, you have a lot of examples where like, oh, I can tell I have peak metadata versus nod. Or I have the ethernet header versus not. I mean, there's there's a highly restricted set. So I think this is is more of a for a follow work, I'd really like to see some some like strapped come out of that. So that would actually get you to the next step of of of being able to automate this analysis. Because it did look a lot like, you know, it looked at a lot like, okay, we use the automated thing and then had to go look at it, which is super useful but you know has some scalability issues."
  },
  {
    "startTime": "01:40:02",
    "text": "Yeah. Understand. Yeah. That's actually a very good idea. As as a reference, I can point to at least a... There's a hot nets paper that came out in twenty twenty one that did selfie similar using a plots. But they didn't generate the data. They used a plus to sort of guide the collection of more data. To cover more data points. So it's something something similar to what you mentioned. Yeah. But I could see something like that being automated. Thanks a lot. And thanks for talk. This is great. Thank you. Right. So the start of the paper, thank you for this stall. It was really nice. Start of the papers is about how you are explaining the models. Right? But as I go further on, it's more like you're also commenting on the data. The dataset set. So they're just... Because I'm familiar with the data excellent work when you you must have heard the data sheet for data? I just think that this has a lot of applicability in knowing how to do not just model explanation, but characterizing the dataset set itself. Yeah. I mean, that I think is very new And another thing is the fidelity score that you have. Is it... If she that with with the precision recall an reference score Have you considered doing a a specific information game measure? I knew I have not, but that that's a good that's a good point I can look into. Right regarding the data Yeah. We did notice that most of the examples most of the problems we identify with this model arose from the bad data. Or for using the data wrong. Basically. So it's we had this debate a lot while developing whether we were"
  },
  {
    "startTime": "01:42:01",
    "text": "finding issues with the model where of the data, but in in the Vpn on the vpn example. For me, Choosing which features to use, that's part of developing model. So that's also an issue with the model even though it's coming from bad data. So they're very connected in some of the reviewers point hand out to us. But so it it should could be used to guide how to get better data or or data as as you mentioned. Yeah. Because, like, I'm coming from an Nlp domain, and there are these are very good well known data benchmark benchmark datasets, which have been, like, really exceeded by current algorithms, but then those data sets are as you have shown with the network datasets sets are also in a sense biased. Mh. So let just think this. Alright. Thank you. Thank you. That was anchor. Okay. So well, the one pending we. This is... No. The... No. It's it's a related precisely with this comments on the dataset, etcetera. When we started to work with the Ai models. I insist very much if you we where network network management practitioners I said that We should focus more on the data than others. And we have been trying to set up mechanisms for publishing datasets the sets that are Usable for making an... And when you make this reflection about getting the model plus the data because otherwise cannot not make or it's much more difficult that we can make any sense. I was wondering whether not necessarily the in the idea for the area tier for whatever. Whether it will be a by that we try to push for the set of public data that could be equivalent"
  },
  {
    "startTime": "01:44:00",
    "text": "open... I don't know have to call it open source say, yeah, Your open data Ai or whatever. So just I I felt myself vin indicated and I wanted just to too. Commented it and to us do if you share the view. Yeah. Thank so much. That that is part of... We we do comment on that in the paper that sharing data in networking is different from other areas that took advantage of the Ee ai such as images or text, because there's a lot of private data in networking. And people are now willing to share that. And I at this point, I think we we've there... There's me some initiatives like the people that produce seek Two thousand seventeen to produce data for machine learning that's publicly available, but they're all fundamentally broken that they're make them kind of useless for us. So the at least the alternative we found was to before people to work with their universities. We couldn't publish for instance you dataset set because that was private for the the the day we did publish the headers. Only not to payloads of that of of those traffic. But it allows it allowed us to at least validate the model that was trained on a different dataset. So that was the alternative we've we found and I think might be the one that we as researchers can take advantage of. Okay. One of the things that we trying is to convince the European commission at least to to fund these kind of datasets. Where becoming to start to be successful to start to be successful So it's something that it will take time I'm my afraid. Great. Great. Alright. One last question. So ask what I wanted to ask after the previous question. So did you reevaluate the models? Using a synthetic data or the curated data as the new training set. Not sure. Follow your question"
  },
  {
    "startTime": "01:46:00",
    "text": "I was asking when you when you had these you know, more interesting datasets sets or curated or synthetic whatever you wanna praise them. You're using the originally trained model And now I knew dataset to evaluate them. Yes. Did you turn around and retrain the models on the synthetic data. I'm trying to figure out if you're saying something about the robustness of the model or just that it was poorly evaluated and trained in the initial paper. That's a good question. Because when he, you know, has as, you know, shocking or it interesting results from, you know, point nine nine to zero is is interesting. But it's not quite giving it the chance to retrain on the better data if we're talking about the robustness of the proposed. Yes. But I would say the idea of this proposed is not to retrain. Right? You're you're publishing a black box and this is your solution to it. So their idea is basically to take this box and put in the production network and each work. That's sort of how the these models are sold to us. And not that you were need that that you need to constantly be retraining it as you should. So our idea we're validating those papers, and that the data that was used was simply that q creating a different dataset to show that if you put this in your network as it is, it will break. Basically. But we did retrain. If I'm the n endpoint ml model we did retrain using the Dataset set. And you was able to pick up on it was able to do better. We're using adding the train data. But we only curated four thousand flows compared to millions of millions of flows of the C two thousand seventeen dataset sets, so we didn't have a big enough impact on the on accuracy. So, yeah. Okay. Thank. Alright. Thank you very much."
  },
  {
    "startTime": "01:48:05",
    "text": "Thank you. Thank you so much. Alright. That's everything we have for today. Thank you again to Boris and Arthur for the talks, congratulations on the awards both both of the price winners will be here for the rest of the week. So if you have further questions, I wanna talk about the work. Please Please do go talk to them. Please also consider going along to the usual usable formal methods group or the the the ras g later in the week and seeing what's going on in those two two new research groups. And was that thank you everybody. And I see your around."
  }
]
