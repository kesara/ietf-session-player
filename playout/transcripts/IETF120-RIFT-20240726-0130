[
  {
    "startTime": "00:00:01",
    "text": "exploring it's very remote Oh, three of this So big Interested networking I couldn't get my case It's so boring Thank you The room is really empty You have one more minute Okay, let's talk Welcome to IETF 120 in"
  },
  {
    "startTime": "00:02:01",
    "text": "Vancouver. We are reef working Group chairs, Jeffrey, myself Please make sure you have read not well it's a reminder for ATF policies and by participating in IETF, you confirm that you are familiar with the policies So please make sure you're familiar. As G specifically, also asks us to remind you please be nice to each other don't do to others what you wouldn't do to yourself yourself agenda for today will provide quick update on what's going on Then Tony will talk about adaptive We'll have Jordan talking about QAWA Auto-AvP updates, and then Jeffrey will talk about our future plans with the sarah multicast and we'll discuss Charter that is to go to IESG for update so we'll had three deliverables initial charter better complication, it's already in ERISA editor queue, so it's difficult to believe, but after all the years, we are almost there Applicability statement, similar stated, it's in RFC editor Q, and Young Model is in IESG evaluation. It's pretty simple, clear document We don't expect any surprise here. So that are three other working with documents that are in progress and that are going to be made as part of the charter so it's a key value structure and processing how TV DAPN segment routing and multicast SSV6 and all new work that we are doing now we will discuss after rechartering and how it's going to progress Yeah who are you"
  },
  {
    "startTime": "00:04:01",
    "text": "He doesn't care So if you won't create my chain, you have Don't ask me for you only get So now it's your time to talk And you could have the clicker. Power is yours yours I'm a sharp grass man because airline lost my luggage so here goes banana republic model All right so that's of course because everybody's pasturing me to do something for the AI, which will take over the world. And I don't know generate endless money and probably heal cancer So the draft is called, of course, as a joke at Rift, because no world, and I don't know, generate endless money and probably heal cancer. So the draft is called, of course, is a joke adrift because, you know, there is this buzzword of adaptive routing fits well um so we're chasing the AI fat. Well, um, of course, as a joke adrift because, you know, there is this buzzword of adaptive routing, fits well. So, we're chasing the AI fat. Well, it's really just traffic engineer right? And yet another guy's another guys and all these people stipulating that, you know, AI loads will not change will be into a rough surprise you know same thing happened on cloud computing the patterns will change and will be in traffic engineering land again so the problem is two major aspects. One is some one is less so and actually I don't even know whose idea that was probably Dimas because no we had a couple of meetings and chew through stuff. So of course, we have to flood a bunch of T-E metrics around, right? That's kind of a simple stuff"
  },
  {
    "startTime": "00:06:02",
    "text": "But that leads to fairly simple southbound computation because we see the full topology, but stuff becomes more interesting if we go northbound, because we don't have the full topology on the leaf. And if we do, then we basically die again the scaling battle so the annoyingly trivial part is to have the T metric. So if you look at the draft, we end up with a new time type. And why are we at the new Thai time? Because it would be not very wise to put all this stuff into the normal node type in my opinion. Right. We want this thing going fast and this is additional stuff that can go on low priority in terms of flooding so what is in this additional note tie element Basically per link TEMAT T-metrics. So the first, some general one and then per traffic class, because of course we have to split the whole thing up into traffic classes Bandwidth is already encoded on the note time today because we use it for very rough you know, balancing but it is not blowing up bandwidth per link. It is really just note to note how much bandwidth is available because it's good enough for just normal forwarding like i said this stuff will be flooded low priority to keep, you know, the convergence of basic reachability blazing fast It floods at the no tight scope. People who know the spec know what it means, though not there's no magic, we don't have to construct anything special and that leaves the southbound. So the top of the fabrics is the full topology underneath right, including TE metrics now But the northbound, of course, just only see kind of the two hops horizon, because it sees itself and it sees the well it sees the node about it advertising the TE metrics"
  },
  {
    "startTime": "00:08:02",
    "text": "So there will be even a picture so the computation right, when we are at the top of February and we want to get to this little guy at the bottom and we have some requirements bandwidth-wise It's kind of trivial because we have all the traffic engineering metrics, so it doesn't really change from what IGPs are doing today And saying it's simple is of course a brazen lie because this kind of computations always lead to something called fish cell problems So if you look at the green path and the blue path to reach the node, you end up with 10-10-1 and 1-10-10, right? So you have possibly bottlenecks at different places and add to that like delay and then you ask yourself okay how much bandwidth do I need and how much delay? But thankfully we have actually not teas, but we have a PCE working group and they're worrying about the stuff since years. So the stuff is kind of understood, right? And not much can be done, right? Basically, it's a CSPF constraint SPF problem, RSVPT again. Mold that we still want, probably to keep the value-free routing otherwise we need some kind of state and steering on there substrate, which will of course become enormously expensive no matter whether you run MPLS or you run ERRB6 or any kind of flavor, you know where you start to keep states on the node and steer the traffic Okay, now for the interesting part So if you go note, we don't have the full topology So for very flat fabrics, it's fine, right? Use the leaf system the top and it kind of sees all the metrics from the top But as soon as the clause starts to go higher, or, you know, one on Dragonfly or something the notes below"
  },
  {
    "startTime": "00:10:02",
    "text": "low in the fabric for scaling purposes have only you know, partial information. They see itself and they see a note above it and that's the horizon So we were talking how to deal with that in terms of, you know, steering traffic traffic engineering for all these, well, AI workloads whatever and funny enough, we already have a mechanism. We have negativity desegregation and it looks very similar So negative desegregation is in the kind most extreme case of this negative disaggregation basically advertises southbound, don't go through me. I cannot reach the place We introduce something which is also a tie type okay and it is big flooded like a prefix, like a negative prefix and instead of just saying do no use me for this prefix, it has a preference. It says, compared to other guys that are at the same level as I am, prefer me less less Okay. Um, that can be transit right? Just like negative disaggregation based on how Okay. Um, that can be transitive, right? Just like negative disaggregation doesn't have to be. And it can be actually generated as any level. So if a node looks at its neighbors and two levels up and goes whoa you know i cannot really get to the briefing through these two levels up, I have much less much less resources than my neighbors at the same level then I will generate the stop and push it downward and say, look, don't go through me because there is congestion up there that you don't see because of the lack of topology information So the computation itself of the FIP is very similar to negative disaggregation computation which is done today, which means that"
  },
  {
    "startTime": "00:12:02",
    "text": "no, the negative computation though most people will be familiar with it, basically looks at negative advertisement and removes those gateways from the next top, right? So it basically takes a prefix which is negative disagree it, basically looks at negative advertisement and removes those gateways from the next top, right? So it basically takes a prefix, which is negative desegregation, because this prefix may be not advertising normally and it says okay give me as next hop the less specific, whatever it has as the next top. And then look at the next negatives and start to remove the gateways right that's say I cannot reach this very specific prefix through me So this will still run first but then we run on top of that, this preference computation So we basically look at these prefixes and we say, oh, this guy says it should be less preferred So whatever still the gateways in the next top are, they can be weighted again, right? To say like, okay, put more traffic onto this guy And now so the more interesting stuff or what tails out of that. So what's very annoying, this spins a new major schema version. We can only make it not the same schema version because they tie type the additional node stuff has node scope and we say we can all keep major schema if you flat something that is weird but it does prefix scope because if you don't understand what this thing is, you don't know what is the flooding scope So we said, as long as you add weird thing, people don't understand this prefix scope, it's fine. But now we have all these preference, right? for the node south, we have a prefix scope, but to add all this traffic engineering metrics, we have another kind of node scope thing. We could avoid that by sticking all this stuff into the node tie but I do not consider it why from a long experience with this kind of stuff And what falls out of that, I mean, in many other this discussion, this is course, right?"
  },
  {
    "startTime": "00:14:02",
    "text": "So routing will never do this adaptive routing no matter what people think they can achieve with incredibly fast flooding and so on It can only do course balancing, right? for something like traffic class class at whatever hundreds of milliseconds resolutions at best, more like two at a second So what will be needed always on those fabrics, and it doesn't really, matter what we talk about here are other people spinning stuff The source specific congestion, single link is of utmost importance. And I think that will be always an L2 stuff, so what? 8-02 other people spinning stuff. The source-specific congestion, single link, CAG, is of the most importance. And I think that will be always an L2 staff, so what, 8 or 2, 11 BB, whatever the cooking, QBB I don't remember. No, none of this used and neither will be used. Oh, you can publish something, right? What was this thing called? something plus plus uh so it hbcc plus using invent telemetry to do switch augmented. So that's so expensive right but maybe that's the way it will go but i think it will be from the destination a CEC message so call admission control message back to the source and if you do if you end up on a fabric that does too much of that, everything will melt down, right? So judicious mix of both will be running you know will scale on very large fabrics. You need this core stuff so you don't get overrun with a million things, but the fine grain will be still needed because this stuff will be never adaptive enough, as far as I see, right? So the draft is pretty fleshed out, but no, the computations are only online Callters welcome I think it's interesting work Yeah, that's pretty much what I have Thank you. So a few comments as a working group participant, number one"
  },
  {
    "startTime": "00:16:02",
    "text": "you don't realize how much you are right. I cannot show you or share test result, but eventually you will oh you mean how I figured out that that's what the stuff will be like no for don't know, 40 years of dealing with the same thing over and over again and the same, you know, illusion selves You've been talking about traffic classes. So traffic class usually has some local definition on the device right it's how you define it routing protocol has no notion of traffic classes. What exactly do you mean? I mean 8-bit integer right now so it's basically an index right now. Should we go? into the definition of globally defined traffic classes? I'm agnostic I was just thinking about protocol mechanisms so we can shove the stuff around. The semantics of the whole thing I was you know pretty loose so we can have an enum type saying, whatever it is, is the traffic class this is the traffic class, and we pretty soon get into AL2 AL AL5, you know. Yeah, so traffic class today pretty much defined by the HTTP setting, right? You take it, you map it into something. Yeah. Are you talking about? multi-instance per traffic class computation? what do you have in mind of Like I said, what you have there is an index, assign some semantics we can say dhcp not dhcp hCP bits I don't care something. People have to bring the stuff. I mean, this is routing It shoves information around the semantics, especially for these kind of stuff, are up for the people who understand, you know, what will benefit this traffic steering So again, today in the you're routing protocol, the distribution scope is adjacency right? You don't go in sub-adjacency information traffic club is kind of sub-straight of this. Do you foresee signaling of information per traffic class rather than agency?"
  },
  {
    "startTime": "00:18:02",
    "text": "So context would be some abstracted some abstraction that is below adjacency i don't foresee the need Well, so, okay, so we should jump back in oh I didn't actually I didn't you would have to pull up the usky porn of the model because I don't have it precisely specified but basically the, yeah, so the encoding is like the This additional note type element says here's a link ID under the link ID, there is a bunch of generic think traffic class independent How much total bandwidth? I forgot look it up and then it says here all the traffic classes and here is the metric per traffic class how much bandwidth is still available What are the losses? Whatever, pretty much Copy paste from ISIS traffic engineering plus some thinking. So that's the resolution I see. And then you have per link per traffic class you have the traffic engineering in thinking. So that's the resolution I see. And then you have per link, per traffic class, you have the traffic engineering info. And go do with it what you want Okay, unless there are no better I ideas in the room. And I agree that the traffic class semantics it would be beneficial with globe agree, right? And it's not locally everybody kind of tries to figure out what the traffic class means they know the zero or the one yeah so traffic class semantics, trafficking, very different than traffic class semantics and basically forwarding. I think something we need to discuss with the working group and do the right thing. I mean, structures here and you know i didn't want to find these semantics back I think something we need to discuss with the working group and do the right thing. I mean, structure is here and, you know, I didn't want to fight the semantics battle. I was thinking how the hell get the protocol to actually shove the stuff around in an efficient manner and get us what we need for the computation Mm-hmm. Cool, thank you. Really interesting work and I'll potentially join you maybe see yeah I mean they did the the"
  },
  {
    "startTime": "00:20:02",
    "text": "additional information is boring but the not bound computation and the prefix preference disaggregation is interesting And potentially draft would benefit from some better explanation, which is try to do. As usual, it's pretty cryptic and potentially draft would benefit from some better explanation which are trying to do as usual is pretty creepy in first the draft is more explicit here I'm just you know telling you a story i don't want to slaughter you with details you know enough ask you diagrams because it's pointless right? So, yes, I'd like to conform I'd like to diagrams, because it's pointless, right? So, yes, I'd like to confirm, Sunny Zanetti, I'd like to confirm that this competition is not for age specific flows, right? It's just for some links bandwidth use or some specific flows right it's just for some links bandwidth use or something else per traffic class i think was all so I think the draft says something. If we start to go into per flow state on the async we're gonna to die. It's Epsilon network, Epsilon networks go into per flow state on the acing, we're going to die. It's Epsilon networks. I mean, people try that at the no end. Economics of this kind of stuff simply don't work. Plus the amount of information you have to shop per flow will make whatever you can up with a total pick, right? The what you need per flow is on conjection the destination to source pushback whether this pushback should be per traffic class and so on, I don't know, because that's CAC admission control and that will run surely on layer two because L3 is simply too slow so it's kind of like I triple E territory and there's lots of work on this ongoing but you know there are different approaches like the plus plus stuff do invent telemetry and don't push back you know i'm agnostic so both types of congestion signaling are important and they interact with each other in very interesting ways so usually you would run congestion control from the emcephs of congestion signaling are important and they interact with each other in very interesting ways. So usually you would run congestion control from the endpoint, but then when there's change in some research in the network, you would like to be able to do some much higher level rebalancing across and practically flaws"
  },
  {
    "startTime": "00:22:02",
    "text": "we know today is going away in the internet they don't have five apples anyway so so because i see that's this extension is for tie and prefixi type or something else, prefix preference type. So it will kind of all. They don't have five apples anyway. So because I see that this extension is for Thai, prefix tie or something else, prefix preference tie. So we are advertised with prefix, right? It's prefix based yeah. Yeah. So it's specific to some flow. Oh, oh, there's preference type so it will advertise with prefix right it's prefix based yeah yeah so it's specific to some flow oh the oh actually the preference is per traffic class so the prefix preference can push southbound. I know I'm on meeting details or read the draft. I paraphrase Yaakov the push is per traffic class so a note can say look, prefer me less for this traffic class. I'm okay on this traffic class oh So a note can say, look, prefer me less for this traffic class. I'm okay on this traffic class. Oh, so I see. So it's a per traffic class per yeah so for me the max resolution we can run routing protocols is traffic class everything else like per fruit the final grains is just wet dreams doesn't work you know simply a long discussion about, you know, practical, you know, what can you practically implement this routing protocol, no matter how much CPU you have and PAV and all the tricks Sandy, and it's a good abstraction because the prefixes are acute distant. Traffic class gives you a fact of all prefixes of same time that should be treated in the same way. Similar to MPLS Yeah, it's MPLS fake. It's 129 in a sense. I mean, I didn't try to invent it that should be treated in the same way similar to MPLS feck yeah it's MPLS fake it's 129 in a sense i mean i didn't try to invent that stuff people spend no half a lifetime and the PC working group is dealing with all this computation issues. So I'm basically riding on the coattails I mean, I know a lot about that, but it's not something I want to worry about, right? So if this type will only be advertised on northbound or it can be also advertised from north to source. No, no, no, so careful, careful, right? Just like negative disaggregation works This works the same way"
  },
  {
    "startTime": "00:24:02",
    "text": "Nobody sends around prefixes. You look at the topology you look at the load on the topology, and you decide that the guys at the same level can do a better job for this prefix on the traffic class because you see on this specific prefix you're completely being overrun and then you advertise southbound is more specific saying look on this traffic class looks like I'm being hammered so my preference goes down. Okay It gets tricky because it's a mixture between what you see advertise as this traffic engineering metric and your local load because we can start ship around Q occupancy either other protocol it simply before the stuff arrives you can throw it away that's known since McQuill in 1956 okay it's that old. And nothing changed. Like, yeah everything is faster it doesn't help you because now you know, yeah, you have much faster CPU, blah, blah, blah, blah. Now I have 400 geese giglings shoving crap and not a few kilobyte link, right? So the computer, that's what I said, the computer merits a lot more tech right but don't don't forget it's, again, it's a fully distributed computation right? Everybody looks kind of what is available as the traffic engineering metrics and they can sprinkle a little bit of the local load and they decide push the traffic off okay it's very coarse but yeah i mean jeff seeing that i mean it's nothing new we've seen that on you know call admission control, on ATM networks and so on. You cannot do perfect flow. You simply cannot disseminate the information fast enough through the network, except some congestion pushback per flow right? And that's simply the reality is what we can build as a technology If we talk certified fabrics, the life would look much better"
  },
  {
    "startTime": "00:26:02",
    "text": "If we had, you know, like a credit control right? But then we basically start to build infinity band. Yeah, seems like I saw some fires from Right. And Infinity Band is basically 18 like I saw some fires from... Right, and Infini Band is basically ATM with a little bit of a different polish, but you end up in packet, fabric suck They're cheap. That's about all that you can say for them If you really want to do proper traffic engineering, you always end up in a credit-based system and in a sell-ified thing. Because only with cells it goes beyond it goes into things like, you know head of queue blockings right and stuff like that So it's actually switching, it gets down to like, how do you run a properly switching metric? So you get the throughput and the delays that you expect And pretty soon you end up selling it's just the way, you know, the perverse reality works which pays all our bills okay we have demon in the queue so we may need to add some more detects in the at a piece which pays all our bills okay we have demon in the queue so we may need to add some more detects in the air because I'm saying that it needs more tax I'm saying it needs more tax No, now he suppressed my thingy. Look at this I can't even move to thing you move too much Dima, go ahead Any one ahead Can you hear me at least? Because I okay, it just takes some time Yeah, I hope it's not all that you have to say. Yeah, try to talk slower and louder Yeah, and don't blame your eyes. It needs a lot of bandwidth uh i will try to blink them slowly thank yeah Tony I like your sessions"
  },
  {
    "startTime": "00:28:02",
    "text": "because it allows to discuss some tangential but very important stuff. So first of all, I totally agree that what you do? describe, it is useful, but it's like slow change mechanism and it's better to work in tandem with data plane adaptive routing, which is in context of IETF should be called adaptive forward actually. And it's probably a small task for future IETF to distinguish two things And it's totally a real problem because many faths spend a lot of time being not totally symmetric either because of incremental deployment or failures or because it's something like drag dragonfly. So it's useful to have a mechanism which will provide an initial hint how much traffic to allocate per direction But if you want to react to actual congestion or Q state it shouldn't be done on the control point. I totally agree and just well, to have some hints on in well-designed data center with small buffers, empty queues round trip is on the order of 10 microseconds and Q conditions changes on the order of several RTTs, so basically to have some decent up-to-date Q state we would need to do 10K or more updates per queue per link for the data centers. We cannot do that in the control plane, obviously And another thing is that, and probably it's deserves some note, is that when we computed some load-balancing form, much traffic to allocate your direction especially in multi-stage clause or similar topology, not on the leaf but on the first level spines. We usually use have the links for North"
  },
  {
    "startTime": "00:30:02",
    "text": "topology, not on the leaves, but on the first level spines, we usually use half the links for northbound reddix, basically half links down, half links up. And we are all advancing over all those half links and now the next problem is that if we look how chips are implemented, size of ECMP group is usually half of the number of interfaces for box and granular is like one record some new chip set can do more flexible allocation but on previous generations and even many modern generation basically if we have 64 uplinks and we work with 60s, markets, ECMP groups we cannot really do something granular because, wow generation, basically if we have 64 uplinks and we work with 64 markets, ECMP groups, we cannot really do something granular because, well, we can only have 64 records. We can do twice as match in one direction than others and do use one, but granularity is a real problem, especially on middle layers like level one spines Yeah, I'm all with you on the second point it is nothing to do with the specific protocol you run no matter what you just cannot stick it into silicon. Yeah, it's, I mean, it's just that people should be careful what happens between the point when control point calculate something and we tried to install that in the hardware you know control plane is wide is wine you build it to last for a long time the chips are like milk oh yeah right right it to last for a long time. The chips are like milk. Oh yeah. I get every year's the stuff that goes twice as fast and costs half. No, we can talk about it On a good year. 40 years, right? and look at is i sires 40 years and we probably long not done. So I'm building the stuff for something where people will build the silicon that can do decent stuff. The first point was more interesting. You can call it what you want like this link adaptive routing, blah blah"
  },
  {
    "startTime": "00:32:02",
    "text": "Yes, look, there I can only say your mileage may vary. The first, I think it's this complete mIESGuided tom strickx it into IP If you want the maximum speed, you go L2. Point Okay. So it's already uh we have a lot of junior for call for some of the draft session I shouldn't be too vocal, but tom strickx it in UDP or base basically already you know tripping over your own feet So if you stick it into L2 and you start to shove out Q utilization and so on, there are already some technologies, and yes, that can be done And I know there's silicon that, you know, does something with it all fine, but it's based Q utilization and so on. There are already some technologies and yes, that can be done and I know there's silicon that, you know, does something with it. All fine, but it's basically looking through a peephole right if you have a fabric that has, you know, just three stages fine enough, sure, every path is two links Once people start to build fabrics you know, all the way down to compute stuff and the compute stuff itself has another glow underneath, right? And you end up with seven, eight stages. Your mileage will wear very And you get very quickly into oscillations with this kind of stuff right as long as the load is low well, anything works, right? The moment the loads starts to go up and you get you know what Nash equilibrium is, of course, right? They basically have a lot of actors. It's not the problem even that they're greedy. They are they have extremely limited information and they will step onto each other and oscillate the system. At a certain point in time, the whole thing is a lava lamp. And that's fine, right? so i'm looking for something where we can distribute the information well enough so you can push from destination back to source in a course manner, right, while the whole thing scales. Because, of course, we can stick everything in IGP and go, hey, go marry right and that will melt down predictively So this, I even think the pre preference idea is kind of your"
  },
  {
    "startTime": "00:34:02",
    "text": "own you know manure that you know, I picked up in terms of ideas You were kind of talking about that, right? And I just kind of ran with it because I couldn't find anything better they will scale right so yes so I think it will be a wild mixture depending, like you say, on silicon and what people strip together and lots of these people have very little experience and they will try wild stuff and, you know, the usual weather stuff works by now depends on the definition of works which varies all the time so this is an attempt to do very coarse balancing around in a very scalable manner and the underlying stuff well I see what comes out of it, you know. That's always in a very scalable manner and the underlying stuff well I see what comes out of it you know that's how I see it yeah good and actually I agree because uh working with slowly changing approximately slowly changing traffic patterns is a totally valid problem there are like daily patterns in traffic and so on. It totally exists. Well, look, if you patterns are slowly changing and a very fat would you see you know i consider that total other illusion we render the Google thingy right, or whatever, Amazon, where 90% of traffic was no north-south, and everybody said like, well, that's the pattern. Let's optimize for it. And three years later, 90% was east-west. So if you know that your patterns are fast, and long lift and ideally you can predict the rival rate right and by all means build a controller it's by far the best solution nothing distributed can ever I mean it's it's it's the national equilibrium discussion right that's exactly right so by far the best solution. Nothing distributed can ever. I mean, it's it's the national equilibrium discussion, right? That's exactly it, right? So my belief is, and that's why all this distribution stuff, one is that we are dealing with stuff that changes the arrival patterns all the time And hence, all"
  },
  {
    "startTime": "00:36:02",
    "text": "these assumptions are breaking down pretty quickly But we'll see You know, see, AI, that's why my first thing says let's chase AI I think AI is what did you say? Every problem at the end is distributed linear algebra. Exactly. Depending on how you fold your tensors, the distributed traffic may look drastically different, right? They may not lung-long lift at all So, yeah So I think we should have kind of extended discussion this may be interim, but practically it addresses some issues that it didn't intend. So I'll provide some taxes but practically you're looking at everybody else state to decide how good you are right? And granularity you don't have two links here you have 128 potentially to 50, 60 links, up links to reach destination over the same traffic class So what's really interesting is ratio of data you could send to you versus others And this is it almost perfectly suitable for that. Again, I'll provide more text I don't think now it's right time which I threw away, was actually you telling the leave that the other guy suck. And I threw it away No, you definitely want to do the CV with computer threw away was actually you telling the leave that the other guy suck and I threw it away no you definitely want to do distributed computation right it is this is better to distribute the computer We're more responsive saying that you suck the way you see it, yes. Rather than talking about other people who will tell about the other people a confusing information that doesn't match up and the next thing you end up in Paxos protocol, right? Yeah, so yeah I think it's really, really interesting work that can bring all read discussion to very different level And I think we should move on Yeah, I'm done. You guys are pestering me"
  },
  {
    "startTime": "00:38:02",
    "text": "Any other questions, comments? hopefully some tomatoes. Thanks No tomatoes? I pass some tomatoes Oh, thanks. I take donations No, not really. I have enough t-shirts now. Okay thanks Yeah, I'll try and save some time for you, Jeffrey Okay, just wanted to give a rough update for the key value tie. Try to get a bit further away from the mic. Jordan, don't worry about time. Just take whatever time you need My presentations can be skipped no problem. Okay. How's this, Jeffrey? or jeff It's okay now. So again, the to be a bit further away from the mic, because otherwise you are overloading. Yeah, not too much i can do with that Okay, so new in version one We introduced the new case subtype, and we have a couple of normative language fixes and boring things like references and editorial bits Next slide so we had some discussions with Jeffrey haas revealed a new problem with respect to how we use the key identifier So currently we can kind of think of the key ID as a, you know, TLV to some degree So this by itself isn't, it doesn't provide an optimal way to this distinguish between similarly structured cases TLV to some degree. So this by itself isn't, it doesn't provide an optimal way to distinguish between similarly structured KV ties that might want to carry different information Example would be you know, we can determine who the originator is when we flood KV ties northbound, but if we need more granularity than that, we"
  },
  {
    "startTime": "00:40:02",
    "text": "need something else to signal it So we introduced the key subtype, which is kind of like a sub tlb. Next slide, please So this is from the draft, you know, including the new one, right? So you have the key type and the key identifier at a high level. It's three bytes of space Hop to the next slide And now instead for a couple of different key types, we steal a bite from the old key ID and give it the subtype So basically for well-known and experimental, that's where we do it. So we give it one byte of subtype, two bytes of key identifier and the OUI key type will stay at three bytes because three bytes So the subtype is technically optional but must be used for well-known an experiment And, you know, there are cases like I think we'll see on the S-Rift stuff, where we can still use a new key type for applications like, well-known applications that might want to use the full three bytes of space Okay, next slide The good news is this doesn't really change any anything to what we're already doing in terms of implementation implementations So using the example of AutoEVPN, the key value structure from the old version in version 5 is on the left where we used all three bytes of the key ID to say, you know, we have a KV tie, but we want EVI specific information on that note And we might have, you know, 10 EVIs"
  },
  {
    "startTime": "00:42:02",
    "text": "But in reality, we had language in the draft that said, you know, we're going to, we have to encode that EVI ID into the last two bytes of the three-by key identifier which effectively makes it look like what's on the right, which is what the key subtype reflects in the draft So we have that well-known to signify an EVI and then we can encode that additional granularity that last two bytes. Okay, next slide Other than that, there's some norma to fix these minor stuff The key target, the bloom filters stuff, it was optional, we just made it normative And then there was a couple of comments about the southbound tIABreak key value pair and what it's useful was. And basically we emphasize it tIABreak key value pair and what its use was. And basically we emphasize that it's used for implementations to kind of test their tIABreaking behavior And we folded it in the new subtypes structure as well And like I said, four references, so forth next slide and I think that's it for this one Questions, comments Oh Sorry, and getting to the queue queue I think we need to explain the key target and also Bloomberg filter with a little bit more text. I don't know, is it the main space? or is it in the key value spec? If it's not in the key value, we should explain a little bit because people talk to me and I thought it's fully obvious how a bloom filter works, but I was mistaken the other observation is that"
  },
  {
    "startTime": "00:44:02",
    "text": "when we were designing that we screwed up mildly. We should have made the kid 64 bits because now I see more and more use cases were the three bytes will be tough on the collision So those are the two observations Yeah, I had this same experience with the bloom filter stuff too anyone who talked to me, well, same experience So the idea is to make K-identifier wider What's the plan? Jordan Sorry, I'm trying out to kill the mic We'll kind of talk to Tony and see I'm not I know Jeffrey, you know, we talked about the key space being wide enough for the Estrus stuff but three bites in that case works. So we ended up just getting a new well known for that. But obviously I take Tony's word at face value that there's other applications where we might do end up with collisions so personally agnosticated Depends what Tony thinks too as far as implementation and what it would take with the base spec No, there is no need to rush that stuff especially because with the auto VPN implementation of the auto-fabric implementation, and the customers now showing interest in some of the stuff you know, more and more stuff shows up on this key value So if you ask me, I mean,"
  },
  {
    "startTime": "00:46:02",
    "text": "we're talking about the generic key value draft or just the auto EVPN key value? No, generic key value Yeah, I would let it you know, add some more good text for the bloom stuff's implement stuff works The key is too small, but it's after the fact okay because no the base base pack is out is it the tragedy No, because you can manage the collisions on three bytes It's just tedious when you implement it It is like the, no, Thai ID and so on. If you blow the stuff, to 64-bit, you can go wasteful stuff Life's easy, right? It's like the IP address. This thing is yeah, you need squeeze But I was just let it sit there until, you know, auto-fabric, auto VPN is cooked possibly you know interrupt deployed something and then it's time to kind of tie up to keep value thing. Right now I'm not seeing incorrect. I'm seeing already use cases People talk to me. So one of them is people want basically to run a DHCP server on top and they want to use the key value basically to push the HCP assignments through the fabric and I'm really like to write that. You already have protocol to do this. It's called DHCP yes you do but they okay so the problem with dhcp is that any kind of proxying really sucks. And even the best implementation in the market have owned one-for-one redundancy and if you implement a stuff in the Rift you don't have any proxy configuration problems which can really drive you bats"
  },
  {
    "startTime": "00:48:02",
    "text": "on proxy DHCP And this would give you you know, unlimited redundancy. Okay. But stuff's tricky. So that's one that people pass to me for forever, right? The V6 looping assignment, as we have now into all these auto technologies works for collision is basically almost impossible even of very large fabrics, but the IP stuff immediately stops on each other feet, so you cannot really hash it and you basically need to run something like the HCP server from the top, which is really ugly because you have, of course, synchronized state between the tops what who assigned what so basically you'll have assignments which compete and then the leaf will push up to all the tofs saying that's what i took now everybody's stores it and then of course comes to between reboot stuff, right? So the leaf to all the tofts saying that's what I took now everybody stores it and then of course comes to between reboot stuff right so the the leaf no it's all the DHCP problems again so that's one thing that people passed from me forever now um there was another one which I don't remember It wasn't Oh, yeah, so the other use case is where people have DHCP servers on the top of recs and they want to shock this information up because other older provisioning systems cannot keep up with the stuff. So they end up very often, you know in situation where whatever, some top over X reboot, some server reboot and so on. And the DHCP is peddling around but their system is so slow to update, and they basically end up with no right up very often, you know, in situation where whatever, some top over X reboot, some servers reboot and so on. And the DHCP spiddling around, but their system is so slow to update. They basically end up with no routing, wrong places, all kind of weird stuff and this will be an extremely fast mechanism to redistribute that from the top of race I hope we will never see this in protocol Protocol"
  },
  {
    "startTime": "00:50:02",
    "text": "I am reporting almost independently of what I'm thinking about right I think the second one is okay because there are actually good amount of customer stripping, no atrocious systems to deal with the with the problem. I mean, once you pull Rift all the waiter, that's host, well, you still have the address assigned problem if you go before, right? so yeah okay so i i would let it skew i think a bunch of things are cooking auto EPP and fabric is not really deployed has been implemented, but you know, it's still people come up with that think a bunch of things are cooking. Auto EPP and Fabric is not really deployed, has been implemented, but you know, it's still people come up with ideas, you know, kick the tires, so no rush to go and, you know, get this thing RFC, me things, okay? Plus the yang is still in flux so I Jordan was, was kicking the yang down the road. I was commenting some I don't know what state we are with the key value store on the yang. So the my take, no rush let's move to next presentation Yeah, and this one's quick anyway it's the next presentation. Yeah, and this one's quick anyway. And I just hop to the next slide, please please Boring change, but an important one So the previous version, you know, as we were writing and implementing everything, we instead of using EVI, just Jeffrey correctly called out that, or we were calling it MACVRF, which you know, as Jeffrey pointed out, would be very confusing to those who actually do EVPN. So basically, we just changed any reference to MacVRF to EBI where it made sense So no functional normative impact that makes it things clear. Next slide"
  },
  {
    "startTime": "00:52:04",
    "text": "And then we did it adjusted to the key subtype for both key value players So you have the global key value pair that again, the length already stated this, you know, well-known states it's global, and we encode the fabric ID into the last two bytes Next slide And same as kind of, this is the same as the example I used in the key value bit where we encode the EDI ID into the last two bytes. So same thing there Yeah, boring stuff uh, the registries are updated to reflect the new subtypes references, and so forth. That's it Questions? comments? So now see you, I guess Well, so we had very good discussions on the earlier topics We're running all the time for some updates I was going to do, but I'm happy that we spend more time on those discussions So I'm going to skip my presentations These are those are just many just updates well no it's good that we it's okay, we can skip those. So for the remaining time, we talked about the recharter We talked about the proposed charters before we were going to wait until we finished all our initial milestones before we started officially kick off the recharging process I think we're probably at that stage now"
  },
  {
    "startTime": "00:54:02",
    "text": "Let me pull up the post-charters we had discussed before and we also added some milestones there And so Jim, do you have any Do you want to say something about this? no not really to be honest i haven't had much time to really look at it. I know we have a conversation about adding milestones, which you done, but I haven't even looked at those yet, to be honest But I think, you know, as long as the working group is happy with the text, then you know, I'll review it and start the process because the base spec is already there now which is really what I was waiting for. So I'm happy to move things forward once the working group tells me okay, that we agree upon the text and then I can take it through the process Okay, thank you, Jim. So I guess, uh, is the time for the working group to really carefully review the text and see if we want to make any changes or we just ask Jim RAD to move it forward Well, we don't have to do it in this meeting now, just many, just many needs offline review and discussions. Yeah, it's pretty straightforward straightforward I think I sought Tony walk into the mic before with no it was not not about charter right but yeah I know I want to ask about charter okay okay Go ahead, if you have questions Me? No, I want to ask"
  },
  {
    "startTime": "00:56:02",
    "text": "where we are with the Charter So we'll send the email to the work group, please, obviously, to ask And this is kind of the Charter that we think is making sense, and there's something that we will propose to ASG yeah nothing to add I think it makes perfect sense and we see you know who works and what and how much of the stuff will be moving forward and how much, you know, dies on the line Yeah I think we are pretty much done thank you everyone for being here, and we will see you in Dublin Okay, thank you, everyone. Bye Thank you"
  }
]
