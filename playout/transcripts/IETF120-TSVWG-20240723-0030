[
  {
    "startTime": "00:00:01",
    "text": "I'm going to say it quite a bit louder if we don't get a volunteer So please think if you could be a volunteer to take notes for TSVWG 3WG this afternoon He would like to 10 novels Are you going to use the knot put in the materials? Excellent Excellent The opening once Hello everyone This is TSVWG at IETF 120"
  },
  {
    "startTime": "00:02:04",
    "text": "And I'm gory and this is Markley and where your working group chairs chairs This is the IETF not well If you haven't read it, you read should. It detects our rules for contributing to this working group So please read it if you plan to contribute It's the same as for other working groups so have a look We already have a note take taker Just a reminder The working, the work group depends on collaboration and people looking at documents So please review other people's documents, especially if you want your documents to be reviewed by others as well We are using Meetecho for this meeting, so please sign a sign in to Meetecho and please use the queuing tool there if you want to speak This precise moment, there are no RFCs published since the last meeting There are two documents in the RFC editor queue, and if our AD approves these, they will be released because they've been in RFC editor Q and being edited, so we expect to see them appearing very soon with an RFC number There are some documents"
  },
  {
    "startTime": "00:04:01",
    "text": "with the IESG after the IE last call, which is the SCTP zero checks up Again, some actions required to tidy this up, but there is nothing to report here everything is going normally and we will soon have that in RFC Editor Q as well So, what about the other document? We have one document that's completed working group last call and it's also with our AD that landing many documents with the AD at the same moment creates a little bit of a workload peak, but this document also has comments from the AD has an AD review, and we're expecting a new version of that to fix those AD review comments and then we'll progress also along this publication path and then we have some documents where working group last call has concluded and we have not yet made that progress to send a publication request so these are currently with the working group chairs and NQB is one of those and we'll talk about that because there are working group last call comments which will have to be a addressed before we can do a publication request to our AD which we also call a writer UDP options also has working group last call comments, which need to be addressed. There are quite a few of those. We'll go through those Again, these will need to be completed and we need new revisions of these documents before we can submit these for publication and if there's major changes we may need additional working group mass calls DPLPMTUD complete today, working group must call previous but is totally dependent on UDP options So that also is pending in the same bunch of documents"
  },
  {
    "startTime": "00:06:01",
    "text": "anybody have any questions on the document status We can continue Keep saying this. We have documents here. We have people in the room and it's really good to see you really good to talk to you. But please do feel you should review the documents Review comments can be as little as I've read this and I don't understand this paragraph or I think this paragraph could be better to more detailed critical considerations. And we've seen these for the documents that are going through the working group but please do feel encouraged to make such contributions something that's unclear to you may well be unclear to somebody else in the future if we don't fix it in our publication process So review comments are always welcome before the documents reach working group last call or during the working group last call and these are the remaining working group internet drafts. There's four of them Next one will look at the charter These are our working group milestones and they reflect the fact that the green documents are progressing and the bottom part of the documents we have one document that's not been updated for about a year it's the user ports for experiments and we've not also seen any discussion of this document in that previous year so this is currently still on our chartered list of milestones, and we're kind of asking is this document needed do we have people in interested in helping to finish this? Where's this document going? Questions, the document editors as much as to everyone else"
  },
  {
    "startTime": "00:08:07",
    "text": "Thanks, right Looks like there's little interest in continuing with this document So one thing we could do is unadopt this work and decide that we are not going to work on this anymore and delete it from our milestones It is the user port for experiments. Yeah Thank you, Christian I'm not recording what you said But yeah, seriously, this is a call for attention on this document if there is no interest in developing the document, then we don't need a charter item to say we're going to deliver it We will liaise with the editor and we'll take working group feedback and see what to do with the document Oh, and here's our agenda, and March you to the agenda Yeah, well, we and March you to the agenda. Yeah, well, we've already been doing the status and draft updates Then we'll talk about transport drafts today, about UDP options and about careful resume And then for Friday's session we will talk about the other documents We will talk about NQB We will get an update on a forest deployment experience"
  },
  {
    "startTime": "00:10:01",
    "text": "and the related draft And then we'll talk about SCTP And at the end, we will talk about the new requirements document for network collaboration signaling Any agenda bashing That is not the case And we'll note that this time there was no request for presenting new drafts Please do ask the chairs, please talk about it on the list if you want to bring new work to this working group if it falls within our charter we'd be very happy to talk to you about it and perhaps include a presentation. But this time we're saw no requests Please do read this particular draft because this is coming up in the next session and it'd be good to have eyes on this Please read it. Greg Just on the agenda bashing, I would also like to give enough update on the L4S interop activities so if we could add that to the agenda for Friday, it would be fantastic Just go ahead and put it under the L4A Okay, all right So, this is the agenda slot for discussing transport options for UDP, commonly known as UDP options And Mike Hurd has done a detailed review of the GitHub for this, that there is a GitHub that's active and recorded on um mike heard has done a detailed review of the github for this that there is a github that's active and recorded all the comments we saw in the last call and these comments have yet to be addressed in a new version of the document. So this is a"
  },
  {
    "startTime": "00:12:01",
    "text": "quick review of the working group last call comments as documented in GitHub. Mike are you online? Do you want to talk or would you like me to go through the set of issues? that have come up? I'm here if you can hear me We can hear you. These are basically very short some summaries of the more detailed document that we're going to share with the working group with all the issues. So please go ahead and talk to them if you can Thank you So please proceed to the next page. We have numbers 32 and 38 are really very subtle They were raised about disambiguating the surplus area for other uses I think the chair ruling was past you don't have or existing uses. We haven't seen any evidence of and new uses we can accommodate within the chair ruling was past you don't have or existing uses we haven't seen any evidence of and new uses we can accommodate with a new option There is, there was one here that got missed and number 33, which was some editorial knits very easily dealt with 35 and 40 or largely the same thing, which means get the very crisp definition of what unsafe means for these options Number 37, which is OCS and other issues. It's mainly fixing terminology again fairly easily dealt with with text in the issue issue 41 was a request for"
  },
  {
    "startTime": "00:14:01",
    "text": "some to the lead-in text for the non-normative Appendix A which is to encourage you uniform implementations Number 40 backward compatibility, we have if I read, correctly, a definition of that action six we have, if I recall correctly, a definition of that in Section 6, the request was to cross-reference that in Section 16, where it's also discussed easily done Some others here when we have per fragment options we don't have any text that specifies what happens if you get more than one instance within a fragment and more than one instance across a fragment and possibly also including per datagram options. And we've requested that that be clarified I think it's mostly editorial. Again, another more editorial if the clarify that end of, end of option list and a per fragment option means the same there as it does in per datagram option next one number 50 I apologize for the type of graphical error That title should have been a knit, some nits in Section 6, which Eric got for us again, very easily dealt with we hope, anyway some frag corner cases this was mainly a request for clarification that how the text is to be interpreted, whether it actually needs new text or not remains to be seen a comment number 52 martin in his when he was did his review as outgoing AD, pointed out that the"
  },
  {
    "startTime": "00:16:01",
    "text": "actual number there is not 3,000 Again, this is editorial really Then some, again, some more editorial requests there on clarifying that we don't report the frag option to the user It's actually acted upon inside of the machinery clarify the exact means of the MRDS side, specifically that includes the udp header and the options of the pre-fragmentation or post-reascension user datagram datagram More, again, more issues that should go we hope to go away very easily There's some stray text that's editorial um, something about no ops in a place where it gets didn't belong There was another editorial inconsistence in the security considerations section and an erroneous note in the fraction section, which I think was just left over from previous iterations that we didn't find when we before last call This is actually our most important thing we have to say is issues needing action We have a controversy in whether it's acceptable to the consider that additional payload checks some and authentication are okay to pass the data ground if these fail without as a default action and basically are there three options there that"
  },
  {
    "startTime": "00:18:01",
    "text": "are three issues I'm sorry that are really much the same. It's 3439 and 58 and there was one where we had a very specific working group a call for consensus The ruling was that consensus was called and now we need some text and then confirm that the text is okay If we can get all these things done in a 33, version 33, or later we think it'll be ready to go back out to the working group and see what the working group says so that sound about right gory Gorey? It does. I mean, I'm the reason for going through the GitHub, even in this quick fly of it, is to just tell people this exists. If you care about the resolution of it GitHub, even in this quick fly of it, is to just tell people this exists. If you care about the resolution of one of these issues, or you want to look at them, please do. Please come to the list or to the working route chairs or the editors and tell us if any of them resolutions that are proposed are not what you expect. I aim hoping that this document is going to be complete when we do the next revision, and it will address all issues at least to the content of the editors. The Wickengwick chairs will confirm this and we will consult with our AD about whether we'll need to do another working group last call with the group to confirm those changes or not once we see how to significant those changes are. This document appears to be reaching the end of its working group life to be published as a document so I'm hoping that this can proceed Comments please Lars"
  },
  {
    "startTime": "00:20:01",
    "text": "Larson. I think I've heard that same phrase like five years ago and this document is never finished and I think it's my my objection five years ago is timed out, so I'm going to say it again I think we just not do this and drop the document However, in the past two years we've seen very significant contributions from people to actually finish it. So it's no longer just jon peterson writing the document So if other people think it was the same as Lars, then please speak up because this is obviously one out it's no longer just jon peterson writing the document. So if other people think it's the same as Lars, then please speak up because this is obviously one outcome of the activity Go ahead coming to Mike Sorry, not to go into the key queue, but I can use my AD power to come on to my to mic. Sorry, not to go into the queue, but I can use my AD power to come on to mic. So, I have been thinking about it. There has been, do you have any plan to actually add editors to these dogs? I've been thinking about it. There has been, do you have any plan to actually add editors to this document? Because I mean, I see like there are like competition, like you just said like there has been contributions and all this thing so this is not a thing person working on it and this might be we might need to see like we get the proper uh editorial and the document title there's been jon peterson who's contributed which is mike who's been presenting here he's he's handled most of the review so um maybe we'll have that conversation Yeah, consider that one because I think that also also shows some sort of like what has changed. I mean, this is tough we're talking about like what has changed, right? So we should give proper attention to proper control And that might help the process be around a bit more quicker which would be good in this step I hope so, I hope so. We do need to be responsive once this don't leaves the working group. It appears it's finished but in fact, the need to respond quicker"
  },
  {
    "startTime": "00:22:01",
    "text": "becomes more acute after the document leaves the working group because other people have other actions to check the details list document and we're having a team that supports that is a good thing. Yep Okay, well, then we're going to ask the editor to prepare a new document and we will follow up on Zahad's comment Are you doing this one? So I guess that's the end of being the chair in this particular meeting and I'll have to assume the role of an author, editor I'm going to provide a couple of slides to represent the people who were at the hackathon table who were doing tests with careful resume and both these people are remote so they weren't actually at the table so which is why I'm going to do the slides and they'll be quick The purpose of this activity was to run matthew quick interop runner and look at multiple clients against the implementation that has been built with Cloudflare Kiche for which we use the NS3 simulator as normally used for the Interot Runner That's got some limitations, but it does let us test what happens when different clients execute the client side against the server that's been updated And next slide And we ran it with a set of clients And in the intro, and all the clients successfully um made a request for data and then the server was enabled to use careful resume In this case, it was permitted to do"
  },
  {
    "startTime": "00:24:01",
    "text": "a jump in the congestion window of 400 packets so a reasonable size jump and all the clients sent back the correct responses so the reconnaissance phase completed there was a transition to one validated different clients produced different patterns of interaction so some clients were able to cause the server to send more unvalidated packets, some fewer. I mean, this is because we're interacting with clients who we don't control but all of them sent numbers of packets during the unvalidated phase They validated the sea wind, keesh client working with Kish server managed to generate a loss consistently, which is probably a pacing decision that's made there, and so it entered safe retreat but the final sea wind that was achieved in each case was a significant growth in sea wind from using the mechanism and they achieved about 300 to 400 kilobytes of sea wind rather than about 80 kilobytes that they would have achieved had they not use careful resumed So the tests show a saving of three or four RTT which is what we hope for when we did this particular test I mean, the benefit depends upon how many RTTs you need to build the congestion window to fill the pipes or a larger capacity path would have got a bigger benefit. But that's a working progress. Next slide Conclusions, it worked at least in that test so we'll be back at the next interrupt and the reason for saying this is we'd love to test different implementations of a careful resume server with different clients and build a matrix so we'll be in dublin the rest of my team will be in Dublin and some people from Germany who have in"
  },
  {
    "startTime": "00:26:01",
    "text": "implemented the Peacock Quick version of the will be there. And we might see, hopefully, other people join us if you have a quick implementation and you want to talk about how to put the careful resume jump and other features around that Please talk to us. Please have a look at the draft we've recently added BBR support to the draft. So there's words on how to this with BPR And we'd love to see some workouts with different clients and different servers at the next intro martin yeah are you in line now Okay. I have two questions without any hands um first what was the test that you were doing? Was it just a download or what? it an echo or something else? And then I'm seeing quite big differences in the final congestion window. What's your explanation? for that and does bigger always mean better? um it was a get for a big object and the pre- pre-configured jump size was 400 kilobytes so assuming the path supported 400 kilobytes and that sea wind would have been okay so we're expecting a final sea wind of around 400 and given you also have sent other packets to get there and these numbers vary yeah I mean that might be the fun thing in asking people why their clients produce different patterns However, this is an interoperator to check the protocol interact and so I don't think we should kind of point at people's implementations and say, wow this client does less well than another client. We were only looking at that protocol exchange in this and seeing that the jump success That's why when we come in Dublin, we will come with a hardware link emulator and we will actually use some performance tests rather than some protocol interaction tests So more data in Dublin on our actual performance. I don't know if the numbers actually may"
  },
  {
    "startTime": "00:28:01",
    "text": "a big difference and whether they totally re- reproducible because the interrupt run doesn't really test that at the moment Any other questions? on the interrupt? So now for the protocol spec it's called Convergence of Congestion Control from Retail state or careful resume if you want to shorten them There's a bunch of authors and this is a summary of what was happening in the GitHub, and being published as internet draft revisions so please go ahead In draft 08 we updated the CDDL and we have in the keesh implementation and also in the Pico Quick Q log outputs because it's essential for understanding how quick works and we've updated that with how from various people around matthew quick community and we think that final CDEL is good to go. We'd be interested in more reviews if people have the of the CDDL block We changed a few things in draft 8 One of the things we changed was we had an observed phase and while we were editing this we put into the observed phase various requirements and between the author group we figured out that most of this requirements for the observed phase would actually guide it says what was making sense rather than what you must do so we've changed the language to not use requirements language when we didn't need to. It just gives advice on what should"
  },
  {
    "startTime": "00:30:01",
    "text": "happen and how to do it We made one change to the protocol, which is in the unvalidated phase We added a little trap door that occurs when you are granted a large congestion window because careful resume permits that and then the application using careful resume doesn't use it which simply says, well, nothing strange happened and immediately transition out of careful resume it's sounds like a small change but it's an important change to ensure that if you implement careful regime, correctly, applications don't get worse performance simply because they didn't send at the moment when they should have utilized the large congestion wind They simply get the same performance had they not used careful resume in the first place and that changed the state diagram and putting only added, I think, three lines of code in Rust, so it wasn't a big change And we fixed typos and consistency because we're continuing to do that and we think we're getting pretty good at finding all of them so if you find any typos or inconsistencies, please tell us Draft 9 please. Next slide Draft nine, or draft nine was the part where everything changed sorry we really thought we should stare at the spec. And when we stared at the spec, we, discovered it could be written smaller There were lots of things in there which kind of said the same thing and introduced things and said things and we could read spec, we discovered it could be written smaller. There was lots of things in there which kind of said the same thing and introduced things and said things. And we could reformat and restructure without changing the protocol in any way, but just basically go through and do a clean of the document. So this is what draft 9 was If you were following in GitHub, we apologize that there was a massive churn on the document. But if you checked, I think you'll find very few sentences were added during this churn"
  },
  {
    "startTime": "00:32:01",
    "text": "but we removed some duplication So that was draft 9 and draft 10 was an important contribution from christian hopps sitting over here but I think basically it added the BBR text that was needed to say how you would do this. It says how you do it in Reno, but then how do you do it in BBR? Well, there are a few things that are different with BBR. The good news is a lot of the things in careful resume are quite BBR like to start with. So the real question is, which bits are not BBR-like? And now we call that out. We make a few requirements on people doing it. There are a rate-based approach the BBR takes. And I think that test is pretty good again we're looking for intropics experience for that and just to confirm that the text is correct, but draft 10 is pretty good Christian, do you want to add anything? So that seemed fair enough. Seems good, right? Next step next steps um ah next steps we're trying to close out the issues. We had one issue number 22, which has been around for a long, long time Is there a need for a minimum number of RTT samples to confirm a path? One of the things that careful resume seeks to do in reconnaissance is not make them mistake of using a path again which is different to the one you previously observed or measured. And we need to measure the RTT So the question of how many RTT samples do we need to know that the current RTT is the same as the one we previously had? And I don't know a number so at this point we don't say a number and we propose to close the issue with no action because clearly as an implementer, you might have some ideas, what you think works and what you have kept"
  },
  {
    "startTime": "00:34:01",
    "text": "But I don't see any particular wisdom on just on this um the RTT has to be within the range we say and maybe one RTT samples enough if you think more then please do more so we propose to close issue 22 with no action action Issue 13, we added a set of examples and various people from the working group who were reading the document and commenting on it for those examples and I think people have valued the examples at the end of the document. We've got a whole state table and work throughs for different cases. We didn't add a case for limited sending example and it's a one examples at the end of the document. We've got a whole state table and work throughs for different cases. We didn't add a case for limited sending example, and it's a while ago since issue 13 was opened If people want us to add that then please say again, you probably know who you are and otherwise we propose to close that because we have other examples which we think probably are good enough for you to be able to get the understanding of how the algorithm works. But if you want that, please say I think at this point, I would take questions. Martin Martin, do Google um i'm not in love with proposed standards that like don't have numbers in them that just say like just pick something. This is very issue 22, yeah? The answer is one unfortunately okay so right so yes so there's a question of the middle which yes is sort of by thy fault default one, but like some sort of recommended value if like if you don't know what you're doing i think is a good thing to have in a document like this Do you have a proposal for number greater than one? okay so again there's there's two separate issues there's what is the minimum and what is the recommended number and I think if you would your judgment and minimum one is fine, that's great I think there should also be a recommended number, which could also be one"
  },
  {
    "startTime": "00:36:01",
    "text": "I don't know. I haven't looked at any data at all But I think having some sort of suggestion is good, even if it's a very weak one, even if it's like a very, like, it's a should that, you know, unless you I, you know, just some sort of guidance so that people want to guess Question, pardon? huitema, one, but I mean, there is text in the draft that is kind of vague because it's a but, I mean, there is text in the draft that is kind of vague because it says it puts limit on that RTT to be between like half the previous value and twice that that's kind of a bit of a wide range And if you have something that I would say it'd be cool to use one if you validate with another of a bit of a wide range. And if you have something like that, I would say, it'd be cool to use one if you validate it with a narrow range and then if you are not in that narrow range initially, then we try to confirm that that's kind of I mean that limit does, it works but it doesn't make me comfortable because I think it's too wide wide Yeah, well the limit, the limit range is half because of the way the algorithm works, because of the, the, um, doubling business. No, I'm thinking of the RTT. Yeah, well, okay, but if you have if you did a previous Seawind and your RTT is a half of what you previously had then your rate is twice as fast Okay, that's where I see my bias. Yeah. My bias is with, uh, with B which the key value is not the actual RTT, but the mean RTT This is Min RTT we're talking about only here So if you do mean RTT, that's from the beginning of"
  },
  {
    "startTime": "00:38:01",
    "text": "the connection. And from the beginning of the connection the mean RTT is typically taken at the time where the queue has not built yet. Yes So logically, the ceiling document does not exactly apply because you're supposed to look for the knee and your seawin will be at about that knee and your RTT will be close to the mean RTT If you are validating you are at the beginning of the connection, you have not sent a lot of data so logically your mean RTT should be about the same Exactly. Should be So if you find something different then it may be because of fluke There are fluks happening at the beginning of the connection So my logic personally would be to hey, if I find the same value life was very good, if I find the value that is between larger, I mean, but not like in this one to two range then I would try again to exclude the fluke But the principle of caution will be that if I find an RTT test way different, probably I should not proceed And instead of proceeding, I may want to retry to exclude something bad but I mean, that's what I would do. I would basically come in narrow the range and retry if you're not in the range or something like because there is uncertainty, so you want to take the minimum for a couple of things okay okay so we have reconnaissance which is the kind of startup phase where you're sending just the initial packets and currently kind of the logic says I take the minimum RTT I previously had and I take the minimum the"
  },
  {
    "startTime": "00:40:01",
    "text": "in that reconnaissance phase if we don't take the minimum in the reconnaissance phase because it should be the main minimum. But you're saying, if I'm reading you correct, that that minimum what we first read from the first reconnaissance packet may be a flu so we could take the next one and still remain in reconnaissance so we still get a chance to do the careful resume thing because the minimum of those two might be better. Yes but mean basic don't bother to do it twice if you're if you have confirmed already yeah yes I mean, this actually doesn't make a big difference, but it gives you a second chance to use the method if you had a fluke RTT sample at the beginning Yes. I understand. Okay, right Well, let's see if we can make a PR and look at that i understand now yeah because you all. Ah, Katulhohohoho right. Well, let's see if we can make a PR and look at that. I understand now. Yeah. Goodsuel. Well, so I generally think that being careful is a good thing, so I'm not sure if we need to really be careful here. I mean, probably one RT, having one sample is just enough considering that this disruption caused by too, sending too much, is only for one RTT. Condition, convergence of congestion control has happened in a more longer period so just having one disruption is fine Okay, well, we can try and work out a solution to this I think we still have another round of edits and as in many of these discussions here, this is all about corner cases, but corner cases are important because they either help you or hurt you. Let's continue that on the list. Are we done? Well, close probably, but we always say have to discuss this. christian hopps suggested we add back a section on the rationale requirements, which we had when we start this whole draft process we our original document tried to say why we were doing this and what the"
  },
  {
    "startTime": "00:42:01",
    "text": "goals were and since we specified things, that text has slowly eroded and disappeared so we probably will add probably I would imagine about half a page no more at the beginning of the spec to restate the requirements and the goals of the whole thing so that somebody coming along with a very different congestion control or in future knows kind of why we're about this rather than just has to read the reno and the algorithms and then the BBR and then try and figure out what to do next. We'll probably put those requirements in and see if that helps that After we've done that discussion, is there anything else that people think we should do could we be ready for a working group last call? Okay, so suggestion from an editor of this document is that we would like to ask the working group to do a working group last call of this properly in the time frame before the next meeting, where we will prepare a new revision and hopefully removed all issues Matt Yes, I'm sort of coming to this conversation late because I've been distracted how much nonsense non-simulation implementation experience is there? Implementation in Cloudflare Kiche, not the main deployed stream, but the current copy of that so a fork of the current Cloudflare Kish and it's been tested over the current cloud fork of the current cloud floor kish and it's been tested over various types of paths nobody's yet tested over a very large data center path and we don't have a very large data center path to test over but we test over various radio links and various wired links So these are single"
  },
  {
    "startTime": "00:44:01",
    "text": "testbed of a small number, fairly small number, amount of data excuse me at the moment yes We are talking with people who have Cloudflare Kish servers You can guess which company that might be. About trying to do some much wider tests and problems before Dublin. So there's been, okay, so there's been no at-scale testing at any scale no at scale testing at any scale of this now but there has been implementation also in peak Picoquake. So we have two implementations Any other questions? If you'd like to help us test or you'd like to implement or you'd like to try your client with us and figure out real what happens when you do this, we have open to implement or you'd like to try your client with us and figure out really what happens when you do this, we have an open server that you can connect to and we do have Q log support so we'd happily um share that Q log back with you to figure out what happened Otherwise, thank you for this time That's it for today This was the day where we do all our administration-y things. Please come along on Friday. There are a lot of interesting drafts appearing on Friday and some proposed new work for the work group Two minutes"
  },
  {
    "startTime": "00:46:16",
    "text": "Yeah Thank you Thank you Thank you"
  }
]
