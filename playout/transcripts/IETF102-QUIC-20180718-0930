[
  {
    "startTime": "00:00:04",
    "text": "yeah thanks ok let\u0027s go ahead and get started this is quick if you\u0027re not here for quick you\u0027re in the wrong room if we could ask the folks coming in to close the doors that would be helpful thank you so this is quick we have one session in this meeting Lara\u0027s my co-chair wasn\u0027t able to make it to this IETF so he\u0027s going to be joining us remotely I\u0027m flying solo also our area director Spencer his remote as you can see we have a lot of other remote people as well on on media echo so please keep that in mind when you\u0027re at the mics speak clearly state your name let\u0027s not have side conversations and let\u0027s make sure that they can productively participate this is the note well hopefully by this part of the week you\u0027re familiar with this these are the terms under which you participate in the ITF or a summary thereof really regarding intellectual property regarding your behavior and how you treat other people and and copyright and lots of other things so if you\u0027re not familiar with these please do a search for IETF note well on your favorite web search engine and you\u0027ll be able to find this document and understand what you commit to when you participate in this process so Joe has very kindly offered to scribe many many thanks for that heroic Duty you\u0027re performing the blue sheets are on the sides if we can start circulating those and once they get to the back if you could please send them to the center so those folks get a chance to sign in as well that\u0027d be great our agenda today is pretty tight I\u0027m gonna try and keep things snappy we\u0027re gonna have some updates from the base draft editors we\u0027re gonna touch base with the operational draft editors we\u0027re gonna discuss some of the issues on the base drafts excuse me and talk then talk about the foreseeable future what we plan for the next steps with we\u0027re can group what our status is what how we think we\u0027re gonna finish this work and then if we have time we have a last-minute addition to the agenda which is an update on the spin network from Marcus any bashing of the agenda okay so first up we have a quick update from Martin all attempt to get your slides up come on you can do it no no okay that "
  },
  {
    "startTime": "00:03:07",
    "text": "works yes apparently we have sixteen by nine so next I don\u0027t make this really quick so this is basically the things that have changed in the last yeah it was an anchor and no longer so probably the biggest change that has happened recently is the stream zero special crypto thing has turned even more special and now longer consume stream means gonna go into details about that in a little bit so we\u0027ll move on next it looks like a lots changed in 13 and that\u0027s because a lot has we added support for ecn thanks Magnus for all of the extra work that was put into that one with my changes to connection ID handling that\u0027s not the end of that we\u0027re discovering now that connection IDs are interesting and complex and new ground and breaking that new ground has turned out to be a little bit painful Mike\u0027s got some more on that later on we added the ability for service to advertise the preferred address on which they would like the connection to migrate to we made stateless reset symmetric and we now actually can extend quick in various ways specifically new frames in this case there\u0027s a bunch of changes to HTTP queue pack I think we\u0027re up to Oh - on cue go one on cue pack which means that there\u0027s we\u0027re still a little bit early on that one and so that\u0027s that\u0027s had a lot of churn next place so when I wrote this which was last week we had about a hundred open issues we still have basically 100 open issues we\u0027ve been killing them pretty quickly but they\u0027ve been popping up just as quickly this is a considerable improvement over where we were six months ago mainly because we\u0027ve gone through and labeled about half of these as part or version two and for those people are not familiar with the way we\u0027re dealing with this with identified a bunch of issues that we\u0027re not going to solve now and those are still open in the in the issue tracker but they\u0027re labeled with a quick v2 label it basically means yes we think this is important but it\u0027s not important for us to solve right now a bunch of other issues are labeled part and those weren\u0027t thanks those ones we\u0027re sort of committing to come back to them later and that might be because it\u0027s to spend it and we haven\u0027t finished our work on that or it\u0027s because we need more information or because we just can\u0027t solve the problem right now for various reasons of those remaining which by "
  },
  {
    "startTime": "00:06:08",
    "text": "various measures we have somewhere between 30 and 50 issues my assessment of these and I think the other editors are in agreement on this is that they\u0027re pretty close to done and the main reason that they\u0027re not done is because it takes work and if anyone can help us out with any of this that would be greatly appreciated and so we\u0027re going to be looked looking to assign work to people over the next little while but from my perspective the end is in sight yeah and it\u0027s just a matter of sitting down and typing some of these will require some discussion in the working group to reach conclusions some of them the conclusions at least to me seem fairly obvious but we\u0027ll discover interesting surprises along the way but they\u0027re relatively minor for the most part and so I expect that we\u0027ll be able to have something fairly concretely complete by the next time we meet here at one of these plenary meetings so the end is in sight that is the light at the end of the tunnel thanks Martin this is my nightmare every night that is the light at the end of the tunnel so you got any questions for Martin about the status of the drafts or the recent changes let\u0027s not get in the issue discussion just any questions about this subject matter all right yeah he\u0027s gonna talk about stream zero we might have some more details about that yeah okay thanks so next up on the agenda is Ian talking about stream zero while we get ready for that I skipped something I apologize John was gonna do a very quick update of what happened on the weekend with a hackathon just wanna use this mic Brooke quick maybe Jenna and God very quickly we had a hackathon we had a number of people show up and participate some remotely implementers there were some people working on draft 13 but many were still working on draft 12 I heard some mumbling about trying to get packet number encryption right here and there and people also seemed to be working on that so I think it would be nice to actually move forward to stream 32 to draft 13 draft that you know is a big big shift from what we\u0027ve done in the past draft 12 already includes back another encryption not everybody\u0027s gotten there yet but hopefully by the next interim people will be on to 13 and working on stream zero issues instead of being stuck on things before 12 okay so what they all add here is if you go to the github "
  },
  {
    "startTime": "00:09:08",
    "text": "I believe kazoo has produced a PR that has a NOC kazuo kakazu as bridge to PR that has a example client hello with a simple message as soon as a client hello with a P any and so that you may find to be a useful structure for figuring out why your Pina doesn\u0027t work um I\u0027ll try to I\u0027ll try to get mink to dump chip to make one and dump out all intermediate points like their crappy version Martin\u0027s draft because like that does like it\u0027s very it\u0027s very hopeful to like have that kind of stuff that\u0027s the one case where like basically you can just ingest the message with no state at all and like running and we produce the exactly the crypto everybody else adds so um that may help people get PID workings peony I know is it all tricking people okay thanks I\u0027m just hoping one last thing that if people as they\u0027re implementing peony can can can find out the the symbol got just that they got stuck on be useful to add them into the drug so please keep note on that okay that\u0027s about it thanks Jenna just just for folks who are new to this or haven\u0027t been following closely we have a very active group of implementers I think we have what on the order of 10 ish implementations right now we\u0027ve been meeting before in the hackathon before the main IETF meetings as well as adjacent to our interim meetings and they use a slack group to communicate if you\u0027re interested in all of that please get in touch with me or Lars or or any of the editors and we can introduce to that effort so in string 0 alright so I\u0027m gonna do a summary mostly what we talked about in in Shuster so if you were there then it\u0027s pretty much just a rehash I am gonna go fairly fast just to because most these issues are fairly decided but I want to kind of go over them because Martin in particular is going to talk about so in the later next slide so this is literally a still kind of a copy-paste of sorts from London these are from accrue slides about the various issues with the the stream 0 design at the time so next slide Rock\u0027em actually these are mostly for reference as a background TLS over TCP you have TLS messages on TLS records and those may or may not line up with TCP segments so TLS record can span multiple segments or it can line up or you know there could be multiple TLS records within a segment that\u0027s sort of sorted that architectural model in the next slide in the draft 12 which is prior to the stream zero changes this is sort of the quick stack as you can see it\u0027s a little more complicated you have TLS messages that are on TLS records that are inside quick frames that are inside quick packets which themselves have kind of a record layer as we\u0027ll talk about in a moment inside datagrams so you know at the very least it\u0027s probably one expert level of indirection here next slide "
  },
  {
    "startTime": "00:12:08",
    "text": "so draft 13 the design the otherwise known is the quick record layer design kind of squashes this down by one layer and it makes it so the TLS messages are in quick frames which are then in quick packets which is sort of the like crypto record layer for the transport and this was already like very much have one hour to TN 0 rgz worked anyway so one or two T and 0 RTG there was no TLS record layer involved unlike TLS or TCP so in some sense this is like a unification of the design we already had where before it was kind of half in one world in half in another next slide we had a new crypto handshake frame so instead of actually putting it over stream zero there\u0027s a special frame it removes a few features like you can\u0027t fin it because you never really wanted to be able to fin a crypto stream there\u0027s no SKU ID because that doesn\u0027t make any sense and each encryption level restarts at offset zero to avoid any ambiguity about like what happens if the start offset of like the next encryption level is before the end offset of the previous encryption level and like various other weird things is not a stream frame so therefore it is not flow controlled by default we discussed that briefly and she said and decided that the effort to flow control it was more effort than it was worth and if we did want to do that that would potentially be a TLS working group item next slide so the the Newport has clear rules about where every handshake message is sent there\u0027s no double encryption quick doesn\u0027t really need to know anything but the TLS handshake just basically Keys get exported it and Kayla says like send this and that this encryption level and vice versa quick passes messages and data back to TLS and says this was received at this encryption level yeah no double encryption and you also get built-in path validation so before before we actually had path challenge and path response and they were allowed during the handshake because we didn\u0027t have a good way of actually making sure that the peer is on path but now the receipt of anything at the second encryption level well technically the third uvaca can tell us but of handshake encryption actually proves that you\u0027re on path so in practice you don\u0027t need a separate on path validation next slide so where the costs it basically requires a new API for TLS that\u0027s that\u0027s probably the largest cost at least that we\u0027re aware of obviously regards a few changes of the quick traps as well but at this point there are already some implementations available and at least that the interrupt thing is actually a little bit okay I think there might be three people who have interrupts now but I\u0027m not sure so next slide huh the code was three or "
  },
  {
    "startTime": "00:15:14",
    "text": "four he thinks from echo three or four so another change we made at the same time there were some issues around not having separate packet number spaces in particular there was an issue that Christian identified the long time ago where by spoofing at I\u0027m an unencrypted packet you could essentially create a hole and the peers Paquette scream and then they would never be able to recover from it for the rest of the connection and that hole would actually be in the encrypted portion of the packet number space non the unencrypted portion kind of the details are on issue thousand 18 but the the critical thing that needs to happen is when you get an acknowledgment you need to know whether that packet you know what encryption level that packet was at that this is being a so you need some unambiguous way of knowing you know this peer is acknowledging five and it was at this encryption level the other issue that was open is that acknowledgement of packets at one level could actually at least in the current loss recovery dock at the time caused spurious retransmissions of packets a different encryption level so you could you know receive a initially encrypted packet and that could come after say zero RTT maybe you can\u0027t process here are 2t suddenly you acknowledge the initially encrypted packet and fast retransmit kicks in and says like oh this peer must uh it must have lost all the 0 T and you retransmit it anyway even though the real problem is you just couldn\u0027t decrypt it and so therefore you couldn\u0027t acknowledge it next bug so the design for separate record number spaces is basically using an acknowledgment or an AK frame in the packet number space you want to acknowledge so there\u0027s no special Act frame or a new akram it\u0027s just you know act frames in initial acknowledging initial packets actually Amsden handshake in knowledge handshake packets you can\u0027t send out frames in 0 to C because there\u0027s no point and one RTG at frames obviously acknowledge but actually they acknowledge about 0 to DN 1 or T packets so next slide so it\u0027s all the the issues we identified it clarifies exactly what level you should be sending your acknowledgment set before there is some very weird wording and kind of confusing wording about like you should always try to send it the acknowledgment at the highest possible level but you could actually end up in a situation where you could acknowledge a packet but the peer couldn\u0027t actually see your acknowledgement if you sent it for example with one arty tikis because even though you received a one or two t packet does not actually mean that the handshake is completed for example on the server set to you know the head of line blocking of the of the C\u0027s earth thus you can so it also makes the rules quite simple so the rules for recovery "
  },
  {
    "startTime": "00:18:14",
    "text": "for all the different packet spaces are pretty much identical there\u0027s no like special cases like if this is at this encryption level do this and so on and so forth and yeah I removed some temptation to do some some relatively stupid optimizations that we came up in the meantime with and the more we went through them the more we realized they were they were foot guns that would get you in a heap blow Dro yeah so next slide so the big cost is basically due to structure cost in tracking cost so I think the logic is fairly straightforward but the you do need at least temporarily to potentially keep around multiple kind of AK frame data structures you may need to keep around multiple flights and packets data structures and the other cost is you\u0027re gonna end up with more of what we call coalesced packets previously referred to as compound packets where you have two quick packets in one UDP Datagram so excellent ah so transport retry so this wasn\u0027t really in the original list or this kind of got baked into the original list of comments about issues with stream 0 but in this process it also became clear that there is a desire to have a non TLS kind of retry stateless reset mechanism that\u0027s much more similar to like TCP syn cookies and you know this is mainly for DDoS reasons so the idea that it really should be a really easy way to do proof of source address that doesn\u0027t involve like consulting your tos doc or doing anything complex and then some cases people actually wanted to put these on separate boxes from the main main host but there\u0027s also the issue that the current retried that we had before complicates TLS interaction there were some fairly like confusing rules about whether you had to send an HR are in a retry packet or not and in general no one really see if we\u0027re happy with the stay of the world so the big goal is to move retraining to the transport and that is largely worked out well but there are a variety of G\u0027s health issues that we kind of didn\u0027t fully think through when we first wrote up the text so next slide but I\u0027ll go over them that the design here so the retry is not encrypted at all so it\u0027s just plain text it\u0027s a long header packet it actually repeats the destination connection ID that was in the clients initial and the reason for that is to do proof that is on basically and then it has token content and so the server sends me a read/write has a token in it I put that token in the next initial that I send back to the server and then in theory this token is proof that you know I am on path and I am the IP that I say yeah and as you can see the initial has the Chokin content kind of where at the beginning right after the long header so yes and the other "
  },
  {
    "startTime": "00:21:17",
    "text": "issues that this this token is actually also used for zero RTG so there\u0027s a new token frame inside the encrypted envelope that allows you to refresh your token once you\u0027re forward secure and of course you must not mix these tokens so you know tokens that are are used in the handshake and they\u0027re used for basically DDoS prevention you know must want to not be used later for 0td next slide I kind of went over these before but retry minimizes CP usage on the server side when when under DDoS and other attacks situations and it definitely simplifies the interaction for for the stateless reject use case so oh yeah and there\u0027s no packet type and pigua TiVoed like where you put things next slide all right so these are the issues that are currently open an additional description there were a lot of things that were intended to written down and just word not written down quite right so draft 13 just has a bunch of little errors that thankfully Merton mostly fixed at this point and and did a nice job of but then there are a few other issues and at this point I\u0027m as well just like that\u0027s next not quite not quite okay bit later yeah well coming soon just slides near you all right that\u0027s it thank you in any questions about the stream zero transition I\u0027ve heard a few from folks about how this might affect our schedule we\u0027ll talk about that a little later in the session but anything else okay thanks Ian next up can figure this thing out we have I believe Brian if you can make your way up talking about the operational drafts hi I\u0027m Brian for those who haven\u0027t already asked I have said skiing accident yeah here to talk about two drafts ITF quick manageability and ITF quick applicability um it does work operations drafts does anybody remember these we actually forgot about them for a while and we\u0027re the editors the point of these is to provide advice to application developers and mapping designers on using quick write so we are chartered in this working group to work on one application wrapping two HTTP with htv-2 like semantics this is however a general first transport protocol so we\u0027d like to "
  },
  {
    "startTime": "00:24:17",
    "text": "have sort of either template information or other considerations that you have to have when you\u0027re mapping something other than hbt you onto quick um and then we wouldn\u0027t have another document which is advise to application and network administrator\u0027s network management tool designers on what deploying quic is going to mean for management tasks that they you know commonly do so the idea is to say sort of a users guide to the quick wire image for people who are only looking at the wire image so they don\u0027t have to go into the 2d protocol itself so this is really the fifth focus area in the working group Charter um applicability we updated at this time we made basically no changes because there had been no text added to it since the last time we just revved it to keep it from a core - unexpired we\u0027ll talk a little bit about the scope of this document because I\u0027m not sure we have it quite right like so originally we had one document which was applicability manageability we decided to split those in part because one looked like it was going to be done way earlier than the other one just you know with respect to the amount of discussion we needed to do we haven\u0027t changed as much but there\u0027s been like no controversy so there\u0027s been no attention right like so it\u0027s like ok great um well we\u0027ll take a look at the open issues and and talk about how we might want to scope if we want to restock this in a couple of minutes in the meantime we\u0027ve done some thinking about manageability um the flux in the wire image so as we\u0027ve been developing the protocol basically trying to track changes in the headers was completely pointless so we just didn\u0027t do it it looks now especially after CID PNE and some of the stream 0 interactions with the wire image the retry stuff that\u0027s all settling down now so it\u0027s time to basically write it up and we did some of that for this time but will need to do at least one more rev on that so the changes in 0 1 we updated to the rev 13 headers we added coalesced packets we fixed see IDs we encrypted the packet number this actually allowed us to delete a lot of text because we were talking about what the packet number might be used for and it turns out now it can be used for absolutely nothing we mention sni for application identification so when sni gets encrypted may have to tear that back out too we point to the experiment for on this thin bit for potential RTT measurement and also point out that you can do initial RCT based on the handshake so those dynamics have not changed like all of the names the packets have change but but at that point hasn\u0027t changed there\u0027s a little bit more work to do on load balancing and usage of the connection IDs but it\u0027s our opinion as editors that this document at that point is mostly done right like so the the the protocol has a relatively minimalistic wire image so the users guide to the wire image is "
  },
  {
    "startTime": "00:27:18",
    "text": "here so you can do with it not much that\u0027s by design right we there may be some commentary that comes into that where we you know talk about why not much but in terms of the technical content this is pretty close to done we looked at the open issues and pretty much all look like originally I said okay well and classify these by applicability and manageability and the manageability list in terms of open issues on manageability that we need to actually talk about is empty um classifying the open issue is the applicability draft we have sort of three classes of these one is endpoint implementation issues an endpoint API issue so this is a little bit less about writing bindings and more about what sort of interface the the transport protocol should give to the layer above great so we originally envisioned this as a document or a be like a binding writers guide and it turns out that we almost that the a lot of these issues came from discussions on the base drafts and they were sort of shunted over to the ops drafts and it looks like there might be from these issues some demand for some sort of abstract interface document whether that goes in the applicability or abstract interface specification where that goes in the applicability document or has its own document is something that we should talk about there\u0027s a second class of these which are sort of additional endpoint behaviors these are you know pointing out things that you could do right like so there\u0027s a do we want to talk about the fact that you can use streams and stream resets to give you an emulation of partial reliability do we want to talk about multiplexing over like some multiplexing multiple sets of streams oversee IDs on the seam on 5-tuple talk about trade-offs in whether or not you do keep a lives or decide that you\u0027re going to do RT t r 0 RT t presumption when you have an NAT state drop and then the third of these are sort of operational guidelines for serving quick so this I put a question mark on applicability here because they\u0027re currently filed is probably on applicability and they were in the original scope of applicability but it also seems like you know yeah right so if there\u0027s there\u0027s a scoping question for the open issues that we know belong on applicability we marry and I we can suggest text but we might not be the best potential authors for some of these like so some of this is like version roll out and roll back in large clusters and migrating Google quick to quick right so people who have experience for that I\u0027m not looking anybody in particular might have um you know better input than we have on that if you want "
  },
  {
    "startTime": "00:30:18",
    "text": "to if you look at one of these issues and would like to assign yourself to it that\u0027s graciously accepted PRS are also graciously accepted I wanted to have a bit of a talk now on um document organization audience especially on applicability cuz right now we\u0027re talking to implementers we\u0027re talking to sort of clients at the application layer and we\u0027re talking to deployers with that document right now and it might be that that\u0027s too much and we might want to split this out into a third document um we might want if we\u0027re doing too much we might want to push them all back into one document right I mean there\u0027s since we\u0027re picking this work back up now and hope you know that manageability should basically be done in the in the Bangkok timeframe is my my optimistic hope if we stopped changing the wire image obviously and then applicability is done as soon as we get text on but since we\u0027re gonna spin that work up we should talk about the organization now I think okay Chennai and God so I think when we talked about the applicability document a while ago the application layer users and deployers were sort of important and cold parts of this what for implementers are you doing in the document I don\u0027t see anything in there that I think of as these fundamentals really so a little bit kind of CID generation port number use right like so so not necessarily like directly implementation level stuff there was actually a discussion about how to handle ICMP quoting which got pushed over to the ops drafts and then got picked back up in the base drafts because that\u0027s actually where it belonged but there\u0027s still some stub stuff about like so handling ICMP what your error interface should look like so these I think are things that are really talking to - to implementers also there\u0027s touches really the mere could have been this touches a point about the the interface discussion because the interface needs to be implemented by the implementers and then used by the application right so and it currently the document gives hint about where an interface should be but maybe what want to say more than that yeah I think the I personally think the transport interface that you that you were talking about earlier is an important piece of this I think it\u0027s something that we should really try to get down I think that\u0027s probably to me the most important piece of this one and then the users the questions on 0 RTP how do you deploy this those are important but not as important as the do you have an organization opinion do we put all of this into applicability or do we take the interface stuff really it\u0027s a it\u0027s a it\u0027s almost a disjoint audience as far as yeah it\u0027s tempting to think of it as a separate document "
  },
  {
    "startTime": "00:33:18",
    "text": "when I look at these issues and I was trying to classify them that really was the feel but I got I\u0027m not trying to like load the question but I\u0027m interested in other opinions so the way I think about this is if it\u0027s if it\u0027s valuable to as you start writing it out if it starts becoming too big the document that\u0027s usually something I think ok yep because I don\u0027t know how big it\u0027s gonna get yeah so gory Fairhurst and I think the there\u0027s a very different audience between people wanted to know an API and use this to those who are trying to run operational Network and want to know how its behaving and what packets are important for them the details probably not in your list the details in how you write it right so we should be careful as we write it that we\u0027ve picked the audience because experience that the ITF is people if you direct it in the wrong way that group of people won\u0027t read it so I think there are two different groups of people who you could write the text for okay so that\u0027s the that\u0027s the split between applicability and manageability right yeah okay tell me Polly Apple I would just like to read area which what I think you and John I\u0027ve been saying of the actual abstract interface feels like it should be a different document that can certainly reference this so I think this should describe all of the bits that are required to give a more normative claim about what an abstract interface should be but that should be left for a separate exercise which I think we should also do soon and start working on is that um volunteering to edit yes okay cool Thanks we talked to Lars about that a bit more I guess now that we\u0027re having a chat at the table we\u0027re chartered right now to deliver these documents at the same time as that the base protocol it occurs to me that a lot of the folks who could contribute to this work right now heads down on that work would it be beneficial do you think - maybe just delay these documents publication by not work on them but publication by even just a month or two so you can get a little more their free time we\u0027d see one I would suggest basically like one um interim cycle right like so a half meeting cycle is probably enough really there\u0027s one and a half months right well we\u0027re gonna we\u0027re gonna talk later about yes yeah yeah so x plus x plus one half cycle I think is good but these documents weren\u0027t to ship at exactly the same time as the bass traps that\u0027s fine okay yeah uh hardy let me just make sure I understand what what you\u0027re proposing before I come in because there\u0027s a little hard for me to hear mark what I hear heard you say was you were proposing that publication of these drafts might be later than the publication of the protocol that\u0027s is that correct I was asking if that would cause pain I wasn\u0027t proposing I think it "
  },
  {
    "startTime": "00:36:18",
    "text": "might cause pain speaking personally I\u0027m particularly concerned about some of the operational guidelines aspects coming later than protocol documents in particular because we\u0027re putting the protocol documents out once we\u0027ve got significant interoperability testing under our belt I\u0027m concerned that people will then almost immediately start using these in fact some people are already starting to use these and that those guidelines might be useful earlier rather than later I think the trade-off is just the quality of the documents could be significantly better I think the way I agree but there are some core pieces to both of them and I think it would be very valuable to have come out as close as possible so perhaps some more discussion on a list of which pieces might get more attention so that we can get those out early might be useful Mia Cuban and I agree I think they should be punished at the same point of time but for me publication is like when the editing phases is finished and we actually have the RFC published right and I think that can be aligned like even if you send it to publication for the is II is she at different times and so on we came then at the end like wait until we published II hope I don\u0027t want to get too deep into the planning of this I just wanted to see if there was a amenability obviously we need to talk and think about a bit more yeah okay well so I\u0027m gonna I\u0027m gonna put people on the spot a little bit um show of hands who here sees one of these open issues that they believe they could help with that\u0027s not committing I\u0027ll close my eyes okay yeah so yeah a few that well okay good all right so we\u0027ll basically follow up on the list with with the heavy guilt I guess all right excellent thanks there\u0027s stairs over there right oh yes that ends yes thank you thanks Brendan okay so next up we\u0027re gonna go into if I can figure out this thing discussion of open issues on the base drafts the editors have selected six different topics of areas they have questions for working group and in clusters of issues we\u0027re gonna go through those we want to leave some time as we mentioned before for planning and then future looking kind of planning at the end of the session we also have the presentation on this bin bit so I\u0027d ask we not let any of these sessions get much more than 15 minutes long if we do that we should be okay first up Martin we\u0027ve got retrying sorry yes mark yes ELISA gender best a little bit we have a pattern of like spending of like discussing for 15 minutes then deciding oh well now we\u0027re like me on the next thing to close some of these issues "
  },
  {
    "startTime": "00:39:18",
    "text": "rather than just like you like oh like like we spent like like 500 message the mail and retry so like I\u0027d like to get retried done rather than what I don\u0027t care like if I don\u0027t get to like you know I don\u0027t know what connect ID like management like that\u0027s sad but I\u0027m not sure I get retried done think every trying fashion as each quarter done so Martin Jonna from Year\u0027s Day you know I think we should do this one first then connection are these in priority order that this there is completely random no that is random its retry than managing keys then stateless reset connection ID is HTTP and recovery okay let\u0027s do that is that a good order list we stick and that\u0027s as I understand it a summary for the HTTP working group not a decision-making so specially my Mike points out there there\u0027s a couple of issues that he wants to talk about so yeah there\u0027s this is separate yeah yeah we want to solve some problems okay so let\u0027s get started yep smells good let\u0027s not talk about talking so oh yeah I mean I made slides sorry do you yeah we go I\u0027m just gonna get straight into this one okay so we have a retry so that we can do this so this kind of address validation stuff that Anne was talking about before token based it\u0027s pretty simple however we identified a whole bunch of issues around this so this in spoofing problems we\u0027ve talked about for a long time the format was you know looping 0rt to interactions and how you do coalescing so let\u0027s talk through this so the summary and talked about this supply sense an initial the server sense of retry it\u0027s got a token in it close puts that token in its next initial and we continue along with the pattern interesting point here is because the server chooses the connection idea that the client uses the connection ID from the retry packet is in the subsequent initial packets a property that was a little surprising as a result out of the of the stream zero design teamwork was that retry can be sent multiple times so there was a number of deployment scenarios where it was necessary to do this and so we can have a number of round trips going back and forth with initials and retries and initials and rate rise anyway you\u0027re not actually making any progress but you\u0027re just going back and forth I thought Colin Perkins are someone who hasn\u0027t been deeply involved what\u0027s more surprising is the initial can be sent more than once II in fact you can send initial under and under also conditions and it\u0027s crazy it\u0027s very confusing name I\u0027m sure we can paint that bike shed any color you like but that\u0027s not important okay so first issue "
  },
  {
    "startTime": "00:42:20",
    "text": "was that the format was complete mess in 13 at the top there is a little picture of the octet that we have in the in in the format in 13 but there was an observation that it is basically impossible to decrypt and decode one of these messages because of the way that the packet number is encrypted and of arbitrary length people have pointed out it\u0027s a bit of a problem we did this because we wanted to have some consistency consistency between the long header format and the short header format and we just missed the fact that we dropped some of this information into the wrong place also the point that retry apparently included a packet number which is apparently encrypted but we don\u0027t actually know how and so there\u0027s a proposal out there that\u0027s got a lot of positive feedback and we simply just reorder the the packet around and we don\u0027t include a Packer number in the retry message the consequence of that is that we can\u0027t coalesce retry with anything else but then we don\u0027t actually have any need to do that as far as I\u0027m aware so I wouldn\u0027t suggest we\u0027re not worried about doing that now is your opportunity to tell me that I\u0027m crazy and this is a bad idea because I haven\u0027t merged the pull request yet but I fully intend to because we got a backlog of things behind this change right salt and next so because we have this multiple retry packet interaction there\u0027s actually no reliable way at the client to distinguish a retry in response to their first initial or the second one and there\u0027s an interesting problem here if you retransmit your initial as you might have to do you can get multiple retries coming back and ultimately with varying delays on the networking and get retries from the initial mixed up with retries from the second initial and you don\u0027t know which one is which particularly when connection IDs aren\u0027t actually changed at the server end so the suggestion is that if the server doesn\u0027t intend to proceed with that with a handshake or it might not proceed with the handshake after this initial it has to provide a new connection ID there must be different to the one that it\u0027s received and it\u0027s got to be a certain size I mean this relatively straightforward just gin up another random number and shove it in there that\u0027s not particularly difficult for a server to do and there\u0027s no reason for it not to do that but this means that every single retry that you receive will have a unique value for this original destination connection ID that you see as a result you can identify which initial it is responding to guaranteed as opposed to maybe in the past and so "
  },
  {
    "startTime": "00:45:20",
    "text": "in the case where you have a packet that\u0027s retransmitted from the client that arrives after the client has sent another initial you can distinguish between the one that\u0027s just echoes from the past and the one that\u0027s actually a response to your your currently outstanding initial on this on this connection so that fix is also in that PR so we\u0027re moving on feel free to go if you if you disagree with anything here so spoofing it\u0027s relatively straightforward to spoof or retry if you see an initial basically all we have there is the randomized destination connection ID that\u0027s in the initial packet if the attacker can see that value then it can generate an retry there\u0027s no other proof from the server end that it\u0027s seen the packet there\u0027s no encryption on this there\u0027s nothing nothing fancy like that this can cause connection failures particularly if an attacker decides to spoof these things and they can successfully do so multiple the clients eventually going to say this server is sending me infinite retries I\u0027m going to give up and kazuo had identified an interesting one where you send a you can have the the attacker effectively spoof or retry and propose a different connection ID if they strip the token from the the subsequent message if they\u0027re able to strip the token from the subsequent message then because they\u0027re man-in-the-middle ultimately what the real server will see is something that looks like a real initial but it\u0027s actually got the attackers choice of connection ID in it not sure what you\u0027re going to do with that but that\u0027s just what it is johner on the previous slide if you could avi over here saying that the server infrastructure has to basically provide unique original destination connection IDs across all devices for this particular set of retrace no no so the destination connection idea that the clients ultimately can use is they the one that is randomly generated for itself or it\u0027s one that the server randomly generates for it and really the only requirement here is that the the values are unique across the this particular one this one particular exchange there\u0027s no there\u0027s no requirement for them to be globally unique or anything crazy like that of course they\u0027re really big random numbers chances are they\u0027re gonna be unique anyways so that\u0027s out of Quigley unique it\u0027s adequately unique yes yeah no is this one even if it\u0027s yes that that\u0027s that\u0027s fine with me I wouldn\u0027t even bother checking for collisions I just chin up a new random number and move on yeah that\u0027s that\u0027s probably the best "
  },
  {
    "startTime": "00:48:21",
    "text": "recommendation yeah thanks Kyle nekritz if we are allowing this kind of spoofing does this make retry part of the invariance it\u0027s none of the invariants we\u0027re promising but maybe it\u0027s one of those things that we were not actively clamping down on yeah so if you if you think about the way that we\u0027ve done invariance is that we\u0027ve made there\u0027s there\u0027s a wire image the quick version one has and that that wire image has a certain set of properties some of which were actually guaranteeing that will maintain across individual version two this is not one that we\u0027re going to make that promise for no it\u0027s not an invariant stuff it doesn\u0027t need to be the the the main reason we have invariance is so that we can maybe one day ship version two so if we if we\u0027re allowing anyone on the path to send a retry it may very easily become an invariant yes ossification is a real thing yeah yeah so I mean I\u0027m starting to think that we went off the rails when we decided that the the OD CID was the was the thing that proved that I was in the corner correlated the request the response um and we did that I think people were sad about scrape scraping pieces of the of the sonication tag but like you know this is a lot like mechanics here going on trying to like basically substitute the CID for a random challenge value and like we already have a random challenge but we already have a random value of the packet which is like the crap at the end which we already agreed is like a random value because we\u0027re using it all over the place or the crap after the end or whatever like I mean there\u0027s just like a lot of stuff here that like you could we could work with and I mean or for a matter you could use the you could use the ciphered PN from the form that was also now random right so I guess I\u0027m just late like making a lot of rules about I just like starting getting very sad about killers well with the CID when like actually we have other entropy in apakah we be exploiting and all weird which I use roundtrip so we discussed this on the issue and I know you you raised this point and for a couple of people having to remember the output of the encryption was difficult I appreciate that but I think this is lame so um you know I I guess my point is like I don\u0027t think I don\u0027t miss it if I think it\u0027s an argument yes yes and I know too I think that your argument is particularly convincing on that front either I think it\u0027s it\u0027s just it\u0027s it\u0027s a choice women well I mean I think you\u0027ve like we now like a bunch of like a bunch of the new complexity about how these generated this huge in terminal a non-terminal on then that\u0027d be much easier than do would be to like always if you\u0027re if you\u0027re a server which like quite you "
  },
  {
    "startTime": "00:51:21",
    "text": "want a shiny at all like generate no connection IDs um very neat bouncing around a lot it just like there\u0027s a lot of new additional complexity in the protocol to handle like this case which would be held on their ways so I\u0027m not sure that I agree with that assist okay well so a server that wants to do this every time they send a retry they send a randomized connection ID that\u0027s all they have to do there\u0027s there\u0027s no additional complexity on that front um I you\u0027re assuming that people know where their terminal terminal no even even the terminal one can know has a terminal warm what\u0027s an empty CID because it doesn\u0027t need it doesn\u0027t want waste space in the packet and so now you have to know that\u0027s apology that was an initial packet they\u0027re always gonna be the same size no no it doesn\u0027t want business in subsequent packets yes but the server gets to change the connection ID with the it\u0027s its initial that\u0027s the final determination of the connection ID this is only only for the for the subsequent initials that it\u0027s gonna fit yeah again this is just comedy weekly screwing crashing ID like that\u0027s you more bullshit like why don\u0027t we just say setup properly in the firt the first time the server responds okay and I guess like um like I\u0027m not sure where to go from here but like the I want to hear from someone else yes sir yeah I mean if you know the only one who thinks this is a problem then what so far you\u0027re the mean for cypher proposing this so I don\u0027t really think we\u0027re like you know this is what we got right this is what is gonna tell us about something else you know I mean I think it\u0027s sort of related to this but like basically right now we have this rule where you once you\u0027ve bound to the destination connection idea I assume the D 1 D 2 T 3 are different destination connection of these right so it\u0027s like once you\u0027re bound to the destination connection the server a server initial case you stick without connection area even if the server responds with retransmissions or different connection amenities or coalesced packets or different connection ladies I wonder why is why we made the different decision to do a retries are special and they\u0027re allowed to change the connection a T because if we bind to the original connection ID with retry then this wouldn\u0027t be a problem at all or mitigated at least so it\u0027s a you get one retry which decides your connection ID but you can do multiple retries and that\u0027s for the spoofing case so there was one reason we actually there\u0027s an explicit reason we allowed from multiple retries was was that you know had the hollow retry request a model of retry was actually subject to the same like a worse attack that if you could do only one other request because TLS enforces that on you and so of like two questions I guess no those are two questions one was that like why don\u0027t we just buy into "
  },
  {
    "startTime": "00:54:21",
    "text": "the connection ID at the first one and the second one was if you\u0027re gonna open new old issues that we\u0027ve already irrigated at some length I think we probably need a little bit bit more warning for that one and I\u0027d suggest taking that to the list okay because we have talked about that in sweat Google I I think this is this is fine and I think we discussed this at length as a proposal I don\u0027t have a particular objection to his approach in in practice because I do realize that this is only for initial packet so as long as it\u0027s I only have to repeat like eight or sixteen bytes saving whatever magic eater sixteen bytes of the initial is like a special case and I can just throw that into a buffer so I don\u0027t I don\u0027t really have a strong opinion I do understand Acker is kind of situation where you you\u0027re forced to change the connection ID so in our case I think we probably will never actually use multiple Rita\u0027s in our deployment at least I don\u0027t expect to in the near future so this is sort of like a non-issue from an operational perspective but aesthetically it\u0027s like I can get a little ugly hey I kind of agree so but I don\u0027t really have a strong opinion so but it\u0027d be fine it\u0027s not causing me any pain we\u0027ve got Tommy and Martin and then we\u0027ll get into the remote kill Tommy Polly Apple I agree very much with Ian that I can kind of live either way this is a little bit convoluted seeming just seems like a perfectly reasonable way of solve it Edgar\u0027s proposal also would be fine the point I wanted to make was that as I had I think I gave you feedback during the hackathon I think we need reworking of connection ID text in general and what would help a lot for this is if we just had a more clear section explaining the best practices around connection ID in the overall philosophy for it that would help because I think the disagreement I see here is kind of around what is this connection ID about when should we be generating them and if we have more of an introduction to that it may help come into this convolution a little bit more clearly yeah we\u0027ve heard that and the editors plan to do I think the requirement for that section even more yeah I think that that doesn\u0027t really engage with the the core question that I could echo was doing I mean we can explain better but ultimately the concern there is that we\u0027re offloading this in ways that it may be not ideal that isn\u0027t all miss you in the applicability document I mean we can discuss if it belongs here but whatever the applicability document says the the transport document has to be coherent on connection IDs and currently it\u0027s not ideal so we plan to fix that I\u0027m fine little person like please pick up I\u0027m fine with his proposal as well as with ekiz proposal what I\u0027m worried about is the spoofing so middle box "
  },
  {
    "startTime": "00:57:21",
    "text": "could advertise that it\u0027s a feature that is validation and thereby add around trip to every - every quick connection and there were a couple of proposals how to prevent that basically by putting stuff into the into the handshake to validate that no men in the middle did a retry and I think we should we should go with some of those solutions Nick banks is next yes little letter will be good though Nick you\u0027re breaking up pretty badly um can you take it to Jabbar and we can channel you from there can you hear me any better yeah turn your video off any better yes so being able to use the tag assumes you have easy access to it if you\u0027re using something like encryption offload the quick server that\u0027s are the quick client that would have to validate that wouldn\u0027t have access to that very easily so I\u0027m the CID is something that has a lot of direct easy access to and think think it\u0027s the best solution which you need the tag for PA don\u0027t you know Eric was rolling I mean you even seen you need to say for texture peony which is the same location as the tag crate well I mean if you offload all the encryption essentially the code it would just pass down the unencrypted value the hardware could do peony and payload encryption so it would have never had access to whatever that ad tag was the absolute about and later yeah that\u0027s true um it was putting out to me separately that this is actually a consequence of a decision not to encrypt we try and have we just encrypted retry we actually we are generic solution would work so I think but I\u0027m really sad if that is another generic solution for this that like doesn\u0027t souffle girl Ally custom screwing around so I agree my solution is informatica better um so we had one we prevented it okay riffing off of that the the retry that we have doesn\u0027t need to be version independent and if this is happening after version negotiation we could say that retry as a version version dependent and therefore encrypted frame it\u0027s already version dependent yes so we can do whatever we want with it that\u0027s that\u0027s not the problem we can decide to encrypt it but the but the conclusion of the the design team was "
  },
  {
    "startTime": "01:00:21",
    "text": "that they didn\u0027t want this encrypted specifically because that that was for that would make the implementation of the offload and and whatnot far more efficient yeah my understanding is that this was basically the the point was to be as close to the yeah to be able to do this cheaply when you have DDoS attacks so encryption would be considered a cost that they don\u0027t want to bear all right that was Mike Bishop and John Iyengar by the way so let\u0027s get back to the queue Martin Duke is next yeah I just meant that if the point attackers we finished rostov not sure what the actual savings are said you were spotted er yeah no I agree s not about saving that suspect I just think this is honest attack so I guess if if what I\u0027m hearing is like people buy a large or neutral and like there are some people who like think that you know that I\u0027m wrong so an interest of like getting forward okay all right thanks we have some talk about spoofing I think the suggestion that we validate the choice of connection IDs that we used in to start out with is probably a good one and will should we should look at doing that I\u0027ve heard this from a number of people now oh yeah this is that this was the proposal that I have so two options so we don\u0027t actually make any promises about successive handshakes or whatnot in the presence of an attacker that has the sort of capabilities that we\u0027re talking about right here so specifically we don\u0027t prevent attacks during the very first phases of the of the handshake from a tactic that can see the client hello it\u0027s is possible for an attacker to generate a server hello that a client will accept there won\u0027t necessarily ultimately result in a successful handshake but we\u0027re not doing anything special once once the attacker has men in the middle capabilities then we\u0027re not taking extraordinary steps to protect can you characterize with the attacker concerned about his circuses not the attack this is not masked attacker I thought you were concerned about so the the only the only attack that I\u0027m aware of here is that the attacker gets to choose the destination connection ID that is attached to the client initial packet that ultimately reaches the server sorry this is a off path or on path attacker it is a man on the side would be able to mount that attack yes okay so right so just just to "
  },
  {
    "startTime": "01:03:23",
    "text": "make sure we\u0027re all on the same page the that the premise of the previous slide I guess two slides I\u0027m sorry she surprised the previous law plus I\u0027m in a military requirement for that for that for the for the DC ID or that\u0027s the ID actually from that from the initial um obviate any minute obvious path attackers from the correct yep so so one of the things we agreed to do was was ensure that you had to be able to see the packets in order to do any of this we off path attackers don\u0027t get any leverage over this modulo the probability of them being able to guess one of these things pretty low so we have agreed previously that we would not do anything special in this case so [Music] maybe you do nothing just to make sure that people realize that way and the attacker with a ability to see initial packets and trades they can even attack you at very negotiation stage in fact even to a point of replying with with no such work and go away so that\u0027s even they can disrupt since even before client in New Zealand and so we ultimately concluded that until we have a shared key with someone that is authenticated attackers were these capabilities can do just about anything to disrupt that denying God I largely agree obviously that\u0027s that sentiment but I just know that this is a slightly different slightly different flavor of attack and then it\u0027s because it allows a man it allows a man in the middle to basically direct all traffic towards a particular server potentially because it\u0027s able to restrict the connection IDs so this is probably something that this is something that came up in the conversation and we also that we concluded that an attacker does not need to bother doing this in particular because if if they wanted to go and do that then what they would do was act would it would be far more efficient for them to us act as a client and simply set the same connection ID on every request that they sent to the server so I don\u0027t believe that to be a problem this is probably advice for the applicability / manageability documents that if you\u0027re running a server maybe you shouldn\u0027t be using the connection ID in the initial packets from a client to determine routing because because in that case you could have a very large population of clients you had send all their packets to you know the one poultry little instance sitting in the back end that suddenly gets overwhelmed and then they could do that you know that one and then they move on to the next one and kill that and so on so there\u0027s a there\u0027s an attack there so "
  },
  {
    "startTime": "01:06:24",
    "text": "there\u0027s that is more interesting actually yeah there\u0027s an interesting case where the four people might actually have more entropy than the connection ID yeah picking this particular attack but it\u0027s definitely worth documenting and I think in the security considerations and in the applicability yeah document as well so the the proposal here I think we probably wanted to separately discuss the idea that we might have Finnick eight the destination connection ID that\u0027s originally chosen but the proposal here was basically we\u0027re not going to do anything special but we would suggest that maybe clients that see an initial packet could use that even if they\u0027ve seen if even if they\u0027ve reacted to a retry just in case is supposed so I agree that there is no security concern about this because and oh I know but device could always forced the client use the same client ID and that effectively minutes the reason why we a yes encrypt us occasion because having a study came is that tell me no application at all right and so the point there is if you can force someone into using the same keys then you don\u0027t get to ship the next version of the protocol because every now now they\u0027re also fight around that particular key so it\u0027s an interesting point and probably motivates the the suggestion that one that I\u0027d like to come back to that idea later I think well we don\u0027t have time for that now and I haven\u0027t looked at that yeah okay so another thing is on the list of PRS that are about to be merged largely because I\u0027ve gotten a lot of good feedback on this is the what happens if you go to retry to what happens to you zero RTT and so the proposal here is well yes you can send zero artesian again and acres analogy there was well tcp fast open didn\u0027t work but you would still be able to until s0 ICT at that point it was a version there is that version negotiations fairly similar in this regard is unlikely to work in the sense that if you\u0027re changing quick versions it may not be the case that your zero RCT ticket is any good for whatever you do in the new version but there\u0027s nothing inherently prohibiting that the rationale for this was well we don\u0027t have any strong justification to say that you can\u0027t try zero RCT so we\u0027ll allow it there\u0027s catch it\u0027s unlikely that the keys that you\u0027re using to protect zero RTT packets will change as a result of having received a retry and effectively starting again and so there\u0027s a there\u0027s a requirement here in here that when you "
  },
  {
    "startTime": "01:09:24",
    "text": "get the retries and another initial starts anymore 0 while TT you don\u0027t reset the packer numbers back to zero because two time pads they\u0027re awesome and so that\u0027s the primary reason there was another reason I forget now what it was but the two time pad thing that was the primary concern here though you could technically we transmit the exact same packet that would be fine yes we generally advise my advice very tactically okay it would be technically okay and so there\u0027s the observation in the in in the PR also points out that there\u0027s a very good chance that the zero ICT Packers that you sent last time might be lost but what they might get then we don\u0027t know what servers gonna do so what\u0027s the berlanger yeah so I was about to bring that up but could could we actually say that if you get an retry packet then the server\u0027s officially said that I\u0027m not committing to State anymore that would be very convenient to say client should retransmit zero RTT data immediately very clear semantics in that regard the the advice of the the PR basically says yes you should expect to have to resend them but it doesn\u0027t say should because a client might decide not to continue with zero RT t at that point that\u0027s that\u0027s entirely up to them there\u0027s no interoperability cost of going either way on this I\u0027m necessary you can resend the same because connection are changes maybe it didn\u0027t change I don\u0027t know some service won\u0027t change it so but yeah good point so so I mean I joined the analogy TfL which I thought all the time is a good analogy I think it is harm in general but I mean we also make some noises about how this is conceptually a new connection and I wonder if the right noises are you should generate that you should ditch all the TLS tape they\u0027re a new client hello and and that would then you wouldn\u0027t have to screw him or the Packer numbers arms every German analogy right uses new connection that would be fine as well I think I I suspect that it doesn\u0027t matter no I just I don\u0027t remember like like I\u0027m glad somebody caught this this packet number reset issues good um and so like I just worry it\u0027s subtle right and so um I don\u0027t think it\u0027s a stir but it\u0027s like saying you could easily get wrong and you and it would only in a would not be it would like just like if you just screwed it up EP sorry right so um so let\u0027s say I mean like I would be taking a different different metaphor for this would be saying like this is a new condition metaphor as opposed thank you like you got a reset I can TCP resets every TFO but it would be a reasonable way to think about the world so yeah that\u0027s a good observation I think we could allow either one frankly yeah so Pat McManus so I think the raising the issue was really great because I had just allowed this in my code because you know it\u0027s not actually zero RTT anymore after the retry there\u0027s been a round trip and just intuitively this made no sense so it\u0027s good to clarify and I agree it can actually be done because it\u0027s you know "
  },
  {
    "startTime": "01:12:24",
    "text": "now call it one less RTT or something that\u0027s still still win and I like the with new packet number rule because that is consistent with the overall philosophy that one does not retransmits right yep yeah deviating from that seems seems bad so I so I would I would actually suggest that you can keep the same counters for all of the packet number spaces that would be the way to think about it right I think I think like having people resend initial with zero and then other things with like you know 52 that\u0027s not that\u0027s like not gonna be okay I mean I don\u0027t least gonna cross problems I mean it\u0027s gonna causing confidence um so um but um I think either we should either we should say ear we should go with like discussion that we send the initial with that with the next sequential packet number or we should go or or we should do like when I said I client hello but I think having gonna be alright that\u0027s good feedback yep Mike Bishop the other reason that we didn\u0027t reset them and something for server-side implementers to be aware of was that the if the 0tt packets were either buffered or delayed they can arrive after your new initial or be processed after your new initial and they are still valid for the connection so you\u0027d better not change the data that send them all right Thanks so uh yeah same thing so different angle on the same question if you get a zero ICT packet you haven\u0027t seen an initial what do you do with it currently we we have a write up that basically says if you get a zero ICT packet you must not generate a retry in response to it you\u0027re only allowed to send a retro and response for initial so the support for doing this is pretty weak there\u0027s not really too many reasons in either direction for this one but basically rather than shrug our shoulders on this one we\u0027ll say should not for this one or May or something along those lines basically because there\u0027s no reason not to do this sort of thing and it may in some cases improve performance if a server receives a zero ICT packet and wants to keep things moving along it can do address validation immediately rather than then wait for the possibly lost initial pattern that the client sent because that can take time far too much time no problems for that that\u0027s that talk all done thank you okay Thank You Martin please stay there stay inside the pink box pretty much yeah next up is managing keys yeah yep that one you know "
  },
  {
    "startTime": "01:15:28",
    "text": "discarding and rekey saris near for name so this is another one that I think\u0027s relatively urgent although not hugely important we\u0027ve had a lot of discussion about how to manage keys one of the nice things about the the updated design is that it\u0027s pretty crisp about when keys are used and what what packets are protected with what keys and what cryptographic handshake messages are protected with which keys but we have this sort of fuzzy bit when it comes to getting rid of those keys so here\u0027s my summary of the handshake there\u0027s a lot of messages going back and forth you\u0027ll notice that there\u0027s a lot of coalescence potentially involved in this but one of the things that you will observe is that the that there are initial packets being exchanged for some time but at some point you stop having a need to maintain those keys what do you do with that well initial is pretty straightforward not a lot of no I mean not exactly secrets we\u0027re maintaining here but still be nice to know when you can clean that stuff up same applies to the handshake keys so you\u0027ve got handshake messages initially starting from when the server sends its first flight of messages and ultimately ending when the server sends its acknowledgment of the clients handshake messages and maybe at that point you can get rid of those keys except for the fact that we have this tile problem on on these things we never really know whether this the halting problem in the sense that you never really know that the handshake is done and the other side is done with that the handshake because so the simple solution for this is to treat each packet number spaced separately and you say that the packet number space is done when the read and write keys for that packet number space read and write keys for the next space are ready so for handshake keys when you have your one RCT keys and you\u0027re using them then you\u0027re done with the handshake keys and there\u0027s a little bit of a little bit of nuance to that because of the arrangement of the handshake but at that point you can just set a timer and so you set a timer at that point and that runs for I don\u0027t know a couple of RT owes a couple of round trips it doesn\u0027t really matter it could be a pretty long time in fact we\u0027ve sort of established because of the way that the tellers keys separation works that you potentially just keep the keys forever it\u0027s just an overhead its memory they\u0027re not actually a threat to anything at that point but still you set a timer and during the time that you\u0027re maintaining that key you\u0027ll be able to receive "
  },
  {
    "startTime": "01:18:29",
    "text": "acknowledgments resend crypto frames as necessary and send it knowledge modes and so that seems pretty reasonable once you\u0027ve gotten rid of the keys obviously the packets that you receive that might have been encrypted under those keys will be done unintelligible and you\u0027ll just be forced to drop them and that\u0027s probably okay so the way to think about that is is you look at each packet number space and there\u0027s also some consideration here for serial ITT but I\u0027ve got the two kind of critical ones here so at the point that the client receives the server hello and at the point that the server sends the server hello they\u0027re basically finished sending crypto frames to each other and that\u0027s the point where they set a timer and at the point they set the timer they can set that timer for a number of round trips and we\u0027re just maintaining that time first long as we\u0027re willing to effectively continue acknowledging things essentially or or repairing the cryptographic handshakes day the same applies I mean that direction of messages is different but the same basic procedure applies for handshake messages you just when you see the last one right to set the timer so there\u0027s been discussion of a sort of implicit acknowledgement system for for all of this you can use the fact that you\u0027ve moved on to the next phase of keys just sort of as a signal that says that the other side has all of the crypto frames from the previous iteration so if you get a handshake packet pretty sure that all of the crypto frames in initial packets drop to their destinations because you can\u0027t derive those keys without actually having access to those messages similarly if the server receives one RTT packets from a client that means that the client has received all of the crypto frames that the server ever might want to see sent it\u0027s a little more tricky on the client end for one ICT that packets because the server sends then before the clients really done or it could at least and so the client actually has to look for acknowledgments of its one RCT packets to signal that and in that case you can stop sending the crypto frames now of course what will happen is that there\u0027s the potential for acts to be lost and you\u0027ll have acknowledgments in flight and you might potentially want to do some more acknowledging at that point but you can actually safely drop the act frames if the other side agrees that this is acceptable there\u0027s a couple of corner cases in this and I don\u0027t think we need to worry about that someone\u0027s gonna jump up and tell me that\u0027s wrong but that\u0027s I I\u0027m not planning to document that optimization by the way I think people who want to embark upon these sorts of "
  },
  {
    "startTime": "01:21:30",
    "text": "optimizations will have to think through the consequences of all of this and be absolutely certain they\u0027re not going to break the other side there are there are models that you can use for this that require that the other side is aware of what you\u0027re doing because what will happen is it will think that it needs to retransmit crypto frames and you don\u0027t need them it doesn\u0027t need them but it\u0027s resending them and expecting acknowledgments and if you\u0027re dropping those packets on the floor you could end up with crypto frames being sent for a considerable amount of time after the handshake is well done and it\u0027s just wasteful at that point so there\u0027s a little bit of care required in order to get this logic right I\u0027m not gonna write that down because it\u0027s too damn hard a number of people have suggested that it would be nice to have a signal that the the handshake is done that is a positive signal once you get the one RTT keys from maybe from each side but I\u0027m thinking probably from the server although I\u0027ve shown it in both directions here that basically says I\u0027m done with a handshake I have everything I need in order to proceed with this connection and once you\u0027ve received that message you can stop sending any packets on the previous back a number spaces you just throw everything away at the point that you received that that message in I was gonna come and I\u0027m the zero to tikis I I think you could probably drop those at the same time safely because you\u0027re sending Zarate in the first flight and by the time the handshake done would be sent that would be in the clients second flight so you\u0027d still allow for a full RTC of reordering of 0tt packets that seem right and so this is that\u0027s an interesting observation it\u0027s yes it doesn\u0027t perfectly solve the problem but at the point that you\u0027re an entire round trip after the zero ITT Keys have been done it\u0027s not quite that good I don\u0027t think because the the handshake done is sent in close proximity of the last of the zero RCT messages so I don\u0027t think it\u0027s as good as you think it is the client-server right this is this is in the direction of this server so the server when it receives handshake done will receive that handshake done basically sometimes I imagine in the same packet isn\u0027t as 0tt now I think it\u0027s a fault RTD you later round it\u0027s not it\u0027s not because in order live streaming of the 0tt data the client continues saying CRT TV until it\u0027s process until it\u0027s process the entire server first flight and so basically they\u0027ll last like like essentially like last circuit a packet is like you know I say is like sent like you know milliseconds before like the see fit yeah yeah um so I mean now you\u0027re like Tyrone I mean now you even do it you\u0027ll have me all it\u0027s gonna happen is you\u0027re gonna like you know they all hakuna and "
  },
  {
    "startTime": "01:24:31",
    "text": "the data but like you want a time or a bit I mean a smarter pollination one a timer over the Hat yep back in them back in the soup so this is my proposal document that you might want to clean up the keys suggest that you might want to use a timer for that purpose and leave the rest of the optimizations for those people who want to have fun debugging thorny key management issues I don\u0027t care so micro I will point out one other other open issues is now that we have an extension framework we\u0027re looking for a poster child extension to exercise it and check done would be a fine extension I don\u0027t think it would be but I mean if you want to use that as a safety valve and for anyone who wants it nothing stopping you from proposing it I guess I\u0027m David\u0027s Ganassi Apple just want to say that I really really agree with this mentality there are already too many things in the spec that like sound a little bit too smart sometimes and as an implementer first reader you go away what is going on so if people want to go crazy and optimize something and maybe documenting on site that\u0027s fine but keep it out of the main spec people who prefer having panchik down could implement the same facility using ping frames so I don\u0027t think that we need a special frame project right that\u0027s the optimization that I did I outlined essentially suppose I know I agree with this as well in the previous iteration before the stream zero proposal there was be more dangerous to this but now that separate act spaces and separate packet number spaces it\u0027s like much cleaner and much safer to do this error control I also grew this on the one thing I would say is that the text doesn\u0027t state when it is safe to do this and yes I say it has to say like the last time but that in the sequence the last packet which you will get with this is here I\u0027m happy to assist for that text yep that\u0027d be that\u0027d be great yep yeah your proposal is that we don\u0027t actually say do you want us do you want would you like that to have like here is a set of timer rules which you could follow or just you may wish use a timer and this is when you this is this is the time you should be setting the timer if you were to set it yeah and basically acknowledging that once you\u0027ve hit this point then it\u0027s all about retransmissions and acknowledgments and you say the timer based on how long you\u0027re willing to spend retransmitting things and acknowledging them but I always can drive it even the simpler "
  },
  {
    "startTime": "01:27:32",
    "text": "version of that I mean if infinite is okay we might just need some essentially non-normative text that acknowledges you know if there is some point at which this happens and you know you may or may not make use of that fact I wouldn\u0027t I don\u0027t think we need to set timer values in particular I\u0027m not gonna suggest a specific value no no that\u0027s that dick so thank you great stay there I\u0027m stuck in this pink box and have dreams about that next up is stateless reset oh yeah yeah we have those done we\u0027re time it\u0027s on yeah so this is one that will never die oh that\u0027s right all right so Mikkel made an interesting observation turns out stateless read reset is by design indistinguishable from a quick packet you can\u0027t decrypt it no one can decrypt it that\u0027s kind of the point but it\u0027s also the case that you send stateless reset when you receive a packet that you can\u0027t decrypt and both Clinton\u0027s server can do this it doesn\u0027t actually take to quiet their client on the server to produce this problem because you can certainly point to service it and each other if you really wanted to do that so that\u0027s a little bit of a problem it looks like this [Music] there\u0027s no amplification so if a packet gets lost it eventually ends but I hear that some people are operating networks that don\u0027t drop packets that often nowadays and I\u0027m not sure that I want this problem so we\u0027ve discussed a couple of simple solutions and there it\u0027s not really that dire a problem when you think about it this way and it turns out stateless reset is pretty small its variable length for various reasons but it\u0027s pretty small and so it\u0027ll be smaller than most packets that you\u0027re gonna receive certainly most packet sort of receive that you don\u0027t don\u0027t know obviously there\u0027s already rules in there that if the packets too small to plausibly be a quick packet just going to drop it on the floor anyway so maybe we can be guys send it if it\u0027s smaller than the packet that was received if it isn\u0027t correct thank you I should proofread I\u0027m learning that my "
  },
  {
    "startTime": "01:30:32",
    "text": "perforating skills are you know double negative only send it if it is smaller than the packet that was received thank you Mark there\u0027s also a slightly more complex solution that says well maybe it\u0027s nice if you send a stateless reset in response to these packets because if someone is say doing that\u0027s for instance telnet and the first path and the first backup that I sent after a long idle period is control-c it\u0027s a single character and that\u0027s going to be a small packet and your connection ID is small there\u0027s a pretty good chance that you will have this packet be relatively small coming in and wouldn\u0027t it be nice if maybe there had at least some chance of being able to benefit from the salaat the Malaysian that we have that will kill the connection off and so you have some sort of proper built probabilistic dropping and as long as their probability is not not zero I\u0027m dropping it then everything should ultimately resolve yeah you\u0027ll get a couple of legs on that on the you know a couple of bounces in the in the sort of perverse scenario where both sides have lost state and have decided to stateless Lee reset each other but it\u0027ll ultimately resolve itself and so I think that\u0027s a reasonable solution and that\u0027s all I\u0027ve got on this deck did anyone have any questions or suggestions or disagreements I wanted to get this in front of people who\u0027ve got a little experience with this one just one my name\u0027s Tim Shepherd it\u0027s just one simple observation that there are networks that rarely drop packets but there are also networks that occasionally duplicate packets and some of those might duplicate packets somewhat more often even though it\u0027s rare somewhat more often than they drop packets in which case you have to choose a and B I mean a little more care is required is just what you\u0027re suggesting sure I don\u0027t know what the answer to this is it\u0027s just a thought I had I thought I should that\u0027s a good question since we have so many people in the room who might actually know things about this does anyone have any idea what the duplication probability would be in those networks relative to the drop probability because we could at least provide some general uninsurance there there are a lot of weird networks out there there may not be the norm of the internet but I couldn\u0027t possibly tell you what they are numbers are for every weird network that exists up yeah so weird is the norm so I guess we\u0027ll have to make some allowance for that let\u0027s hear from non editors for a second Cory why don\u0027t you go ahead so Cory Perez I mean there are networks that I should drop package due to a QM and other things etc and there are pet works that duplicate packets for odd things so it\u0027s questions do you want to work everywhere in the internet or do you "
  },
  {
    "startTime": "01:33:32",
    "text": "want to work on just one part so it\u0027s a trade off for you numbers won\u0027t help you I\u0027m afraid because there\u0027s always gonna be this tail end of stuff that is really weird yeah well if the drop probabilities is high enough do you think what I said I hope that yeah maybe maybe we get you to look at it and and say with you whether or not you believe that this is a problem sure explanation the way I understand it more to it and I\u0027ll try and help and the courses can be robust to this not optimal yes yeah that\u0027s really what we\u0027re looking for yeah are you jabber channeling David one sure go ahead Thanks there\u0027s kanasu jabber relaying so to people Praveen blossom Runyan wanted to say that randomization makes it very hard for debug ability let\u0027s keep things predictable and Mike Bishop was saying that acts are another oh yeah well it proved een asked me to relay you anyway I\u0027m gonna continue to ask the editors to let others cycle through and we\u0027ll let you guys have maybe the last word Eric Eric Nygren I think the a key thing is making sure that whatever we have is very deterministic that this ends fast because even if they\u0027re the same size of an attacker can induce this Pinconning by by injecting something that two end points start ping pong game back and forth it doesn\u0027t matter that that the size that their small packets not increasing in size it\u0027s that ping pong itself they just keep injecting things these drugs are having a growing set of stuff ping pong NC not the proposal here was not if though if they did not decrease in size you would drop them so it would always be strictly smaller right and I guess that may be worth thinking through are there any cases where you can trick things and in ways of various format might make it look to two endpoints that they\u0027re different so for example if there is some if there\u0027s some encapsulation or translator in between that is going and adding a little bit of stuff on to them so that between those two end points you get something with it that violates that property so maybe we\u0027re thinking of of is it worth having something more explicit here that really guarantees that that it that it terminates or the determinates fast okay over here next Tommy so I\u0027m not sure if this will help by wondering if there\u0027s another tool in the toolbox of things we can do to help here I understand that the set this preset is stateless but can an endpoint carry some decaying State of the number of resets that it has been sending and essentially just have some plausibility like you could very easily say that if within the past ten seconds I have sent a ridiculous number of research I\u0027ve detected that there\u0027s something pong and just stop doing it "
  },
  {
    "startTime": "01:36:32",
    "text": "for an hour just back off and actually have that drop rate be relative to the amount that you recognize ping ponging possibilities we do actually okay something along those lines yeah okay come on next okay so Jonathan axe I mean that my first point is does it actually have to be that the condition is that it\u0027s the packet is you know you know small or equal to say recenter could it just be if it\u0027s exactly the size of a say let\u0027s reset it\u0027s obviously something smaller can\u0027t be causing the ping-pong either so they\u0027re variable sized they are variable sized yeah all right and the other point is I was gonna say is in the case we were describing of the you know they tell that I mean so I mean even if your probability is quite high like 50 percent you\u0027re still going to almost certainly get us a let\u0027s reset within three or four RTT so yeah I think I think it\u0027s probability if you want to do probabilistically I think you can safely be quite high to cause a very fast decay and in most preset cases you\u0027ll get recovery within two or three graduate retransmissions yeah that was my that was my entry intuition as well I have four points first point is let\u0027s remember say is an optimization it is not like it is a nice optimization but it\u0027s not the position the second point is you must do something bookkeeping anyway if how many say this recess you sent because otherwise you end up like sending our crap close save this resets like for like the enormous fault of packets that are coming in and I believe three locations I think it\u0027s gonna say do this any right so um so so like says justice and bookkeeping anyone any suggestion is eminently reasonable um third points can you go to this slide this that this really seemed this really seemed like it might be okay because if you\u0027re only getting really small packets you know I\u0027m like that much in flow and any real any real application that like a replication refine shutdown is gonna send you big packets and so I just give it going back to principle one or principle 0 depending on what kind of computer scientist you are that seems like they probably be just fine um and my first point is I I concur with I think Nick\u0027s point about randomization random being bad and in that but in that um in in in that vein it\u0027s possible the turistic algorithm where you part by you hash the incoming packet and then they blah blah we\u0027re gonna close the Q\u0027s John if you want to get in get in now okay go ahead yes I was gonna basically say what I Korea said BER me which is we use something we call a time waitlist and do exponential back-off for first a lisp reset to try to avoid situations like this the other is on packet duplication we have seen this before in real networks it basically never happens unless it happens all the time so you have like one broken switch that just basically sends every single packet everyone yeah something like that so it\u0027s it\u0027s like a very bimodal thing we\u0027re like everything\u0027s fine into like all of your servers are ddossing each "
  },
  {
    "startTime": "01:39:32",
    "text": "other and then we also had to solve this exact problem for client initial a long time back because it wasn\u0027t the keys weren\u0027t asymmetric or there was no way to tell the difference between a server initial area one and in that case we actually decremented the TTL so we would like make sure the TTL decreased as the client initial went back and forth and I wanted to add that that\u0027s one potential mitigation is you can copy the TTL in and that does ensure that there\u0027s no infinitely I don\u0027t know if that leads to much input information but it\u0027s a very simple solution and it totally works so I was hi friend Trammell I was basically gonna come up there come up here to say what he had just said um there\u0027s another thing that you could do so I really like the simple solution there\u0027s another thing that you could do this simple solution by tweaking the size of the stateless reset and saying that the state like not just saying don\u0027t send it if it\u0027s smaller in the packet was received but say that the stateless reset must always be packet size it at most pocket-sized minus something and then you essentially the TTL itself is encoded in the packet size if you can that requires probably a little bit more rethinking of how stateless reset works but um what wait what are this what are the packets they\u0027re smaller than stateless reset the the problem here is that the this reset has to be large enough to be plausible alright yeah and you don\u0027t know how large the other side has set its connection ID to be oh okay the largest possible connection idea the other side could have which means they end up being something any order for the octet thirties were doctors okay so my ideas ox and onions ideas awesome do that Manistee they will enter so they\u0027re you know if we compare this behavior to TCP with TCP we see there are some state machines that are triggered a connection termination so and they are primarily you know at least some of them are around we switch offload terminating tunnels you know removing state in the software based on the termination of a connection so it would be definitely good to have this deterministic because otherwise it leads the software to basically go through a huge number of slows and in concept it\u0027s simple but the scale is quite quite huge so it\u0027s it\u0027s not very easy to say like just run a timer and delete things that have or expire flows so that\u0027s my feedback here I would prefer it to be deterministic so I\u0027m for a long time a significant part of me has held the thought that stateless reset is something we should jettison altogether because we have a nice beautifully authenticated protocol and you know allowing someone that\u0027s clearly not participating in that chain fluence your behavior just feels wrong "
  },
  {
    "startTime": "01:42:32",
    "text": "I\u0027ve been convinced that operationally like you you can\u0027t work around this at some point but I think that does argue for the simplest possible solution here the probabilistic things you know make me it\u0027s a lot of machinery for something that for a party that\u0027s not really participating in the protocol and that\u0027s concerning right and Jen I ain\u0027t got this to me does bring back the question of do we really need this to be symmetric that\u0027s symmetry doesn\u0027t help us here no point to serve it as service of each other with this all right suppose we have that from yes sorry you\u0027re right you know yeah all right so I like I like the suggestion of the TTL that may not be accessible to a number of people but it\u0027s it\u0027s certainly something we could we could strongly recommend particularly in this sort of too small case and we\u0027re talking about the IP DDL right IP TT oh yeah yeah and so so then then your acting is effectively it\u0027ll just keep driving itself down to zero and eventually work it through right thank you that\u0027s all I\u0027m thank you you may leave the pink box so next up we we\u0027ve got three more issue presentations on mic if you can make your way up the connection ID then HTP then recovery I\u0027d like to finish these three up in the next 25 minutes if we can so connection IDs okay so we\u0027ve had connection at ease and quick for a while they\u0027re very useful for helping a connection survive changes to the four tuple and I think we\u0027ve all had these all right good I think we\u0027ve all had a lot of intuition about how we think they ought to work and it turns out that trying to specify that gets kind of hairy so where we started out in pre and pre peony land was that each connection ID was in sequence had a specified packet number gap to help avoid having a packet number of give you likability and then they have a stateless reset token problem with that is you get head of line blocking because if you miss one of them you can\u0027t use anything further down the list because you have to know the cumulative packet number of gaps and once we had probing and connection migration it gets really weird trying to sort out while I use this other kin "
  },
  {
    "startTime": "01:45:32",
    "text": "with the packet number gap on the other path but what do I do here on the main path where I haven\u0027t changed connection ideas so once we had packet number encryption we said great we can get rid of all of that and packet numbers are just this class not packet number so our connection ideas are this cloud of things that we\u0027ve received when we can use any of them all right we can use any of them anytime we want head of line blocking isn\u0027t an issue great this is simple but to break link ability if your peer changes then you also need to change and exactly how do you figure out that the peers change was in response to your change and not the peer changing at the same time so you need to change and I started trying to write down the rule of how you would figure that out and I couldn\u0027t and if somebody implemented it and actually did figure out a rule that would be nice but what we came up with was we actually do need that sequence number so it\u0027s not entirely clear to me that when you\u0027re pure changes CID you need to change so any pair might changes Yeti for fun um that I mean well you do to change your CID the time you change your CID is when a path has changed and so the question is is that P is the pure changing CID the only see only how the path has changed it\u0027s not clear to me that\u0027s true so the spec recommends that you change your connection ID when you think there might be in that rebonding like you\u0027ve been quite quiescent for a while sure and if you want to any kind of unlink ability across those if you\u0027re pure just responds with the connection ID you were using to you\u0027re new to your new point of connection no I understand the point but why bother saying is that so you have you have a behind in that and B not behind that and any thinks he might\u0027ve had a not rebinding and so he uses in his CID but B knows he didn\u0027t have in that refining and so B knows that B knows that B knows that the path changed and so-and-so be responsive I mean so so in that case you don\u0027t have to change your CID so it may be the case that the only way to detect this they could be conservative but like but like I\u0027m not yet persuaded that it\u0027s not possible to turn where the path has changed without like using the CID as a trigger are you are you using and B as two different clients or I\u0027m saying they\u0027re they\u0027re they\u0027re Pierce so if he knows that he knows that IP didn\u0027t change cuz it like couldn\u0027t see the incoming packets so I believe we\u0027re being conservative and we\u0027re also in this case when a changes their connection ID they might want to appear to be see so that the folks on the network might think that there\u0027s other people behind that "
  },
  {
    "startTime": "01:48:32",
    "text": "net Forest and I I appreciate about what but what I\u0027m saying is that if you if you receive a new key if you receive a new connection ID from someone whose dress has not changed then it\u0027s not clear to me that you actually have to change your own connection ID and so like that that could see that Mikey you add this lock step I lost that condition i I think we chose the lock step condition because it was convenient for other reasons that\u0027s all okay but I get I guess but we\u0027re talking about has inconvenient so I\u0027m like you know that\u0027s one I guess I guess I like like this is her like I guess I\u0027m trying to figure out like how much this is a historical talk and how much this is like a motivation for pretty good design if it\u0027s a historical clock I\u0027ll sit down and shut up but if this is like driving us towards like some particular design like as our eyes as a motivation then I\u0027m not gonna shut up fuckin visits right way decal so this piece this section of it is historical of how we got to what\u0027s in draft 13 okay but it is new and draft 13 and if you think it was a mistake we could revert it and take a different truck well I mean it\u0027s like well I\u0027m seeing like I see you back to add some epicycles and so like like that\u0027s why I\u0027m asking like before we throw example cycles like whether we should be like going back to that principles so I guess like so one thing it\u0027s like I mean like curly design half of my head which means apply is wrong like like like why can\u0027t you just straight the rule to update like you only update when you believe that heroes it has sent you a new to transport parameters sorry new transport address than the one you\u0027re currently receiving the CID on Sojin I and God I don\u0027t know that you need to you could be very easily assumed that all of these are associated with path changes right and I think the the problems or whatever you\u0027re going to say is still going to hold true like each of these events whenever the connection area is changing if you assume that the path is also the network is also changing that\u0027s final assumption if you need to make that assumption notice the text in the document right now requires the pier to change the connection ID every time it sees a connection any change no I know that\u0027s but that\u0027s but the reason you\u0027re carrying to infinity is because everybody\u0027s ping pong ping pong in the pink point in the the it\u0027s changes right and so if you like if he what I\u0027m saying is it\u0027s like imagine the case where like the dresser completely stable right and one side changes because as mike says he thinks he may have had an hour he\u0027s been offline for 45 seconds he might have an hour binding event on and so it sends it but he hasn\u0027t changed then then if the other side doesn\u0027t respond with a change that you won\u0027t come to infinity and if you have changed and you and if you have changed and you do send it then like I think you can put that from the from the you know from the from the initiators her from the a spur stretches behind the NAT when he receives the second CID like he doesn\u0027t have to change again because other guys guys room I said dress hasn\u0027t changed so so so that\u0027s a bit just let\u0027s stop let\u0027s let Mike get through his presentation and then have our discussion so I think that is a an "
  },
  {
    "startTime": "01:51:32",
    "text": "interesting suggestion let me talk about the other issues that we have with this model and it may be that going to that would solve more than them more of them and that\u0027s one of the solutions that can be on the table so there are some advantages to having a sequence number so that\u0027s what we have in draft 13 which says that there is a sequence for each connection ID that gets issued by your peer and that makes the behavior pretty easy to specify if you are starting a new path then you have to use a higher sequence number than you have ever used before for this connection and on each path you will never send a packet where the connection is a sequence number is less than the highest you\u0027ve ever Center received so that forces the ratcheting behavior on a per path basis so to give you a quick example I\u0027m using a B a B and C so you can keep track of the sequence numbers multiple paths are hard to draw so forgive my bad drawings so we have a connection both sides are using connection ID a which is a different value in each direction and also they\u0027re doing some probes on a side path to get ready for a potential migration they use B for that the fact that you probed doesn\u0027t change that you\u0027re using a on the main path and if on the main path you change to see the other side moves to see that doesn\u0027t change the other path you can stay on B if the other side tries to roll forward again to D but for some reason you don\u0027t have D you just go to the next one that you do have and then the Pierre has to match you so that way you only have consistent rules for how you move through the connection IDs that have been issued so that simplifies a lot of the specifying what you do win but there are some problems with that let\u0027s say you\u0027re using a on the main path and you have lots of other paths you want to probe so I\u0027ll use B C and D because I just got those from the Pierre but they all get dropped because those paths don\u0027t work now one side says I have no spare C ideas the other side says I don\u0027t need to give him anymore he\u0027s got three outstanding so you send any mode indeed so it\u0027s possible to become unclear whether appear has actually used the connection ideas that you\u0027ve issued him and we need more that\u0027s one problem that we still need to solve in this model also if the only packet that you ever sent that a given connection ID gets dropped and eventually you forget about it but "
  },
  {
    "startTime": "01:54:34",
    "text": "it\u0027s not actually dropped it\u0027s just severely delayed that can trigger a stateless reset so they\u0027re actually so there also needs to be some kind of coordination between the peers when they\u0027re no longer going to consider a particular connection ID to be associated with this connection or you get into some weird states a common easier place for this to happen would be let\u0027s say you use that to probe on a side path and one side considers the path to have been abandoned because you haven\u0027t probed it in two minutes but the other side says well I just haven\u0027t sent a probe lately but that\u0027s still a path that I have available and I know it\u0027s validated so if you have a long lift connection and you\u0027re rotating connection at ease frequently it\u0027s not practical to remember all the connection ideas you have ever used particularly if the peer can force you to move to new connection IDs that\u0027s also especially true if the all the connection ideas have to be plumbed into the load balancer so that they get routed to you but if you can\u0027t coordinate when it\u0027s safe to forget a connection ID and remove it from state then you can trigger a trigger stateless resets and there are cases when you might actually want to expire a whole swath of Si IDs for example let\u0027s say it\u0027s encrypted you\u0027re doing Q rotation you\u0027re about to rotate again you have to make sure that everything that was done with not just the previous key phase but the key phase before that will never ever ever be seen again for the life of this connection so if there\u0027s a PR right now for two more frames that say hey I need more C IDs and hey I\u0027d like to get rid of these C IDs there is another proposal for how you get rid of connection ideas which is to say that there\u0027s a certain number outstanding at a time and you can just Auto expire based on how many new ones you\u0027ve gotten I think that we\u0027d have to work through that carefully because again there\u0027s confusion about which the ideas doesn\u0027t appear actually have and agree not to use but that\u0027s also a possibility so then this is a proposal that I think we need to sort out I think this is true even if we don\u0027t force the pier to advance and lockstep so I\u0027d like to know how we solve it in that world if we if you want to go there Jen eyeing that I don\u0027t think that at a connection ID works reordering that was reordering which can cause race conditions like so could send a stateless reset and then some the data a connection ID of the data connection ID sent drop in the network retransmitted but before that "
  },
  {
    "startTime": "01:57:35",
    "text": "the stateless reset is sent all kinds of things the way this is in the PR is that the the client will stop using a particular connection ID once it receives the phone and the server will forget it once it receives the acknowledgement of that frame so you won\u0027t get a stateless reset until you\u0027ve act now if it\u0027s reordered across the Sun okay so the client sent it before before the retire CID frame arrived but then the server receives it after the ACK is what you\u0027re saying yes so oh no actually the solution to that is when the client removes the CID it also removes the stateless reset token so it won\u0027t recognize that stateless reset as belonging to this connection anymore all right go ahead mark yeah so nan Thomson I\u0027m not a huge fan of this and I know I proposed an alternative design I think that ultimately was kazuo suggestion originally which was that endpoints would advertise a an absolute number of connection IDs that they are willing to to remember and that number would be the sum of the ones that they would be willing to remember posture those that might be in flight and that would work I think much more simply than what you have and the only thing you would then need is because we have this reciprocation requirement you would require if if I sent you a connection ID with an ID of 10 you would have to make sure that you sent me all the connection eyes these up to 10 in response and then it says I think that that\u0027d be a simpler design I agree that it feels simpler I I would need to work through it I think some of these problems about getting confused of who has actually sent what will make the peers not agree about what this current set is but there may around that so I don\u0027t think they have to agree actually but not not entirely but the only thing that\u0027s important there is to remember that if you support 10 if you say that you support 10 different connection IDs you have to count the ones that you sent but not how to acknowledge yet in in that set otherwise that yeah you have to assume that the other sorry you have to assume that the other side remembers 10 plus the ones you haven\u0027t had acknowledged yet this is "
  },
  {
    "startTime": "02:00:35",
    "text": "pretty complicated and made my hair fall out let me for that yeah first of all I think like given that we have another proposals here or I think like trying to merge this at this moment is going to be very problematic I my am um and frankly I\u0027m trying to think we need like a Tamron model this like figure out like whether or not it\u0027s gonna break because I\u0027m having a lot more reasoning about it um which I mean what really worries me cuz like these things like like my sprucing things is like we spend a lot of time building things and then like about two weeks later because you ho sent some email saying like this is totally screwed up because of this use case or and like I like Marshall I appreciate that service I think we could we can work that I worry about having the rival and I put a call predicated and kazoo hopping a brainstorm so um the with that said I think this would be the first time we declared the semantics of some place to the protocol dependent on receiving in knowledge Minh from the pure and that makes me kind of sad um like I normally think of like packets going into some bucket or they just like gradually migrate to their side and then like you know ideology mints remove things from the bucket and so having that fed back upward to me so I have to like do some other action like scares me so um I think to be the first time we\u0027ve done it if it\u0027s not which if it isn\u0027t we should take those things out and and if it is we probably shouldn\u0027t start I think isn\u0027t but we have and we have previously taken out the other instances it doesn\u0027t sound like we\u0027re gonna conclude this today so I\u0027m going to cut the queues go ahead dude skin Ozzie Apple all at a co-worker\u0027s point about this being pretty complicated and starting to lose hair also most clients and my understanding correct me if I\u0027m wrong will probably be sending c.length connection ID so we\u0027re sounds like we\u0027re building a lot of complexity that won\u0027t necessarily be used just something to consider please keep it simple human tornado so questions that\u0027s come up is could this be simplified a little bit by not requiring the need just with retire when you action of retiring my trigger computer send the Union ones up to X or whatever yeah I think that\u0027s another flavor of you have a certain number that are outstanding right the other way of doing it is the action of issuing new ones retires old ones Atlee but either way and also the pier has to match them for the to issue yeah although you did I think you did justify why we\u0027re trying specifically some would take care of the delayed it would be more explicit you had one more slide might be needed I can I propose a way of moving forward if you can do it succinctly yes yeah I think we I was thinking the same thing yeah and then perhaps get it together "
  },
  {
    "startTime": "02:03:36",
    "text": "and talk about it in New York is that a reasonable timeframe okay show of hands who\u0027s interested in participating on such a thing the usual suspects okay Mike do you want to take charge of collecting those folks together sure okay great so if you\u0027re interested in helping out with that design team talk to Mike and we\u0027ll expect to hear back before New York okay and then the last slide is just to say that in addition to the things that could actually cause your connection to break there are also some annoyances involved in this the spec currently says the CID from the handshake has a sequence number of negative one some people don\u0027t like negative numbers the surface preferred address also gives you connection ID and it doesn\u0027t actually say what\u0027s number that is and the client the handshake connection ID doesn\u0027t have a state list reset token for the client and if you want to be able to define one how do you do that so these are all other less connection critical CID issues that have been discussed on lists okay thank you so stay there now you\u0027re trapped in the box welcome the box next up is HTTP we have this and then we have recovery so like to try and at least fit both in let\u0027s see how we go come on go ahead all right so quick overview of notable changes since London I will try to move through these and it fairly rapid pace so we can get to recovery if you\u0027ve read the drafts that should not be news to you the HCP frames no longer defined flags on every frame type priority was the only thing that was using it so now it\u0027s just part of the priority definition yeh saving bytes its GP to uses zombie streams that were never opened and are implicitly closed to maintain the priority tree that has some not happy implications on server memory consumption and also quick can\u0027t implicitly close streams so it\u0027s GP over quick now has a partner priority placeholder explicitly defined and also along with that we now have to account for the fact that 0 which used to mean the root of the tree is actually a request stream so we have to have something know something else to handle that this lets you do more aggressive pruning on your servers priority state because you can keep track of which nodes are in active active or placeholders placeholders never get removed you can remove and trim out the "
  },
  {
    "startTime": "02:06:36",
    "text": "inactive ones with some fairly simple rules like you can take out any branches that are all in active nodes you can collapse down any interior regions that are all inactive nodes and the client can predict that you\u0027re going to do this and so it helps the server in the client have a consistent view of the priority tree from both sides we\u0027re in h2 it was actually fairly easy to get confused the other big change in HTTP is that we have now put a tight bite on unidirectional streams they are essentially self describing the first byte tells you what type of stream to expect it to be and this is a point of extensibility we have four types defined currently - 4q pact and then - in the core spec one is for control stream the other one is for push if you don\u0027t understand it abandon the stream which may involve the stop sending frame at the quick layer and in terms of recommendations - extensions if it\u0027s data that develops over time like the cue pack table use a stream if it\u0027s data that you have in your hands all at once go ahead and define a frame like you did in h2 but this is this gets basically the same semantics as new frame types when we discussed it and she saw the hum was roughly split between yes we want this and we\u0027re not sure yet we had a follow-up discussion on the list that was mostly positive there were some drawbacks that we know are no come along with this debugging without tools gets a little bit harder because now you can\u0027t remember what stream ID belongs to which what stream ID is to control stream you can\u0027t look at the unidirectional stream and say oh of course that\u0027s push but considering we\u0027re talking about an encrypted binary protocol I\u0027m really impressed if you can debug it without tools anyway and there\u0027s the slightly annoying state that if you receive data on a stream out of order it becomes open but if you have it receives the first byte you don\u0027t actually know what type it is to assign it to a handler everybody that I\u0027ve heard who has tried to implement this just has a handler whose job is to collect unknown stream types and it holds it until the first byte is readable this has an interesting implication on the structure of the document which is that push is now more or less separable push streams are just another unidirectional stream type that you don\u0027t have to support and if you receive you\u0027re never gonna get one anyway if you don\u0027t send max push ID greater than zero you don\u0027t have to understand max push ID frames or generate them if you don\u0027t support push priority explicitly has pushed out something that can be prioritized but if "
  },
  {
    "startTime": "02:09:36",
    "text": "there are never any push IDs you don\u0027t have to care about that combination of bits we have a ton we removed a setting that said I support push or I don\u0027t if we add that back-end as a master switch push starts looking kind of like an extension like any other extension which is kind of a nice property for the protocol to have so if we want to add the setting back even if we don\u0027t I think this is where push stands in HUP over quick and past that when I first did the slide deck there were no other non non editorial non parked non quick v2 issues in the HCP of a quick spec then I opened one this is I think just left over we missed something so quick says for 0tt if the server accepts zero rqt data the server must not reduce or reduce any limits or alter any values that might cause the client to accidentally violate its true settings when you finally get the transport parameters that\u0027s very sensible its GP over quick actually has what we decided way way back in the Tokyo interim and then later decided was a bad idea and the transport which says the server will permit the client to violate its settings temporarily until it knows the real settings and then the client has to retroactively Li comply that gets really ugly with things like Q pack where you can remember that the allowed table size used to be 64 K so you say all right I\u0027m going to use 56 K of that stuff at 32 K cookie and they\u0027re send a request using that cookie and then you see the settings frame and find out you\u0027re allowed 4 K what do you do at that point you can\u0027t you can\u0027t reduce the table without evicting the value for a stream that\u0027s already in flight and you could kill the request but then you kind of missed the point of zero TT and I think the right solution here is we got it right in transport and we just missed updating the HTTP dock but that has some architectural implications which means if we were to make HTTP match the transports requirements now you have to ask HTP about a particular 0tt ticket whether you\u0027re allowed to accept zero TT on that and that is also kind of painful so I think the question to the working group is which type of ugly do we prefer and I\u0027ll note that the server already has to dig out the old HTTP settings to figure out if the client is violating the old ones and to distinguish between malicious versus confused Eric rajala and they fight the premise a quick is tight integration between the layers and "
  },
  {
    "startTime": "02:12:37",
    "text": "so like wall it is like disgusting Oh like it seems like that\u0027s the disgusting we decided to mean like like it I think I suppose this is him things I know I know I know he\u0027s like things everything should we tell the bottom but I mean like you know our philosophy I think is to have tight integration and so when we discover a new point is that integration that\u0027s like that\u0027s like that\u0027s let\u0027s go with that faucet feed relay it most we have to unless is are really good reason as opposed to like a new piece of like Cronus that we haven\u0027t like previously like does I do accept but I mean I don\u0027t feel strongly about that do my instincts I suppose I think are I completely agree with that as well getting flow control right and other components right it\u0027s like hard enough in its own we don\u0027t want more edge cases okay I hear unanimous let\u0027s do ugly and make the layers match great so once I fixed that we will be back to there are zero actual functional issues and open against the dock so please implement and find the rest because I know they\u0027re not all going okay thank you Mike you leave the pink box so it\u0027s 1143 we\u0027ve got recovery we want to talk about forward planning and if we have time Marcus has some updates on the spin bit I don\u0027t know if we\u0027re gonna get to Marcus but we\u0027ll try it depends on how much people want to chat and if you it can you do five minutes gold I want gold if if you can just limit yourself to five I think so there are a few editorial issues open for recovery but I tried to pick out some of the non editorial ones that I would like to resolve at some point before v1 they don\u0027t need to be resolved today but at least start thinking about them next slide so this one hopefully we can resolve right now the earlier transmit threshold is currently one quarter and the dock that actually followers I believe the at least initial Linux implementation I don\u0027t know if that I\u0027m still using one quarter for early retransmit on the other hand in the other spots in the dock we recommend 1/8 of an RTT of Ray during threshold so the inconsistency is a ugly and B I have data in map RG tomorrow that indicates probably 1/8 is a better number for quick anyway so my proposal would be to make both of them 1/8 until we have some more data both for consistency and sanity and that also allows us to use a more rack like logic and combine the early retransmit timer in with the time-based lost attention more cleanly gordy fires to very quickly we talked about this in TCP an where the "
  },
  {
    "startTime": "02:15:38",
    "text": "mechanisms to use with TCP is it not better just do the discussion in one place and and be over with it or do we want to talk about congestion control separately and recovery separately for the two things and just used to meeting slots Janet July you could certainly discuss this in PCM also just to be clear I think it\u0027s we are building our own mechanism quick is building its own mechanisms using TCP ones as informative it\u0027s not it\u0027s on it so it\u0027s these are basically similar but not the same mechanisms sure and that has big issues I think that we really really need to delve into so this this makes it complicated when we really don\u0027t know what we\u0027re doing with TCP even and then we start doing it account here but um I\u0027m don\u0027t take up time but it\u0027s just hard to do this so the proposal isn\u0027t to do this now and when you say more data you mean before we ship the final product right yes and then if people come up with data in three months or six months then you know we can of course reevaluate this with more data but right now we don\u0027t all the data I have says eight one eight seems fine so I think one does not object I will I will do that and close us next issue max data before sending an act this is actually kind of important this came up with the ecn conversations the current text attempts to be a little bit more general than the current than the default TCP implementations and that it allows you to send acts less frequently than every two packets and a lot of networks this is an excellent optimization and decreases the ACT low rate like very substantially experimental evidence shows that this can be very valuable however reno is also the documented congestion controller and reno is act clocked and so you will end up with slower slow start growth and a few other issues if you use reno and only acts a every 20 or 40 packets and so i think we need to kind of reconcile those two things of you know if we\u0027re gonna recommend we know we need to have reasonable default acknowledgment behavior and the proposal that gentleman came up with was to send a transport pram indicating the sender gets to indicate how many bytes the pier should receive retransmit oval bytes before sending an acknowledgment and so the default would be tcp style maybe like 20 400 bytes or two packets which every one we decide this is a quick question and agreeable coins that appropriate back accounting because this trick is the video confusing to me if you use if you use appropriate ibaka by Counting this should be okay this is then the popping on them so this isn\u0027t really as much about appropriate by counting as it is about the fact that right now the doc literally says as long as you acknowledge you adhere to your delayed "
  },
  {
    "startTime": "02:18:39",
    "text": "act timer of whatever you say it\u0027s going to be which defaults to 25 milliseconds you can act as infrequently as you want there\u0027s just no prescription whatsoever about say asking every two packets or at packing effort after every n bytes and so I\u0027m proposing adding that back in but how Island appear to specify what they want the receivers behavior to be because for some concession control algorithms PCC and BB are for example it\u0027s completely fine to send an acknowledgment say like after every 10 or 20 packets and for things like Reno tends not to work as well so that makes sense do you have any clarification texting the draft I think I need to understand more clearly we are running out of time it\u0027s okay these are the two most important issues okay okay sure we\u0027re okay that generally anger Yoshi I think this might help you understand the difference quick does not require you to act after every two packets so you could actually act once every half hour didi if you want so the main point here is to allow the sender to compensate for that in its controller by saying this is I can\u0027t really compensate so you must send acknowledgments every two packets or something like that so this is really like the sender string the receiver how frequently it it needs acknowledgments back from the receiver based on bytes Marcus and then Praveen in the record enclose the cue out of necessity Marcus - system is these bytes of packets we discussed both on the issue I think we\u0027re leaning towards bytes at the moment okay I will join that discussion then okay okay all right so so because of appropriate by Counting we don\u0027t really need an act every two packets we just need an immediate act if you will process at least two packets in the current batch so we can still do stretch acting like if there\u0027s bulk data flow and you got like hundred packets you can still send one immediate have you don\u0027t need to send fifty acts and I think that\u0027s still good enough so that\u0027s why we should mind it that you should generate an ACK at least every two packets but it could be more right the proposal would be to add text actually that allows you to if for example you can you do do you receive a message in such 40 packets out of the deal idiot I don\u0027t think I understood that very well but I think I\u0027m running out of time so I can I\u0027ll follow up on the issue or are in line with you okay thank you very much okay I\u0027ve left a sliver of time here at the end so we can talk about the future so planning for future activity than working group we have a September interim planned in New "
  },
  {
    "startTime": "02:21:40",
    "text": "York City it\u0027s on the website registration is going to close in three 1/2 weeks if you haven\u0027t registered yet please do so very soon it is I hope we\u0027re not going to be space constrained it\u0027s the same size of venue approximately as we\u0027ve had before and the number of people coming has been falling so that\u0027s hopefully we\u0027ll be okay we\u0027re gonna do an interrupt beforehand as we always do and we\u0027re gonna need to figure out the scope of that Interop work so we\u0027re gonna need a Sept 7th implementation target are you sure okay cuz website says six we need update the website then we need somebody to own driving that definition is anybody willing to do that mum Thompson I proposed the same one that we had last time because what it says is draft draft thirteen with a couple of tweaks unfortunately and please please PLEASE HTTP so HQ yeah more emphasis on HQ so we did we did thirteen plus fourteen ninety eight editors so the so whether you 14 or not you propose we just we we just go without like a like patch applied version okay unless you want to produce a 14 that happens to have 14 19 in it nothing else so we could potentially do 1498 and nothing more in it in the new revision if people said on slack I guess I guess what I propose is something with just semantically come on to that I\u0027ll leave it to the editors to sort out what the how its instructed then if we get all of the changes to retry and I think might be a reasonable thing to do that yeah well that that would be the nice thing about that is a bolt-on so if you don\u0027t do it it\u0027d be fine okay I can help you update that we can take this to the wiki and enter the list if necessary so talking to Lars talking to Spencer talking to the editors we think we\u0027re getting close to done and that\u0027s a message that we want to send to the working group very clearly you know we\u0027re are chartered milestones are November there still seems to be an intent that we want to try and meet those milestones in in in spirit at least we may of course come across issues we can\u0027t resolve by then or have further discussions but there still seems to be an intent to try and ship it on schedule so if you haven\u0027t started reviewing the documents now would be an excellent time you know we anticipate the editors are gonna do not only be able to share a number of issues to resolve as you heard we also have a fair amount of that a trail work to do they\u0027re gonna try and make the documents more reader friendly so so don\u0027t feel like you need to go in and pick apart the grammar or the spelling or anything but in terms of what the documents contain or don\u0027t contain please start looking at that with the eye that we\u0027re gonna be finishing pretty soon you know we had one big change as a result of previous meetings with a stream zero "
  },
  {
    "startTime": "02:24:41",
    "text": "work and we\u0027ve incorporated that\u0027s good I think that it\u0027s it\u0027s fair to characterize it\u0027s to be progressively harder to make a big change as we move down the road towards completing so so please do keep that in mind I think we talked briefly before we\u0027re talking about shipping the base drafts we\u0027re talking about shipping the OP straps possibly at the same time or at least that\u0027s the default if we want to vary that we need to come to some agreement about it it doesn\u0027t sound like we have that easily yet we have the invariance draft as well which will probably do a slight refresh on but otherwise I think it\u0027s gonna stay the same those are all ship at the same time the other elephant in the room is the spin bit which is probably why Brian\u0027s standing up if all goes to plan Bangkok is working we\u0027re going to make that decision you know we said before we need an experience that it demonstrates it\u0027s useful in managing operating networks so if you are gathering that data please bring it to the working group ideally before Bangkok it gives people time to a Viton to look at that data and get comfortable with it and and feel free to talk about in a working group list if you want to coordinate with other folks but I don\u0027t think we\u0027re gonna be delaying last call if we don\u0027t have that kind of data this is a decision we need to make to ship may I make a friendly suggestion here sure so we\u0027ve taken in the past um information about to spend that off the interim agendas just so there\u0027s no you know perception that you know you have to like actually addressed a lot order to do this noticed a lot of the people who are doing sort of core work on the spin bit or at the interims anyway um so maybe we should revisit that for New York so we excuse me because we blew the schedule today so I don\u0027t really have a time to talk about it and like I\u0027m trying to talk about it with a large part of working groups would seem to be useful before we spring it in Bangkok we\u0027ve kept it out of the interims mostly so that it doesn\u0027t consume too much of that time that we have otherwise used when we\u0027re done with time consumption at this point right so sorry I think we\u0027re done with time consumption I hope so also practically it becomes very hard to find a venue of all the people for all the people who might be interested in that discussion we already have problems with finding venues that would make it much worse I anticipate carving off a very healthy amount of time in Bangkok and probably even holding a side meeting beforehand to prep everybody and get some discussions going alright ai-ai-ai-aight will miss you guys in Bangkok that\u0027s kind of unfortunate that that\u0027s sad to hear Brian if we can have a controlled discussion in September that somehow moves us towards having a more successful conversation in Bangkok I\u0027m into talking about it I just I have concerns so we\u0027ve also you know if we finished up in Bangkok the idea is we go to working group last call then wgl see made collect some issues we need to discuss IETF last call if it happens in a timely fashion may collect some issues we need "
  },
  {
    "startTime": "02:27:42",
    "text": "to discuss so we may need an early 2019 interim larva I\u0027ve discussed this and we think what we\u0027re going to do is start putting together the arrangements for such an interim you know January or February something like that but not actually pull the trigger on it and and say we\u0027re going to do it until after Bangkok so we know if we need it we don\u0027t know when to waste people\u0027s time but just to give you a heads up so that\u0027s the way we\u0027re thinking we\u0027ve been doing this pace of having one interim between each major ITF and if we do that it\u0027s going to be in Europe Asia because the next ones in the u.s. any questions about that okay one other thing that\u0027s come up we have two minutes left is the name of quick itself from what we\u0027ve observed still causes confusion amongst implementer is amongst people who are writing about it in the press potential users and this has been bothering us for a while because there\u0027s quick google quick and ITF quick and we say gee quick and quick but we don\u0027t do consistently in people outside of this room don\u0027t use it at all talking through this changing the name of quick at this stage doesn\u0027t seem realistic I mean after all we have really nice stickers so instead remember community made of what we think is a very good suggestion is to maybe when we ship this thing when we ship it will call it quick version - with the idea that Google\u0027s verse no quick was version one so I\u0027m not going to open this up to a working group decision I almost consider this an editorial issue I wanted to give a people heads up about that if it gives you heartburn or you have concerns come and talk to Lars and I just a little bit of comparison from acne we discuss we had the same discussion about renaming because we had let\u0027s encrypt acne and ietf acne and they were originally available for a long time and what has ended up happening even though the working group decided to do nothing was that the industry is calling IETF Acme v2 so calling anyway yeah okay thanks so that also has another implication we\u0027ve had this background discussion about quick version to what the next thing is after you know quick for HTTP obviously that would become quick version 3 or something else but since we\u0027re now talking about getting to the end of this work those sorts of conversations become more in scope and we should start talking about what the thing after we ship quick version I was about to say 1 version 2 is going to be so please talk amongst yourselves talk to Lars and I and we\u0027ll start figuring out what that next phase of work might look like I think we\u0027re done for today so hopefully we\u0027ll see a good number of you in New York City in September and then of course we\u0027ll see everyone in Bangkok thank you oh and and Marcus so Marcus had slides on the spin that we didn\u0027t get to those they were kind of requests to the last minute Marcus do you want to use the room to maybe give a presentation for those who are interested because it\u0027s lunchtime or should you want to just send the slides "
  },
  {
    "startTime": "02:30:44",
    "text": "of the list any preferences I\u0027m sorry where\u0027s Marcus there I\u0027m sorry I\u0027m that\u0027s you that\u0027s why you look so confused yeah you want the rim "
  }
]