[
  {
    "startTime": "00:00:51",
    "text": "hello we're just going to wait a few minutes for more folks to join"
  },
  {
    "startTime": "00:02:50",
    "text": "okay we'll get started this is the ABT core virtual interim we'll have two hours today and the info on the notes and the meeting links and other information is on this slide and we'll provide more of the same in a bit so this is meet Echo so you enter the queue using the hand icon and you leave with a similar icon and please enable your audio if we call on you because otherwise we won't hear you and you also have to unmute uh and and then mute yourself when you stop speaking and you can enable or disable video that's that's your choice and use of a headset or Echo canceling speakerphone is highly recommended all right so this is an ITF meeting and so the note well applies remember a number of ietf policies that are uh in effect and when you participate in iitf you agree"
  },
  {
    "startTime": "00:04:01",
    "text": "to follow those processes and policies a number of them are listed here in the BCPS definitive info and so forth so please make yourself uh aware of that and then in addition the ITF is intended for professional collaboration networking and there are standards of conduct we have an anti-harassment policy and and procedures for that uh and hopefully none of those things will come up here but if they do you can talk to the Ombudsman but we strive to create maintain an environment in which people are treated with decency and respect foreign I'm getting info that there may be more than one medoco meeting going which may be is a little bit weird uh yeah a bunch of people are in another"
  },
  {
    "startTime": "00:06:00",
    "text": "meat Echo session uh let's see if we can fix this foreign hi Peter uh you were in another mediocre session yeah when um when I looked at the calendar invite the link was to a different session and then somebody went up to me that looking at the oh sorry so FYI I'm in both of these at the moment and they're like eight people in the other one and I guess 15 people in this one wow so why don't we uh is there a way for you to communicate to the other one the the the coordinates of this one so they can all come here yeah yeah I can go tell them to come here yeah okay I was wondering what was going on thank you"
  },
  {
    "startTime": "00:08:07",
    "text": "hi Jonathan yeah you really need to be consistent about which link you put into the calendar entry yeah well yeah it's really odd to have two of them wow well the other one was the one in the calendar entry I suppose the this one woman agenda hello and it looks like they shared the chat which I guess because it's a zulub oh okay that's okay looks like Peter people are coming over to this one okay uh Bernard just to catch up a little bit um I uh in the other version of of uh uh who uh helped take notes uh except for the discussion Rock and I okay I invited other people to watch that carefully because it is never a bad idea for people to watch people when I take notes okay well thank you Spencer I'm go and I'm very glad that you are we have now merged the parallel universes at least as far as the one we know about"
  },
  {
    "startTime": "00:10:00",
    "text": "exactly exactly perfect so uh Jonathan I guess you had been in the other meeting going through the slides sure yeah how far did you get no I didn't start the slides I was I was waiting for you okay all right I was waiting for you all right so I think we're all together now I think so yes or at least you know we don't know of any other meetings okay all right okay so we have uh we've gone through the tips well hopefully everybody knows and uh the note well and that note really well so uh how about Jonathan why don't you uh take over the uh chair slides uh we have and I will shut up here okay I do want to keep driving the slides and I'll just talk sure okay sure sounds good all right so yeah so about this meeting um as mentioned Spencer has volunteered to take notes um but he is also presenting so please somebody else volunteer to write down any important action items while he is talking you can use the note taking tool which is in your toolbar in the upper right it looks like the square with the pencil over it and as always you can also correct anything that Spencer gets wrong yeah so if you if you think that he particularly if you think that he did not correctly capture what you said and do the one that what you said you think what you said is important presumably you do because you otherwise why would you have said it um please make sure it is captured correctly in the notes next slide all right draft status um published a bunch of drafts I think these were not that recently uh skip let's see uh pp9 is still a misref on indirectly on frameworking um um skip has three discuss positions and"
  },
  {
    "startTime": "00:12:01",
    "text": "more discussion today um frameworking is still waiting for over um ID but what was it here so I can't nag him and EVC is an idea of last call next we adopted three drafts we have a call for adoption on one more which we're discussing today and I think there's one more I was supposed to call for adoption on but I forgot so I apologize for that and but we will discuss anyway next okay there was an issue that got pointed out about the ietf registry for the RGB payload types um there is an iot iata mime types which is complete I think everything all our pillow types are there uh the question is do we care about this which is to say do we um I mean I feel like it is probably bad to have an incomplete registry the question is do we want to fix the registry or do we want to tell Ayanna to abandon this registry um so if anybody has any opinions on that please come to the next yeah Harold you have an opinion it came up in in on the webrtc mailing list in w3c M yeah the bad thing about these two Registries is that the yeah the types that are registered in one are not necessarily usable in another and the RTP payload types registry are is the ones that are usable in RTP well the other one is [Music] is usable for basically for files and that's kind of silly um I mean I think"
  },
  {
    "startTime": "00:14:01",
    "text": "that's um true I mean do we think that having that registry I mean do people ever go hey what uh what payloads can I use in RTP let me check this registry um because it seems yeah I mean maybe they do because that's why somebody was mentioning on on yeah well what could happen in theory at least is that they they look into the into the one one of the Registries and thus don't find the RFC they're looking for in and conclude that it's not registered it would actually be better to add just to one that with a flag that says usable for RTP or usable for files but that's um that's a that would involve changing negotiation procedures damn it yeah dealing with the media types people might be well dealing with the with the media man working group that's true that's you guilty as coached yeah Stefan Stefan yeah trying to unmute here um so I'm I'm usually against boiling the ocean in in Any Which Way um so how much work is it to fix this so my understanding is what you propose is to fix that for good but that would be going forward or that would also affect all the old stuff and second question would be how much effort and work is it to just through this other registration that would be one one RFC with like two pages of content or something I mean I think the main issue is I mean"
  },
  {
    "startTime": "00:16:00",
    "text": "we know some of the you know the the the you know prominent RGB pillow types that's missing the question is somebody would have to go through and find all of the you know see if there's any obscure pillow types that's missing um and we need somebody to volunteer do that no I disagree why why why not being why not being pragmatic for a change and just fix fix the problem that actually may have a real world impact rather than going back to Sun Microsystems Whatever uncompressed video stuff from 30 years ago yeah I mean the problem is people are missing stuff that is widely deployed so I presume also uh EBC is probably going to end up missing as well yeah I mean I think the other thing we need to do is figure out what we need to put into the recommended Iona registration boilerplate for an RTP payload to make sure that Ayanna puts it in this okay this is Spencer can I just can I just uh ask make make sure that I'm getting this clearly in the notes and people can type also but the the problem the problem is basically that there are widely deployed RTP payload formats that are not in the mime type registry is that is that is that no they are in the mime type registry there's a second registry called called um Taylor types which they are not in right okay okay but but those are widely deployed RTP payloads yes exactly oh uh uh oh that's even more interesting thank you I got that backwards yeah so yeah we have two different payload type Registries that are one is specifically for rgp and the other one is you know generic media types and some things are only in the in the generic media types one so because our Ana instructions aren't clear enough I'll say to add it to this table"
  },
  {
    "startTime": "00:18:04",
    "text": "Stefan mentioned as you mentioned EVC um uh I don't know how many have paid attention to that but that was the last call comment from uh from Murray I think about about uh that the that the registration that is in the EVC payload format uh is limited in scope only to the uh to the use of RTP um and we had the same language in the VVC payload format and that was to avoid a discussion whether this is a binary format or not a binary form or nerd I don't know you know I I don't know about but that's no longer I care much about it um but I I wonder whether you know if we are boiling the ocean there rather than finding a really quick and dirty pragmatic solution for stuff that's relevant to this universe uh I I wonder I wonder how much red holding can happen uh in this area so I mean I would certainly don't want to go finding file formats for everything that has RGB payload format that would be a very so important here's here's my offer if if someone who knows about media types is willing to help me uh um drafting a two-page or a five-pager or whatever number of pages it takes that solves a pragmatic problems for codex I care about and throw in another three or so which I don't care about anything and I think you know it's also fixing a historic problem may be different from finding a solution uh going forward so there's no reason not to do right yeah we should probably talk"
  },
  {
    "startTime": "00:20:01",
    "text": "to Ayanna like what what would be the best wording in the documents to say hey we need this to be in the yeah so this this sorting out someone has to do who knows the people there and and who knows how how this works I'm willing to do the uh the the legwork yeah but not more than that so okay well thank you yeah so I think that thank you Stefan for that offer I think we probably should accept this and once you do the inquiry you can come back and tell us what I mean I think you want somebody else to do this inquiry yeah oh okay yeah well that we can do it yeah I think we'll probably use chairs is their best bet yeah all right okay yeah so we we will yeah for the notes chairs we'll follow up with Diana and try to figure out what's what I am typing that as you speak thank you thank you okay thank you all right um all right yes I was these are two things that I think that I was supposed to do last time and forgot and I apologize and so please put those in the notes for Action items for me this time all right so these two things uh I think we'll discuss the S frame one in a uh today as well yes all right so these are two action items we'll put on our action item list all right I think do you do you want do you want to just cut and paste those into the uh into the uh yeah perfect thank you anything else just to make double sure that uh you're not going back and ask for another adoption call right the v3c thing that's a that's a clerical error on your side and not and no that's a working group last call not a call for adoption I I got it but uh that will be"
  },
  {
    "startTime": "00:22:02",
    "text": "issued now yeah apparently I think the last call would be interesting wonderful thank you yep okay here's the agenda all right uh okay here's the agenda anybody has any comments on it um and otherwise people we're already a little behind schedule so I apologize for that we'll try to keep things relatively on time but yeah jpeg 2000. Pierre Pierre Anthony that's right yep can you hear me hello yes yes sorry I just muted myself and so I couldn't respond but okay great yes hi uh my name is uh Pierre Anthony Demir and uh thank you very much for having me this morning and I just want to quickly go over a um proposed RTP payload format for the iitf standards track and uh um this is to tackle an old friend jpeg 2000 and there's a internet draft available at the for those that are interested in following along I'm not going to go into much detail the draft is pre-complete so maybe next slide all right and on the call it's also and by the way these are our photos from probably 10 years ago so um and also on the call is David tomman who was one of the original authors of jpeg 2000 and who's also one of the co-authors of the proposed payload format so and this is intended to be interactive so feel free to enter up ask questions next slide all right so jpeg 2000 for those that are not familiar with the image codec it's been a itu and ISO standard and IC standard since 2001. it's really the Swiss army knife of image codecs"
  },
  {
    "startTime": "00:24:01",
    "text": "supports lossy lossless resolution and quality scalability dynamic range multi-channel sub sampling um you know it's royalty free and it's widely used in high performance applications both um image and video and Source some of the examples on the top right and it's a standard in medical geospatial you know satellite archival cinemites the standard for Cinema distribution worldwide Studio post production and it's been essentially continuously maintained and improved since 2001 and uh David and I and also Mike Smith who's on the call have been particularly active in a past couple of years making sure to keep jpeg 2000 up to date and be responsive to feedback from users and so one of the feedback from jpeg 2000 users that's been consistent over the years had been that it's entropy coder was uh particularly slow it was an arithmetic coder and so in 2016 or 2017 we started an effort to provide an alternative to the arithmetic coder and so that's the next slide so um proposing an alternative to the original arithmic coder it's called an HT block coder it's a much much higher throughput block coder I mean I could talk for hours about this but basically it provides a increase in throughput um by basically an order of magnitude of course it depends on the bit rate but uh kind of uh overall numbers and order of magnitude increasing throughput for jpeg 2000 at the cost of about five percent increased uh file size so you know five percent decrease in coding efficiency and that's really um that was a new part of jpeg 2000 that was published in 2019 and this particularly in a new part really opens the door to inexpensive and high quality low latency streaming and so if you go"
  },
  {
    "startTime": "00:26:00",
    "text": "to the next slide and so that's really was one of the motivating factor for starting work on proposing this new RTP payload for jpeg 2000 um and um which is intended for streaming of video signals encoded as a sequence of jpeg 2000 code streams so it's not every frame as we'll see is uh one code stream and it's just a sequence of code streams and there's a existing um RTP table for jpeg 2000 and again so the the idea here is to improve on this uh existing payload then as we'll see support and and leverage some of the advances in jpeg 2000 like this part 15. and we'll go over some of those that in the next couple of slides so support sub code stream latency also allow resolution and quality scalability at the RTP packet level and so forth and it's really designed to meet the needs of today's applications like for instance Sim tst2110 which is uh a standard for video streaming well for audio visual streaming in professional broadcast applications all right so next slide so pretty straightforward the payload structure and there are two types of RTP packets one is a main RTP kit packet that contains the code stream Header information so and then a bunch of body RTP packets that contain the rest of the jpeg 2000 code stream both types of RTP packets have a 64-bit payload header and so next slide so nothing exceptional there I think uh kind of high level basic parameters the media type that's being proposed is"
  },
  {
    "startTime": "00:28:00",
    "text": "video slash jpeg 2000 scl that's SEO is for sub code stream latency kind of typical use of the RTP header Fields the marker just signals the last RTP patch kits of a code stream the timestamp field is a presentation time of the video frame or field to which the codes group corresponds and the sequence number is extended by an extended sequence number as in RFC 4175 and that's to accommodate very high very high throughput you know very high I should see very high bit rates and are typical in some of those high performance applications so nothing exceptional here I think next one all right so what is sub code stream latency me I thought that maybe I should spend a slide on this because maybe some not everybody's familiar with this and that's the ability to start transmitting parts of the encoded image before the encoding of the full image is complete and that makes very very low latency is possible you know so just as an example here that's a kind of a practical number so 32 video lines at 1080 Lines video at 25 FPS that's a latency of 1.2 milliseconds and that's very useful for instance for applications so uh okay next slide and enabling this kind of sub code stream latency is actually non-trivial because in order to recover from packet loss you know you have to identify resync points within the code stream and it turns out that jpeg 2000 has forever included the ability to provide those resync points but unfortunately that's provided as a metadata which was in those PLM and PLT markers that are actually stored in the header of the code stream so unfortunately with kind of uh standard jpeg 2000 it is not possible to"
  },
  {
    "startTime": "00:30:02",
    "text": "write those markers until the entire code stream is created which kind of defeats the purpose of and enabling sub code stream latency so this RTP payload format introduces two additional two fields in the payload header which identify resync points in each RTP packets and these are the POS and PID header fields all right next slide also resolution equally quality scalability um as for those of you that are familiar with jpeg 2000 it's possible to packetize to organize jpeg 2000 code streams so that uh um they're organized in order of quality or resolution levels so for instance in this particular illustration here all the low spatial frequencies are stored at the start of the code stream and all the highest spatial frequencies at the end um and uh so we have two additional fields in the um in each payload header that identify which quality and resolution levels are present within each RTP packets and so the the idea here is the receiver or network agent can just select quality resolution levels at the RTP packet level without having to parse the code stream so you know you can simply for instance a network agent can easily just uh get generate a half resolution version of a of an image just by uh getting rid of RTP packets dropping RTP packets okay next slide another feature of this proposed RTP payload format is high Precision clock recovery so the RTP timestamp is pretty low resolution compared to the RTP packet rate especially at hybrid rates"
  },
  {
    "startTime": "00:32:00",
    "text": "and so there's a in in the payload format there's an additional header field that indicates a transmission time of each RTP packet in the same time base as the RTP timestamp and then allows for um increased Cloud recovery speed and resolution in the receiver and that's an optional feature that's enabled using a a bit in the header field so that's another something new feature of this payload format Next Step another feature is code block caching so jpeg 2000 can can be used or as has been used to transmit um video content that consists of mostly static contents or for instance just the mod you know screen content and uh of course the idea there is you'd like to not have to retransmit continuously this the static parts of the image and so the payload formats introduces a very simple code block caching which allows a sender to only occasionally transmit code blocks and I'll go over what code blocks are but transmit only occasionally transmit parts of the image that are static and on the other side um the receiver maintains a code block cache and uh that it uses when it receives an empty code block from the sender and just again for background in jpeg 2000 a code block is a collection of coded samples that belong to a rectangular you know special spatial region within one resolution level of one component so again so basically this allows the sender to only occasionally send code black you know parts of the image that are static and the receiver maintains a very simple cache where um it fetches from that cache when it"
  },
  {
    "startTime": "00:34:00",
    "text": "receives you know an empty code block from the sender that's okay so next step and um I didn't go over everything so for instance it uh compared to especially the existing RFC for jpeg 2000 streaming and also this pedal format supports much finer and much more detailed color space parametrization and signaling and and so forth and um anyway so this is uh like this to be considered as a standards track RFC and there's an ID that's been posted then it's been revised already once based on feedback we received and we really welcome your feedback and look forward to working with the working group thanks Stefan Stefan is this active now yeah so I read this draft um I find there are a lot of good points here and I support the adoption so I want to make three points the first um thank you for using the IPO references and of the iso references so we will have no trouble in um the normative referencing citation part that we recently had on the iso side with us I do recommendations are free for download so so no issue there um second I find this idea of sending the packet send time in a payload head I find that intriguing I I don't know has anyone seen that before it's it's smart you know buffer management can can do really really good things and then one point of criticizing is the way how you guys describe the syntax is like an ascified version of a syntax diagram as"
  },
  {
    "startTime": "00:36:01",
    "text": "used in jpeg that's not what we use here um and that's not what the old jpeg 2000 payload format used either I don't know whether we should whether whether consistency with um with uh the traditional way of specifying syntax here is is desirable but my guess is it's it's probably nice because that is that's the way how how syntax is described in in packet protocols in the ITF is basically the same uh everywhere and you guys are not following that so I would suggest to to edit that part of the draft that's editorial work yeah it's it's not it's not substance thank you very much thank you yes could somebody uh get uh Stefan's last uh last point in the minutes uh I got everything but the last one thank you so uh John Lennox somewhat as a terrorism someone as an individual I mean is it chairs want to say I think there's no problem with us doing a second pillow type the same media type we've done that I think at least twice before I think we did it for mp3 and we did it for each 263 so that's fine and the normal negotiation procedures between them should work fine and so there's no issues there so I think that's fine um just speaking as individual I'm afraid I haven't read your draft yet but I I'll just the noise I hear one is that the um on the sending time step there is a RTP header extension for that I think it's one of the first ones to find um and I mean I would ask would that work for you um because I think there's like you know some feedback defined in relation to it and whatnot if it wouldn't and you know if there's Untitled reason that wouldn't work that's fine but I think you should at least take a look at that um I could probably find the RFC number"
  },
  {
    "startTime": "00:38:01",
    "text": "for that if that would be great absolutely or something else Jonathan uh but I think I mean sorry let me see um okay yeah one of the design goals um so I I had not seen that so that would be great to have that as a reference one of the design goals was to um keep the um header uh to 64-bit um so that it's easier on Hardware you know fpg yeah so this would be the RCP this would be the RPP header extensions rather than the payload okay so it's actually you know so um yeah I think um yeah transmission time offsets that's RFC 5450. 54.50 all right thank you yeah yeah and then um the other question I would have is just on that you know I guess jpeg 2000 mostly doesn't have um interframe dependencies like things that are like more video codecs do but I guess your block cache does and um I guess my question is is there a way for a receiver to tell that it's lost a packet that contains a something that should have been cached because obviously things would go badly if if it did um you'd get end up referencing either having a cash Miss which I guess you could tell but you wouldn't know where what you missed or you'd actually potentially load the wrong thing from the cache and there's various techniques we've developed so that might obviously make your header bigger which you don't want so have you looked at that and have you can you tell if you've missed a packet with the cash the C Flex set well and you know it's possible to tell if you've dropped if you've missed a packet in general sure yeah so um but you know if you join if you join a"
  },
  {
    "startTime": "00:40:01",
    "text": "stream in the middle it may take some time for the receiver to build its cache essentially yeah I think I mean yeah I guess do you assume that you have some reliability mechanism and the big basically you know would expect that normally all packets would eventually get there well I don't think that can always yeah yeah no I mean I just think there's there's ways you I mean we don't have to discuss this online but it's all I'll look at your draft yeah I'd love to discuss it in uh yeah in more detail and um you know and of course uh um you know the the sender for instance knowing that the network quality the network conditions are bad might choose to you know not uh you know send you know send empty code blocks less often right so so it's really yeah this architecture it gives control to the sender to decide you know how often it does not send a code block um that that's fair Stefan but regarding this discussion this sounds a little bit familiar from things like the Opus payload and and places like that where where there were also like like code books formed and they and and the air resilience of of that was debatable let's put it that way um I don't think they have uh I don't think they were talked into specifically addressing that and I don't think we have a history of specifically addressing uh um you know incorrect reference information that may be incorrect because the the data stream is is not good that said uh what what people do outside of RTP payload formats um but could be also implemented inside"
  },
  {
    "startTime": "00:42:01",
    "text": "of the prtp payload formats is to have something like um you know have I had a field uh this is the the checksum calculated over your current cash and uh then the decoder sees that and if the Dakota sees that and it doesn't match its own checksum calculation then at least it knows that there's something wrong and uh can do whatever whatever is sensible to do and in that point then comes the question whether there's something like like an Adaptive form of a full inter request or to be transmitted in the in a back Channel and that for that is um you know 4585 type of stuff could could be in adapted form useful so um I think a little bit of error control support in the payload format is probably not not the worst possible thing for this guy um but again it's already a fairly complex document so let's keep that in mind too it's it's yeah and fairly complex so we have we would add complexity there thank you this is David hook Tobin here I wonder if I could just briefly address that um the code block caching I think we might be making a bit too much out of this or more out of it than is really intended um this is this is a really Base building upon the fact that jpeg 2000 is um both error resident and also extremely robust to just missing pieces so this mechanism actually really just encourages the missing of pieces and combines a default strategy an alternative default strategy for handling missed pieces you could almost be considered like an error resilient strategy so"
  },
  {
    "startTime": "00:44:00",
    "text": "um we don't really need to worry about the resilience of the method because um essentially the method is is intended to work with a codec which can decode the content perfectly fine even if virtually any arbitrary piece is missing apart from the main header um so so it's kind of intended to operate in that environment now yeah I mean that that I mean I would I mean that makes perfect sense to me I mean my work of a concern is not you know a dependent and I don't like I don't know exactly how your cash strategy Works what would happen if you're if you if you not that you cash entry is missing but the cash entry is wrong because something later updated it and if every cache entry has a unique ID that's fine but I mean I'd worry like if you're showing static image and then flip the screen and you missed the flip then you might you know fill the you know think you can reference the cache from the previous image without any bad uh that is a good point yes that is good point of course the thing will eventually be replenished but that is a good point Stefan this is this my final one on on this draft um given that all these great ideas in here um you guys are aware of of uh the uh patent policy of the ITF into your disclosure applications which is triggered right now obviously right um I hope you are thank you from the point of view of the notes what are the next steps here or yeah just I just want to address the previous comment and uh thank you Stefan yeah absolutely um I'm very much aware of those things so I think the next step is you'd be looking for working group adoption that that's what would uh we would request yes please"
  },
  {
    "startTime": "00:46:03",
    "text": "item is on the chairs to issue a call for adoption yep okay I'm sure that's in the notes uh Spencer I do have one question if there's just a few seconds in terms of collecting issues and feedback um of course the mailing list is there an issue tracker or um should I open you know should I just open an issue uh GitHub or I mean we have I mean we have a um a GitHub for the working group so I think you could work with the chair so you can um we can import you into that uh GitHub repellent you can do stuff there if you'd like excellent thank you all right thank you well thank you very much everybody and looking very much to your feedback and continued discussion and to the call for adoption thank you again okay so next item is an atvc profile for whatever you see so we have with us on this call myself as well as Philip Panky and some of the developers of uh the chromium hebc support uh John Lin is here so uh we're going to be going over some of the feedback we got as during the call for adoption and hopefully solving uh some of the issues so here's uh we have a GitHub and a bunch of issues got filed there and I'm going to go over them individually and hopefully we'll come to agreement on what to do next so issue two is about the out-of-band S prop VPS SPS and the PBS uh in RFC 7742 which was the original webrtc video RFC it basically says uh"
  },
  {
    "startTime": "00:48:03",
    "text": "that webrtc implementations must signal this information in band and must not include in the STP they generate so that's kind of the past history and this draft does something similar basically saying also that this is uh it must be signaled in band and not uh out of not in the STP um and so the question is do we have consensus to keep the approach of 7742 um any opinions let me let me put it this way are there any opinions that the cake of the draft so far is wrong and should be changed okay yeah Stefan and and srinivas Stefan yeah this this unmute takes a while here I'm I'm I'm willing to accept this on a pragmatic basis I'm the one who proposed original layout of band parameter sets back in 2002 but uh it hasn't taken off in this environment so so let's just follow practical implementation uh implementation practice rather than options that are available in uh according to the words of the fact that thank you universe hey um you need to unmute yeah sure I'm sorry I was actually waiting no sorry thank you so I've just wanted to check uh so uh not providing them out of band or in the STP will"
  },
  {
    "startTime": "00:50:01",
    "text": "probably uh delay the joining of the session for webrtc client so how I mean in this case we probably have to send the SPs PPS information along with every ID or frame or an iframe so why we consider this approach of not including them in the STP in specific uh reasons for not allowing this kind of information in the in the STP because this must not is a strict implementation that it it should not support it it shall not support it sorry um if I can speak to that you know as an individual but in the implementation experience I think the reason why we did this for h.264 is because um the uh you know in practice you know video Codec you know uh interactive conversational video codex change resolution a lot which is going to need a fresh SPS DPS and um if whereas STP doesn't tend to update that often um and also you can't necessarily guarantee that an encoder is going to pick different STS PPS IDs and trying to decode with the wrong EPS Causes Chaos so right you're better off so yes this does mean you actually said FPS PPS with every IDR which is what people normally do for yeah this is what it says here yet which is what you normally do in three two six four um but that's better than being in a situation where you might end up trying to decode with the wrong FPS and PPS which would be um because very strange things to happen I think because he can't even parse you can't necessarily even parse your video frames if you've got the wrong SPS and PPS okay yeah so um we did have a PR"
  },
  {
    "startTime": "00:52:01",
    "text": "um uh created to address issue two which is to clarify this because as Jonathan mentioned some of the encoders didn't update the ID um and there was some issues uh in matching the in band sets to the IDR so uh pr10 adds the following text basically to say the idea must be preceded by the relevant parameter sets with the same RTP tabs timestamp uh any any problems with this PR OK okay all right issue three is about TX mode um the current draft didn't cover that at all and then people said oh okay what what should we do here um and so uh I created a pr9 to try to update this um and uh basically the guidance is to not include the parameter within STP should not uh and if it's present then as the RFC 7798 says a value of srst must be inferred um so that's the P that's pr9 there was a remaining question which is uh what happens if the webrtc browser receives an offer with another mode like mrst or mrmt typically that would because of the guidance here would come from a Gateway not another browser and should the set remote description just fail to apply it because 7798 section four three says that receivers must support all of the TX modes um so I don't know uh John Lin or others have an opinion on this gentlemen do you want to speak to what what you'd like to have happen"
  },
  {
    "startTime": "00:54:00",
    "text": "please you need to unmute foreign Ted yes are you speaking we we could hear you uh German you seem to be muted now yeah I I mean I would prefer that that remote description to fail if you get an offer with the text mode no status SRS ft that's my preference but I'm not sure why off the 7798 state that reviews must support srst and MRT and rpt but implementation wise this makes things easier I'm not sure why previously that becomes a requirement for supporting all text modes Jonathan um yeah so um I think we wrote it that way because we didn't know what most people were going to use I mean I believe in practice I don't know of I mean I don't know very many h.265 payload type in buddies you get anyway but I certainly don't think that anybody supplemented Mrs you know"
  },
  {
    "startTime": "00:56:00",
    "text": "mrmt um I know that like for instance for VVC and EVC we um decided they're not worth implementing and so we uh only implement we only defined srsd for VVC and later codex so I think that um I I would think that I I very much doubt that even from a Gateway you would get anything that isn't a srst because I don't think the anybody decided to go that way so my inclination would be to say this is um uh that it's fine to uh it's fine to fail I mean if you feel like I'm going to get cured knock yourself out but I don't think we should require the Brothers Implement it in the spec okay uh may we put that into the notes as uh recommendation unless there's an objection sounds good okay it's just a Spencer recommendation from who well uh go ahead sorry yeah right the just sense of the room is that it's okay for set remote all right thank you I was I was just lucky I was just lacking a uh I was just asking lacking an a now and thank you okay for yeah either mrst or mrnt okay all right um next issue is Issue four and so I believe uh John Lin questioned the usefulness of Max cpb and Max dpb um and just to clarify these are additional constraints on top of the level ID so they're put in if the receiver can't handle uh what would be required implied by the level ID and that includes in the next issue we'll talk about if"
  },
  {
    "startTime": "00:58:00",
    "text": "Max FPS and Max br but um so the proposal here in pr8 is to remove these as parameters that we expect webrtc implementations to support so basically what we're saying is we're assuming that implementations uh don't need these additional constraints and that the level ID is sufficient are there any objections to removing Max cpb and Max dpb Jonathan uh yeah I think this mostly I mean I will defer to the implementers here if that's what you know people who are actually talking to the actual codecs you know if you do that if the level IDs are sufficient to describe what the Hardware codecs are doing then um yeah let's do this if there's like ever any case where like a Harper codec is well I can't quite I think they're actually above the level ID not other sort of constraints below the level ID but it's what I meant to say well I can't quite do I can do this level but I could do more CBDs or dbbs than you then the level 86 specifies but I suspect oh okay yeah I suspect that's not what Hardware implementers are doing and at least there's no API to specify that so in which case you don't probably need these okay um so the next issue is similar but relating to Max FPS and Max br um and we had some discussion in the issue people were saying well in vp8 we did want Max FR and Max FS"
  },
  {
    "startTime": "01:00:01",
    "text": "uh and that was an issue not uh it was in it was required in 7742 that that that be supported it wasn't supported and then uh there was an issue and 34 Stars which meant people were upset that it wasn't in there but um there is agbc is different than vp8 because you have the profile tier and level negotiation and vp8 didn't have that so again as uh Jonathan said it's it's an additional parameter in addition to the level so it isn't quite quite the same thing um so the question is whether we need the max FPS and Max br um or whether the level ID is sufficient and pr15 removes Max FPS and Max BR as parameters Jonathan sorry that was a lingering hand I don't I don't know okay that's uh John Lin do you have an opinion here I guess you I think you were okay with removing all this stuff right yeah I I think I I'm okay to remove this because I think it's a kind of overlapping with the level negotiation right okay are there any objections to this pr15 which removes Max FPS and Max br a okay all right so the next one is the pack I uh packets um these are defined in section 444 of"
  },
  {
    "startTime": "01:02:02",
    "text": "7798 uh in the payload type 50 and then in 4442 we have the temporal scalability control information tsci so um the issue here is that in webrc implementations this tsci info uh typically ends up elsewhere as well such as an RTP header extensions I believe the overlap is there's a bunch of them that overlap um including the the frame marking RTP extension but also dependency descriptor or generic frame descriptor have this kind of sne kind of bits uh bit information so the question is if it's negotiated in these RTP header extensions what implications do if they get to tsci also in the Packy extensions so you could essentially get this in two places um and so in pr16 basically there's a proposal to say hey if you negotiate these header extensions the tsci in the header extension takes precedence and then the implementation must ignore the tsci in the packai oh I mean that's assuming you understand them in particular I'm worried about some of the um SFU cases um particularly like if some receivers understand the heteric sentiment comes out um I would be inclined to say must be consistent and other than that uh when you say it must be consistent you mean you know you have to you know I don't know but basically you have to tell the truth I mean I don't know don't be wrong but basically put them both"
  },
  {
    "startTime": "01:04:01",
    "text": "places and it's you know because I mean I'm concerned like about a you know a SFU that needs to strip them for some perceivers and things like that well but then they had our negotiation header extensions would be with the SFU right so if you're saying basically it negotiates them but then it doesn't do it right or something or it negotiates them but then you know wants to forward the packets on to other receivers and then I mean I'm worried about the case with where the sender would just not bother to put them in um into the payload payload format if it's negotiated the headers which actually happens with vp8 on Chrome um oh so um yeah I mean I feel like this is an issue I'm not sure in specifying this I feel like this is this is an issue you know we already have with other payload formats I'm not sure that specifying it specifically here is that helpful when we already have the problem for existing payload formats um but that's an individual opinion so if other people disagree with me I'm going to be in the rough uh gianlin I know you had you had an opinion on this so um because we don't see this for ABC right with TSA ACI information uh it kind of become inconsistent because you mentioned we have a duplication here my take that if you"
  },
  {
    "startTime": "01:06:02",
    "text": "already negotiated the DD extension we I agree that you should own a DD first otherwise FTD is not negotiated then we maybe properly we we can honor the kfci information so there must be some preference here so what do you do about it right yeah yeah I mean if TD is there we ignore tfdi but if DD is not there we we will honor kfci yeah I think it's it's reasonable Jonathan to say they should be consistent I think you probably it probably would be some somebody would be screwed up if it wasn't but um the question is how the receiver you know processes the whole mess I mean does it I mean and it doesn't need to be specified if they must be consistent and I think more interestingly is should you say you know should you bother sending if you have you've negotiated DD or should you just omit it right right that's the other question yeah some ice it would be easier if you didn't right yeah but by default right are you planning to send it even if if you have the RTP extension yeah yeah so maybe uh maybe for the notes the uh"
  },
  {
    "startTime": "01:08:00",
    "text": "this should say something like if you if it's negotiated uh senders probably shouldn't send it yeah that's fine for me I believe that's okay well I just what I just heard was if this is negotiated Senator shouldn't send it yeah what was it sorry the tsci okay thank you if it is cool basically if it's negotiated in a header extension don't send it in the payload oh okay oh thank you that was that was that was the part I was not able to lace together yeah okay thank you I I will I will modify the pr and we'll talk about it in the GitHub all right so uh last issue relates to rpsi and I think more generally to uh alternative reference frames and references in general so uh basically the question was should should this hvc information support rpsi and it also got into how the references are handled Etc but um I think the looking over the rfcs the sections are fairly clear so RC 7798 section 83 defines how to support rpsi and hebc so that's there and it's clear and then there's a use of RTP and webrtc document RFC 8834 which basically says that receivers should generate the rpsi and then the receiver should act on it so that's pretty clear guidance and then uh there's also some clarifications in RFC 8082 section 6-3 basically how to deal with the rpsi in the context of layered codecs so I think the RFC guidance is uh is is pretty clear here"
  },
  {
    "startTime": "01:10:00",
    "text": "but uh there are some practical issues uh that uh in webrtc implementations that are worth talking about uh in particular library to see hasn't supported rpsi since 2017 it did initially supported for VPN and bp9 but uh it was problematic and it got removed the h26 form of limitation does not support alternative reference frames although some people would like it to do that it doesn't and then the av-1 payload spec doesn't mention rpsi so it's not supported for that either um Jonathan my I would suspect I mean my suspicion is that given that the this is entirely targeted towards um hardware implementations and I suspect the hardware implementations generally don't support any kind of reference picture selection at least most of them don't um it seems I'm not sure that this is useful you know would actually be implementable even if um yeah Harold interestingly enough the question of uh reference frames came up in in at the WTC last week right right before loss and the claim there was that according to my colleagues that talked to Hardware manufacturers reference frames were perfectly reasonable to to designate on the hardware but to only two or three operating systems will allow you to to to direct the hardware to do the right thing through the drivers right so yes it was a dealing with reference frame sounded like it was quite feasible if the push for supporting it was strong enough"
  },
  {
    "startTime": "01:12:11",
    "text": "yeah and in a t-pack there was a new encoder API discussed that would actually make this possible to do in uh in webrtc so there was that code limitation which potentially could be removed uh Stefan but I hate medical um so rpsi is from from all the air resilience tools that are that are using media coding features obvious is is really the most efficient right it's it's it's it's really great stuff um the end with respect to hebc while I haven't seen uh Hardware or drivers and stuff that that would support that I would just from a theoretical analysis of of the codec itself um it it shouldn't be particularly hard um the reason is that hevc is a need for metadata associated with the which is each reconstructed frame that's that's absolutely minimal that's different with the neocodex and uh including ab1 there but for for HBC it's absolutely doable yeah so on on this one I'm tempted to to recommend to at least at least leave the door open because it it solves a real problem um and I I wouldn't rule it out but that uh reasonably smart people uh would Implement that in in the foreseeable future and if you provide now guidance not to do it um that's you know it it would it would"
  },
  {
    "startTime": "01:14:02",
    "text": "probably um just just trip uh the uh the the implementer community away from from something that's actually useful and works so yeah so I I would be silent about that at this point thank you yeah so Stefan because the use of rtb and document says it has a recommendation I don't think this document can override that it already says should Implement on the sender and receiver so yeah but you know you know but you you can still I I don't think I don't think standard formalities here should count right um what you I mean you you could you could make a must out of it but I wouldn't go uh in that direction either because you can't enforce it right silent silent on it Harold yeah just uh another notice that we currently have a CL in uh in uh progress for lib webrtc that adds rpsi support for h.265 so uh now so the fact that live wherever you see the you you dropped off for a minute there Harold yeah suddenly mute kicked on kicked in so the the fact that live web RTC it doesn't support rbsi at the moment doesn't mean that it won't support anymore or whenever that that CL gets reviewed yeah so I guess John John Lynn you're the author of the CL right so I don't know if you want to comment on it all right"
  },
  {
    "startTime": "01:16:06",
    "text": "yeah so yeah I draft last year because um a few customers like Mata and the zoom request this uh to support long-term reference actually Hardware supposedly that driver support these on windows so most uh vendors so this is the not only a TVs is specific but also ABC support is so this will be very useful feature when you have a package of frame lost and with this long-term reference picture selection you avoid sending keyframes right so that is really when we would like to have that okay so how about this uh proposal uh basically keep with the existing rfcs recommend the support for rpsi maybe quote the other rfcs and then try to try to land the CL and make it happen and if we have other issues we can come back to the working group does that seem like a reasonable resolution of this are there any any objections okay so I think that's uh that's it for the issues um I don't know Jonathan if you want to comment on the uh call for adoption uh but uh that that's it for the issue discussion today yeah I think there were a number of people in favor and nobody against so I will review the comments that I think it should we should it is we should adopt please okay uh and then uh"
  },
  {
    "startTime": "01:18:00",
    "text": "put a put up to do put a action item for me to to declare to send them up to the list saying that yeah send a summary of the call for adoption uh Spencer in the notes could I ask someone else to uh take over his note taker I am uh uh I'm starting to get complicated here uh just you know just as far as me trying to stay focused thank you thank you I'll keep watching but I'm not going to be typing thank you okay all right RTP payload format for skip uh Dan or Mike yeah this is Dan so next slide we released version six last Tuesday um some minor updates to it to uh added a key point section to try to summarize up front at the beginning of the document some of the repeated questions we seem to be keep getting from reviewers um to try to bulletize those points right in front of to address those those concerns again just to go through this quickly again the skip can be considered a tunneling protocol payload is opaque um that's kind of one of the things we wanted to drive drive in right up front that that's that that is what is going on again skip is an application protocol that uses rtps of transport um and again to emphasize the third bullet again we are not like most other RTP payload rfcs and that we don't have a concise or discrete payload format rather we're tunneling other codecs through um the skip the skip payload um again the reliable transport is done"
  },
  {
    "startTime": "01:20:00",
    "text": "through skip control messages is again that's implemented at the application layer and we have versioning mechanisms within skip to avoid um the obfuscation of the protocol we also added an example of listing skip in preference order when there are multiple codecs listed in the uh listed in the STP and probably one of the bigger changes that we made after getting approval from the skip working group was to actually provide a link to an older public version of the skip 210 specification um again that was repeated over and over again by all the reviewers that that they weren't getting the document or they didn't request it or whatever when they did the review therefore they couldn't do a review or Inc or did an incomplete review so um again we provided that specification um again the basic the basic principles and protocols that are defined in that older version are relevant today there's not been too many changes regarding that level of specifications so we felt comfortable in providing that public link to everybody at this point yeah um so yeah I think you're in an interesting position because you've provided the public link now and now we're starting to get people reading that and asking questions about the skip State machine right and uh act as though it I mean the info's out there so you can ask the questions and we can answer them but they're really not relevant to the draft like we had a question about video and the state machine and when it gets turned on and the key key exchange and so forth yeah sorry yeah so it's going to be it's interesting you've now you've now made it clear that the information is available so now they're going to read it now they're somehow we have to get"
  },
  {
    "startTime": "01:22:00",
    "text": "out of this because it is a tunneling protocol right which means yes you have all this great information now but please don't make use of it right you know that's sort of the trade-off we did within the sense of trying right you know with all these reviewers saying well we can't do a review because we don't have access to the document so in the in the effort of trying to get this thing moving forward here you know we sort of capitulate it and say well we'll provide the link to the documents you can do a review but like you said don't do a deep dive just because we can't you know the protocol is what it is and we can't change it so well also because it's it's not it's not relevant right I mean you know it's an example of the latest one was when is you know when exactly is does the video State transition to secure for video and you know the various versions of skip210 have maybe have different answers you you mentioned but it it doesn't really matter because um you're just going to take the payload and stick it in RTP and you know and and if you're uh intermediary the whole point is you shouldn't be parsing the thing to try to figure that out anyway right because that would make it that would break the whole thing so yes if I may comment um you're exactly right the the question coming in about the video mode is you don't want to be harsh but the truth is it's out of scope for for what this draft RFC is trying to do we're a tunneling protocol what is in that payload should be opaque to any device other than some skip device and if if you really want to learn Skip and make a skip terminal we can happily turn you in to turn you on to people who can assist you right learn to do that but I think the point is well and also that info that you would learn to do that should not be applied into middlebox correct nothing should go on in the middle class"
  },
  {
    "startTime": "01:24:03",
    "text": "yeah so um yeah I'm going to read I'm going to read 06 again and I I think you know uh it's gonna it might be frustrating for you because I think you've now answered the availability in open part but you've now opened another can of worms because the stuff is out there and now they're all going to read it and now they're all they're starting to ask all these questions as if the answers mattered um correct and remember it is an informative reference it's not normative it is not necessary for it to be there right and I sometimes wonder what would happen if we didn't even list it in there and just submitted this well because then they'd say you were hiding it well they seem to say that anyway but yeah but now they can't because it's in the open so um let me I'm gonna read it again and and just if it makes you feel any better these same questions are coming up in the quick working group because middle boxes you know in TCP we're mucking the things and making all kinds of problems and so in quick they have something they call greasing which is basically they randomly change bits so you know yes you have all this wonderful info but we're we want to make the point that you can't mess with this so we're going to change it so if you try it's gonna break um I I don't think we want to do something quite as extreme here but uh we're just trying to tell people not not to not to use all this wonderful info you've made available so anyway I'll go over it and try to try to see if that point is clear or else we'll have a whole bunch of new discusses on a different set of points true and you don't want to be rude to people and say I'm not here to teach you skip but it isn't it well it's even I mean it's even worse because even if you did teach him the whole point is don't use that knowledge please yeah please forget everything Nostalgia it's not like we don't have other lives right so"
  },
  {
    "startTime": "01:26:00",
    "text": "all right yeah so the final fly just goes over the ballot stuff the ballot position where we are at this point and what we can do to try to poke in prod to get people to make a decision or cast a vote I mean they were four people on the list that had that didn't even cast a ballot I don't know what what's up with that and try to convince the other some of the other three that are in discuss to to persuade them in our Direction so yeah I will go over it again to try to um I I think what I'll do is I'll also try to look at language and other rfcs that have the same problem like in quick um to about we need we may need to add a paragraph on protocol ossification to just make it clear why that you're not hiding anything you're just trying to trying to get the the you've got a problem with the middle wind boxes right now and that's what you're trying to fix so giving more knowledge to the middle box isn't going to help you correct and the hole isn't going to fix your problem that the RFC is to try and form the people who make middleware boxes that this protocol exists and please don't do anything with it just let it pass right right so like the last thing you want to do is have everybody Implement a particular version of skip and start looking at the payloads and fooling with it that's exactly the opposite that would be that would be worse than where you are now in fact yes yes because it would produce problems at various places in the network where it used to work and now doesn't and now you know it was great somewhere in the middle where it seems to be broken that would be bad right because now you basically got these sbcs that are randomly breaking you not because you're skipped but because you're a uh a payload type that didn't wasn't set up to handle so uh you don't want to transition from"
  },
  {
    "startTime": "01:28:01",
    "text": "that scenario to one where they're understanding Skip and breaking you specifically because you're the wrong version of skip and we're in a point that would put us in a point in time that we would have to make changes to skip but couldn't Implement until we somehow notify all oems right Network gear that they need to make a change in place by a certain date so we can roll out our changes right right yeah and that's where that's that was the situation in TCP which is why in quick they they try to come up with all of this uh antiocification stuff to prevent that same I mean in TCP essentially they've given up at this point okay uh because that the middle box junk is so is so prevalent that it really can't be removed uh so they're big and quick they they've they're taking these antioxification but that would be a little extreme for you to get start to get into bit greasing but uh uh yeah yeah that that doesn't help yeah okay um so I think uh for Action items I think just chair review to uh of the whole uh uh ossification tunneling language to see if it's clear and then we'll we'll make another idsg yet another review request and see if we change any votes so one yeah one one thing um you know it's time to make phone calls this this email this email stuff or it's time to to actually you know talk in person to these isg people um people so so someone has to go to Prague and they really set up a meeting beforehand and talk to"
  },
  {
    "startTime": "01:30:01",
    "text": "them yeah I think I think a lot of these comments were were still based on on you know lack of education and no matter how many emails you send explaining every little detail and no matter how much additional text you're putting in people don't read yeah even even though it's true so you have to talk otherwise you will not get the thing over the over the uh over the over the hurdle yeah and I see people are busy in Prague but uh I'll set meetings up beforehand yes it's it's I think that's the only way to get this done thank you I think that's a good point Stefan clearly the emails do not seem to be working um so anyway I guess that's a chair work item to discuss how to how to uh how to move this forward as well Spencer so if you're going over to the IDF this time uh Jonathan I think you'll be there right I should be I'm still waiting for right okay yeah Spencer uh just my experience from another uh working group and seller uh I had asked Murray to uh chase down and discuss for one of the documents there and uh Murray uh slip that there's apparently a uh slack instance for the isg that he's using to Ping other isg members so uh and that that that is likely to work much better than email uh between now and Prague okay thank you all right so we're going to transition over to RTP over quick we've given it a half hour we don't quite have that because we're running a bit behind um but um please somebody take notes so can somebody volunteer to take notes for this next section [Music]"
  },
  {
    "startTime": "01:32:00",
    "text": "all right I'm gonna try to make it short um next slide please uh so yeah sure short update on what we've changed since the last meeting um read the section on considerations for using stream sources using datagrams that mainly contain some background info about the differences between quick streams and datagrams it's purely informational it does not add any restrictions so you can still use both in one connection we explicitly State now that applications are responsible for adapting rate by deciding what what they actually want to send and previously we had a sentence that said we don't mandate any algorithms but we made that a bit more explicit and clear now and then we have PR 120 which moved large parts of the rtcp analyzers that we talked about in previous meetings to an appendix there still is a section and a new issue that I'm gonna talk about very briefly later that concerns the same part but we already moved a large part of the rtcp analysis now um and then the next last two pull requests that are listed here I have some more detailed slides later and yeah we published a new version yesterday um zero six okay next slide please so this is one of the open issues currently and we have talked about stop sending and reset stream in the past a couple of times I think this slide doesn't have anything that I haven't talked about in the past meeting um but to quickly recap of a receiver sends stop sending and the sender must according to Quick send reset screen um we say in our document that the sender still should continue to send media frames of that media stream on new quick"
  },
  {
    "startTime": "01:34:00",
    "text": "streams because stop sending should not be interpreted as stop sending me this media stream but only as please stop sending me this quick stream um and currently we say that the clicks the RTP over quick sender has then must continue sending media frames starting from the first one that it hasn't tried to transmit on the quick stream before I have one more slide on that do you want to wait on that before we discuss pen or do you have a question regarding these points already I've been going over the draft uh with respect to the treatment of rtcp and uh one of my questions a bunch of things when you say for example send New Media frames I think you also mean both RTP and rtcp right because the stop sending could affect the rtcp as well um yes that's a good point that's not covered by the text about stop sending currently I think but yeah I I found a bunch of places and I've probably found another issue but relating to the treatment of rtcp uh in particular I think that would be really bad as if somehow that feedback stopped getting sent for some reason because of getting a stop sending something like that anyway uh Bernard Bernard uh if I could just uh make a suggestion um we've got uh a couple of open issues from from you and uh uh uh 128 was is uh quite an open issue that we have not discussed yet um uh it is likely that that open issue will be uh to sliced and diced into multiple issues right and so uh you uh you are you are you know issue these are encouraged but you might want to you might want to see uh where the you know where that uh where uh 128 land and it's"
  },
  {
    "startTime": "01:36:01",
    "text": "uh children land and see if you still need to say something okay thank you and that's actually that's actually good advice for anybody but uh especially for Bernard especially on that uh on that issue thanks all right next slide so last time there were some questions about what happens if there are media dependencies um and since we say that the sender should continue sending New Media frames on new quick streams but not re-transmit the previous ones that received stop sending there is an issue what happens for example if the frame B the second frame on a screen depends on the frame a and this has to send on a new click stream the frame a may not have arrived completely because that's why this receiver sends stop sending it doesn't want this Frame anymore whatever and then the sender must continue with frame B but sending frame B doesn't make that much sense because it may only be decodable when the receiver already received frame a um so we um we would or we currently the application is in charge of what's what's to do with the next frame um there are some options listed here in the bottom of the slide so the sender could for example decide to drop B Because B will not be usable by the receiver it could create a new independent really decodable frame or something like that and continue with that and treat this stop sending us some signal to um we reset the decoder um or we could transmit B on a new stream accepting that it may not be decodable and resulting in some artifacts but we would like to not add text that allows the sender again to transmit the previous frame a on a new click stream because that is an issue"
  },
  {
    "startTime": "01:38:01",
    "text": "that we discussed about in the past and we needed to add some boundary on where to restart on the new quick stream so we added this sentence that says start from where you perform what you have never sent before and so we would like to keep this as the boundary because otherwise we get into a situation that we discussed I think in Yokohama where the sender could three to stop sending as okay I'm going to retransmit the same thing on a new stream at the receivable sent again stop sending and it will kind of end up in a loop where the receiver keeps saying higher and wanted and the sender says you need it to decode the next one um so yeah we would like to keep the bluff matters is now and maybe add some hints as to what the application can do in this situation but um yeah we would like to ask if there's any other problem with the solution or if we um you need to consider and we forgot to consider anything about this all right so if there are no comments now but you have something later then please add it to the issue otherwise we will just add these hints on what the application can do and then keep this um restriction that the sender has to continue with the next Media frame yeah I would I would say uh I would be concerned about interpreting quick layer feedback as as rtcp feedback like treated tropson stop sending as a pli or some other feedback I think that that seems problematic I think it would yeah I think it would be problematic if we add that as text in our draft um we expect that the creek at the quick implementation will issue that's a real world service some error to the applications of the application will uh no there was a stop sending and then what the application does was that is um left to the application yeah I think we don't want to add text"
  },
  {
    "startTime": "01:40:01",
    "text": "that says this specifically yeah uh Bernard I just want to add we've uh Madison and I were talking about this uh pretty recently uh and uh I think that the the more I'm thinking about this uh what we what we met when we said stop sending is pli for a new stream actually is pretty close to creating a new an independent next frame uh but uh I think I think I think that um I agree with your uh discouragement of uh guessing what uh guessing what uh quick feedback uh quick quick error you know quick quick messaging like that actually means um in ways that are not defined and I I don't think that I don't think that uh avoiding that is going to cause any problems at all so I think I I definitely agree thank you foreign the past um they are basically the versions of stop sending and reset stream that includes an offset and the offset specifies up to where a quick stream has to be reliably re-transmitted and after that everything may be unreliable um that sounds useful but we are not sure how exactly or how relevant it will be in in practice because it allows an application to make earlier parts of the stream reliable but when the receiver or the sender decides that the later frame is already too late for example and we want to cancel it and want to drop this then why keep the offset to reliably transmit the earlier Parts um we currently have a node on this or a node that references these two graphs in"
  },
  {
    "startTime": "01:42:00",
    "text": "the document but we would suggest that we don't add more text about repabilities and we would only keep them as informative references in the appendix that already lists quick extensions for future use um that might be potentially useful but since they are not not finished documents yet and we don't really know if it will be very useful we would um not any or not add any more text about this yeah they're not yeah so we came to Bro roughly the same conclusion in the web transport API the only place uh so that we would not add this so that if applications when they have the ability to process send closed stream or anything like that for the same reasons um the only point of contention was whether it might be useful in a control Channel so another is not for media but for some control reason where you want to make sure that a particular like message gets control message arrives so that was the only place where we thought it might be worth discussing uh because for something like partial delivery it really doesn't help you so and I make sure I understood what you just said Bernard uh you're talking about a you're talking about a control Channel that's still being transmitted over RTP right well uh in this particular case we were looking at for web transport it was the control channel that sets up the sessions right uh and there it did seemed to be useful to have closed stream and know that a particular like uh say you were asked for a session to be set up and then you decided to close it you would you would be able to say hey I want this particular command to get through and be reliably transmitted but after that I'll do the shutdown so that it made sense there but in the case of media uh we discussed it and we didn't think it made any sense because you know if you're in"
  },
  {
    "startTime": "01:44:00",
    "text": "the middle of sending a frame and decide you you don't want it anymore you're just going to send the reset um and you wouldn't want it to be partially reliable you just decided you didn't want it to get through right so yeah you couldn't think of a reason why close stream would be useful for media but but the only place where it was debated was in the control okay so anyway thank you yeah I think what you're saying here makes sense the only the only place where it might be worth a little bit more thinking might be like is there some rtcp message you must get there you know uh you want to get there but otherwise I think you're right yeah for rtcp I I would argue that a receiver should probably not send stop sending for rtcp anyway because it doesn't make sense I think and for the sender yeah there's someone that knows what it wants to get through right and if it knows I'm gonna have to open new streams for the following rtcp messages um like if they do stupid things then like um why would he use or need close screen for this so I yeah I don't think it's very useful for rtcp either Johnson um yeah I think um given that all of RTP and rtcp is designed you know to be unreal you know for unreliable networks I think there's no need for something to be to force something to be reliable because rtcp rtps and rtcp's own mechanisms will handle that properly so yeah I agree with this and I don't want they don't want to have an Armature dependency on something that's not done yet and quick if we can avoid it yeah that's another good reason so okay we will then remove the notes in the main document keep the list in the or keep it in the list in the appendix and um yep then close that issue um okay so this one is one of the things"
  },
  {
    "startTime": "01:46:01",
    "text": "that I mentioned earlier that we merged yesterday I think um we had some voting on suppressing quick signaling in favor of uh no uh rkcp particularly I think it's in favor of quick signaling um but in the introduction we said that we don't want to change any of the protocols so we just needed a standard quick protocol implementation and uh we also don't want to change any of the rtcp feedback rules we just want to be able to use Quick State information that's there anyway to enhance the statistics that are um that are provided by rtcp so we change that wording to don't say that we suppress any feedback and instead enhance statistics um so that we don't require any updates to quick or rtcp feedback rules and yeah we merged that yesterday then next slide uh yeah exactly then rtcp multi-op topologies was another issue that we created pull request for that we merged yesterday um this adds a section for considerations for rtcp enhancements and multi-op topologies which means for example if we have a participant in a session that uses RTP over quick and then we have a middle box and on the other side of the middle box there's a participant that does not use RTP over quick but some other protocol then this other participant may need rtcp feedback as usual and RTP over quick participant May um not send as much rtcp feedback as the other one expects because it can use great stuff to enhance this um so now we added some considerations for this for what what could be done to solve this problem so first of all the previous pull requests that I took before this slide already solves this a little bit because we still say that we need the basic rtcp receiver reports for example so that"
  },
  {
    "startTime": "01:48:00",
    "text": "will still be there anyway but if the middle box for example has some or uses quick acknowledgments instead of relying on negative acknowledgments from rtcp then one solution would be that the mailbox adds them themselves or another solution would be that we need some signaling that tells the RTP of a quick participant hey you actually need to do rtcp as usual because there's someone not using RTP over quick um so that the RTP request participant can still provide this feedback and then there are a couple of topologies listed in the earlier sections of the draft I think um I think RFC 767 has a lot of more topologies and yeah there are maybe some topologies that are not covered by this but they are one questions that we thought about when we discussed this was which of these do we actually care about today and is there any of them that would not work is the solution that we propose here um yeah so if you have any feedback with this then either now or in the GitHub issue given that we only have 10 minutes left minutes left um and yeah Jonathan um yeah I mean I've been and let's make it into more of the signaling issues which we haven't really talked about yet but I think all of the RTP mechanisms beyond what the base 3550 does have negotiation mechanisms in sdp and I think you know if there's things you need in the on the RTP side then you should negotiate them and if the end if I didn't negotiate them then you shouldn't use them and that sort of gives the flexibility to make sure people need have the RPP features they need [Music] um so I think on the which I think probably hopefully resolves most of these issues thank you all right yep that's what's a draft now says um and yeah then next slide is already the last one I think"
  },
  {
    "startTime": "01:50:01",
    "text": "um there's a list of issues that we are currently focusing on the first two are finished error codes we have one request for that which we already merged some time ago but it's not yet finished uh there will be some little additions to that um but it's almost done and then yeah these are the or the the list here's the list of issues that we are currently focusing on there are a couple of more issues in GitHub but um some of them are marked with one fix or not yet or future document or something like that because there are things that we can't or don't think we can do really much about yet for example multicast I think we don't need to work on this yet before there's anything that specifies quick emoji cars or something like that um and then yeah the last two issues here on 127 at 128 are very new from Bernard I think there are a lot of good points in there which we added to this list which we are going to focus on next but we didn't have a chance to look at them in hotel yet um yeah and I think that's all for today any questions they're not I did have I did have one comment which is that I'm beginning to see work uh quicker momentations incorporate l2s l4s uh for uh uh low latency so I think there is uh and I believe there was some work on Apple in that regard so I think um there does seem to be a coalescence around uh some of the issues you've raised but maybe not in the directions you describe in the draft so just something to to look at as uh the"
  },
  {
    "startTime": "01:52:01",
    "text": "implementation of l4s proceeds yeah uh Bernard just the suspense I uh I saw I saw I mentioned of that in uh the uh meta issue that you put in Fairly recently and uh I I agree with that and uh I appreciate I appreciate the I appreciate the uh pointer to uh Apple is one of the places where that's popping up that'll be helpful too thank you yeah I don't think we have quite enough information to know about how effective it is uh because usually you know it's gotten it's now in iOS 16 and 17 um uh and but not quite deployed in the by the isps yet but uh anyway in terms of implementation progress it is it is making substantial strides yeah uh and I I think that that is a very reasonable thing for us to focus on um it it may also be worth me just saying um medicines refer to this a couple of times in the in the meeting but uh he and I are trying to keep the labels on issues uh up to date and coherent uh we have I think three or four issues that have been added since the last time he and I talked that uh he and I have not added labels to yet and uh we will obvious you know we'll obviously update uh labels for things we discussed on this call uh soon but uh I just encourage people to take a quick look at uh at labels anytime that we're getting ready to uh talk about uh quick over RTP sorry RTP over quick yeah anyway thanks thank you okay Peter we have a couple of minutes uh but luckily you don't seem to have a lot of slides so take it away"
  },
  {
    "startTime": "01:54:01",
    "text": "yeah yeah this should be short next slide so since last time uh there were two pieces of feedback one was to allow what I was calling the stage one or media format specific packetization to Output more than one RTP packet and then to apply the stage two or S frame specific packetization to each one of those packets so I made that change in GitHub um so that's good and then the second was that we should issue a call for adoption so I didn't see the call for adoption happen yet so I went ahead and renamed the draft in GitHub that's on me I forgot I apologize I will do it right after this meeting okay so I haven't uploaded this to the data tracker yet the the rename but I did change it in GitHub so uh Peter maybe you issue it under draft Thatcher and then we do the call for adoption does that make sense it's current oh do you do you want the the call for adoption to be the one that has the change okay oh it doesn't okay I think it's I think it's probably cleaner you know clearer to just do the I mean if if it just did not know mostly just to avoid having um version thrash and Peter's GitHub but I mean let's go to the next slide okay sure the next steps uh so Jonathan's going to issue the call for adoption and then assuming it's adopted I'll submit the renamed uh draft the ietf data tracker and then what um let me see if there's still issues and if not we do working with us cool I think yeah okay I would ask it is there uh other implementation plans for this"
  },
  {
    "startTime": "01:56:02",
    "text": "that's a good question um yeah this does seem like something we'd want to have running code for just to write sure about it right okay that's good feedback foreign that's all I got okay in that case I think we're done with anybody else I think we're uh done for the day um I guess we should we'll go over the minutes and make sure we've got all the action items and so forth any other final words thank you and we'll see you all at itf118 thank you all thank you"
  }
]
