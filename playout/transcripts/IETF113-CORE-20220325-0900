[
  {
    "startTime": "00:00:09",
    "text": "and now we are on top of the hour so i think we can start welcome everyone to this uh co-working group meeting at ietf 113 hybrid after two years or so it's nice to be here and i've seen you again uh on site i am marco tyroca my co-chairs are jaime jimenez and president boardman you can find in this cover slide also a new resource for the working group the zulip stream so of course as usual you assume people to have read the documents to be discussed today in the agenda please do your best to use the allocated time in the best possible way to discuss um issues that benefit from face-to-face discussion the not well applies and slide comes later the blue sheets is collected automatically through meteco carson will mostly pay attention to the chat and jabber and we have ricardo hogland that volunteered to take notes thank you very much anyone is welcome to help him out and of course this this is an officiality of meeting then not well applies uh please get get familiar with that if you're not already it's not about ipr and patents it's also in the special about our code of conduct so be nice and professional with one another right we are on friday so probably you have seen this many times and you are masters of this already but the meeting is recording and it works in a particular way for in-person attendees you have to be signing me taeko to be able to build a single queue for the church to manage and to be counted in the blue sheets and so on uh you can do that using the light version from the agenda and the data tracker if you still want to use the full version please"
  },
  {
    "startTime": "00:02:01",
    "text": "keep audio video off and as to join the queue you have to join the qmi takeoff first of all before going to the mic for remote participants this work pretty much like it has worked in the last two years if you cannot use audio at all just type make on the chat to ask for relaying your question all right this is the agenda uh for today it's pretty packed so uh please try to stay on time and shares will be sure that happens uh we start with a bunch of working group documents in the first half of the meeting meaning href conditional attributes group communication for co-op or group combis and then the group of score document and the key update for oscor on kudos document and then we continue with uh three non-working group documents transport indication on traditional responses and dns over co-op before we continue is there any agenda bashing that anyone wants to propose here in scene none then moving on and usual update on the document status in the working group so double reason to celebrate in the recent weeks we have uh two documents published as rfc um 9175 that used to be a echo request tag thank you very much as usual to the authors and the working group for this and a few days ago only also 9177 was published and used to be a new block thank you very much for this too awesome yes [Applause] and similar news should come anytime soon about two other documents that are still in the rfcq but one is all 48 done"
  },
  {
    "startTime": "00:04:02",
    "text": "even as ml data ct and the resource directory is in out 48 and waiting for very final touches as far as i know before it can proceed for publication and we have two documents in isg processing uh young cyborg and sid so young zebra is really almost there there is one more comment uh to be addressed and all should be concluded next week and for c there has been a lot of discussion also in a side meeting yesterday between authors and the id on a final discuss ballot to be addressed and this requires some more text to be added but that should happen also very soon all right and then a bunch of documents post working group plus call meaning the other two documents of the quarkon clusters that just waiting for the first two uh ones i've just mentioned before they can actually go under shepherd write up and then we have the group of score document that has passed the second working group call and should be ready to move on but we have a presentation about it later today and that's all for the document status unless there are any questions comment on that then we can start with the actual presentation and that's on cars then for href okay so this will just be a quick status update the draft is called href the subject of the draft is the cri the concise"
  },
  {
    "startTime": "00:06:00",
    "text": "resource identifier which is essentially concise equivalent of the uis sorry to interrupt your mic is pretty noisy it worked better when you tested it maybe it's just noise distance almost breaking up yeah okay that will be my internet access this is provided by the german telecom okay still understandable that's right ugly okay um yeah just tell me when i'm no longer intelligible um so the idea is that your eyes and your references which we love so much um actually have an underlying data model that just has to be discovered and we can provide a concise representation format for that so that's the point of this draft this has been originally started by klaus harker and right now we are just trying to finish that and there have been a few uh updates since the last itf dasher 8 was the iit f112 version where we had added percent encoded uh text and there have been a few tricks to that in dash online we also did an editorial step by by moving all the yeah weird stuff into an appendix the small print appendix that you probably only have to read if you're actually implementing this and in dash 10 we finally added the last ui component that we so far hadn't supported the user info structure this is the thing that comes in an ad design before the host name and that is really bad if there is a password included so that that feature"
  },
  {
    "startTime": "00:08:00",
    "text": "is not um part of dash 10 but the user info itself is occasionally being used so this is now also possible to represent and a few more editorial inferior changes and we also have a separate cdda rule for both cri and ci reference because in many cases you really just want cis and so you don't need the full cia reference production what i'm doing right now is implementation work so there are four implementations that i'm aware of in four different languages and well if you implement something you uncover little issues so this is exactly what's happening right now and in the process we are also expanding our collection of test vectors so there will be a connection that all these implementations support and that new implementers can use that as a reference to test their implementations but really the implementation the objective of the implementation is to exercise ci in a number of contexts and that's of course coral which is what ci originally was developed for but also in the context of various uh data formats that use queries and we need to make sure that these work well with um the eyes which is not too easy because curries are really just a synthetic on your eyes so they do not map to the data model um at all so we we have to provide some some help for that and that is of course also in"
  },
  {
    "startTime": "00:10:00",
    "text": "the context of sibo packed where we want to make sure that the cis can work well with sibo packed okay and finally where we are we have five remaining issues on the repository we have one pr on the text of the document we also have two more pr's on the test vectors i think that that's maybe something the implementers can decide among themselves but the other things really could help i could use help from the working group so if you occasionally maybe can look into core working group href repository maybe watch it so you'll find out about new issues and comment there that would be really helpful my personal estimate would be that we probably need about six more weeks to do this implementation uh work and then maybe one more interim before we actually can get all these little issues laid down um as well so look into the issues list on github to see what these nuclear issues are um yeah we are no longer having really big questions but the the small ones need to be answered as well so that's my summary thank you carson any questions comments okay do you plan an actual revision submitted in about six weeks or so or even some discussion before that happens well one or two revisions until we we are done with the implementation testing and then maybe we can do"
  },
  {
    "startTime": "00:12:01",
    "text": "another revision after the interim sounds good okay see no questions in the chat no one in the queue i think we're done with href thank you carson thank you okay uh next in the agenda is bill hi bill hi can you hear me now yes very well thank you yeah i might have some audio trouble so if you suddenly see my audio cutting off then okay okay i'm gonna start video uh i hope it's coming through yes okay and see you hello everybody in vienna and remote couldn't join you this time but i hope to do that next time so i'm going to share slides now it's coming up please let me know if you can see this we can see them go ahead good so everything is good to go all right so again uh good morning everybody uh it's a very small presentation that i have so this is about uh the conditional attributes draft for um core and uh and this is just delta from what had happened from the last interim meeting so the last interior meeting we actually resolved a lot of issues um at the moment there are no more github issues um and uh there was uh some um resolution made on the value of the band attribute we included some text about the proxy considerations inside the implementation considerations part uh there is security considerations done but then during the last interim we"
  },
  {
    "startTime": "00:14:00",
    "text": "actually had a small chat about um what more could be done in this draft before it goes for working through glasgow so this is what i'm here for uh firstly there was a um a request that that perhaps the term attributes or conditional attributes um could be explained a little bit better uh and perhaps put it into his own section but considering the the whole draft is about um attributes it felt a bit weird so i um the introduction of the the draft so that um i try to clarify uh what conditional attributes are so um the old specification define contribute conditional attributes uh as just providing fine-grained control of notification and synchronization with core observe and there was some artifact about resource interfaces blah blah blah and then there was saying that a resource marked as observable in its link description should support this control attribute so i i recrafted that text and um um initially i essentially i basically put that this is this is for use with call observe but also um it's um how how do you actually convey the the conditional attributes so so using the query component of a quad uri and it can be either a name value query parameter or then um just a name without a value and and we we are able to um essentially describe the resource using multiple conditional attributes um please uh let me know if that is uh not okay i hope it's okay and um and this is already in the in the current um working group no sorry the current editor's draft um it hasn't gone into the into the newest version um and um once everything is done once you have good this then i will resubmit the new version hopefully that will be the last one before working group last call so this is this is basically the"
  },
  {
    "startTime": "00:16:01",
    "text": "the let's say the editorial the last editorial which i'd like to do um one more thing that came up in the interim meeting was um the the fact of whether we need a registry and what kind of registry does does this draft require so uh in the inner construction section i had um originally included in the last version of the draft conditional attributes registry to uniquely map these names to what they really are but then the discussions came about whether this is necessary and what kind of registry we should have um there was some discussion on about whether there's a you know what the pros and cons um so obviously it would be nice to have registry to to remove the integrity of how this can be defined and that the direct let's say um implication of this is that some of these names are used in in different contexts in in different places so for example lte is used in the conditional attributes draft to mean less than but then lt is used in the query parameters i think in in the resource directory to mean lifetime uh so and uh resource directory actually already defines the sub registry for rd parameters to to describe lt's lifetime so um that's that's one thing that i i'd like to resolve today um obviously i don't really mind going forward that the draft never actually had a registry before but it would be great to to um to get some resolution on this um and also the discussion was whether it makes sense to have a more general uh attributes registry but um the one let's say the one caveat to this is uh i'd like to just call it rfc 80 20 88 20 so to describe why we should not be doing that uh because it it we don't want to use up the um the use of these uh attributes in in other kinds of"
  },
  {
    "startTime": "00:18:01",
    "text": "uh client other clients that may not necessarily be using this so um and then specifying more elaborate structures to avoid these collisions is not really an acceptable solution so you know it's it's if we can go if we go generic then i i i feel that perhaps it will really um complicate matters but um on the other hand i i know that um there are experts in our group who probably will know how to deal with this better than i do so this is why i'd like to put this to the floor today have a discussion about that and then take this forward and hopefully resolve it so quickly that we can go to the last call uh so that's all i have actually for today so um please if anybody has any comments let's go go ahead yep um i just thought about this especially this example of lt yeah i think if it's used in a particular context like resource directory uh it should be no problem that it's reused for something else right in another context so you cannot rule that out it will happen in this way so that seemed seems to be fine although it's of course better to look at what others use and then try to uh yeah try to use more inconvenience uh where possible yep so i i agree with that i think that it's it's a it's a good in my opinion i i my personal um preference will be to to introduce a new sub registry for"
  },
  {
    "startTime": "00:20:01",
    "text": "specifically for this purpose um without uh impinging on the use of the same attribute space in in our career parameter names in other applications uh i think it's clearer but um if you if you the rest of you feel that perhaps a registry is not needed then then we can easily audit that as well in the draft and then move this forward christian are you on the queue or if esco hasn't yeah all right kristen yeah because then i'm just um i'd like just like kind of i don't have a particular opinion on whether a registry structure makes sense but i would like to point out that just because the one thing is used for observations and one is the resource directory doesn't mean that they might not overlap because especially as it is phrased now with everything that is observable um should support the attributes a lot of things in the resource directory are observable um not partic not particularly used with the less than and lifetime but in general you can find things in the resource directory and then look it up so these things might easily need to be combined are you um christian could i trouble you to to say that did you just imply that when you say these things might need to be combined are you implying a common sub registry for both because that would require some considerable thinking if lte is used for example even live with m2m already so i've i have i i don't i don't know whether whether it comes up if if you go for regis for actually registered things then probably doing this across applications makes sense but that might also be a point why not doing a registry in the first place"
  },
  {
    "startTime": "00:22:00",
    "text": "would be a thing to consider but then um these things would be combined like by the particular buyer server and then the server could just not combine this and that ext um component just because they have overlap conflicting requirements so maybe that a registry would also not be something that is completely normative in the sense that as soon as one of these elements shows up um these semantics are implied but more um something for coordination between components where they where each component would still uh where the the particular arguments would still um that the semantics would be opted in by the extension for example resource directory of or conditional attributes but just seeing which names are in used allows our news allows the authors of these extensions to make a more informed decision on which names may not make sense to use here because they might get into conflict with something else so it's it's not a red it's another registry that has where as soon as you see the name it has a meaning but more when you want to pick a name then you may look there and see where there is no conflict yet okay thanks thank you ask you're out you're still on do you want to say something yes go ahead yeah i just want to react on that so yeah i think the example that christian mentioned uh shows that there is a kind of real risk of uh clashing of these uh attributes especially uh yeah if the draft now says that any observable resource should support these attributes uh maybe the resource is already uh supporting other attributes and there could well be a clash of course in the"
  },
  {
    "startTime": "00:24:00",
    "text": "names of those so that's something to to consider i think if it's uh if it's a resource like something like a temperature value that doesn't support any other attributes then it's fine to apply those conditional attributes but if it's something like indeed a resource directory resource that's already using uh attributes with same names maybe for something yeah something else then yeah you immediately have a problem if you want to combine those things and and i don't think you can actually apply all the conditional attributes in that case so maybe yeah require some thought if there's a way to resolve that or uh maybe it's possible to yeah while discovering resources to uh to see if a resource supports the conditional attributes or not that would also be great but i'm not sure if that's already defined well i mean the the drug does not say that you must support these attributes you just as you you should so you don't necessarily need to have that the collision at all but the client needs to know probably is uh like are these attributes supported or not uh yeah before it rises usually i think for for for observe it's usually best effort you you don't necessarily need to know that i mean it's um just like just like for example if you if you try to set pmin or pmax it's it's kind of like a request to the server so the server can choose to ignore that uh we don't necessarily need to um enforce it yeah could we ignore it so you get more basically the ideas if it somehow fails you get more notifications than you uh yeah ask for in that in the fallback uh situation yeah exactly yeah at least if if the server accepts that so it could also respond with an error of course if it doesn't know those"
  },
  {
    "startTime": "00:26:00",
    "text": "new attributes so that's that's why i said maybe it's good to have have it potentially also discoverable whether the resource supports these new attributes or not if there's a way to to do that so i think uh core discovery has some various ways to mark like an interface you can mark for the resource so it supports this particular interface for example that could be a way but yeah that's just a thought thanks okay thank you carson so um of course there is also the problem of forward capability compatibility here um so if an application already uses foo and then we register for we have a problem so one way to reduce that likelihood would be to define a namespace for conditional attributes so anything that starts ca dot or ca is something that that sensor application wouldn't use because it might be used for a conditional attribute i'm not sure i'm suggesting this but i want to bring it up as a way to make forward compatibility more likely yeah yeah so actually that's the reason why i put that that sub bullet point that this namespace issue was not um was discouraged quite strongly in the rfc as well so uh that did occur to my to my mind as well that would would that be a possibility but but then i don't know if we really want to go down that path yet well you're talking about application namespaces i'm talking about the namespace just for the condition attributes which would not be a surprise and wouldn't clash okay well that's one one option then if you really want to go with the yeah"
  },
  {
    "startTime": "00:28:01",
    "text": "if you want to prefix the parameters with something else but uh okay listen i'd just like to emphasize again this has been said earlier in these discussions also the query a uri query option is a critical option and in general an application will not just ignore something just because it doesn't know it because this is a critical option the practice of ignoring query parameters has in my understanding come from php just php applications just usually not doing this and a few other implementations of web servers but that doesn't mean that a client can just make up the same the uri and add a query parameter and then just hope that it means the same unless the server says otherwise okay it appears that the queue is closed marco so yes an interest of time yeah we are back right on time by the way okay so um so thank you um we will take that on board and then prepare the next version and um um we'll take this the mailing list perhaps the next interim as well what's your timeline for the next version as soon as the uh the queues open i think i'll put in the next one so this is now um i think zero three will be will be perhaps latest at the before the next interview meeting hopefully i can i can come then present the next one that'd be great it's the 7th of april by the way very good one month thank you sticking now thank you very much thank you okay so we are exactly back on time again and"
  },
  {
    "startTime": "00:30:01",
    "text": "the next presentation is group combis from esco please go ahead let's go so hi marco good to see you and and everyone else in the audience uh yeah i hope to be uh yeah at the future my itf meeting at least uh one more one more time or multiple times but we'll see so this is their presentation about communication for co-op the group called this draft yeah what i will do is show some examples of recently added contents here so i assume that everyone is roughly familiar with the topic of the draft so it's basically a normative draft that specified how to do group communication in co-op and adding basically adding more content to what was described in the original code rfc also particularly security is also added using group oscar all right so i'll tell you about what happened so after the last itf meeting and the interim meeting we did a lot of work in adding examples there were also two open github issues for that so the examples we added are for uh basically how to encode an application group name within the co-op request to make that more clear and also for the discovery there were some clarities about that so how to discover co-op groups and application groups"
  },
  {
    "startTime": "00:32:02",
    "text": "directly on the co-op service so if you don't have a resource directory available but you just want to do it using co-op discovery how would you go about that so that's kind of illustrated with examples basically a lot of this is application specific but it's good to uh have examples for that but you know yeah approximately what what what you can expect there also new appendix was added so these are message exchanges for group communication just showing typical uh yeah group communication flows like a basic one one with observe and one with block wise transfer second bullet is here a particular change we made was of removing the uri host option to encode a group name so we initially added it because of a comment in an earlier itef meeting but uh yeah this gave some confusion uh and yeah if you want to resolve that it becomes very complex so we decided to just remove it it was a kind of uh yeah creative use of an existing option to do something else so that we thought well let's not encourage that particular usage so it's better to just remove it here uh also a lot of text and editorial improvements were done and now all the open issues are closed so next is to show some examples from the new version six draft so what we have now so this is example for section two to one so that's about name encoding of application groups and here you see a yellow mark this application group name and how it is encoded in yeah co-op request in the uri and in the actual co-op message options"
  },
  {
    "startTime": "00:34:04",
    "text": "and yeah the second box is a second example of the same thing a little bit more uh compact carbon pressed in this case so that's pretty straightforward there are more examples in the draft i will now move to the next slide so it's for another section about discovery so this was the discovery without resource directory that i mentioned and the idea here is in this example that you have as input co-op group that's a known entity also marked in red and a client now wants to discover what are the associated application groups to this and what servers are in it yeah basically and also discover the resources that belong to that group so what you can see here on the in the box an example is that the request is sent to the group with a query looking for specific resource types that denote a group so that's in this application specific example that's the g dot something is the resource type for a group and as you can see two servers are returning responding basically with their groups and marking a particular type of group so basically this is discovering the the likes like you say the entry or the root resource of the group if the client wants to do more resource discoveries of what are the resources within that group we can just do a second request that's not shown here but to get more details okay what are the resources within a particular group that are supported all right then moving to the next example so it was the"
  },
  {
    "startTime": "00:36:01",
    "text": "appendix that [Music] was added about message exchange this shows a basic example so a client sends a multicast co-op request to a b and c and all of those respond with the unicast response one of them is lost and there's kind of a special twist in here in this example you can see that client c is responding from a different port that is just to illustrate that yeah this is kind of allowed behavior that's specified by co-op so for yeah these multicast requests the source port of the responding server is actually not not used in the matching request to responses that happens in clients so the server could use a different source port as is shown in this case okay and there's more examples so i'll show uh one more that's with a more advanced example much longer so this is the blockwise option you can see that in yellow so there is a block option in the request and also in the responses so you can see the servers all supported and we'll send back the first block of the resource that's being requested in this case it's a log resource so you can expect that it can be rather big on the next slide that example continues so now the first block is in so what does the client do the client will basically use unicast clockwise transfer to basically go to each of the servers and then fetch the rest of the resource that's also shown here this is all uh content coming from a and then the example continues we'll go to the next next slide and it's the same for b so from b also the"
  },
  {
    "startTime": "00:38:01",
    "text": "content is fetched so for details you can also look look in the draft and this basically concludes what i wanted to show here [Music] one more thing that's the next step so we don't have any current updates planned all the issues are closed and so that's why we think it's now ready for the working group last call to be done at some point for this version zero six but if there are any more issues found of course before that we're happy to to work on that as well okay thanks any questions so there was one observation on the chat that maybe ui ui host wasn't as bad so can you maybe quickly recap why why this leads to complications yeah i think the the point was the uri host option is also related to the parsing algorithm that co-op defines so you get this input uri basically and as output of the parsing you get multiple co-op options [Music] so the the argument for for including an application group was that um basically you do not include it in the group uri but after the parsing you you add in the uri host you added additionally so it's not included in group uri and that's that's that's obvious yeah that's kind of changing the yeah like changing the"
  },
  {
    "startTime": "00:40:02",
    "text": "parsing algorithm almost there or yeah doing something after that and that's yeah okay let's take it off it gave so many discussions that yeah it's maybe best not not to mention it at all uh i mean why why would it doesn't really help then okay christian i can't stand here so for clarification the the way of naming the group just with the uri host is still fine as long as it's just in the group uri so if it's in the group uri that's a way of naming it but not adding it like sideways okay thank you yeah that's still allowed yeah but then it's uh also um because it's in the authority component it becomes the co-op group also so that means in that case the application group and the co-op group are one of the same and they are identified by the same information item basically so that's that's the point and we wanted to to basically encode a different application group name in the uri host option so that's what makes it confusing actually yeah okay okay thanks thank you oscar any uh reaction from the chair so what do we do i leave this to kirsten of course yes so did you want me to say something about that"
  },
  {
    "startTime": "00:42:01",
    "text": "yeah we will leave to you about the concrete next step to take if you think this is a problem right now well i to me it seems that we we are ready for a new place for it so that without people to the fact that this spec is done and they should be reading it so that sounds like a good next step to me okay you okay uh next presentation is group of score and it's on me so carson if you can drive the slides that'd be good at least i moved to the presenter mic the amount of mouse movement that is needed to do that it's amazing one second [Music] hey do you see them are these those sides yes thank you okay this is marco uh this is an update on the latest version of the drupal score document next slide please right the document underwent a second working row plus call and based on that we submitted version 14 wait for the cutoff and this was based on two reviews um we got during the last call uh from esko and rickard thank you very much indeed for that there were very good comments and escos came uh first in two parts uh the the main actual comments followed by a separate mail with editorial needs so we worked on those first and we're also objective discussion at an interim and rica reviews uh instead came on the editor's copy produced from processing esco's review which was very convenient to finalize the document"
  },
  {
    "startTime": "00:44:02",
    "text": "next slide please so this is a summary of the uh main comments from esko's review that we uh addressed uh in through different incremental steps so there was first a proposal of overall direction to take on those on the list uh the most controversial delicate points were discussed at the cone interim and it's basically those listed here so we enforce the clear-cut distinction between authentication credential and public key in terms of terminology and phrasing around those uh and then it was also a point about clarifying the trade-off between uh storage over and convenience for for storing uh whole authentication credentials uh one very delicate point was about making uh optional the feature at the group manager to recycle group ideas so that a group can live forever in principle still in a safe way and there was especially important to well confined uh this optional feature in in a very self-contained section so that it was clear to be uh something optional for the group manager to support so that's all the case now and exactly about these point uh there was a further confirmation um on the list and finally a number of points related to what was uh mandatory to implement support and whatnot rearrangement of references to be appropriately normative or informative as the text uh citing those um and the yak option used for uh synchronization of sequence number three challenge response moved up to the document body you find more pointers in in the slide next slide please yeah and this is actually it we believe that the latest version of the data"
  },
  {
    "startTime": "00:46:01",
    "text": "tracker uh well addresses uh the working classical reviews and we had actually confirmations about that on the list uh we are not aware of any other open point or or issue specifically on github so we think the work on this document is actually done for a working group and that it can proceed with the next step meaning the shepherd write up in after uh some discussion we we found out that christian amsas is available to uh act as shepherd for this document that we really appreciate and that's all from my side thank you so one quick question um what is the web of normative references you are enchanted in it is group combis and the cozy documents that hopefully will be uh uh yeah published anytime soon they are not 48 for a while now but except those if i remember correctly it's only grouped on this and well those documents have to proceed in parallel anyway because they are mutually referring each other okay great thank you okay there's no other question or comment i think we are done with this topic thank you okay and the next presentation is about kudos from ricard and from now on all presenters are on site by the way"
  },
  {
    "startTime": "00:48:00",
    "text": "so you you do this slides no i got those slides yes i will share them here from the phone version yes okay go ahead yes thank you right so i will be presenting this draft today key update for overscore kudos and uh yes my name is riker herglund so yes as a content recap of what this draft actually contains it has basically two parts and the general challenge is that oscor uses these aad algorithms to provide security and in order to do things securely you need to follow a number of limits when it comes to number of encryptions and failed decryptions before you have to rekey the keys that you use for message processing because excessive use of the same key can enable breaking security properties of the aea the algorithms and there's a reference to a document in cfrd at the bottom right where you can look more into this and so essentially this draft has two parts the first part is about the aad key usage limits in os core where we define appropriate limits frost core for a variety of algorithms and this basically means that when these limits are reached you have to rekey um the keys that you're using and we also define like how can you practically have a counter for the key usage how do you change the message processing compared to vanilla score and what steps then should you take when the limits are reached and the recent update here was that we recommended a new set of values for the qv and l for the as128 ccm8 because that has to be handled separately from the other"
  },
  {
    "startTime": "00:50:01",
    "text": "algorithms since there the limits has to be lower basically to get acceptable probabilities for um security but today the main focus will really be about the key update for our score procedure and this is a procedure that's loosely inspired by the appendix p2 of os core and the goal is basically that well when you reach this limits then what you want to do is renew the master seekers and master salt and from those you want to derive a new sender recipient key and one good thing about this procedure is that you achieve forward secrecy and just as a recap on how this actual procedure works you can see here on the right hand side the message flow but the general idea is that the client and server exchanges two nonsense r1 and r2 and then you have this update ctek function which takes this nonsense as input to generate a new score security context and but we also did we extended the oscar option to have a place where we can transport these nonsense so now we have defined this bit d and when that bit is set there is an id detail field added to those corruption so you have the id detail and you have x which is the length of the id detail but the purpose of the id detail is essentially to carry these nonsense back and forth and you can see that also to the right hand side that the idea holds the nonsense and now i go into a bit more detail on updates that we did or additions that we did from the latest version of the draft so one thing we added based on discussions and feedback and also discussions on the core mailing list is a mode of kudos where you do not have forward secrecy and the point of this is that you need"
  },
  {
    "startTime": "00:52:01",
    "text": "to be able to support a stateless key update because if some device loses state like for instance due to rebooting and it cannot store information to persistent memory which may be the case for some constrained devices it still needs to be able to run a key update procedure and the in fact the the original version like the appendix p2 procedure that oscar defines does support this stateless mode of operation so what we did here was we add an extension to kudos basically that there is now a way to by having yet another bit this p bit you can indicate if you want to run kudos in the mode with forward secrecy or without forward secrecy so if this p bit is set to zero you run it in forward secrecy mode which is the original mode and um if you are capable of writing to persistent memory you should use the forward secrecy mode so it the the knob for a secret mode should really only be used by devices that have to use it because they cannot write to persistent memory yeah so if the b bit is set to one then that is an indication you want to run kudos in the no forward secrecy mode and we defined some concepts related to this so you have like two sets of key material basically like you have the latest master secret and latest master salt and this is the information from your last most recently derived score security context and this you should store on disk if you are capable to do so then you also have the bootstrap master seeker then bootstrap mesh assault and this can be information that is pre provisioned to the device at manufacturing and this is information that the device itself would never change right and if you want to run kudos in the no forward secrecy mode basically what the difference between the current definition of kudos that we have is you do this modification that the security context uses input to derive"
  },
  {
    "startTime": "00:54:01",
    "text": "your new security context you simply replace the master secret and master salt in that with the bootstrap master secret and bootstrap master salt so your starting point is always this bootstrap information and because of that you sacrifice for a secrecy but you still have all the other properties for kudos remaining and now there is a way like for instance if one device supports writing to disk and the other device does not support writing to disk well the device that takes initiative if it can write to disk it will try to run kudos in the forward secrecy mode right um so it couldn't be the case that the initiator tries to run it in for a secrecy mode but the responder is unable to continue because it cannot practically write to disk so it cannot remember and store the latest key material but in this case we have this agreed downgrading of mode so basically if the responder is a server you return a protected 503 error message with p set to one to indicate yeah i want to run it in the no forward secrecy mode and if the client is responder you can send the protected request to with p set to one but basically if you attempt to run kudos and the other party responds with the p bit set one saying i want to run it in the no forward secrecy mode you can simply try yourself with the p bit set to one so at least you can run it in common so you basically have to downgrade to the device that has the least capability and yeah here are some open questions if this is a reasonable approach and if there are any comments or if this and now basically we have this in appendix actually and to as a suggested way to do this and so one open question is also if this could be good to move to the draft main body uh joran yes uh can you hear me yes"
  },
  {
    "startTime": "00:56:00",
    "text": "so i'd like to thank the others for for doing this this work i'm i mean there's plenty of updates here this is just the first one and i think this is a really good good part uh that we should keep and move up to the body i could see many settings where this is useful uh you could have i mean if you could use this not only for things that are masteries manufacturers that it could be things like uh afternoon printing you could fill this bootstrap master secret with with the result or it could be the result uh after and provisioning through the ace oauth framework and it could be used uh in in the reset button settings so you could i mean even if you have both both the bootstrap master secret and the uh the latest master secret fields you could have a reset a button for example which means that you pick from the bootstrap master secret register if i understand right and and that i think it would be really useful um so this gives a lot of options there's some security considerations here you obviously need to integrity protect the field but you have you're coming to that in the latest line and and also to to handle the situations when you have i mean there are a number of cases now p equals one and zero and existence of these whether you support the boost trap master secret or not but i think that's not not overly complex and that's this looks good yeah thank you thanks a lot for the feedback on that yes uh carson yeah i also think this is a nice work i have a pretty trivial question how often can you use your bootstrap master secret can you repeat how often you can use the booster plaster secret yeah so this is just another key and"
  },
  {
    "startTime": "00:58:00",
    "text": "there is probably a limit to how often you can use it yeah we haven't really done any security analysis on on that for now on how many times you can use it until you really have to change also that but that's i think it's a good good question something we can we can think about a bit deeper yeah so your assumption was you cannot change it so essentially you have to throw away the device when yeah i mean we are something well let's put this way our assumption was that device itself cannot change it so like the device itself couldn't write to itself to change it but possibly through some manual intervention some a technician may be able to go and change it okay and carson i think uh and the authors i think this is not a big problem i mean in the sense that i mean assume that you have a good entropy of of the bootstrap master secret and what what happens at the key update is just that you're adding nonsense so yeah so so you shouldn't i mean you shouldn't really have a problem uh as long as the original entropy of the of the bms is large enough it should so that that i mean it bought it what you say boils down it it falls back to the the assumption of the entropy of the of the secret key yeah i'm just interested in this because if if it's a limited uh number of times you can use it then of course it becomes an attack vector for the u.s attack so you have to be aware of that vector yeah and there is a limit yes but that limit will not be the limiting factor in this correct okay thanks a lot for the discussion i think i will proceed to the next section then um i don't know how many"
  },
  {
    "startTime": "01:00:03",
    "text": "so now another addition we did and this is also in fact added to um an appendix in the draft is how can we keep observations around and this has been something we discussed in earlier meetings also so basically there is a problem that we identified and that problem is if the client starts an observation let's call it ops one by sending a request direct one with the request pivx and then now after that the two pairs run the kudos procedure and reset the sender sequence numbers back to zero and later on while this observation is still ongoing now the client sends a new request rec2 but this also uses checkpivx because the client restarted from zero it's partially it's under sequence numbers so the problem here is that now a notification sent by the server for the observation one or a response to request two would both cryptographically match against the request one and request two and essentially because they're using them they're using the same request pov in this case right so we needed a way to avoid this um accidental use of the request piv for open observations so what we do now in appendix is we define a method where you do this jumping we call it long jumping beyond the partial levees that are already in use for observations and more information on this is also on the next slide and we also now propose to have a new bit b that you can actually use to signal interest if you wish to keep observations or not and of course if both parties do not wish to keep the observations well you can simply discard them every time you do their keying there's no need and to keep them but if you wish to keep them you can indicate it with this big p sorry bit b so what is this long jumping method it's basically that when you want to send the first request after you did the key update kudos execution"
  },
  {
    "startTime": "01:02:01",
    "text": "the client should determine the partial av which has the highest partial me iv among all ongoing observations and the point is that you wish to now set your sender sequence number to that value plus one so you jump beyond this so there's absolutely no risk that you will be reducing that partially that's already occupied for an ongoing observation um but then we identified after some discussion like a sub issue or related issue to this which is that to remove ongoing observations the client needs an explicit confirmation from the server because otherwise the server may still consider observation to be open so what you do if this client cannot get the confirmation the worst case these observations would be around forever and you would always have to jump to a very high sender sequence number or partially however we now define this epoch counter so for each ongoing observation you have an epoch and when this apple counter reaches the max epoch you can both parties delete the observation and this counter would be incremented every time you do the key update right this is like to reduce the risk that you have observations staying around forever and always forcing you to jump for a head in the piv space so in this case it would be a guarantee that let's say the max epoch is three then after three kudos three year keying executions you would guaranteed to have deleted that observation and both sides do that so now the question here is like for instance what is a recommended a good value for the max epoch and we're also yeah any kind of commentary input on this and one thing we were thinking about it if it can make sense also to have like um a negotiation within kudos where you can mutually agree on the max epoch uh there's euron in the queue euron yeah thank you yeah i i i'm a little bit critical to this i now have read it a little bit more in"
  },
  {
    "startTime": "01:04:01",
    "text": "detail so i'm i'm not really sure we should do this at all but i'll provide since we're running out of time here i did not ask those questions now but um yeah i think this is maybe a little bit engineering too much something that we should first understand if we need to do so i'll get back on that yeah fair enough thank you thanks for the input uh try to take about five minutes at most for the remaining yeah thank you i um yes so i'll go through it a bit quicker and so one other thing we added was the ability to renew the sender and cpid recipient ids on the pairs so we have this now in appendix d and it's basically a procedure where um you say as a pair okay i wish to use this recipient id and the other party says which new recipient id it wishes to use and when you have then you basically you generate new contacts based on those new recipient ids and you can continue the communication with new recipient ids on both parties and this procedure can also be embedded in a kudos execution or run standalone so we defined a new option for this it's just the recipient of the option again the idea is pretty basic in there you put what recipient id you wish to use in the future and the other party does the same and here's the message flow so basically what you can see here is the client starts with a recipient id of zero now in request one it includes the recipient id option indicating 42 in the response the server indicates that it wishes to use 78 and at the bottom then you see that both sides have generated new score security context and now the client in fact is using 42 as its recipient id there and the server is using 78 so they have actually successful transition to the new values"
  },
  {
    "startTime": "01:06:01",
    "text": "and again any feedback objections or alternatives is very welcome here yeah again just a brief i think this i don't see any problem with this but i'm i haven't seen the compelling use case that's one one comment and the other comment is that this must only used when it's protected with the previously established security context so it's not enough that austria is being used it has to be previously established security context but yes there are some exactly like you should also not run it after a reboot for instance because yeah there are some restrictions on safe ways to use this uh which i think we also cover in the text yeah yeah then it's not the previous established security context so that's exactly right one reason okay thanks okay um and then i had this final part which is about so throughout this draft now we basically defined three new bits one is the id detail bit itself to signal the inclusion of the id detail in those corruption then we have the no forward secrecy bit p to signal the use of the node forward secrecy mode and then we have the observation speed b so we now first of all the id detail bit that is placed in those corruption as you can see there to the right but then the question comes okay where do we put the bits b and p to also provide integrity protection of these bits so our idea and proposal now is to put this this is based on on feedback and discussions and i know crystal gave a lot of input on this so the idea is to put these bits in the byte x which is currently the length the size of the id detail so we take two bits of the x field to encode this bit b and p then we still have six bits remaining in x which is sufficient to describe the size of id detail and the point here is also now what we do is we take the x value as input to"
  },
  {
    "startTime": "01:08:01",
    "text": "the key derivation procedure to achieve integrity protection for the bmp bits yeah and then just a quick summary and next step so what did we do in this version we suggest now a way to do a key update without forward secrecy defined in appendix e we suggest a method for preserving observations across key updates suggesting appendix c and we all started yesterday procedure to update the overscore sender recipient ids defined in appendix d we propose an alternative placement for the signaling bits then we did some general improvements in the massive processing and also nothing i didn't really cover we have a document an optimized way of count storing the count q variable which is basically related to the limits that you have to count the amount of times you use a particular key and that's in appendix b and yeah our plan is basically to address open points and issues we have a number of issues on github and feedback is very welcome and we also want to move the suggestion we have added now to the main document body of course taking any feedback into account and um yeah then we also want to basically do an implementation on this based on an implementation of what score we have in the java californium library so thank you and any comments or questions are welcome signal in the queue nothing in the chat in interest of time unless they're very compelling points to raise now i think it's pretty clear how to proceed yes chris okay no we can continue discussion at least or definitely otherwise thank you thank you ricard and the next is christian with transport indication"
  },
  {
    "startTime": "01:10:00",
    "text": "can you hear me yeah i had to clear up hello everyone my name is christian amsas and i would like to i think transport indication is next um there you are oh that's sorry sorry this sorry picked the wrong one yeah okay protocol indication that's the right one okay um what i'd like to do here right uh today is give you a brief summary on the on the topic because we've talked a lot of in during interims and gone into details there but i think what will help be helpful for today is to talk about what this is and what that why why why this needs to be done and what other challenges and solutions uh conveniently the secretariat has been providing these small badges and this roughly sums up what this draft is about that is everything before the before the authority in the component um of the co-op uri might have different values so the typical examples that we see are co-op over udp and code over tcp but really this applies just as well to couple web sockets um and any of those transports that have been around in draft be it corp over serial sms bluetooth and there are a few ideas around of people who want to do it over quick and that might be done through taps so maybe keep a look keep an eye open for that i'll be talking about udp and tcp primarily as placeholders here the thing is um the way if you if you look at a device that is concretely implemented what you usually see is that it has a few resources in there so an led and the firmware and provides different transports but what on the uri level it actually is is the one comes in through co-op over tcp that's called plus tcp column slash slash authority component and then some resources christian please don't go away"
  },
  {
    "startTime": "01:12:01",
    "text": "from your microphone grab it apologies and i'll just um point to the right half of things right okay and so these are distinct uris and of course a server may implement things that this server or this firmware over here on this firmware over there is really the same thing and most servers do that but at least uh at least from the uri definitions this does not follow so we might need to indicate what actually what the situation is and whether a client may just when it is doing cover or udp switch over to tcp and continue on the same resource now something we could do is to define that just for a particular set of servers uh just to define that for particular protocols these are the same thing um it is generally discouraged in in the context of your eyes because they might previously not have been and there are a few other problems like there could be cash entries that need to be aligned to that um what does it mean for security what does it mean kind of how identical can two things be if they are not accessed the same way and last but not least this would be a breaking change because exp existing implementations can already distinguish between the same resource as accessed through udp or through tcp so the current proposal is to not um is to to not unify these but rather to provide access to the resources on one side of the of on on one protocol through the other protocol and conveniently uh corp always really gives us all the tools we need for that because there is um there is the proxy scheme option and if a device is accessed with a query"
  },
  {
    "startTime": "01:14:02",
    "text": "with a request that includes that option the uri host option still has the same default value that it has already that is the vip address and possibly the port of the previous request and if they are as neatly aligned as cobo vdp and kobo or tcp are that is they have a host name and they have a port and that's usually the same one then not even that your ihos needs to be expressed so a device that wants to a client that wants to access the firmware resource over cob over tcp can just already do this in principle by just adding the proxy scheme option and then asking the device to act as a proxy to the resources that are even on the same device which sounds like a lot i mean we have to add proxy functionality but really what it is is the device must be prepared to ignore that option as long as um it implements the same resources on both on both protocols so reads like a lot um but really what it is is simple to implement and just adding a few bytes on the wire the suggested mechanism for advertising this is using web links which we already use for discovering and advertising anything else we probably don't want to advertise this proper this proc the availability of the proxy per resource because that would mean that if we have 15 resources we advertise 15 different statements so instead it would be advertised once per server and following the links that we already have the statement could be if anything is linked from that root resource which in practice things are because of the implicit rules of rfc 6690 then you may follow that additional link to find a proxy and use that proxy"
  },
  {
    "startTime": "01:16:02",
    "text": "now proxy is a co-op service and basically um mapped to a socket somewhere whereas all the things we can talk about in in web linking are your eyes so and we don't have a particular uri scheme that identifies a service running on a particular port the terminology which was sharpened thanks to klaus's input is now such that we still talk about your eyes so this green box is replaced with a with an actual uri indicating the root resource of that server but the predicate used there um says that this is pointing to a uri and what it actually means is put the put the transport and the and the protocol out of that and use that so so far this address is the the first two goals that is we introduce a mechanism that allows discovery and the other is that we don't add uri aliasing to a world in which it was not taken for granted so far um by the way if you have questions i think now would be a good yeah okay now might be a good time because i can take a okay i can't go back here because this is like the basic groundwork otherwise i'll just continue on with to the next um part here that is asking the queue actually no question i didn't see him let's go please yeah this question on this proxy statement so when would that be included if you do discovery so it's like every time you ask for anything it adds a proxy statement or do you have to ask specifically for something to get the proxy um this is so far not precisely"
  },
  {
    "startTime": "01:18:01",
    "text": "described my roth expectation would be that it is that it is done whenever there is something that looks like initial discovery but might warrant a few more words so especially with servers that provide a lot of different transports it can well make sense to narrow this down um i'll take that as an input for uh for for an updated version um to say something about which proxy statements make sense to um send unprompted and whether and how a client might express interest in them there is um providing so there is there are a few words on how a client can ask for them explicitly but especially with the lookup defined in 6690 and used also a resource directory that is really an extra query step with corel things might be a bit easier but then again we don't have the coral query format specified yet so that might be selling things that we haven't even um really hunted yet okay yeah thanks i see also use case here for uh clients that do co-op discovery and and get a big list of co-op s resources back so if you use this statement uh and the client understands it at least then then you can make the list shorter overall by removing yes of uh yeah overhead but that's only in link format i think yeah probably nothing that's generally good input thank you i'll take it for the next document version so of course this has security implications and i like to say that it's just really another proxy there is of course a bit more to it but i think that's just you should take um so if a proxy is advertised um this"
  },
  {
    "startTime": "01:20:00",
    "text": "way the general expectation of the client should be that the proxy can still provide credentials for whatever the original service was um so there would be no downgrade of security um there are of cour kind of this works really well and transparently if oscor is used this also works for tls um based connections as long as that proxy is as i've been describing it so far um really on the same device so if the same device just opens the tls port in addition to a dtls board it would just provide the same certificates there if someone wants to use advertised proxies over tt over t ls that are not in the same device that's pretty much out of scope for this document because it is very complicated and probably not worth encouraging there is of course the case of traffic misdirection so even if for example with oscar the connection is secure in terms of what oscar provides such a proxy could still be advertised to make the client send its data up around another services so that service does an up around through up through um attack so the attacker at least sees the traffic pattern um the latest version now has a few words on that um among other things saying that yeah if you want to protect against that you better also use dns sec and look at what routing advertisements you take because if you don't watch for that you might wind up in the same situation but basically it's up to the application which requirements to place on the statement because the fundamental security properties are already upheld by the requirement that the serve the proxy still needs to provide good credentials now so far this resolves the long-standing issue of"
  },
  {
    "startTime": "01:22:02",
    "text": "reconciling the various co-op plus something schemes and maybe that's enough maybe we just want to look into a few more things that the document also provides in particular that someone else might provide that proxy service for example a resource directory that allows cross-proximing between coop and core plus tcp connections and also we still send a few bytes more so on the on the pro on the proxy side this is rather straightforward because generally this statement can be produced by any other party in particular those that are in the discovery path and the rest is really up to the security requirements of the application uh the line on proxy usability i won't talk say much more other than yeah of course if there are clients or if there are proxies already in the same in this whole game things will still keep working on the topic of um optimizing away those additional bytes that we might have on the wire there is a specialization of that option that says that this that the host is generally not doing any name and protocol protocol-based virtual hosting if the host advertises this property then the client can just do away with that proxy scheme option that it would otherwise have to send looks a bit like a last thing on the wire i prefer to think of it as an agreed on compression um basically similar to schick because we establish a context although not um all not statically but dynamically and that context then says there is an implication that your ihos that you arrive um [Music] sorry that proxy scheme and your eye host are already always that"
  },
  {
    "startTime": "01:24:01",
    "text": "but the security implications are a bit harder to manage and there's still ongoing exploration on that which probably boils down to such statements only being acceptable when they come from the original source which might be which is probably okay so to summarize um i think it's not too hard to get all of this going especially because most of the options that we need are already there we can do this without breaking the general rules of the web that is do not just introduce url aliasing yep um and i think it can and should be done the question is um what am i missing and is this something that should go through this working group thank you any comment question carsten yeah chairhead off the answers are yes and yes let's go go ahead yeah okay sorry um yeah i was just thinking uh doing it in this working group sounds good and it might require indeed yeah a document to clarify that use of the proxy option so um yeah it sounds sounds useful at least to do it in this way thank you uh cheretov uh yes and yes from my side too anyway"
  },
  {
    "startTime": "01:26:01",
    "text": "uh okay i'd just like to have a first feeling from the room and ask a usual question we can use the very sense tool so i'm going to ask who thinks the draft is ready for working group adoption race and agree there also was a comment from the chat ari said he needs a solution and the presented solution looks good okay there's 10 raised hand and 0 do not raise hand for the minutes we'll confirm this to the list i think we can literally go for a confirmation of adoption considering this of course any further feedback is welcome thank you thank you okay uh having eaten five minutes from flex time we are still good on time i think and you can move on with the next presentation christian yep so this next slot is about non-traditional responses where i've recently joined the ah now um who's author team i recently joined and again i'd like to start with kind of setting out the problem space here that is that um without defining what it is we've had a few variations on how responses come in to coop requests so the simple thing that happens in in at least in my application like 99 of requests"
  },
  {
    "startTime": "01:28:00",
    "text": "is that there is a single request and there's one response and if that response is retransmitted that the retransmitted version might be slightly different but the client still processes only one response now multicast has been around from the start which means that there are different responses coming in from different source addresses observation was um part of co-op almost from the beginning indicate um which allows the server to send more than one response over time um and then a few documents explored how else responses could come in so for example co-op over sms was to my knowledge the first document that described that there could be something like a triangular request where you send a request from the client to the server over sms but also indicate that you would pretty please want the response sent over udp down to that that particular address which would be indicated in the request and that was taken up later in in core responses the endpoint id draft that was around i think around 2017 um had options for observations that changed the server's address so then again a later response would come in from my next address that the client wasn't originally expecting it from and more recently uh the uh the multiblocks um rfc and the mo and the um proxy for group communication draft um use mechanisms by which a client can tell the server that it is really okay to send a few responses as long as the regular flow control which is unaffected by any of this is upheld and that the client would be willing to receive particular a particular set of messages what they all have in common is that the responses arrive on the same token"
  },
  {
    "startTime": "01:30:02",
    "text": "and i think it makes sense to call all of these are non-traditional responses because in all of these cases something comes back that was not ex requested precisely like that through precisely that channel so the definition that is now in in the responses draft is that a non-traditional response is a response that is not the single response that was generated for request that was received on the same transport in particular that means if there's one response to request that is non-traditional all responses are non-traditional but there might be one that is that is standing out not necessarily by anything the transport provides because any um additional response just looks like the others but quite possibly only one response matches the request in some sense because there are the others might have say options that clearly deviate from what is okay to respond with so there's an additional definition and looking at it now i might want to flip terminology to not have too many negations in there but a matching response is one that works well for the original request and has no options that make it incompatible so for example if um and that is what's been using in the block wise request um clockwise rfc and new blocks sorry 9177 is that a request is sent for a particular block and one of the many responses that come back one response is indicating that particular block again and the others just include block options for later blocks or earlier blocks but blocks that are clearly not that one so the document as it is now does a few things that could all be useful on their own and"
  },
  {
    "startTime": "01:32:01",
    "text": "anticipating the next slide this is what we'll need a bit of guidance for one thing is it provides terminology so right now every document that somehow introduces non-traditional responses has to reiterate on the topics of tokens has to say again that and by the way flow control of this is all still as in rfc 7252 or any extensions to flow control and cons and nons work as they always have so this document could provide terminology for this and there are two concrete drafts where i think it would be very useful to pivot over to this provided this is something that we can this is a direction we continue going in same goes for implementations so um i've seen implementations of observation of various quality varying quality in different um in different implementations and these often don't work well together with for example multicast and if there is a general concept of non-traditional responses and how these work i think that this can um also go into implementations and they would then just say that ah we are expecting several um responses um client implementers please um please provide your hooks in case a non-traditional response comes in or tell the stack how it how it's handled in this particular case without the need for the stack to implement down every one of them and their combinations the current draft also defines a few a few options for example one by which your client can generally request several more responses over a particular over some time so that's the okay that's the fourth bullet here these options could be by applications and the draft also describes that there"
  },
  {
    "startTime": "01:34:01",
    "text": "could be pre-configured pre-configured requests which means that there isn't there are no added options it's just client and server agree on a particular set of configuration values and then those responses are just sent using based on the terminology established here uh we have carsten in the queue yeah i just have one more item for the list since our security models need to be able to bind responses to requests we need to understand how the security models are impacted or on the other hand provide guidance for the security models to handle how to handle these responses yes very much yes okay so the questions that we'd like to ask is a um are non-traditional responses something that this working group is interested in working in general and then b if it is is this document the right taking the right approach so um do we um do we provide con concepts that are useful do we provide options that are useful do you want to keep all of that in um apart from the interest interest topic there's also the question of do we conflict with anything so so far i've compared this against everything i found that did multiple responses and i think it's matching pretty well but we might have overlooked something and um so this is something that i would like to have checked and then the remaining question is basically aof any other feedback so yeah thanks for your attentions i would be very glad to hear questions on"
  },
  {
    "startTime": "01:36:00",
    "text": "this on feedback any questions comments let's go yeah i think these are good questions i find them difficult to answer at this moment but but i wanted to ask one question uh from the implementer perspective so you propose that by introducing this concept of non-traditional response that it would improve also the software quality in that way but because the the stack would have a sort of catch-all function or callback or whatever for the non-traditional response case yeah it doesn't know how to handle it otherwise yeah so the the stack would still need to be so what right now happens is the stack needs to be aware of the full semantics of all the non-traditional response options so it needs to handle um the proxy the the multicast proxy option needs to handle observation and with that terminology the stack could just have a list of options with their respective rules of how long how many responses or how long responses come in without necessarily having to implement all the nitty-gritty details and can leave some of that to the application okay well still they need to think about that but that sounds useful at least there so it's more prepared for the future in a way if more things will be defined in the future yeah okay thanks marco cherhatov i've read the the last two versions of the draft and i plan to give out review anyway i couldn't see any conflict uh really with other documents and actually i think it's good to have a"
  },
  {
    "startTime": "01:38:00",
    "text": "single framework as reference point for terminology taxonomy and concepts that are already used here and there any way and otherwise we risk dialects of this concept to develop and so on and just create confusion thank you hank was the question or were you just stretching looks like chatting going on okay so i suppose we will see a next version posted anytime soon or in the next few months yeah thanks okay thank you so could we have a show of hands for the first question say it again question could we have a show of hands for the first question in these will you type that or do i type that i'm typing good and of course my next question where you are stereotyping would be who would be interested to review such a document so just type in the chat if you could help reviewing that"
  },
  {
    "startTime": "01:40:01",
    "text": "so i'm going to ask is the working group interested in general work and non-traditional responses raise hand if agree and just confirm it in the chat i'm interested to review so the poll says nine race end zero do not raise hand 10 raise end okay let's wait a few seconds more than raisin and zero do not raise end for the minutes [Music] okay thank you and for the minutes also you're in the chat said you can review this document and also esco at some point there's a comment from david navarro in in the chat i'm kind of discovering this response to star options they look like a vector for those attacks should the document address it yes that's the security considerations all right okay thank you thank you christian last but not least martin about dns over co-op okay um yeah i'm talking about uh dns"
  },
  {
    "startTime": "01:42:02",
    "text": "queries over corp um together with and also representing my other co-authors which are on this slide right now um yeah i first want to talk of course a little bit about the concept and then update you on what we did since the last time we spoke in this working group which was the an interim last year then show some of our preliminary evaluation we did on the various dns transports we could use and then go over into the discussion where i want to discuss a new content format caching options if we need to account for observe or so-called server push if we take https lingo and the question of how abstract the draft should be or how concrete um yeah for the motivation basically we basically just want to uh protect against eave dropping when doing dns requests in with iot devices and of course the usual way to do it is to encrypt the name resolution and uh basically there are already some solutions for that of course which is dns over https dns over tls then newly added the sdns over quick and dns over dtls but all of these have problems when it comes to the iot um the first two of course uh use tcp which conflicts with some of our resource constraints we face in the in the constraint iot uh dns over quilt has similar problems when it comes to that and dns over dtls has a so-called path and deal problem which is even amplified when it comes to constraint link layer videos with like the ones we face in 802154 or lower one so our proposal is to do dns over co-op we can then base your user encrypted communication based on ddls or oscore use the block-wise message transfer to"
  },
  {
    "startTime": "01:44:00",
    "text": "overcome the plasm due problem and also share the system resources with co-op applications so we can basically save some memory by using the same buffers and sockets and also you reuse the corporate transmission mechanism and we basically just do that by putting the dns query in a co-op request fetch and that is then issued to a doc server that's that one can then basically just get the information either from a local storage or another dns server and then respond in a co-op response also encoded as in the dns response um yes since last time we spoke here we basically removed the originally proposed get and post method which came basically from doh we put a little bit of thought into how caching and cache validation is done with the e-tags we also added doq as another consideration and why it constant conflicts with constrained iot scenarios uh we clarified how our content format is and accept this handled and yeah also did a lot of to be done by mostly just saying that they're out of band for example the service relate uh selection but also put some consideration on how messages uh that are too big basically dns messages that are too big should be handled by a doc server and yeah and also added some considerations on how to use dns over corp with a why to use uh dns over coop with an unencrypted connection and why it might be also beneficial for evaluation we basically first looked into what is there on dns traffic in the iot and basically made an empirical data set of that to get some idea what name properties and resource records are there um we then did that and"
  },
  {
    "startTime": "01:46:01",
    "text": "used that information to experiment do some experiments in a testbed with two clients which uh requests a name uh from a resolver via forwarder and a border router the clients basically just query 50a or aaa the quad a records often for a name of length 24. we do this over udp dtls co-op corps and oscar and uh yeah basically these 50 queries are done around five queries per seconds and poisson distributants of course this completely ignores the end start requirement which is uh outlined in 7252 but we wanted to see the network basically in a constrained manner so we get some interesting data and yeah we did 10 runs with that on cortex and three nodes with an 82154 radio and basically we got the following resolution times which we plotted here as a cumulative distributive function and we basically see three groups types of types of communication so this is basically group one this one on the top which is just gdp for a records group two which is co-op and udp and for post infection udp for the quad a records and then this other basically the whole rest is this group three and the question of course is where do these performance groups come from um and when we look at the packet sizes we get basically our answer because uh the group one is basically where no message fragmentation is happening um group two is where the query is unfragmented and the response is fragmented and the group 3 is basically where both query and response are fragmented so our conclusion of that is that when it comes to performance basically"
  },
  {
    "startTime": "01:48:00",
    "text": "the fragmentation has a far larger impact compared to transport or co-op methods and i guess this is not a big surprise for most of you um but yeah but our conclusion from that is basically that we need a new new content format other than the normal wire format for dns over co-op which because even with the most realistic query and response sizes we see fragmentation even when we just take our minimal name length of two the response for a quad a record already gets fragmented and so yeah basically we want to have some kind of compression basically to get below that number um and some ideas we put forward for that not yet in our draft but to discuss here is to basically omit the authority and additional sections of the dns response omit the qd field because acute count fields because the question section is always of length irons most resolvers even just throw away any query that has more than one qr question in it then make the class and type optional and basically imply the most requested ones which are hopefully soon in in quad a apparently it's more in and a but yeah we hope that will change in the future um then you self-eliminating numeric values like we of course for example have in the co-op options uh for the for all the numeric values um and maybe even make the question option completely optional because requests are most often times bound to their responses so we basically already know what the question was when we get a response and basically we propose two options here which we haven't clearly decided yet on which is basically putting the question putting it in a cyborg"
  },
  {
    "startTime": "01:50:00",
    "text": "array and put the question in the sibo array and the answer section in a receiver array of arrays or uses what we call a remote get address by name where we basically just put a query the name that we want to query into the query into the request maybe also a type and then basically expect an address as a response but um in general uh this probably should be discussed in a separate draft and there is carson in the queue yeah go ahead carson yeah just a quick question what is the the percentage of the space that is taken by the actual labels here but what by the labels the dns names um well it's always these most of the time it's basically the number of characters plus two bytes for the delimiting characters so yeah it's oftentimes really a small part of that especially when you look at some name links i have a slide in my backup slides which i don't want to scroll forward to because this uh meet equals thing is a little bit okay i'll look it up there i i can show you at the end maybe if there's time yeah because we could come up with a much more efficient encoding of adh labels which are probably the majority of the labels that we are looking at yeah okay [Music] yeah um then the other discussion we want to basically open is that we have basically currently two proposals for how to handle uh caching and the max age option and dns ttls which all use relative values and so we they might get out of sync at caching proxies uh indeed in the doh rvc basically there's a proposal just use the minimum ttls as a freshness which would"
  },
  {
    "startTime": "01:52:00",
    "text": "equate and go up to the max age option and then the clients basically need to figure out how to do the ttl to the dtls and basically this would mean that you basically look for the smallest ttl and if that is not the same as a max h just subtract them and calculate the detail from that that of course and the other option would be to do it also like doh but then adapt the ttls already at the server so basically the minimum ttl is zero and everything else is just the difference from that and then the client basically just needs to re-adapt this based on the max age if we do this it looks at this in detail so basically we get our response at the dock server see the ttls get the minimum ttl off the dns response and put it into our core header that then is sent via a cache that which does stores the response and we wait some time then when we query the the next time we basically find it on our cache and of course the max h now has decreased and differs from the minimum ttl so we need to somehow adapt this and basically this solution aims to be mostly just compatible with doh so if for example the dock server is a dh proxy and the other option would be the adapting ttl i already talked about which basically then subtracts all the ttls with the max h option and then we do the same thing again um at the client we see the max age option just added to all the ttls uh we basically are already done so uh we put mostly the workout on load on the server which in this scenario is assumed to be the more powerful node and also we have less cash invalidation because even if the ttls change"
  },
  {
    "startTime": "01:54:00",
    "text": "uh in the responses we get from some upstream dns server assuming they are off always uh the same time amount of time apart we don't change the content of the response so uh if the content if the e-tec is for example based on hashing the content then we basically don't invalidate our cache we can just get a valid response from the dlc server from the core proxy okay and then the second to last thing to maybe to discuss is the section five three which uh talks about observe and server push in http 2 which basically based on this doh section um which is about to uh how that maybe the the response to the potentially next request could be delivered to a client and then cached by them um with core someone could think maybe that the name could be of the of the core rd could be requested and then basically also deliver the well-known core of the core id but um all in all this would require the corp put somehow the request information in the notification or so we get back to this non-traditional dns responses thing so that the client basically knows where to cache and for what to cache this response that it got just out of the blue um and another use case of observe specifically was that there is dna state for operations but there is also the question if this is even needed by just some step resolver or doc client yeah and the last thing basically is how to how abstract the draft should be klaus harker there put an issue in our issue tracker and he basically proposes that uh to"
  },
  {
    "startTime": "01:56:02",
    "text": "that that we just specify a rest api that the server then serves how to retrieve the dns information and leave all the protocol details uh to the implementation so yeah [Music] maybe if there are not yet any questions or people need to think about i can show what carson was asking about oh there are four more minutes to go okay then yeah uh so basically here i uh resolved all the layers by um by all the packets by layer and uh you see for the minimal mim format there is i mean uh there's basically these four bytes but they are part of a bigger dns response because of course also the quad a record itself is in it like the ip address but maybe we can also compress that somehow if it's a known prefix or something like that there's a question or someone named loren in the queue and after him esco thank you for your presentations this is basically very interesting you do you focus only on ip address a and quid a or you you are all the record well at the moment we are focusing on quad a because that in was what we saw in our data set was the most requested uh stuff actually uh if you don't account for mdns it's basically the only record we saw or b or the a records in to be honest but we of course want to also support other um kind of records okay yeah so i had a thought because you mentioned observe and"
  },
  {
    "startTime": "01:58:01",
    "text": "i think one particularly interesting technology is the dns push approach so you do a query and the server pushes updates to you uh over tcp or tls yeah so that seems very uh suitable to just apply observe to it and i guess you already consider that yeah but i think that's basically what rca 800 8490 is talking about so yeah yeah it's eight eight seven six five it's also uh notifications and then that's for example used also by embedded devices i'm working on on those kind of solutions where actually they will query for services so using uh yeah dns sd type of queries and getting responses and those are also updated whenever there's a change so whenever a new device comes online the device can be notified like hey there's this new new service online yeah and that's using basically the dns push so directly over tls but i think it could also be mapped to yeah do the same thing with observe very well yeah i i guess i mean that's why we put it in there because we were wondering if there is some use case to have observed if then maybe some adaptation unneeded to it but from what i hear basically it's basically just the normal observe so yeah maybe we put an option in there and say it's for dns push or maybe we don't uh yeah that also i guess depends a little bit on the direction the approach will take in the future yeah okay so indeed the use case is there but well i think what technology exactly uh is going to be used yeah that's that's"
  },
  {
    "startTime": "02:00:01",
    "text": "still the question of course but yeah okay okay thank you so it looks like you know what to do i could count uh kind of four main topics or tracks to be more explored uh if it's useful you can even start one thread each uh on the mailing list to get more specific feedback yeah on those uh otherwise definite material for discussions editorial meetings yeah um yeah exactly so yeah and um please if you are interested in reviewing versions of this draft please send a message to the chat so we can gauge the interest in that uh thomas says he is interested to review and by the way he was thanking you and cultures for the nice work okay thank you um thank you we are exactly on top of the hour just to mention again that we resume internet meetings on april 27th by weekly as usual unless there's any big compelling comment anyone wants to make i think we can join the meeting thank you very much for your participation and work thank you for the presenters this was a great meeting thank you bye hmm uh"
  },
  {
    "startTime": "02:02:10",
    "text": "you"
  }
]
