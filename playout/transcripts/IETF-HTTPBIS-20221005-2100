[
  {
    "startTime": "00:00:14",
    "text": "all right welcome everyone started soon good morning can you hear me yes excellent thank you good morning good afternoon whatever it is Wherever You Are Tommy you're here as well I can see I am um I've kind of lost my voice so if you can do talk in here that'd be great okay um this is the first time for using medeca so it's a little bit disconcerting but we'll see if we can get through it see here uh so this is a a meeting we may not use all of our a lot of time but we'll see how it goes I think for Tommy and I the main purpose of this meeting was just to to do a little prep work and to uh make sure that we're in good places with all the drafts uh for more involved discussions and actions when we're all in London or participating remotely in London um so uh it might just be status updates we might talk about issues but mostly we want to make sure that if there's anything blocking progress on the drafts that we have uh that we can you know"
  },
  {
    "startTime": "00:02:01",
    "text": "unblock them if at all possible um so uh for this meeting we we've got let's let's get through the fun bits uh this is an ITF meeting that means that we operate under the note well policy uh which I'm going to attempt to put up on the screen right now let's see how that goes uh uh do you really want to share your screen well oh I'm gonna have to use system preferencing things okay so if uh you're not familiar with the note well I'd encourage you to go to uh uh your favorite web search engine and search for ietf note well it's the set of policies that we operate under uh regarding things like intellectual property harassment code of conduct um uh working group processes and so forth so if you're not familiarized with those you should become so uh as soon as possible yeah that's not gonna work right now okay um we need a scribe for the meeting uh can anyone volunteer to do that I realized that that's an interesting question are we have we fully transitioned over to um zulup or is Chipper's still working I have a feeling that jeopard is not still working any volunteers prescribe thank you anyone who's not subscribed in the past three or four meetings won't described because we do kind of rely on the same"
  },
  {
    "startTime": "00:04:00",
    "text": "people to do it time and again and I'm reluctant to call on them yet again in chat Martin is he's doing it oh fantastic thank you Martin um if you can do that uh and and send us the uh notes page there's a there's a page in the in the agenda for minutes on the Note server that's the best place to do it if you can if not send them to us afterwards and likewise in the in the minutes there's also a uh blue sheets that if everyone can or actually I think that's automatic now that we're using meet Echo isn't it so that may not be necessary uh that's a good question too so the agenda for today we've got uh resume uploads uh signatures uh the query method client search alt services and origin in HTTP three do we have any agenda batching do they do foreign Mark you're very scratchy feedbacky and someone in the chat here says that perhaps it that's interesting okay it's the same sound that we got in the ID meeting last ITF and then when you muted and unmuted it seemed to reset it for a while like a Kodak issue or something how's that any better very clear now better okay"
  },
  {
    "startTime": "00:06:00",
    "text": "all right Tommy is that you sharing your screen I am not but I did just upload the slides as the PDF so you can just present them directly from whoever wants to present them can present them uh directly from meadeco by asking to share pre-loaded slides and you are sharing your screen am I surprisingly mission to do so oh that's fun all right well let me try and share the slides then if that's sudo working and if not we'll try and do it for me to go directly [Music] um there how's that so Mary let's take it away um yeah so um hello everyone my name is Miles clyder I'm here to talk about resumable uploads um this is my first presentation of this kind so I hope it all goes well um and I assume it's just I say next slide probably um at the appropriate moment um okay just um a brief I think we got 30 minutes for this topic um I've planned the presentation for about 15 minutes um the draft has been just recently adopted um so there are still a lot of open fundamental questions on how to proceed with this um this is also when we go through these open issues you will see that most of these are really basic things that we need to sort out before continuing to the more details"
  },
  {
    "startTime": "00:08:03",
    "text": "um what are resumable uploads the idea is basically to allow transfer of bigger objects which can be interrupted voluntarily or involuntarily through connection issues at any time and then be resumed without having to transmit all of the previously transmitted data I think most of these will be most of us will be comfortable with this concept um and yeah so that's why we hear the draft got accepted and now we have to sort all of these issues through um these are the three most pressing issues um in our opinion um I will go through them step by step introduce it a bit to you and then maybe get a bit of feedback on this so that you know what the current status so let's start with the first use of server generated upload Uris let's go please to the next slide so the issue about upload identifier is basically the most basic and fundamental the idea is if the client wants to resume an upload it needs some way to communicate to the server which upload we are talking about just like an identifier the current draft uses for this the concept of a client generated upload tokener I will go more into this in the next slide but this has raised many concerns um with valid reasons um so this is why this is the most important one as a comparison there are other methods of course like using server generated upload URLs and these are also used in other protocols for resumable uploads for example the test protocol is something that we have also worked on before um which is an open source protocol for resumable uploads and they have chosen a different approach"
  },
  {
    "startTime": "00:10:00",
    "text": "but I would go into that in more detail what it means in the next slide please right so the client generated upload token means that before the client starts the upload and basically before it contacts the server of any intention of doing this upload it generates a random token this for example can be just a uuid it can also be something else and then this token is included in every request that is sent to the server regarding this resumable upload for example a header in the current graph we use the upload token header and then the server always knows what upload we are talking about the there are many benefits but also many big disadvantages to it one benefit is of course that there is no additional requests needed to get the upload started you can the client can just send the request include this upload token and it can already include some data with it it can basically get started from the ground up there's no round trip needed and this is of course really great to reduce um latency and just um be a quite performance system um another Advantage is that the upload can be resumed in any state basically we don't have to wait for any identifier from the server because if we ask for such an identifier the response can get lost and if we don't know this identifier we can't resume and upload we don't know what to talk about we can't really communicate about it so this is also a nice benefit of this approach that we can resume in any state because the client always knows this token it can always tell the server what uploaded is talking about um another like a bit small Advantage is"
  },
  {
    "startTime": "00:12:01",
    "text": "to trace um the upload for the system if you have proxies or different hierarchies of servers um you can always use this upload token as a kind of an identifier what what object is um is this request handling but of course there were many concerns raised about this um because it takes away the responsibility of the server to generate this identifier this identifier is generated by the client and the server must handle with it meaning if there are possible collisions between tokens because even if they are generated randomly there may be collisions between different clients um I think it's over has to deal with them also it kind of breaks with like one of the fundamental um mechanisms hdp because the identify vacation is not done in the URL or the URI but it's actually done in an header um which of course is a very um how you say controversial thing to do I would say um so there are these valid concerns of course however in the draft that is as adopted right now we still use these client generated tokens um on the next slide we will see an alternative to this um what we call a server generated upload URLs this is basically the opposite to the current approach that we've shown before in this the client sends additional request for the upload is started asking the server to create an upload resource is that's basically hey I want to upload x amount of bytes please let me know where I should send the data to and then the server responds with an URI maybe in the vocation header um where it points to a resource where"
  },
  {
    "startTime": "00:14:01",
    "text": "this upload can be then performed this response can be a 200 response it can be an intermediate 100 response it doesn't really matter what the format is but just the the server gives information back to the client where it should redirect the actual uploads to the benefit of course is that the service in full control of this identifier meaning it can ensure it's Unique it can encode additional information in it like which server to direct it to code some other information into it um and of course this entire upload creation fits nicely into the typical scheme that you see with HTTP you know you have requests and then responses everything is encoded in the URI um which fits nicely into um a lot of structure that we have of course also disadvantages um these are these advantages were the reasons why we originally chose to go with these client generated tokens meaning you have this additional round trip in the first request for creating the upload resource there can no can you can't really transfer data unless you want to have some work around for this and this is maybe not really helpful especially if you have also want to enable resumable uploads for smaller files um you you have to handle this additional round trip another problem is if this original file creation request fails the client is um left in a bit of a weird State because it doesn't know how to contact the server again like it doesn't have has no identifier to talk to the server and in general an upload creation request is not um retryable or it's not even potent um you can retry it but some servers may"
  },
  {
    "startTime": "00:16:01",
    "text": "deny the second creation request because and resource is already being created um so this opens up another set of issues um maybe these disadvantages are worth to handle maybe it's just we have to accept it um but these are like the disadvantages of this um just to emphasize this is not yet what we have written the draft this is basically an alternative it is for example used in the test protocol and also in many Production Services because it just fits so nicely into the schema but yeah this is basically the topic of upload identifiers um this is in our opinion the most fundamental question um so any feedback on this is um uh highly appreciated because this is basically what will allow us to build the rest of the protocol upon um okay enough about this issue please go to the next slide where we talk about another topic and that is the topic of feature detection what we basically mean by feature detection is can we make it did we want to get discussion on that first oh yeah I do see a lot of activity in the chat so maybe possible I expected this to be the most controversial topic so okay yeah Martin says with 1xx this round trip is in parallel to the upload um this is true um this is a point that we wanted to talk about later um that relying on one XX responses is something that we also have to think about"
  },
  {
    "startTime": "00:18:00",
    "text": "um because this basically means that you cannot implement it in current browsers without browsers modifying their apis it's something that we have to see if we want to accept it or not um why can't the initial request starting to stream the upload as well um yes it would be a possibility we yes sorry just just from my perspective I wonder if if we have valid use cases for different styles of interaction would it be workable to Define multiple patterns and and have different use cases adopt the pattern that works for them is that is this a situation where we can do that um I would say so yes yes as well um this is not something that we have discussed so far so far it has been more about which approach will be more like the the only correct one but this is of course a really good point that maybe we it's worth keeping both approaches [Music] right the token can be used if the clients or make a statement okay well maybe we should move on then we can come back to it if people have some more thoughts yeah okay go back to the presentation um excuse me"
  },
  {
    "startTime": "00:20:05",
    "text": "don't know how to use the queue so maybe I'll remind everyone you put your hand up and then you can talk to people um I I think that why not do both is kind of a value case yeah that's what happens when we fail to fail to work through the reasons for each one of the um the different Alternatives and understand what what sort of constraints are on the problem I don't think we're quite there yet I I see on these slides some of the characterization of the advantages of the client-side thing um might be better addressed by having for instance different um different client generator tokens or something like that just for the purposes of tracing for instance so um I'm not sure that this is so clearly um a while not both situation yeah I I think we'd have to do the work um I'm just reminded more now we have different mechanisms in HTTP like put and then you know post and get a location back now 201 because there are distinct use cases and they need different mechanisms I'm not sure that we're in that state here we might be yeah the reason I say that is that part of the reason that I'm seeing for the client-side one often comes back to being able to to do something within that first round trip and that to me doesn't really gel particularly well with the the idea that you've got a um a long-lived and potentially resumable upload if something can complete within one round trip then great why build all this machinery now I've got to go and Scribe all that"
  },
  {
    "startTime": "00:22:02",
    "text": "yeah maybe on the base also on this point um in a few situations it is nice to have one API for uploads that work for small files as well as for bigger files um so this is a really good point that's saying that um it's worth considering big files where it's worth to do an additional round trip because if you upload a large video one additional round trip may not be that problematic but if you talk for example about smaller images one additional round trip could basically just double the entire upload duration um and in systems it might be interesting to have only one API for accepting all um files so it would be helpful if this resume will upload interface will be constructed in just a way that it actually works for different sizes great if there's nothing else for this for now um I think we we can continue watch the next slide yes um talking about feature detection uh what we mean by this is there has been interest into integrating resumable uploads in the HTTP Stacks that are offered by platforms for example directly into browsers or the HTTP stack that is available on mobile platforms in such a way that they can transparently upgrade upgrade a file upload to resumable if they know that the server supports it so that without the developer explicitly enabling it it would upgrade a file upload to resumable if it sees the oso supports it of course it would require that the client somehow discovers that the server supports it actually"
  },
  {
    "startTime": "00:24:00",
    "text": "the current approach that we fought about in the draft is that the client in the request indicates that it is interested in resumable uploads for example using a prefer header with or in the current draft we use the upload token header for that but this might or might not survive depending on the outcome of the first issue and the server then responds with an intermediate response indicating yeah I do support resumable uploads please go ahead um and use this API for me if you know such requests or response would be received by the client it would then have to assume that this is like a traditional upload which it cannot resume of course this also brings other questions up well if such a response get lost in the way how would the client react to this is such a method really backwards compatible or could it run into issues if the server doesn't know anything about reasonable uploads this of course brings up a whole another set of questions um of course this is only one approach so far there might be different alternatives this idea might also be discarded altogether if we say okay no we don't want to transparently upgrade file uploads to resumable uploads we want developers to explicitly opt into this mechanism um so this is something that is also worth discussing if we actually want to have it or not yeah um that's about this issue is there any feedback right now yeah koyong says we have a desire to support it in the HTTP client Library itself transparently upgrading all uploads into"
  },
  {
    "startTime": "00:26:02",
    "text": "no adds no overhead and requires no opting in so we can do it for all uploads um this is basically what I was talking about some there's interest into doing this um but it's also a question if there's enough interest into doing this yeah I get some support for it from the chat which is great a link relation could be interesting foreign if there's no else mentioned maybe let's continue to the next slide um because it is also an interesting point that talks about this basically browser compatibility um the question is can we make these resumable uploads work in such a way that they are compatible with existing browse implementations uh for example if we rely on intermediate responses and we run into issues because the current fetch API in browsers does not expose this information it makes it not accessible to developers meaning we would first have to wait for browser vendors to implement and standardize such an interface and this might take a long time it might actually be a problem for adopting such a solution this may not be a problem if we say as before that we allow multiple approaches in such a case the client would have to select the one approach which works on its platform um but only relying on approaches which would not work with current browser implementations is uh problematic in our minds because it"
  },
  {
    "startTime": "00:28:00",
    "text": "just is a big barrier to to adoption of course this is like only talking about browsers um I think on most mobile platforms for example you can ship your own HTTP Stacks so this is a lot of concern for these platforms but for browsers it is um and there's of course a big Target for resumable uploads um yeah in the next slide they are just a collection of we do have a couple people in the queue um Oh Martin and Lucas videos not mirrored wonderful um so the the challenge I think is we have two options both of which aren't particularly good from our perspective and someone's going to need to do some work either way um in order for to teach the fetch API about the requisite 1xx responses you would have to Define new apis uh new procedures within fetch that's non-trivial um just putting that there um we haven't done one XX in the past um it's potentially possible to do 1xx generically but then you're you're introducing some other interesting interactions with the existing one XX features like 100 continue and um 103 early hints which both of which are supported in Fetch but supported as an internal function the alternative is to Define 1X the new one XX is a new um a thing that is understood by fetch such that the browser itself would then be responsible for doing the transparent upload resumption and all those sorts of other things again that is entirely possible but it still requires changes to fetch and um I think either way if you want to be"
  },
  {
    "startTime": "00:30:01",
    "text": "able to do this in the browser there's some work to be done with Anna and the other folks who look after fetch in order to make this this happen I do think this is probably the most useful aspect of this whole thing so it's worth doing but it's probably more work than writing this spec hello um yeah I created that issue I I do agree there's a lot of stuff around like patch API I'd say that's a web platform more than browsers lots of stuff that you could potentially do there the the the issue I created was more after discussion with some some people around who are like you know give them a very high level view of what the feature is like wouldn't it be cool if things worked like however however a web page presents to the users some way to upload things um it's just kind of handled internally by the web brows and you don't need to deal with it uh if if a web browser doesn't Implement such a feature it just behaves like it used to and it might fail and you might just have to manually and try you try and you know keep failing until you get onto a better network but if that wasn't the case it would just work magically a bit like uh making my downloads more reliable um it's very speculative I don't appreciate all of the um the work or the changes that are required I understand that there it's more than just writing this back but yes I think like 20's point I think there's a difference between trying to expose all of the Machinery such that JavaScript folks can fill in the gaps versus working with with vendors to try and do this inside um and and sometimes doing the thing inside could be easier than having to design you know a well-formed abstract"
  },
  {
    "startTime": "00:32:02",
    "text": "General API that can accommodate all cases that sounds like a big amorphous mess that's going to be hard for people to get their heads around versus you know like 100 expectors kind of handled today and no one worries about it but um we're all worried about any other status code why why is that it seems a bit bizarre there's reasons but I don't appreciate them I'm so wondering if other people do and can maybe help us here cheers uh yeah and for my part I very much agree with Lucas there um I think it's possible to oversell how much work it's going to be getting something into fetch um you know yes it needs to be detailed oriented they specify everything algorithmically um but but historically the hardest part of getting stuff into Fetch and similar what working group specs is getting browsers to commit to interest and implementation um so if you can get one or especially two browsers to commit to it I think you've got a pretty decent chance uh as Martin mentioned we already have some 1xx status codes in Fetch they are one-offs I would shy away from designing or trying to design a generic 1xx API in Fetch I think you'd get a lot of scrutiny there for for security and privacy and other concerns but putting a bespoke Handler in in for for a particular mechanism is is much more achievable and again as Lucas says that's if if you know you need to do that if you need to expose it to JavaScript so I wouldn't I I wouldn't say you know it's an impossible or it's an incredibly daunting task it's just you know you're gonna need to do some spec work Anna's very willing to work with people the other what working group folks are too and of course you need some implementary interest that that is what they want to say"
  },
  {
    "startTime": "00:34:03",
    "text": "yeah uh hello uh so this is where from Apple so I think uh we do have two use cases for this protocol we have the browser use case or the generic client use case where we want to upgrade a regular upload into a resume or upload it's not a use case where we just want to uh we already have the people adopting task 31 and they have their service and clients working and they just want to upgrade to this new protocol so I believe uh the current craft have this feature detection being optional so that it does not depend on the list 500 responses uh this really I believe that this provides uh support for both use cases like for the use case of a browser we depend on 100. for those other use cases you already know that your server supported you don't need a hundred you can just create and resume yourself uh so if we switch to a server generator token uh and or or things like that we will also need to take both use cases into consideration um yeah thank you for this this feedback I think it's really it's a nice perspective um on especially fetch API um that of course we don't have to make a generic implementation but just something that if we decide that way that is like a another um detail that should be handled internally by the fetch API um there's of course a really really good point um okay maybe let's um briefly come to the the last slide um to to get this presentation over"
  },
  {
    "startTime": "00:36:02",
    "text": "um there are of course other issues um besides the three big ones that I mentioned just now these are more important in the meaning that they basically allow the LIE the fundamental work that we can then build upon are the issues which are currently open um are talking about prioritization of concurrent uploads meaning if we can interrupt and resume uploads at any time maybe it's interesting for um vendors to prioritize certain uploads and prefer them over other ones of course this is a very hypothetical question um that is not too urgent right now I would say the second issue um and and please forgive me I messed up these two issue numbers they're not the same actually um I I did the mistake there the other issue is basically talk about a header called uploading complete this header is intended to indicate for the server that an upload is not finished in one request but there will be subsequent requests and there are some concerns that this may not work with other HTTP mechanisms um but as this Heather might not survive depending on how we decide um regarding our first issue um I put this yet a bit to the side because this is not too urgent right now um but yeah this was a brief overview of the current state um of the resumable uploads draft especially highlighting what our current questions are and thank you all for all of this feedback already and if there's any other feedback um please let us know thank you thank you very much that was that was I think really useful look forward to this draft progressing uh any other comments on this one or can we move on"
  },
  {
    "startTime": "00:38:01",
    "text": "I don't see anything in I see a comment from Austin could this overlap with item potency key somewhat ah so there's a draft in the HB API working group called item potency key which is is basically a way for a server to realize that a post message for example has been sent before and so to have exactly what semantics for that request [Music] um my instinct is that they're adjacent but not the same but it might be interesting at least for for the authors to be aware of it yes that is very much interesting especially because we talk a bit about eating potency here yeah I'll make sure you'll link to it um and Julian remarks it'll be good to collect information about 1X support and client libraries on the wiki yeah we've attempted that before maybe we should just try and continue to collect that information uh because uh it it's good to know about I think as I understand it we're getting some bugs worked out in a few of the remaining problematic implementations hopefully it'll get better over time okay thank you very much Marius [Music] so next we have uh signatures Justin are you with us yes I am don't have so much looks like it's Broadcasting yes okay fantastic uh yeah we don't have any slides um for this so a quick update uh signatures is now in working group last call which means the document is completely perfect and"
  },
  {
    "startTime": "00:40:00",
    "text": "it will not change at all before it gets RFC obviously um for uh real though this is a long and fairly complex document there's a lot of moving Parts here um so we need everybody's eyes on it especially um from from Annabelle in my perspective especially the really deep HTTP experts in this group to make sure that we are not using the wrong HTTP term in the wrong way in the wrong place because that's been a lot of uh as as folks who have uh read previous drafts of this uh that's that's been a lot of what Annabelle and I have needed uh education on in the past so um uh you know ultimately all eyes on this that we can get would be uh deeply appreciated um there's an extensive security consideration section as you would expect with a document like this um we recently tried to bin all of those into sort of major categories if we're obviously missing anything or any aspects of uh the considerations um you know please uh raise those as issues uh as well so that we can um uh continue to sort of Polish this on its uh on its way to the next stage of the process uh we do have multiple implementations of this across multiple languages uh and no they're not all for me uh though a few of them are um and uh We've also been starting to see um implementers of uh previous attempts at HTTP signatures so the Cabbage giraffe for example we've seen a couple of cases of groups using or adapting a cabbage draft implementation into uh the into the current HTTP message signatures uh draft formats and structures and things like that um so that's been really good to see"
  },
  {
    "startTime": "00:42:00",
    "text": "um because there was you know there's a lot of inertia behind sort of those um uh Community drafts uh the the IDS that came before this working group effort um so it's really good to see that um uh that's starting to really move forward regardless we think that the document is uh is good enough to um make the next uh stage right now and we welcome all feedback so um just a heads up uh if anybody wants to queue up please do but uh I I've heard some some folks wondering what the appropriate level of review of major new security mechanisms is in the iitf currently um if you look at how TLS was reviewed TLS 1.3 was reviewed before it went out whether we need to put the kind of call out to get some some you know academic looks at it some some security researchers looking at it and some verification of of what's going on here um I I expect we'll probably get some some people making comments to that effect sometime soon so okay really just a heads up for folks Justin and for everyone else the working group to start thinking about what they think about that what the appropriate levels are whether we need to have a more extended working group last call or appeared after working group last call to give folks a chance to get that much more broad review and and what what people are comfortable with I know we've had uh you know this document in process for a long time and a lot of folks are impatient to get it out the door but we also want to make sure we do the right thing there so we'll we we we'll see when that feedback comes in and we'll have a discussion probably in London I'd say um to to that effect Mark is there a plan to formally engage the security directorate ahead of the uh iesg or IAB"
  },
  {
    "startTime": "00:44:00",
    "text": "review stages again we already had an earlier review from them right we'll request another review uh uh and I think that's probably a good idea I think I think we should yeah I I think the question is whether that's sufficient or whether you know it'll be interesting to also I think probably Tommy and I need to talk to folks in the security area and figure out what their thoughts are about that bigger topic and whether we need to do something more than that um but but yeah as well sure yeah no uh to to address Christopher Wood's comment in the chat uh yeah this is not a replacement for sort of the you know the deeper security uh analysis that Mark was talking about uh this is this would be in addition to it um I I do most of my work is in the security area and there's a uh there are a lot of folks that do formal analysis of protocols especially multi-party security protocols like this one um that uh would probably have uh some good things to say uh or some good feedback to give uh on this document um whether they say good things about it or not that's you know that's up to how the analysis goes home I can reach out to some folks that I know um that are that have done work in the uh in the oauth and app spaces uh in the past and uh I know um at least one of the core TLS folks uh yarn Schaefer's been following the HB signatures work pretty closely uh with he's got his own implementation as well so he might be somebody that we can um we can try to uh tap for contacts uh in a similar way that TLS did I don't think this needs quite the same level of formal scrutiny that TLS 1.3 did it's working at a very different layer of the stack and and that comes with a lot of benefits"
  },
  {
    "startTime": "00:46:00",
    "text": "um and but I you know I'm I'm not opposed to making sure that the right academics get their teeth into this uh your muted marginal income oh sorry from my perspective I'd love to do Clarity on on you know how we we decide what the appropriate level of review is you know when is a a formal workshop and and that kind of level of effort necessary and Justified and what are the gradation below that and so forth and so on so that that's a bigger discussion that we should probably kick off but yeah uh Chris sure can you hear me yes hey um yeah thanks uh thanks for the update um and I I wanted to just uh reiterate sort of what Mark was saying um uh I was probably the the one of the people that had formed his comment just now I was I was kind of surprised to see this in last call without um seeing sort of some uh analysis to the extent that um uh TLS received during its um publication process especially considering the complexity involved in the spec um I I recognize that it's like a different layer in the stack like it's not like a key exchange protocol it's some like like just a digital signature thing um but I don't think uh these days that absolves it of any like um uh additional review or at least review that's comparable to what like other ITF security protocols um receive so I would suggest that we like Park this um even if like the word group less call comments are positive until we receive that analysis um I don't know I mean to your part point mark I don't know um uh like this seems like a a question someone larger than this particular document and I think maybe sector like um and other security area people um uh would like to engage on um figuring out what is like the right bar we need to hold drafts accountable to these days um uh but just like given that the the"
  },
  {
    "startTime": "00:48:01",
    "text": "number of security considerations that are in the draft um it I think it that alone suggests that this needs some sort of real formal analysis um and if they're photographers or the Security Experts that you that you referenced Justin um are able to do that that would be lovely I'm sure there are other people um someone in the the TLs orbit um that you know are looking for things that are of interest to people in the industry um that we could you know tease them with um so this like I'm sure that I'm sure we'll have no trouble finding people um so uh I I don't have any concerns there I I do have concerns about advancing this though in the absence with that analysis thanks okay um so that makes sense to me I think uh Tommy and I will do some work in the background coordinate with you where necessary Justin and make sure that we don't unnecessarily block this document and also make sure it's the right level of review I think there's also a minute discussion he had there that maybe we can we can start in London get some better guidance for groups of the future um uh perhaps we should get one of the uh security ads and the uh ad responsible for this group uh in the room at the same time to figure out uh I I do think it's it's a two-part question what to do with this draft because it does kind of straddle the line and also kind of what that threshold looks like in the larger sense it at least to start yeah or I I'm kind of thinking it's probably a gradation that there are a lot of different possible responses depending on the situation and it'd be great to have that kind of you know laid out somewhere yeah who's the ad for this group is it Francesca Francesca is she's on leave right now so it's Murray gotcha and I think she'll be on leave through"
  },
  {
    "startTime": "00:50:00",
    "text": "uh uh London but we'll see right um yeah and and Lucas points out in chat it'll be generally that the early sector review could advise on the level of someone else's that might be needed I think that's really good feedback right we did not get that feedback you know really so so maybe that's some feedback we can give them about their process yeah I was that's I was thinking the same thing because you you said it more much more succinctly any other comments on this draft Lucas uh um certain examples and stuff like that um I was happy to help but I didn't hear anything more and I haven't had an opportunity to look in the draft as if there's anything specifically there so I'm gonna I'm gonna guess the answer is no and that you're happy but if if that if in case we fell off like that item fell off our agendas and I'm still happy to provide some support there I don't know if Roberto is still here but I'm I'm pretty sure he'd be happy too um yeah and although we we're in ad review now the digest draft is kind of uh stuck there for as long as it takes I guess so we have an opportunity there I guess to align anything if then they're different things but you know um it's not like our ship is completely sailed yet but I don't anticipate any any future changes to digest so I've got I've got some bandwidth oh there cheers yeah so we added a security consideration um specifically about covering the uh the message content um under the signature and that the way to do that is to use the digest field um and uh so there's uh there is a"
  },
  {
    "startTime": "00:52:01",
    "text": "non-normative example in signatures about that uh I had requested sort of a you know uh an example in kind in the digest graph because saying digest doesn't protect the rest of the message in the same way the the signature does and here's how to do it uh if I recall the discussion at the time was uh largely that uh explaining that would add a lot of complexity to digest which is fair um and that that wasn't desired at the time uh if we want to uh if you and I want to have it as uh you know an offline discussion about whether or not it makes sense to bring that in I'm I'm happy to do that um but I think I'm pretty happy with kind of where things are between the two drafts right now in practice these are going to get used together all the time I'll um I'll take the opportunity to take another look with stuff um so leave it with me sounds good thank you okay well if there's no one else thank you for that that's a good update and it sounds like a few more things to work through and talk about but uh we also have to you know see if any issues come in and work in group last call too thanks for that Justin next up we have cookies is Steven here and can I share this yes I'm here can you hear me yes I can let me see if I can figure this out it's ah presentation view right"
  },
  {
    "startTime": "00:54:06",
    "text": "there great thanks so hi I'm Stephen Bangor um I'll be going over rc6265 this otherwise known as the cookie stuck this is mostly just going to be a fairly quick status update um and for anyone who is at ietf 114 a lot of this will look pretty familiar next slide please so these are the changes since the dash 10 draft um I presented all of these at ITF so I'm just going to kind of speed through them um standardize max age uh prior to considerations around third party cookies specify that no decoding should be done requiring ASCII for domain attributes a number of editorial changes next slide please um let's see remove note to ignore domain attribute uh invert and change cookie octets cookie serialization case insensitivity note another note for not designing not to send invent cookies a warning not to send nameless cookies and an improvement to the max age attribute parsing next slide please these are new since ietf 114 we offloaded the service workers site for cookies computation to the service worker spec which I believe is still in a work in progress but it's still more correct than the previous uh computation was um we are also comparing the cookie name prefixes case insensitively so this is the underscore underscore host Dash and the secure version of that it turns out that some servers will process cookie names case insensitively because of course they will and so the servers were"
  },
  {
    "startTime": "00:56:00",
    "text": "setting these prefixes without actually getting any of the guarantees behind them um let's see prevent nameless cookies with a prefixed value um so these are these are generally malicious cookies that are attempting to impersonate a prefix cookie so um the cookie line would look like uh equals and then a value that appears to be a valid set cookie line and when the browser sends this benefit to the server uh it'll just send the value part which impersonates a prefixed cookie um as well as a notorial change down here as well um next slide please so these are the current issues we have oh that numbers those numbers don't add up um this says 12 open issues with an additional 18 deferred issues uh my mistake there um the thing that are the most interesting ones are the ones that are currently in scope before we've we've closed all open issues so we have same-site cookies and redirects so this is how do same-site cookies handle redirect change across different sites um set cookie parsing algorithms should force more of the syntax requirements and nameless cookies client server inconsistencies that last one is interesting that's similar to the nameless cookies prefix value it's a cluster of a couple different issues um there is a change under review right now that is that's going to help um Rectify that one and then finally this isn't uh in your slide deck but I wanted to talk about some post RF c6265 this work so we've already got some some work on the horizon after this uh after a new spec is minted um cookies having independent independent partition state or chips is working on an internet draft this is"
  },
  {
    "startTime": "00:58:01",
    "text": "partitioned cookies for anyone unfamiliar with that partitioned by the top level site and then there's work being done for splitting out the cookie spec into different relevant specs it's being referred to as like the cookie spec layering we had a recent discussion at TPAC between a number of people on what the high level design would look like here um that's it for my update are there any questions oh Daniel go ahead let's see you have to unmute yourself at the top left ah okay audio problems so to see the raised hands anywhere there it is yeah Daniel worst case if you can type your question or comment into the chat we can relay it uh he asks was the redirect breakage in all same cases or mostly in the Lex by default case yeah I'm actually glad you asked this because I meant to speak a little bit more to that point um so it is primarily in what we at Chrome are referring to is unspecified same site um so this is when a cookie is not explicitly given a same site value"
  },
  {
    "startTime": "01:00:01",
    "text": "um that is basically lacks by default but we also apply a we apply a post exception so cookies should not be sent on not non-item potent requests but we found that that broke a bunch of stuff so if a cookie is younger than two minutes and it's a post request we'll actually allow it through and it's in those situations that according to the metrics that I have so far are showing the are primarily associated with these with these sorts of problems um we had a discussion at TPAC over this as well and the results were we need more information um so I'm working on adding more metrics to see if we can sort of understand this this use case and where this breakage is coming from a little bit better but those are going to be delayed by a number of months I hope that helps any other questions comments from from my perspective so you've got two non-editorial non-deferred issues open from what I can see so it sounds like we're we're very close to working with the last call uh do you see anything else blocking us or um I mean we've had so these nameless goofy things were security bugs that popped up as long as no other researchers find anything interesting I think we should be good okay that'll be great uh and Daniel also says uh for what it's worth Mozilla is considering not implementing The Lex by default part of the spec because of breakage and because partitioning proposals kind of mitigate this issue anyway toward the issue anyway okay well I'm interested in that if you want to like email me or set up some other time I like to discuss that with you"
  },
  {
    "startTime": "01:02:02",
    "text": "or through some other he says we'll do okay great that sounds good um so so once we resolve these in if there's an issue there we can we can discuss that as well um we'll go to working group last call go to the ITF process it sounds like then there's a discussion about you know what the next steps are we have a number of deferred issues here there's been it sounds like good discussion at TPAC and some proposals in the community uh and I guess the question is would the next revision of the cookie spec or or whatever happens to the spec you know do we want to keep it here in the HTTP working group do we want to create a new separate IDF working group do we want to do something else that's a discussion the community we can have as well so if there's nothing else I think I'm done I think so too thank you very much okay um stop sharing good next up we have the query spec uh which I believe has a few issues open uh Julian is here but can't uh us speak so otherwise indisposed let me get to the issues list real quick and see if we can share that great can folks see that bigger so if I take [Applause] editorial issues out we're left with seven open issues oh and sorry [Music]"
  },
  {
    "startTime": "01:04:02",
    "text": "yep six open issues I think the last time we discussed query uh we we felt that we needed a bit of a push to get these issues discussed and had a uh maybe even a miniature design team that hasn't happened yet uh so if folks are interested in working on Aquaria or helping to solve these questions uh please get in contact with Julian uh I'm gonna try and help out as well and I think uh I'll try and get some folks working on it in in London if at all possible any other discussion on query uh anything you want to realize relay from chat Julian I hear that my mic stack is back so I'm going to mute for a second is that better good foreign says 1am in a hotel room on vacation Fair call all right well just that just let that serve as a reminder then about the query spec um if if folks want to contribute to that please do we'd like to get that one across the line relatively soon uh next up client search Brian are you with us or trying to be can you hear me see me if you could just oh so I apologize I've been a little uh"
  },
  {
    "startTime": "01:06:08",
    "text": "Mark's uh email about this one sort of spurred me into jumping on uh you know I'm trying to do a little bit of work on the outstanding issues although I think there's not much out there um there's a few things that need to be done to move it forward um the first one here being uh just an update to reference the new uh RFC 9110 um it there are a few terminology things a few things but it's largely editorial I think it's good um no defined client search error mechanism for the origin so this has been a sort of a recurring discussion the question about the fact that if the back end origin Server doesn't like the cert for whatever reason there's no sort of erroring mechanism uh that could be used to signal that the TLs layer that that's an issue um whereas I guess normally you know like the browser negotiating Mutual TLS with a server if a traditional server if a server doesn't like it um it'll send a TLS alert and just kill the connection and this allows the browsers to um clear their cache of client search they may be using for that connection for that site or whatever um all around a UI that you know isn't used a lot and I I think most people consider not working very well I've pushed back here saying this really Beyond this this go book the specification to try to Define that kind of mechanism that any kind of erroring should should occur by selecting appropriate content and or returning a 403 um I believe Martin's sort of backed me up on this in somewhat different words"
  },
  {
    "startTime": "01:08:01",
    "text": "and at the last interim Tommy suggested that um at least some text be added to the document that mentions that case um well I thought it was you know somewhat sort of apparent it's apparently not I'll use the word apparent a few times so there is a pull request on this that basically has one sentence saying that much that if the uh thank you Martin um it's a uh I can't remember the words when I apologized basically that um if the cert is you know Access Control decisions can be made uh is that oh yes thank you I moved one paragraph because it seemed a little bit out of place and basically said access controls decisions based on the client's certificate or lack thereof can be conveyed by selecting response content is appropriate or with an HP 403 response if the certificate is deemed unacceptable for the given context you're really just trying to follow up from Thomas suggestion and note the the particular possibilities in the response here um to any kind of Access Control decision or a bad cert um so pretty not a lot to it um but um yeah hopefully this is good enough to kind of close out that issue um uh uh Martin here in the comments saying he agrees but uh it's definitely not worth fixing I agree though it might be worth explaining um I don't know that I want to or even incapable of explaining it much more than than that um foreign"
  },
  {
    "startTime": "01:10:32",
    "text": "and you know it needs to portray the failure of that you know failure in some way to a young thing tonight it needs to do it monetary I don't know if it was just me or everyone but Mark here words with a little bit muddled I don't know if it's my connection is yours um but I think if you if you have suggestions for elaborating on the text alternate text I'm more than happy to take them but I do agree agree with you agreeing that the general something more than than that is at a scope so I think I think concern that David has is that there's um it probably has some expectation about the fact that if you provide a certificate in TLS you get in the patients in TLS that the certificate is not good enough and here we've got an example of where that's not going to happen I agree that this is this is just it just sucks this is just how this is and we're not attempting to solve this problem and um I'm not sure that the proxy is any in any position to to look at a you know"
  },
  {
    "startTime": "01:12:01",
    "text": "403 responses or what have you and infer the difference between a 403 response about something and something that's tied to the certificate in a way that it can provide TLS layer signals that's just not going to happen here um so we should just say that it just can't or it maybe can't and look at that that's enough I think the the mechanism that we have here is pretty good I don't know that there's I don't know if there's any way we can we can improve that situation immediately I made a suggestion on the request uh not see any suggestion yet but I'll take a look thank you um I I yeah I'm sort of at a loss there's a comment I I don't know what the best use of time is sorry yeah what about um um unfortunately I still cannot hear Mark very well um but this was I try to get through this really quickly they so there was some a few revisions ago we added an additional hitter header to optionally convey the chain in addition to the end Institute certificate um might do much of that added in there and"
  },
  {
    "startTime": "01:14:00",
    "text": "crib some content from TLS about the ordering of those certificates um which ultimately at the last interim Martin suggested was somewhat problematic and unnecessary and suggested to just restate that without that and say that the the order of the certificates is is the same as the order that appears in TLS um trying to avoid the question of whether the certificate chain passed from the proxy to the origin is in fact the exact same as their certificates presented in the TLs handshake and or a chain that was put together by the proxy itself prior to sending it to the back end um I think it's not clear to me that either is I'm intentionally trying to be ambiguous about which it is and allow for either um and basically made a pull request trying to defer the ordering to uh Martin's suggestion here whilst um is still describing that it is the chain uh that yeah that doesn't do a lot more than that removes a few um removes explicit talk about the ordering the first TLS for it and tries to clean up a few other places where the the search chain is discussed and just um either clarify or make sure that the the content around it is sufficiently ambigued to us to allow for for either one and that is I tried to explain in the comment earlier Martin um the reason that that may or may not contain uh or may or may not have appeared in the TLs handshake Texas there as I said it"
  },
  {
    "startTime": "01:16:01",
    "text": "was from the original text that Mike added but but also I was was wanting to keep it there because it I think it still accounts for the the case where the the proxy itself might have assembled the chain prior to dispatching it to the back end um that said I I don't know I'd be okay changing that text to removing it because I think it still leaves the ambiguity but that that was the reasoning hey anybody uh have any further discussion questions comments let me all right um so these are the only issues we've had for a while we have PRS out so I would suggest that we finish reviewing them um because pairs are relatively new and once they've merged then we need to ask the question about if we're ready for last call because we haven't had any new issues come up for a while or do we have implementations do we want to wait for implementations I'm not aware of implementations as I've always been somewhat concerned that this this draft comes along a little bit too late trying to document current practices after the fact um so I don't I don't know what"
  },
  {
    "startTime": "01:18:01",
    "text": "implementation status or interest is like or is likely to be like in the future but uh yeah I think unless we had an implementer stepping up and saying we'd like some time to evaluate this and and do some you know prototyping or implementation work um then then it would be indefinite and that's not great it's also an informational spec it's not standards track so I think the bars may be a little bit lower there but if folks have thoughts about that we should we should talk about it while we have everyone I guess I go back to wondering Martin can articulate thoughts on that that one point here while we're all in the same place but whether you're particularly concerned about that text or just asking for clarification now I think Lucas is in the queue as well but oh apologies well I can answer the question I can go after okay so I I think that the model might not text is a little problematic um I think it it invite questions about what it is that you're doing here I prefer to say something more along the line so if it appear that the certificates appear in the same order that they were in the TLA soundtrack unless you of course to put someone else there and that sort of covers off a whole bunch of possibilities in terms of properties that do their own path building and properties that get information from other sources and all sorts of other things we don't have to specify that but there's a sort of very"
  },
  {
    "startTime": "01:20:00",
    "text": "clear easy path for those proxies that are just looking to to implement this and pass the information Network nothing that covers most of what we want rather than going well maybe maybe not or sort of directly acknowledging the maybe not side of things by saying well you may have reasons or agreements with the origin server it's uh that's none of that business okay I'll put some suggestions on that on that yeah thank you I'm not entirely sure how to say that without inviting other questions I guess but yeah if you have a suggestion please thank you yeah and I think also by default we can assume that if the client is assuming the proxy has it the proxy can assume the origin has it unless configured otherwise because that's the situation the situation I can think of where you would have something that wasn't in the handshake where the client is assuming that the proxy already has certain certs in the chain and therefore amidst them so some of this discussion it began though with the the chain in the handshake not actually being a chain but more of a tree structure to support the possibility of cross-signing and so forth and whether that that would be conveyed directly um in the chain to the to the origin or whether the origin would would assemble what it needed for validation to whatever anchor it had and then only pass the the chain that it that it used um which which then sort of opens up a larger question and"
  },
  {
    "startTime": "01:22:00",
    "text": "discussion about who's actually responsible for validating what's going to be a validating the trust chain and and how that information was conveyed um foreign if I remember the discussion on that PR correctly we wanted to allow for both the case where the proxy is validating the chain and where the origin is validating between so yeah I think I think so one suggestion is a reasonable way out of include what was in the handshake unless you have reason or configuration to do otherwise okay all right that works and uh suggested wording there again Martin would be much appreciated and yeah agreed with your comments in the chat trying to avoid answering some of the questions uh Lucas um yeah okay yeah oh okay um so last time you came on it took a minute to sort of hello hello hello hello [Laughter] um I'll speak I'll repeat it into the chat if I need to um I can't speak Authority deliver implemented interest but cloudflare does have like you know a a a header that we give to people about client certificate validation I think"
  },
  {
    "startTime": "01:24:02",
    "text": "um obviously like having a spec that's done for some definition of done can can improve some of that interest but it's kind of like it's sort of not up to us either I wonder if there's some way to engage the people who consume the header that like to say there's this other thing coming like they they might be able to push some some interest and demand on the the people who would be generating that header if that makes sense like who are the big customers that use client search um and and would they be interested in that I think we've got a good population of people here who who might implement the feature but they're looking for some like interest from from their customers say to to whether they should shift or migrate or add both maybe that would help I don't know any other comments questions I see agreement from Mike that that academicism was a situation there it's not surprising okay thank you Brian um try and get those last couple of PR's tweaked and in there and have a bit more discussion perhaps and and hopefully make a way to work or bless course it sounds like sounds good thank you thank you next up we have alternative services which has an issues list"
  },
  {
    "startTime": "01:26:02",
    "text": "uh which of the authors wanted to take the lead on this one apologies we didn't coordinate that beforehand um I can step in for that one I don't think we've had a whole lot of movement here because we're going to be spinning up the design team to discuss a possible successor draft and what that means for the best that we currently have adopted so some of these are going to roll forward to be addressed by the new draft some of these are going to possibly get closed down as out of scope and I think really there's not anything we need to settle here before the design team meets um so we have a Time picked for the design team meeting I'm about to send out the meeting meeting invite for that and if there's anybody who hasn't previously let me know you'd like to be included please do say so now that sounds great um I suspected we were in that state for this draft but uh it's good to hear that you're making some problems there at least putting the groundwork in to make some progress so hopefully we'll uh we'll get it going there um I think we can move on then to the final draft in the agenda which is origin H3 get that up oh does not list issues we need to fix that and and where are we at with this one Mike so we had one open issue that was editorial uh there was a PR for it that sat and merged for quite a while I've merged it I've pushed a new version of the draft so there should be a01 now and there are no other open issues it's"
  },
  {
    "startTime": "01:28:00",
    "text": "a really simple draft does anyone object to working group Last Call on this would be my question and also has anyone implemented today I think the implementation question is fascinating here but you know Martin comments that they have a plan to meet to discuss a plan that's indicative of this area pretty much I think there's probably some more bigger discussion to be had here that might tie into the previous work you mentioned and or at least be adjacent to it so um I yeah I think I think once you you tell us that you're ready we'll uh go ahead and and uh start the working group last call and uh get get this one out there this is really effectively bookkeeping yeah the story anyone could have implemented this the obvious way and been in complete compliance with this draft right right Lucas hello is this any better yes turn off and on again um yeah I I think like my issue just got resolved it was really basic I think there's a danger of kind of face planting here and and this is so obvious an easier thing to do that we go oh yeah but we might redesign the world and we shouldn't no we shouldn't spend any more effort on this there's like zero effort to spend if if origin frame as it was defined for H2 it's not just the frame it's all the other stuff that comes with it like if if people want to implement that thing great like if they don't and they want something else we're gonna have to go away and redesign that and it's not going to be called origin it'll be called something else so um yeah not not finished it's off raises"
  },
  {
    "startTime": "01:30:00",
    "text": "weird questions for other people in the community like there's a um a thread of discussion around trying to contribute origin support to go right now for H2 and they're like well H3 is not done um well wait or like so um I I think just do this and and we'll deal with the other stuff but because that'll take a year or whatever that would be my opinion and I think the draft's in a good State I would Implement support for this in Wireshark um as like whenever I find the time I know that's not a real deployment but I mean as you said this is bookkeeping this is exactly the same as the existing origin frame just for each three there is a fix I would like to make to the origin frame but it would be breaking so I'm not doing it here fair enough okay so we'll go ahead and proceed with that um that sounds eminently sane thank you Mike for your service and doing the the bookkeeping stuff we need folks to do that too so thank you very much for that um I I since we have a bit of time I want I have one other piece of business I'm going to briefly talk about or at least get some opinions on uh the retrofit draft we have uh just these two open issues um and and the one that I want to discuss is the 2225 uh Martin asked you know right now the retrofit draft has the new date type defined in the draft and in discussion I think we've kind of Outline Three possibilities one is just to leave them in the uh retrofit draft and let people find it there the other is to split it off into a separate draft so it it is it is its own RFC it has its own number so maybe a little easier to find and Julian made the third suggestion which was to do a revision of"
  },
  {
    "startTime": "01:32:02",
    "text": "structured Fields itself to add the new type uh we don't have any open Errata on structured fields and I'm not aware of any big changes that need to happen there um so this would probably be the only change the only thing that comes to mind for me is if we reopen structured Fields so quickly we could perhaps remove the a b and F from the document because I think since then we've decided that it might be a little distracting and we're trying not to use it um I I don't have strong feelings in the other three ways I think left to my own personal devices I would probably just leave it in retrofit or maybe just put it to a separate draft I'm a little wary of revising structured Fields so soon after it uh opened up uh I just want to know if anybody had any thoughts uh about where they should end up and I already see Justin I said negative one to remove the Navy enough well that's luckily a different discussion so maybe I shouldn't have put that out there but does anybody have any thoughts about where this should end up so it seems like Julian likes the idea of her revision of the structured Fields one I kind of like that idea myself honestly if we can we can teach the ITF to to accept revisions uh on on relatively short time scales um that's that's good for everyone involved and um to Julian's point it's much nicer to have all of these things in the one place we can just go this is the spec you implement this back and it has some test cases that are associated with the spec and I think that it's probably doing a community a better service than trying to patch it in certainly you know an appendix and some other unrelated draft might be a bit more difficult to find and um I disagree with Justin I think"
  },
  {
    "startTime": "01:34:00",
    "text": "ABN f is a an abomination can go and I see Tommy is agreeing with Martin's sense there as I understand his comment in in chat I guess my personal response is philosophically I absolutely agree I would love to wean the ietf and indeed the entire Community off of referring to numbers um because it's ridiculous uh you should have you know one version of the thing I just I'm a little hesitant to make my draft the guinea pig but hey what the hell what's what's philosophy for um Justin uh yeah so I I agree with the philosophy that it makes sense to put everything all in one place um I'm just going to say out loud what everybody's probably thinking it feels really weird to do that because this is you know the paint is barely dry it feels like on um on a941 and so um like I I apart from that strange feeling though I don't see a reason not to uh because we wouldn't be really trying to change other pieces of the draft where we're extending it and keeping everything in in one place um alternatively If This Were to go in its own separate extension we would inevitably have a this draft that would collect it at all in one place at some point in the future so we can write it now or we can write it later oh also keep the ABF foreign I found it very useful for implementation personally that's the dangerous part um that I think so taking all that on board it sounds like we want to put it in a revision of structured Fields"
  },
  {
    "startTime": "01:36:01",
    "text": "um I think my only comment about that is is that that sounds great as long as we can keep that effort very constrained so that we don't make it a you know six month 12 18 month whatever efforts that uh blocks other work if other work needs for example if people you need to refer to the date stuff so we need to have it tightly scoped um so I guess for me personally maybe the next step would be uh I could submit uh zero zero of a draft as a proposal for a revision and we can do a call for adoption on that if folks think that makes sense we can even try and do that in the London time frame okay and yeah I think it's a great Habit to get into it we could even call it a living specification if we were so bold any other business uh we have a little time if folks have other things they need to discuss otherwise uh hopefully we'll see either in person or online people in London anyone okay thanks to everyone for your time and like I said hopefully we'll see you soon and and again if you're interested in that design team please do get in touch with Mike uh we'd like to get that going thanks oh Tommy thank you to everyone for your good input thanks"
  }
]
