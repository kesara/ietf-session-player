[
  {
    "startTime": "00:00:06",
    "text": "uh hello e e can someone test the audio say hi or something hello everyone can you hear me yes excellent hi hi hello everyone e"
  },
  {
    "startTime": "00:02:31",
    "text": "so maybe just one or two minutes Asal is here so he'll be showing the slides um I updated the slides a little bit actually okay let me see did you upload the slides to the data racker or uh not yet can you send me the link sorry about that yep or you can send me the the the file and I'll do that right away for you so I will present the slides we will be starting in a minute"
  },
  {
    "startTime": "00:04:03",
    "text": "uh you should have them now Alex yes I'm just uploading them so this is um an official in for the shic working group um well as usual would be showing the intro slides and uh in particular the network so you're aware I'm sure of the patent rules at the ATF so if you're aware of any a new proposal which is subject to IPR then please announce this IPR or refrain from discussing these new ideas and uh you know that the ATF is very sensitive to um code of conduct and how people behave during those meting those meetings so please behave and if you're aware of any form of harassment then you may contact the Ed team the link is given here and the the agenda for today is three pieces and yes I guess R's slides will be uploaded soon so we'll start with um uh shake for cdz devices so it's going to be Ard and then uh to tokenizer base compression and and then we'll have"
  },
  {
    "startTime": "00:06:00",
    "text": "a discussion on the Chic architecture Concepts and some Maes that car and enough work together and so with this maybe since it's already time we can move directly to Edgar edar are you ready do you want me to to throw you to present your slides um I did some minor changes it's okay that I share my screen okay please go ahead okay so I should be to CR you the screen it's okay it's waiting for your slides let's see okay can you see not yet it it says that the share is being started but I see I'm not see see the slides actually okay you see them there there actually they appeared as a small icon next to the icon of the speakers in the lower part of the screen okay car and as well Pascal did you receive the slides I no I'm seeing that the screen share is being started but I don't see the screen share itself it's maybe on somewhere on the screen of uh uh I granted I granted edar but go ahead edar other people say it okay okay H so basically we did some changes to the to the or additions to the Zero Energy device draft and um basically what we have added was a something related to uh more details about the delay friendly ER"
  },
  {
    "startTime": "00:08:00",
    "text": "optimize Transmissions also a bit of the architecture how it could work and also about the context configuration so um for example the fragmentation parameters and then also a little bit about payload compression so um this presentation have a a some slides that I already presented like for example the different topologies the one we are focusing mostly is the topology one where the device is connected to the base station directly at this at the moment and then we want to ER mostly ER focus in device C and device B so um the the these devices are the most capable and they have some kind of energy storage so they could ER in theory produce um um transmissions and and even amplify the transmission so they could actually reach a mro base station um so this also I have presented before so basically what are the characteristics of this kind of devices so they might have long delays and they require overhead reduction because ER they don't have that much power for the transmissions and then this is the first slide I want to discuss the whole idea"
  },
  {
    "startTime": "00:10:00",
    "text": "is that um these devices they produce certain kind of um payload uh which I I will talk a little bit later and then but this payload most probably cannot be transmitted at once so it can be that they have to segment it in several transmission and you never know when these Transmissions are going to be finalized so it's kind of unpredictable in some cases when H the device will get energy to do the next transmission therefore it needed in the architecture that the operators could kind of catch this kind of packets so that they could when the object or is um finalized can offer them to the applications or the application servers so that could be done either by AP teling or by apis or some sort of way of notifying hey now there is some data and you can fix it um this is maybe one of the things what we we try to explain a bit better so the idea here is that we utilize Shake as a transfer protocol what does that mean it means that instead of dividing a a bucket in fragments we divide a full object in fragments and then those fragments have some timers and have a also a window and"
  },
  {
    "startTime": "00:12:03",
    "text": "a r transmission and then these size of the tiles they should fit to the sizes of the transform format that these kind of devices can utilize and the whole idea is that we can adjust the parameter according to the expected delays or patterns of that device so how the device is expected to um uh to behave then these kind of different parameters could be updated also the window size and then when finally all the packets are being transmitted then they should be a notification yeah this uh whole object has finalized and we can ER then transfer it to the application so this is one change with respect to how we use Chik at the moment because we are proposing to use it for the full object instead of using it for one pocket and this would mean that um you could also think about an object like a jumbo IP packet of course but um yeah the idea is that by using the characteristics of chic we can actually achieve this kind of um delay tolerance or delay um friendliness towards a the energy harvesting that is needed here then uh we were talking about this"
  },
  {
    "startTime": "00:14:03",
    "text": "Contex configuration and then there uh we were saying that um there could be h two possibilities that uh there could be preconfigured already in some standard some configurations that you only select Maybe configuration number one has this kind of er characteristics number two and so on or it could be that the radio network for the more capable devices could send the characteristics of the um context so there are these two options but um for the more simpler devices most probably this would be the option Theo one configuration and the more capable devices that even have compute maybe could have this second option and now what this mean well first of all we have to think about the delay expectancy so how long do you expect that the ER they could be a delay so it could be that the the expect is that there no DeLay So then that would be one type of configuration or could be that the delay is in hours in days in weeks or even month uh so then based on that then we would need to have different uh values for the timers for the ER packet transfer interval the inactivity or Al the R transmission and"
  },
  {
    "startTime": "00:16:01",
    "text": "also H depending of how big the packets are going to be transmitted if they are a small medium or large and then of course this will affect the reliability as well yes Lauren you have a question or comment just a comment about the the delays so in the data model we we Define way to represent time uh that could be very very short but can be very very long so I don't think it's a it's a PR here then there is an implementation dependent yeah um what the the idea of this delay expectancy is that we are thinking about for example is out of band configuration so if we have something ma to ours for example so you would think that maybe you will have R transmission timers that could be of Maximum 6 hour and in activity timer of three to four hours so maybe this is something that could be used if something is using solar panels for example so you wouldn't expect that um uh the device is working in the night and it won't work in the night but during the day maybe this would make um sense or if there is a something that the person is running and then this collecting energy from the movement then there is the case of a day"
  },
  {
    "startTime": "00:18:01",
    "text": "so it might be that uh it ends uh it takes a full day for the device to uh recharge for sending a packet then it can be that the this we have we are thinking about four to seven days for having ret transmission and in activities of two or three days and then we have the week case uh um where the maybe the idea is that the ransmission timeing and activity timer could be quite close to the transmission time because you don't want to weak weeks hello I hear you but I lost everybody else uhuh here okay I will was a discon but again yeah something happened with the server well hopefully you hear me now I I I reloaded my page I hope I'm not respons POS for restarting all okay ER I hope you heard the last thing I say so about the retransmission and inactivity timer to be quite close to the transmission time and then the same happen with the month so these are so long periods that the the values uh that we think they should be quite close and then"
  },
  {
    "startTime": "00:20:01",
    "text": "um of course these are extreme cases that can happen still that um uh there are certain um things that they don't receive enough power um because they are on ground or they are I don't know in some location where they don't get er energy to recharge so those could be extreme cases but maybe we want to consider them anyway and then finally the last thing we were uh adding to the draft was to reuse the same uh compression engine that this used in Chi maybe also for the some payload so the the the idea is that if you have something like C CML uh where you have certain values you could actually compress quite a lot of it if we have a way to indicate that you are also compressing the payload and uh we have been thinking that we could go this way that many devices is are going to be quite simple and they are just sending certain values and many times could be even the same value therefore we could reuse the same compression engine for the payload and then uh make it possible H that with the same implementation we could even reduce further the packet sizes by doing this kind of P"
  },
  {
    "startTime": "00:22:00",
    "text": "compression so those were the updates we did and then one question uh um I would like to ask also to the group what do you think would be good to also think about adopting this kind of u h draft and uh evolve it together so that we get it um further and then uh maybe utilizing uh 3pp I know that we have beening 6 use cases and the sh is has gain quite a lot of relevance so starting with the this ambient iot or could be something that we could uh actually influence yes go ahead back yes edar I I have two questions first of all uh before I ask my question U yes I'm mean I'm in favor of adopting a work like that as you know some form of best practice document that would explain how you can use uh shic for extreme low energy extremely rare communication um this being said I was thinking out loud of what those Communications are because um yes you gave an example in 5G case makes sense I was wondering about daily tolerant networking in general yeah like for example satellite yeah or even to the planets you know yeah if and and when you're doing that you might want to relay pack and so I was wondering because now at at"
  },
  {
    "startTime": "00:24:02",
    "text": "the moment we don't relay fragments I was like okay do we need some work about relaying fragments how that would occur yeah and and that might be actually relevant for other topologies like for example toy topology two as something like that yeah and we we we don't have it right now in shic I was like oh okay so if it's purely a lower lower layer thing then shik doesn't need to know um but is there something we could be doing even if we impose some restrictions on the repeater um is there some standard work that we would need you know for those repeaters just something that was thinking out loud at the time you were speaking Yeah I think um we have to maybe start with the simplest case the direct communication and maybe after that start to consider what happened with intermediate note but um you agree with me you're considering a best practice type of work at that point when you're doing that you don't change Shake right well there are some changes that we are proposing like for example ER that we can use shik for fragmenting a full op object unless we are saying that well we are saying that this is the same than um a big pocket I don't know yeah but but CH is kind of transparent to to what you're compressing right so if it's a big big packet quote unquote yeah I understand well as long as we can agree that that's the case there is no problem um and then the other thing is maybe"
  },
  {
    "startTime": "00:26:03",
    "text": "about the packet sizes and and they could be different configuration so this is mostly maybe context management there could be different configuration because the same machine or the same any device could have small packages or large packages and maybe it might have different configuration if the packet is small or the packet is large it might be that because it's large is going to take days to transmit the whole packet but if it's a small it might take hours so then the configuration might be different so it's a little bit more in the how to configure this kind of things that in the Chic um ER functionality itself so maybe I I agree with you that is a bit like best practices in that sense yes laen yes two two question and comment uh do you which do you target one uh fragmentation mechanism or you uh all of them are are possible what mean you it's a on error or it's no a for um I think we could have a a any although for cellular I think a on error is the most suitable okay and and so you know when you you can send to the device because if you send an acknowledgement"
  },
  {
    "startTime": "00:28:00",
    "text": "to the device and the device is sleeping then it will be lost yeah and most probably ER the the specification needs to have some way to communicate with the device when it knows that the device can receive so that's something that has to be a standardized because uh the device need to be tracked so you need need to know what it is okay so then there will be some kind of ding U capability H but then that will be most probably for the more capable devices this B and C um I would even think that maybe even see mostly okay and do you see an interest for the fake in fragmentation because we we are starting working on that and uh it could be a way to secure your transmission without having uh to request what is missing yeah sure everything with fragmentation will be [Music] um interesting okay and for and forther comment I will contact you offline but we had the PHD student that work in a compact way to represent sendil so I can send you excellent thanks yeah Alex yes thank you very much Edgar so um yeah I mean a lot of very interesting topics here we are a little bit short of time so I started um a raise of hands about your your question to adopt as a working group item um so we'll let that run for like let's say two minutes um I just wanted to to add"
  },
  {
    "startTime": "00:30:00",
    "text": "to join the command from um uh from Pascal that probably you know this is heading to an informational type of document um you know but informational in some sort um and I find it like very interesting in several aspects um probably what we can what you can achieve with this document is to um identify like okay it will work like this so that we can see okay we're missing that piece we're missing that piece and then we can do a very focused like standard uh standard track uh uh document what what do you how how do you feel about this yeah sure we can start like that and uh we can see also how the 6G is evolving as I say there are we are starting to consider chick not only for these Zero Energy devices but for all use cases so it could be something that they evolve even further so that's okay yes yes yes I mean definitely and I mean I really uh personally I like very much the work that you that you that you're doing with this document and I I think that it's an excellent way to drive like to to to to get this topic in the working group so that that's that's great for me um and just one probably a mini pointer you remember that last time we discussed um that you presented the work uh Juan Carlos uh said that in Wi-Fi there is like a similar kind activity that is that is starting yeah so um maybe you you would like maybe you can like Ping him and see hey well is it something something that is close so in"
  },
  {
    "startTime": "00:32:00",
    "text": "which could be only one document or is it is there sufficient differences so that um I mean just to see if if he's interested in contributing in sure that sounds it's really very timely and very very interesting work for me personally um so with this being said uh uh so we I'm going to terminate the show of hands so we have nine people voted for and none against and none with no opinion so at least for me um in this working in this during this meeting uh everything is like good adopted but of course we'll need to confirm that mailing list in the mail yeah moment of course we're heading for an informational track um excellent thank you thank you everyone yes thank you yes I'm sorry do do you want to publish some update before we do the official call for adoption on the meeting list or do you want in which form do you want you know what document do you want us to use um I would have to check the if something um something uh let's say very important is still missing and then I can't reply to you at the moment I don't yes so please please send us an email offline uh to to the chairs to tell us that you you want to make an additional publication before we do the call here clearly the intention of the working group is to adopt but the actual content uh people will have to check it on the web and um but I I think the current content is good enough to start the adoption in my op and then um if we there is um some uh"
  },
  {
    "startTime": "00:34:04",
    "text": "feedback or comments we can consider them and if needed then we can do a new version but I think with the current version is okay to start the ad option and then we need to work further for example if we want to establish some Er specific configurations like we were talking about and things like that yeah I was I asked a question because we we discussed the need for relays we discussed whether it's informational or not informational and so it's better to to adopt a document which has close to the type of content that we want the final document to have so if if you're very clear that you don't want fre lays so far or if you're really clear that um yeah I think for the time being relays are not being conf consider even in the standardization so I wouldn't in 3pp so I wouldn't start from there at the moment okay okay so if you're if you're happy with the current document to call for adoption we can do that yeah I think maybe some Er format Corrections could be done because it's I'm more concerned with the scope the document than you know autograph something yeah like okay we can just just shoot it up and then you know we'll we'll confirm on the mailing list and then you know we'll change after excellent thank you yes sure thanks Edgar and I'm really sorry we're a little bit behind so the floor is yours"
  },
  {
    "startTime": "00:36:00",
    "text": "um let me see will you share the screen or should I go ahead go ahead if you can okay just a second um okay perfect so you're sharing so I'm going to be presenting about a concept that I have developed in the last ITF in the hackathon of using uh the bite pair encoder tokenizer the ones you have in common llms for compression of arbitrary strings uh yes thank you for the control so um there is a g repo with the code I have not yet shared I will work on that um but for now I can give you some of the results and and a bit of the the general point of of what I'm trying to do so just for context uh you may have used llms recently I mean you there is the wellknown G gbd4 there is Lama there is a million other Mixr and so on there's many um they use a process called tokenization tokenization is an independent process from the LM it has its own so the tokenizer has its own training data set of text um which will be different than that of the llm it will be much smaller of course uh and the point of the tokenizer is to translate back and forth between raw text or strings and sequence of tokens and the llm later only ever sees the tokens and and never um deals with any text directly so um for example there you have uh using the well-known gp4 tokenizer there's a million tokenizer there's many um uh you can see how the encoding of the hello world text looks like in four tokens so um the different tokenizer have different vocabulary sizes uh they have different encoding SCH I'm using bper en coding but there's others and and each tokenizer is"
  },
  {
    "startTime": "00:38:02",
    "text": "optimized for compatibility with a specific model so there's a lot of um manual testing at least to my knowledge manual testing optimizing depending on the use case so um next page so what what I'm trying to do here is for uh seore has a bit of a limitation which is that the uh arbitrary strings are not really uh uh subject to compression so if you have uh uh addresses or you have keyboard inputs or arbitrary strings normally you just send it as it is uh so this would be like a new uh general purpose solution for arbitrary strings is not a map is a vocabulary that needs to be shared between the two end points but uh that you can run for any string and um the vocabulary in my test didn't have to be too big 30 Kil kilobits kilobytes actually um already yielded some degree of compression um then another nice feature I think Caren mentioned that is that you can do a a string pattern matching of the tokenized string so you when you have the two tokenized strings you can compare them providing again that you have the same vocabulary and it works also on strings that are not I mean it obviously works on new strings that are not used for the vocabulary training so you have new you know let's say you you receive strings in other languages or in other um other kind of strings that maybe have similar tokens you you will reach some degree of compression and then this means that if can you hear me sorry I lost connection for a moment yes you're back yes okay um did you hear the string pattern matching or did I was I cut short earlier sorry about that yes yes it's okay it's okay okay perfect"
  },
  {
    "startTime": "00:40:00",
    "text": "so just micro micro stuff all right so um basically yeah as I said like it works on new strings that were not part of the vocabulary training so um okay it doesn't I lost the control of ah now it came back sorry no it didn't I lost control of the slides let's close the deck can you share it again uh I took control I can I'll change the slides for you thank you yeah is it is it this where you want to be next implementation is it okay here hello can you hear me one less please there's some weird connection issues apparently I don't know if it is just me no it's not just you I mean we all experienced it earlier so let let's do a slide four please so the let's say that in a in an example you have there some address arbitrary address that the device is sending then the tokenized version would look like an array of those integer based on a vocabulary of uh let's say it looks like 4,000 tokens roughly or 3,500 tokens roughly so next slide uh what do I have in my implementation so I was using minan BP minimum Viper encoding python Library pretty useful the c 2 for encoding and decoding needless to say I I do first cabore and then of the cabore the remaining uh strings uh I think it's CL I forgot the term but the three type three strings are the ones that are"
  },
  {
    "startTime": "00:42:01",
    "text": "tokenized and then for the vocabulary I was kind of trying to cheat but I was not very successful I was using Broadley dictionary an rfc's a straining test but uh you could use other Tech I think it can be optimized greatly the vocabulary but still U anyway that that's what I had for now for the vocabulary training aspects so basically what you have there in the screen the the code it shows you the training phase in which you have you're checking the occurrences and you are seeing which are the tokens that are the most common and then basically you take the ones that are the most common and then that that's your vocabulary uh next slide so for example on a let's say that you have this type of Json um you you could so the tokenizer would not affect common er uh first of all it wouldn't affect integer values because they're already optimized or float values uh it wouldn't affect uh mapped uh parameters so you have already your own mapping function from temperature to Value one from humidity to Value two or whatever there's no point that's already very compressed but for instance if you have something like a URS with common patterns that can be tokenized or names or addresses or things in different languages or time stamps those could be suitable for tokenization um next slide and then on the results basically uh yeah as a disclaimer I was using synthetic data is not that easy to come by with big data sets of uh of uh iot related the payloads for some reason I couldn't find many I found some databases for uh somewhat related uh uh strings like those of uber vehicles with location information or that type of stuff I I couldn't find better synthetic data better real data so I was also using synthetic data model based on live 102m schema and yeah"
  },
  {
    "startTime": "00:44:03",
    "text": "basically what what I achieved was about 20 30% uh data compression from the original SE compression so basically compressing all the strings and then U another thing that is enabled by the way I mean is that the once you have everything tokenized you can run inference on the receiving end uh because at the end of day llms consume tokens on the next there is a graph of the um of the yeah the values that as they were compressed so you have uh the SEO length in red and the tokenizes uh the total uh tokenized length in purple which is right below um yeah I mean nothing surprising there basically the uh yeah the the total string length is longer than the to I length as is to be expected and um yeah I mean I did run also larger tests but I mean actually one thing I could be useful is to get my hands on real data with the has strings and all that so that that would be very convenient by the way um but uh next slide please as fruitful thought basically you can achieve a certain degree of compression by default on arbitr strings so that's pretty nice um and then of course it's not what you're targeting is Hardcore compression then you will run multiple cycles of Viper and coding but then you cannot do a string manipulation uh then another trade-off would be um the hardware requirements of the endpoint they are not so again providing that you have the vocabulary running this tokenizer is not expensive but of course draining the vocabulary is expensive but you can do that in another endpoint so ideally you you run them in your system you you you create the vocabulary do it in your system and deploy it and send these 30 kilobytes"
  },
  {
    "startTime": "00:46:01",
    "text": "once every now and then and and share the same vocabulary among all of the uh endpoints and then uh yeah the vocabulary size and the size of the input string so depending on the vocabulary size you can achieve much better compression uh at the cost of course of require more memory um yeah and the for future work uh basically like I haven't explored too much the running inference on the receiving endpoint but I think it has a lot of potential as well um then optimizing the vocabularies I already mentioned like I it was a best effort and the input training test as I said like I didn't I was lacking a little bit on on on that side as well due to the synthetic data if if I if there was a really good data set for uh iot data uh for Strings I could use that both for the vocabulary and then for the compression and then try also with new uh training sets afterwards and then I think it's just references the next slide please I know yeah so first yeah sorry before that so I don't know I mean this was an exercise in the hackathon just to to see if this works and to to try to see if this is something um I don't know where it fits in the ATF I mean you need a vocabulary shared between the different endpoints for this to work so that was that would be a requirement Main requirement really um and I don't know if anybody has explored this already or I mean I'm not inventing bite pairing coding that has been done for a for a long time but in the context of compression I don't know if it has been used in this way ER in shic or in other places so I would welcome feedback or or thoughts um one more yeah sorry go ahead thank you very much Hae so um as we are a little bit behind of time so I'm I'm I so I love your work I find it super"
  },
  {
    "startTime": "00:48:00",
    "text": "interesting just if anyone has one question for so okay I'm I'm keeping the floor then so um yes it's it's like mostly on on observation um and yes I think that as you said it's really important to see where we get the data to train these um uh these dictionaries like these shared uh uh tokenized dictionaries and to see also how the compression rate varies with the size of the D dictionary and like the compute power that's necessary on the end device um so that that would be really useful thing I think um because then we can see if there are use case what are the use cases for that right uh and yes L said that both you and Edgar you're talking about payload compression yeah so probably we should yes add this to the architecture document as a way how do we address that um but uh yes so I um I I I found this really interesting uh work and um let let's get back to the on the mailing list uh and uh I would really like to rediscussed one you know on a time that we have a little bit more time sure I mean if anybody has comments or thoughts please contact me over telegram WhatsApp and and just be blunt like any you know if this is nonsense just tell me what the hell are you doing and if this could be something also be equally blun I mean I'm just curious to to know how far can this go and whether it's useful enough I understand that for those who work hardcore into compression maybe it's not so useful but for general purpose General compression mechanism this could be good thank you for the time yes of course with M pleasure and thank you for for for the presentation so uh we are a little bit behind of time uh quite a lot so Carles are you presenting or is it is Anna"
  },
  {
    "startTime": "00:50:01",
    "text": "presenting hello hello yes so yeah well I will present the the first slides and I will present some of the last ones okay so yeah see just one point if you would like to have like time for discussion maybe we can also consider putting part of the discussion like part of the slides for the next time because I know that you have like a very big important presentation so like uh take your time and the next time we'll we continue okay that makes sense thank you okay so um this presentation is about some of the thoughts that we have an and me we are trying to to think about how our six load draft which is about transmission of shic compress package over 15.4 networks uh would need to be aligned in order to be like synchronized with the shic architecture draft especially after uh the last date of the Chic architecture with com Concepts such as the shik Heather and related Concepts so um well I'll be a bit faster but basically well uh the main incentive behind the six low document is trying to use shik as Heather compression mechanism as an alternative to six lopan traditional Heather compression over 15504 and uh now however there's the shik Heather concept which has been really developed in the last update of the shik architecture draft so for six low uh we would like to keep this shic Heather fully compressed only well that's only if possible otherwise well contributing as low header of head as possible so as you may recall uh the main problem we have in in the six low draft is multihub communication uh so sending sheap compress packets in a multihop scenario so for that there's route over and there's also mesander and for rout over we have three modes in the document straightforward which means"
  },
  {
    "startTime": "00:52:02",
    "text": "that all nodes well all the intermediate nodes the routers have all the rules that are being used in the network however this has issues in terms of scalability uh then in order to avoid that we have two other modes tunnel baste which uh exploits if you are using Ripple then there can be a tunnel from a source up to the route and then from the roote if the destination is internal to the six lopan Network then uh there's another tunnel downward and an alternative is pointer based approach where there is a pointer which is prepended to the shic compress uh packet and the pointer will tell any intermittent note how to find the residue of the compressed I6 destination address so that the router even if it doesn't store the rules uh it can still determine and reconstruct which is the pv6 destination address in the packet so um okay from here there are some Concepts we've been thinking about and uh first of all we understand that there could be like two possible Network types uh one of them is what we call single instance networks where all devices in the network would use a single sheet packet instance and in this case what we plan to to require in the document is that the Chic header in this case must be fully compressed and then there's another case here in red multiple instance networks um where at least some devices in the network use more than one shic packet instance here we understand that the shic header cannot be fully compressed and this has been like the main uh object of our uh discussions so um here we have some example networks and how uh this multiple instance concept would would be and and the fact that we we actually need the shic header which cannot be fully compressed um by"
  },
  {
    "startTime": "00:54:00",
    "text": "the way in the box at the right when you see that it's not compressed it should say it's not fully compressed okay so here we have an example this is an T tunnel based approach so let's imagine that a transmits H aate transmits a shic compress packet up to the sixl BR who would be a ripple route and let's assume that it's using rule id2 to compress the packet then um well you can see also that there are several rules being used here with several rule Ides and you see two colors so black means one shic packet instance blue means another shic packet instance each instance would have its corresponding set of rules so when the celb receives a she compress packet with ru2 then the question is okay uh which one of the instances is the one uh that needs to be used um the black one the blue one so for this uh we need this Chic header which cannot be fully compressed and in the other direction it would be a similar problem so if host a receives a shic compressed packet with rule id2 then it needs some not fully compressed Chic hether to be able to determine whether uh it's the black rid2 or the blue rid2 that has been used so this is an example for TR then for pointer based or Pro um something similar may happen in this case it's not necessary to to go through the route imagine that host D transmits a packet to host a and uh well in this case if host a receives a ship compress packet with rid2 then there would be a similar problem uh okay which is the rule that needs to be used the black one or the blue one so for that we need this uh not fully compressed shik header and in straight forward where as you can see the the intermediate routers would need to store uh the rules being"
  },
  {
    "startTime": "00:56:02",
    "text": "used well something similar happens as well here host a would transmit to its next hop which would be the 6lr on top and then if the shic compress packet uh carries R2 again there's the same problem U which one is it the blue the the black one and for that uh we need a Chic header which is or cannot be fully compressed and uh um also in this is a special case because um in the straightforward scenario this would work as long as there is something some means that make sure that there is some parameter in the shik Heather maybe session ID or whatever which has to be unique Network wide um otherwise this might not always work so um finally there's mesh under so here uh by the way there's uh the issue in the slide that well there's no sixl RS in mesh Ander but this would be mesh and the forwarders that anyway um imagine that hostd transmits a packet to host a then uh the packet is routed by mesh under it reaches host a and uh a similar problem might happen so if we look at the the details of the example it might seem that for instance if host a receives a packet with rule id2 then it might be possible to say okay uh if the cender is C it's the black rule if you look at the information on the right on the legend and if it's uh the it's D if the source is D um then it's the the blue Rule and well this is something that could be used because in the mesh hether there's the information of who is the origin of the packet however uh then there might be ambiguity as well in in some case there could be two rules uh corresponding to different sets of rules"
  },
  {
    "startTime": "00:58:03",
    "text": "and uh for communication between the same two endpoints so even in that case we might need a not fully compressed Chik header so then uh the formats would need to be updated the formats that we have in the draft because um now we have to introduce the presence of the shik Heather so this is one example for trro tunnel based so uh as you can see uh in with red uh there's the Chik header which would be prepended well would appear before the shik packet and uh here the point is that in some scenarios uh this could be fully compressed the shic Heather would require the transmission of zero beats over the year but in others as we've seen there would be some beats that would need to be transmitted um in the case of pointer based well this is the Pro Heather this is the Heather that is prepended to the shic compress packet which includes the bat pointer to discover the compression residue of the I6 destination address and here the natural thing would probably be that after the pro Heather uh there would be the Chic Heather and then the Chic compressed packet however as you can see we are considering to locate the Chic Heather like in the middle of the pro Heather and that's because somehow we felt like uh this could simplify a bit or keep more simple the definition or the behavior of the bit pointer the pointer States after the end of the address length how many bits do we have to count to find the start of uh well the compression residues and um however well uh we thought that this is maybe a simple way to to do it and well maybe more natural again here in straightforward rout over uh we would have a Chic header uh before"
  },
  {
    "startTime": "01:00:00",
    "text": "the Chic packet again in some cases fully compressed uh in some others maybe not so we believe that in the draft in the six document uh we may need to add some section discussing specifically the Chic architecture Concepts how they apply in 15.4 networks and uh we understand that there are the two possible scenarios that we were mentioning single instance networks where the shik header is fully compressed then uh when the standard say one shik Heather instance which is minimal which contains like a single implicit rule that everyone all nodes know similar to what we were doing in lp1 uh recently and um then there's only one shic packet instance therefore it has uh its own its corresponding set of rules then maybe one question might be what is the discriminator here um so we think that perhaps it could be the shap dispatch or in the case of the pointer based approach the shake pointer dispatch because it's like the first field in the 15.4 frame payload which tells that what comes next is uh compressed by means of shik and parallel to that there would be like another section for multiple instance networks so here um there's uh for the shik Heather IDE is that it cannot be fully compressed as we've seen before then for the shik Heather instance there would be one set of rules which might comprise maybe more than one rule if necessary um there would be several packet instances each one with its corresponding set of rules and again for the discriminator we believe that the same applies that uh perhaps it should be the shic dispatch or shic point dispat um then I guess that maybe Anna can can continue or I can browse the slides for"
  },
  {
    "startTime": "01:02:02",
    "text": "her if there still so so I mean we're like two minutes behind the time uh would it be okay for you too to like maybe just have like a one or two minutes for questions and then start again with your presentation next time because I find it like very uh very fundamental for what we're doing and um it would be really nice to have the time to really go into it um yeah sure um so uh I don't know an do you have anything to add like a very very rapid thing well the next slide was about the transition protocol and how we can um Define the way to know that after the IP header compressed by the 6282 we have the she compressed by UDP and C header and the next slides giv the shic header for Des skying the UDP next hether and the coap port to know that the the next head there is not only shik but you have an newp and you have Coop after and the rule that we may use to compress this okay so what I I guess we need to Red discuss that next time I mean yeah so so let's do it correctly next time and just because here we have some points to discuss about session ID and how we can uh if we really need it or not yes we need to discuss more in detail yeah I mean it's it's really and and probably actually it's quite good like this because we we have like a rapid overview and then we have like the time also to get again over the slides and and actually really discuss them um so probably I will suggest that we stop here at least what we want to do is to use all the new version of the architecture"
  },
  {
    "startTime": "01:04:01",
    "text": "and to apply it to the C slan pollution and see the different points yeah that was the idea of this new version yeah yeah I mean it's it really looks like an amazing work right it's uh and it's very like it's there is a lot of things to for us to discuss like a lot of questions and so thank you both thank you Anna thank you Carles for actually doing all that work because it's really it's like a very like I have a lot of questions in my mind and a lot of things to say so it's um it's very exciting times as well um so I I'd suggest that we stop here um sorry everyone for like having uh for ending like five minutes behind the time thank you everyone for being here um thank you Marco for taking all the notes I mean there everyone participated but I saw Marco taking a lot of the notes so thank you a lot um and see you in two week time bye thank you all thank you bye bye bye thank you byee bye"
  }
]
