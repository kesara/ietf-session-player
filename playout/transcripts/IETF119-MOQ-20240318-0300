[
  {
    "startTime": "00:00:03",
    "text": "Yeah. I already put the agenda in. Just note down if there's anything decided on anything. Also, if you're in the room, please remember to Grab the QR code to sign in. For the on-site tool, and so that you have recorded your attendance. Okay. Cell. Ian says running a few minutes late. Okay. No. Because I'm a little Okay. We've just heard that the I IETF chair is gonna be kicked out of something tomorrow. We"
  },
  {
    "startTime": "00:02:01",
    "text": "not gonna inquire further than that. It is just after the top of the hour. So we're getting ready to start. Thanks everybody for joining us. Here at What is, in fact, IETF 119? We'll be fixing that. That, for those of you who are sports fan, is the GABA here in Brisbane. It used used were both Cricket and Australian Rules Football aka 40 an interesting contrast in in kind of What cricketers wear and what footy players wear? I encourage you to go and look that because it's very, very different indeed. We're gonna go through a little bit of administrative to start this is the note well since this is, one of the first working group sessions for the week especially if you're a new person to the IETF, you should be paying attention to this, and it's Oh, you're not here. Yeah. Okay. 5, 6, There we go. So this is this is the note well and not the GABA. Especially if you're new, you should, take a quick look at all of the BCP here, which includes information on the standards process, working group processes, Our anti harassment procedures, our code of conduct, information about copyright, patents, and the privacy policy so please, familiarize yourself with this and note, especially that you have IPR on a particular idea you bring it up in a working group meeting, you must disclose it to the that's the way we work. If there are any questions to that, I'm gonna turn them over to the IETF chair. Got it. Another whole day to go, and he should be taking taking some Xinnam, Meeting tips. For those of you, who are here in person, you're welcome to you the QR code that's on that screen. To get the mobile version of this to join the queue and do other things. You're also welcome to use Steve, Steve,"
  },
  {
    "startTime": "00:04:03",
    "text": "full client, if you wanna be able to see the slides on your laptop, but please do, be careful of the bandwidth and turn off the video streams you're not actually using. Also be very, very careful if you're using the full client to make sure that you remain both muted and video muted as you go. There is an ongoing chat and the, In the client, it's also available via Zulu. Any questions on that Right. For the administer administrigia, the normal thing to do at this moment would be spend 6 minutes trying to find a scrap. However, Magnus Westerland, before the meeting even started, has volunteered. Thank you again, Magnus. If you're willing to volunteer for our second one tomorrow, please see one of the chairs afterwards and tell us what bribe in particular you're looking for because we're very open suggestions on that. We've been doing chocolate, but turns out you'd like finger limes or some other more Brisbane specific treat, just let us know. 2 PRs, oh, okay. If if you're willing to take notes, we might talk to you about landing a pair, but I will warn you they might get backed out afterwards. don't necessarily claim they'll stay lit. We That's a working group consensus institution. So Is there anybody who needs to bash this day's agenda. Okay. Seeing nobody interested in bashing the agenda will now go to the Hackett on review on MOQ2 read up from the hackathon review. I will note, that there actually two things here, and I'm gonna refresh these slides while while somebody else is talking. One of them"
  },
  {
    "startTime": "00:06:01",
    "text": "is that the hackathon review mostly wasn't hacking here, but people doing it in an airport. Was wonderful to watch the exchanges, going on because it was mostly like okay, if I can get to this before my flight, I'm gonna try it. And, of course, Luke, who has both a toddler and a newborn, was tacking away despite be extreme lack of sleep that implies. So lots of dedication on his party. You. Okay. So I think as far as I know, there's still 6 implementations I'm not sure if there if anybody else has started one that I'm not aware of. Think 5 of them have done all the code changes to implement draft 3. Then we're sort of in the process now of getting things to talk to each other. I think Suhas and Mathes got their set up working. Martin, I was getting close with Luke. Martin and I are gonna have this week. So probably do like we did in Prague and spend some time in the code lounge this week So, just trying to push the things along now that we're here in person. But I think and we'll and maybe we'll try to one of those, make one of those Beautiful interop matrices, matrices, we're done at the end of the week, you can push that out. I might have to vamp longer because I don't see our speaker in the room. Traveled and Okay. Does that work? Okay. Okay. You need to share this. Is this across? Is this a That is not box. a and So this is subscribe subtram So you recall the last, interim meeting there was"
  },
  {
    "startTime": "00:08:03",
    "text": "somebody know really one off button Oh, there's Test. Okay. So at the last interim, we talked a little bit about a bunch of different ways that we could hit the subscribe and a bunch of corner cases that we were coming into in the subscribe. So, And, Yana, and I have gone off and worked on this for a while and come up with a proposal So next slide, please. Before, before we jump into this, I'm sure everyone's gonna be like, yeah, as we start going through this, you're gonna go, you know, your first reaction will be, no, but then what about this or whatever? So let me, sort of explain what this proposal is, explain a little bit why about why we came proposal. And once we sort of, you know, and fine with clarifying questions all along the way on that of what's what's being proposed. But once we get to that, let's let's push off towards the end of like, Hey, is this proposal worth doing or not? Let's get through what 1st. So next, Okay. Next again. You know, when we did the subscribe the first time, it was just like, oh, yeah. We'll be able to put these numbers in that are salute or relative that say where to start and where to stop, And then as we started doing it, it was like, wow. Everybody has a different idea of, like, the the different, elements that are working together, not different people, but, you know, the client and the relays are 2 different relays might have different ideas on what these numbers are at any given point in time of just the timing of things. Like, when you say start from relative -1. What does that mean? And and all those things So we ran into a ton of corner cases on this. Next slide. It's much more of these corner cases on this. And we were going through and thinking about all of the users use cases that we'd seen, and"
  },
  {
    "startTime": "00:10:01",
    "text": "trying to make sure that we had a solution that meant those and then also dealt with all of these, issues, like, had fairly clear answers to all of these. So that's the solution I'm gonna, sort of describe here next next slide. A couple more slides. Okay. One more slide. Okay. So this bunch this, I'm gonna build up on them. Okay? I'm gonna start with the simplest part here, which is the subscribe part. And this is really only about getting to sort of the live edge or close to it. So what we're proposing is that when you do a subscribe, you can specify a starting point that is only, that that talks about it it the data that's there and what you start getting. So instead of this sort of plus or minus ones, which took us down, sort of, some complicated things, or we're hard to find exactly what a live edge was or these things We tried to make these a little bit crisper. So the current one is whatever it it it's the the group that is the largest group ID Whatever that one is is the current one right now. So in my example here, we had a group of 17. The last one, which is generally the one before it, but to get a crisp definition it's the largest group for which the relay has received the last object in the So you, you, you have the last, so, you know, the red object right there before the green one. Okay. So the last group in this one is 16. Sorry? Yes. That is that is another. We need to know that for many other reasons. That's sort of an open but we're working on the assumption you all we we How exactly you signal the last object and things is still a little bit unknown, but we definitely need to know And then the next group is, wait until the beginning of a group that is larger than the group that is current that is the current group that's your currently largest one. So this group 18 And look, these things deal with these definitions are are are selected carefully to dddd very concrete,"
  },
  {
    "startTime": "00:12:04",
    "text": "relay knows what it needs to do, and they deal with issues like gaps or other things, that that could happen. So that's the the starting point for the subscribe. Next, next slide. We think of the the the relay as, you know, the the subscribe creating some some state in the real life. That sets up, effectively a filter of what data is gonna to it. So as the relay gets objects has happened. It has a little bit of information it can look at and decides Do I forward this down to the person who did that subscription, or do I not forward it to that that's basically the decision that needs to happen when it subscribes. So this range filter type idea was, I think, I think Luke originally as the person it that way, but I think it's the right way to think about it. And So the other thing that we did is when we started looking at the use cases for the stop, Instead of providing an absolute spot for the described here, and we're gonna get to fetch in a second, which is like a subscribe with more absolute numbers in this one's also relative So you can say I want to subscribe to, I want to so a default subscribe would just be subscribing forever, right? For all the objects that come after the, the start point. But you can optionally add an end, which is a number of group that you're going to receive that that sets up the end filter of that. So the use cases for this was people who want or, like, I wanna get the current group but just that group. And then later after I've received that data, I might make some other subscriptions or other information once I know what the current group is. So you'd set 1 as this. And it it gets rid of all the errors that you could have in the case where, like, you know, you put an absolute number in as a stop group, but you're already past that point in the stream or things like that. Right? So this, again, because it's because it's relative. It's relative to where the start was. It's very simple and well defined from the relay to know how Now"
  },
  {
    "startTime": "00:14:03",
    "text": "When the, you know, a a point of clarifying on this too is that When the stream starts moving on to group that are larger than whatever this is. Subscribe or ends it or anything like that. That is done through signaling to do with the unsubscribe subscribe done or whatever we not do for it. This is just a filter of what objects get for it. Clear enough on this stuff so far? K. I'm seeing not. Okay. Next slide. So this does not what I was just doesn't allow you to go get the data at the start or any of those things. So this so wanna talk about fetch here for a second. And as I say on the bottom slide, don't get hung up on the name mean, we could have fetch and subscribe be one thing, but, but logically speaking, we have at least two sort of 2 different styles of operation here, whether it's one method that does both or not. Okay. But the fetch 1, Fetch only does absolute ranges. So you you say, a start and a, a start group and an end group, and it's, it's gonna get you that data. It also doesn't deal with future requests. 1 of the so it doesn't deal with stuff that might show up in the future or may not show up in the future or any of that. It's just This tells you what the system has now. So if a relay, gets a request for an absolute range and it has in its cash, great sensitive If it doesn't have it, it needs to request it upstream. It goes in Upstream and gets it. And if it goes all the way upstream in, some parts of the request are not available. Communicates that information down that, at this point in time, that stuff's not available. This also makes it very easy for a relay that got fetch requests from different clients for overlapping ranges, but not exactly the same range to keep track of what it's doing because it's all absolute numbers. So if the first client asks for 1 to 10. And the the next client asks for"
  },
  {
    "startTime": "00:16:00",
    "text": "and so that the relay requests that upstream that knows it has an outstanding for 1 to 10 on this given track. And then the next thing asks for, you know, 5 to 15 It knows that it all request at some of that range, and it could do the right thing of of demuxing that if it wanted and, and sending the upstream request just for the the subset of the 5 to 15 that's or sorry, the 10 to 15 that's missing. Next slide available on this. So, It also, you know, it finds out about non available objects in the, the, the, the region. It doesn't try and figure out why they're not available or they might be available later or whatever. It's just like Here's the data now also one of the things that we've really felt like was grossly simple or Gross this wrong word, but greatly simplified this would be delivery order of this fetch data is guaranteed exactly. And I'll get to why I think this is okay in a second. So Let's say the relay had cash Let's say I I requested objects 1 to a100, and the relay had cashed 90 to a100. It could deliver me 90 to 100 right away, and then it could deliver me the 1 to 90 in whatever order it got it. That really simplifies some of those things. And the the issue that we the way how we figure this out, that's not an issue is that when you're in the type of use cases where you're using fetch. You are actually the client, if it cares about the order, it can make multiple fetches for the orders it wants. So if it wanted to move forward in time, it could have requested 1 to 10 as one fetch, and 10 to 20 is the next fetch, you know, in the same way that HLS system would do. Or if it wanted to get its most recent data back and then move back like the the the the the if it if if instead of requesting 1 to a 100, it requests 90 to a 100. 1st if that's what it wanted. Okay. I here. see a couple of questions in the queue Yep. Okay. are you gonna talk more later about how fetch So interacts with"
  },
  {
    "startTime": "00:18:01",
    "text": "deliver or, like the stream mapping what you just said, we're I will save my question. okay. And Yeah. Let me clarify why I was so the reason I'm asking is that what you just said, which is that I asked for 0 to 100. Say objects within one group and the relay has 92100, if the stream preference is per group, it can't send me 92100 because it can't go ports. Or something like that, anyway. Right. And we also have the, I'm gonna talk about this pretty sure have a little bit later, but the not quite that issue, but also the issue was if you request something twice, if you requested 10 to 50 and then 40 to 70 Like, if you do 2 fit or just never I I mean, that was too complicated. If you do a fetch and ask for 0 to 10. And right after that, you request 0 to 10 again, you get it twice. Okay. The fetches are, are very much Who knows why you requested it twice? We'll assume the client knows what talking about. I have a little bit more on slide later on that, but not much. Victor. Yeah. So, I I I mean, I enter stand why you would want to not guarantee delivery order, but there are cases in which like, if I want to request 1 to enter it in in your orders, that kind of would mean that I have to send 100 requests. So I I think there's some room to ask for some things that you're not necessarily to get. Say say a little bit more on that. I I'm I'm not quite sure I quite followed well, well, what I'm saying is it's the server will have, like, they really will have to send them in some order. So it might as well want to know what orders the client wants them in as the client probably has some idea of what"
  },
  {
    "startTime": "00:20:00",
    "text": "orders wants them in typically either in one direction or another. Oh, And it can also indicate how much it cares, which is like it could not care of knowledge can't care a little bit. I agree that it is very that we do not guarantee anything, but what they're pointing out, that they're still use in communicating what The client actually wants. That that makes complete sense. I agree with you on that. Have It's clear that fetch is, object based. You can ask for individual objects the previous slide, suggested the subscribe, so now would be only at group boundaries, and it's only, object 0. Is that, is that part of the plan? We yes. Yeah. You you are correct. We had let's go back two slides here. Hoping we could still retain the ability to start a a non zero object because think about the, like, rehydration case or, you know, connections going down some, you already had half of the group, and you just wanna you know, renew your subscription, at the point that you don't, you know, that that you started missing things. So I you'd have I guess you could do subscribe at the next group and then do a fetch for that, but it just seems like a little bit more mechanics, go back one more slide here. Was that a conscious decision to to things that object 0? We so we had we had a another proposal on here know, at one point in time, and it's it's moved to maybe the last slide in the deck or maybe deleted from the last slide of the deck. Which was now so we got these 3 options here. We had another option now which was the current object inside of the current group. Instead of just starting there. And it was a conscious decision to be like, you know what? Let's get through having these things first and then decide if we need those you know, if we need to add that. So we certainly weren't trying to rule out that possibility of starting any of those positions, but we're trying to"
  },
  {
    "startTime": "00:22:00",
    "text": "sort of agreement that we need at least this much before we jumped into those. I think there are good use cases for starting at a nonzeroogic So if if that's if that's If people agree, let's, let's try to add that back in Okay. Can that make the minutes? This is Rod. For subscribe. Yep. Yep. Who who else is in the Look, look, Yeah. Apologies if you're in the newborn, I was just gonna say for the this this slide, I would also want to subscribe to know about what's not available and what's being dropped. Just because there's a case now where you're you're ambiguous where it's like, I don't know if group Eights ever gonna come. So it's nice that Fetch has this property, but it's a property I'd also like for subscribed. So the problem that we had with that, Luke, is we we tried to put that in and we don't know how subscribe will we don't know how the relay or we'll ever know whether that's going to happen or not. Now, you might the original publisher might. But it's, you know, we we were trying to figure out what's what's the the driving use case for that because it seemed like most of the use cases that needed that it would most likely to be, fetch that you were using at the time to the data now, I, I mean, no problem with marking some group as, like, like, some way of indicating that, you know, a group doesn't exist or something, but we were we were we were struggling on the use cases that needed that in fetch versus in subscriber. Think you'll probably have a similar problem with fetch, but, I mean, I just have groups be sequential. Personally you can detect gaps. But, anyway, keep going. so Yep. Okay. Next slide. Okay. So one of the other things that we came around in trying to get the education to go away is that, if Relay's cash, they should cash at least the lasting current"
  },
  {
    "startTime": "00:24:02",
    "text": "So basically the, basically, that's cash that's 2 groups worth as a minimum. They can cash more, obviously, but they have to have that that is what would allow the subscribe stuff to to work in a in a very consistent way. So this is a additional, you know, tax that we're putting on who implement relays the cash. But it doesn't seem very much. And if we have this it certainly removes a bunch of the edge cases. So that was one of the things that we, we added that that really simplified going through some of the flows. Next slide. Okay. And next slide again. So I'm gonna talk a little bit about how we got to some of the in this design. There's not too much in here. Come. Part of it is, you know, that there's 2 really different things that we're controlling on, that we're dealing with a lot on the, on the relays. And that's the, forwarding and fan out and the other parts, the the cash. And that the subscribe sets up a state in the relay. That tells it what it should forward. It's a forwarding table. And not much else. And so that's about when data comes in, you know what to do with it. Of of where to send it next. The fetch is a fairly different operation in some levels is it tells that it relates to do whatever it needs to do to get copy of exactly the data you asked for. If it can't do that to tell you, you know, it can't do that. And These are, are are fairly different operations, some at some level when we started, you know, separating them out and going through all the little edge cases on them. So next slide. There's no relative cash. So When we tried to do relative fetch, We, which of course ran into all kinds of corner cases of the client doesn't know exact you know, the client and the relay have different ideas of where might be in time or where the current things are. So that's a lot of our current bugs came out of"
  },
  {
    "startTime": "00:26:00",
    "text": "trying to have relative requests on a fetch type thing. Now This results in these overlapping things that are very hard to reason about. You saw that count like, you just go back and look at the, you know, us all at a whiteboard trying to figure it out the previous meetings or all of the discussions previous meetings obviously hard to reason about. And, you know, hard to debug, hard to get all those things in. So like, if we can avoid this, this would be great. Next slide. Sorry, back one slide. I'm gonna talk about something on the other one. So on, I think that one of the things that come out of this one is that when we really looked at it, it's like, well, even if you only have to subscribe for a current group to find out where things are and then use some fetches to get some old historic data that you needed. You probably could do this, and you probably wouldn't add you probably wouldn't add a relevant RTT. And I'll talk a little bit more about this later. So it didn't seem like removing relative fetch was dramatically impacting any of the use cases that we could look at. It looks like a combination of subscribing could always meet the needs. Next slide. And this comes back a little bit to Alan's question. So subscribe ID or track alias. And this has been a topic of some confusion of, like, clearly, we don't need both of these, but we one do we need? And as we started thinking about this stuff more, we realized that actually The subscribe largely uses something very much like, it it basically the data that's coming ascribed is a track alias, is is pretty much where what it is and what it wants to come from. However, The data from the fetch particularly once you make the jump, that if you do 2 identical fetches for the same stuff, you're gonna get 2 copies of the same object. You probably want to know which one of those 2 fetches the object was associated with, even though the same object, You end up wanting to have an identifier that's matched to that fetch. I'll call it fetch ID here, but it's what would be called subscribe ID in the we currently have written"
  },
  {
    "startTime": "00:28:01",
    "text": "So we actually end up with the idea that, In a given object that's being delivered to you, you don't need both of these fields. Depends whether it was coming from a subscriber or a fetch. But the semantics of what goes in that data slightly different depending on whether it came from a subscriber or a fetch. And this actually, help clear up a bunch of our stuff. Next slide. And then it's I'm close to the end here. Wife fetch and subscribe versus just subscribe. As soon as we combine the 2 together, start ending up with these combinations of of things that are not legal. So if we had one method called describe that could do both what I described as fetch in these slides and could do the stuff I described subscribe. You start ending up in with fields like, well, it can do this thing. When it's in subscribe mode, it can do these relative things, but when it's in the fetch mode, it can do the absolute things. And it just seems quite a bit more complicated to reason about that than just having 2 separate methods with very clear semantics of what they do and what type of errors they want. Obviously, this is effectively editorial you know, if if the working group, you know, people felt strongly about this, we can put them into 1 instead too. But I think the, the 3 of us all felt like this just was easier having them separated than, having them together. And Jonathan, Yeah. Problematic. Maybe I've missed something, but How is the Client knowing what the absolute numbers are for the Fetch, is it actually subscribed first? To figure out what the head is and then fetch Yeah. Pretty much. Or or that it knows something from the catalog, right? That's that's the other way. I could know something. But yeah. Yeah. I'm just to think about You know, I thought, you know, I've 15 minutes late to the meeting. So I wanna fast forward before watching use case where I don't wanna be receiving the current head because I'm not I'm not gonna Let's go get One it. me slide Just let for me here. Yeah. Okay. Yeah. So this this this actually gets to somewhat that the use case of speeding up. So one of the questions on that is"
  },
  {
    "startTime": "00:30:01",
    "text": "I walked in 15 minutes late for the meeting. And I I wanna do it. So and I wanna I wanna catch up. Now, So this comes to why don't we allow something earlier than last to the subscribe. I wanna subscribe to minus 15 minutes. For example, and then carry on. The groups so what we we decide we didn't need that. And that in this case, we probably would be alright with the RTD and I'll get to why in a second. So you do a subscribe for 1 for, you do a subscribe for, the last group or the current group. With the optional thing of how much do you wanna subscribe to to one. Now you know all your information, you can go do your fetches that you need. When we started thinking about how much time, you you know, what is the group size? K. On tons of the common systems are fairly live like this. It might be like a 5 second group or why is it 5 seconds? It's because that's a that's amount how much time, you'd be willing to wait or buffer forward. It goes together with the human factors of So we decided that The group sizes are set large enough to make the the user experience work well. That a single group is probably all you need in a very, very short real time component where one extra round trip hits you So let's just say that somebody proposed, you know, last minus one that went one farther back on that. We could do that. We could just add another e num for last minus one. But we don't think you really need it. We think in that case, the user experience will be almost exactly the same. Is if you ask for last, and then use a fetch to go get the last minus 1. And it has to do with the fact that group sizes are setup to be relatively large relative to the RTTs. Does that make any sense, Jonathan, are you buying this Okay. One one problem I see is that,"
  },
  {
    "startTime": "00:32:03",
    "text": "this assumes that clients are okay with concurrent delivery of all of the groups and objects if they're doing piecemeal subscribes and fetches and everything, Whereas if they really wanted all the bandwidth to be devoted to things in order, it wanted I I wanna start playing out right now. You know, what I asked for, That would slow down the play out because now The know, the 5 second back group that you're asking for is competing with also the live edge that you had to subscribe in order to get information about that 5 second prior Yep. So now you you're you're getting it all in parallel. And it's slower And so you have a a delay and play out that not be good for the app. You're you're getting a little bit longer queue. And I know you have only two slides left in your you are just Yeah. Let's just hit the last then two slides let me go through the queue. Yeah. and Well, whatever. Okay. So I think we're into discussion. And then let's show me the last this is the now slides, the last slide. Or what's the last slide after this one? This is the last Oh, okay. Great. I think we're at a great place to take the queue. Yeah. Jonathan again, just to respond to that. I feel like maybe this is too much designing up the mic and too much into the weeds, but I kinda feel like for the go back a few minutes case, you don't actually wanna get those objects. You wanna know what the head is, what the that is the number they had, but so I feel like if you want something that is to subscribe as head is to get an HTV. Maybe that's too much in the lead. You know, so, John, then I totally agree. I think I I had always assumed that we would get we would end up wanting something to work. It was like, an option that's like, tell me the names of the objects effectively, but don't give me the data inside of them. So I think that that would be a really I've always assumed we'd have that sort of extension eventually anyway. So that seems like a really good positive thing. Duke Google. Martin So in Denver, I was a fetch skeptic. I've actually found this quite convincing, and I would be pretty happy with this framework. I think the whole, like,"
  },
  {
    "startTime": "00:34:01",
    "text": "I think this is kind of a I think it's a second order question about about, you know, how we adjudicate this. I wanna watch the whole thing, but starting from 0. We can avoid buffering quite as much by sending a total of 3 messages if you subscribe to just Literally one group, to get the ID and then that fetch that. Everything. It didn't fetch everything and then do another subscribe once you get the right point. That sounds a little inelegant, but, I mean, I think being live with it. If it comes to that. But We could probably spell this message in a way to avoid that case if you really wanna put in the effort, but, You know, when Yeah. When you say it that way, I'm like, oh, yeah. Sounds a little in and elegant. But the we were striving is how form some primitives that thing that can we to can do every operation with and not add more basic primitives than we need. And, like, we can get it with those 3 like that, and it didn't seem like it would impact the user experience to do that. I agree would probably would not impact the user experience. And and even if we could sexually compose it at these primitives and have, like, a message that con that consolidates permitives like that. I think would be fine as well. Thanks. Thanks. K. Thanks. Janaya, just one comment on one comment to that, which is, yeah, the the goal here, I'll second what Colin said, which is To find the right parameters, is is powerful. If you find the right parameters and you can compose them in various ways, you can reason about the composition, which I think is very powerful. And then you can abstract the composition into a separate message if you really, really think that's important. But commonly, we don't I wanted to respond to most question earlier as well about bandwidth utilization across these different things. I think that's a broader question. Not limited to subscribe and fetch. It's it's to fetch and fetch as well. And you're going to have to deal with the right I would argue that's a prioritization question and broader scope and separate. Luke?"
  },
  {
    "startTime": "00:36:02",
    "text": "Yeah. No worries. So Just to step back a little bit, I think the goal of fetch is to simplify things. Right? trying to take something that's complicated and subscribe It's It's just a big complicated, like, Toolbox. I think the problem though is I don't actually see the implementation really changing with Fetch. I see it as now I have to juggle fetch and subscribe at the same time. Instead of just trying to juggle subscribe by itself, I am at, like, a relay is gonna share the same cash between fetch and subscribe. It's still gonna need to treat them almost as the same, It's just have a different keyword for doing it. And I really, really, really as somebody who worked in HLS a lot, I I wanna get from, like, no, I'm not requesting, making a fetch every 2 seconds. Like, I'm not doing that anymore. That's and I don't want like for the idea is to be simple. It's it's not doing it. Making it harder. Making, I think it's just making everything harder evolves honestly. And I it's it's I I do like the idea of trying to make something simple, but freaking the primitives. And it just doesn't do enough, and it makes it harder. Sorry. Luke. He's he's he's fine. A question specifically to look. Look. What specifically does this make harder? Well, so the relay needs to to combine fetches and subscribes, needs to know that a relative, subscribe is gonna share the catch with an absolute fetch it needs to somehow take the objects received from the subscribe and put them in the fetch cache. And I think the big one is just for clients. Like, if you start playback, I can only receive subscribe for new stuff. It means my protocol needs a way of knowing about what old stuff was so I can fetch first to then set subscribing. I I I just wanna just send a subscribe. Like, I don't wanna have these, like, This dual mode. Constantly and I'm not for a I just wanna in your universe. And I'm sorry. I don't wanna take lot of time, but"
  },
  {
    "startTime": "00:38:03",
    "text": "tell me when to stop. In your universe, if you just send a subscribe, what does that actually mean? Well, what what do you mean does it mean? It it basically, think Cullen said it really well in the slides. It's a range filter. A subscribe and say give me everything from this start range to this end range. And if something matches it, send it to me, fetches weird because fetches I mean, I I I don't know. I I don't know how those interact with subscribers. Give me this range and fetch also give me this range, but I want it slightly differently. Mean, is your subscribed effectively Understood. Thank you. Oh, can I me? hear you? You hear Pings. Yes. can. We Okay. So, from the implementer who who who's try to implement this, subscribe the waste defined to him multiple times. I I greatly like this proposal. For one big reason is that there's no relative, offsets. And and the and the scope of the relative offsets has been reduced to 3 enumerations if if if I if I make also on which is very simply it greatly simplifies the release implementation and also it simplifies, it it makes the scalability, for the the major use case, which is, like, pops up and stolen really useful and for that reason, I would like to replacement on the framework. And also, I I like the way the last is defined. That that would make most of the use cases that's been bought about, the players needing to have, some playoff buffer ready before this playing, which is very common in the streaming cases where the live, which is not right now, but, few seconds before on the last kind of addresses use case. And anything beyond that, in the past is not liveage anymore. And that falls into a clear category of effects wherein I I I I really don't care if it comes a slightly delayed because I it's already deal. It's already way behind my life, and I I should be totally okay with it."
  },
  {
    "startTime": "00:40:01",
    "text": "And dealing with that fetch. So if you subscribe, with the current next but the last giving a slight, peek into the past solves most of the live edge and the interactive kind of use cases and fetch going back where the live where we don't worry about language makes makes total sense. Top, top, top, top, Thank you for working on this server. So I think this is the right direction to to have messages that map very cleanly to the application semantics rather than having one huge overloaded method that that, know, has dozens of of complicated corner cases and invalid and invalid, in the gray areas. So I think this is the right direction. Other things I think may be missing is that, the primitives that that we need. I'm not sure we're all here. Are the ones that we talked about earlier was having like a park to subscribe. You're doing subscription, but you don't wanna start the data flowing to you. Just wanna pre warm it at the relay. And I think that may be useful for what we just mentioned, just getting the live head you could do a part subscribe, and then subscribe, okay, would give you what the live head is, but it's not actually streaming the objects to you. That could be a primitive that actually gives you what the live head is so that you can then do your your real fetch or your real subscription based on that. But I think that's an important parameter that we should at and if and if it's another message, I'm fine with that too. I think our message space is big. We shouldn't, try to overload everything onto one message. Right. Right. I think that I mean, this certainly was We were trying to make this orthogonal from the the parked issue, but there's certainly, you know, this easily works with Park. So that makes sense. And maybe that, I, I hadn't thought That's why you're saying that that solves some of these issues a little bit to have that as well. Who do we have next on queue? Turk. Quick question. Do you envision scenarios Hi, Colin. you need to rate control these fetch requests. Yeah. So,"
  },
  {
    "startTime": "00:42:03",
    "text": "I think everything that's coming to us, I'm not So we didn't talk I shouldn't, you know, speak for all three of us or anything, but we didn't talk extensively about rate limiting that the fetch request. But clearly, the data that's coming back from them. You know, you know, you know, this needs to fit into the overall prioritization, ordering issues, congestion, all of those things. We were just seeing is, this is asking for what you're trying to ask for. The methods of how it comes to you and what order that comes in exactly. Will just happen the same way as that would happen in, that's in the draft at all. Right now. And so we're not trying to change any of that. And that obviously prioritization is an open issue in the draft that we're gonna attack at some point. You know, this, this be subject to that. Yeah. Thanks. Victor. I'm trying to understand so do I understand correctly if it's like the key separation between subscribe and fetch? Is, subscribe is like, I'm so cribing for saying since the future with a filter and status. Here is a range. Please return me well defined semantics. 4 What you're asking. It's my understanding. Correct. Yes. And if you, and so fetches primarily about the past somewhat too. Right? If you if you ask for things that don't exist yet, At the point of fetch, they don't know whether they don't exist will never exist or any of those You're just gonna find out don't have That's all you're gonna get from the fetch. Okay. So my question is, so currently subscribe as it's presented on flights. The last few fetch like one group back. What are the semantic property slash guarantee on that being resolved or not. So that's where we so it turns out if the relay doesn't cash at all, that's no big deal because the subscribe just goes up."
  },
  {
    "startTime": "00:44:04",
    "text": "Right? But if the if the this is to make that work so that it was guaranteed to work. What we needed to do was add that one line of that tax on the relays that if you cap, if a relay cashes it all, you know, it should cash the it last and current group. I have a I know, my take is you I and, you know, this is a question for the River rider. I I have a hard time imagining there's gonna be somebody stand up, and it's gonna be like, no, we're gonna build cashes, but we're only capable caching a single group. Not 2 groups. I suspect that if you're down to cashing that little, you're gonna cash 0 so it didn't seem like a big tax. And as soon as you know that it's either those two groups are both there or at 0, If it's 0, then you're just gonna go upstream until you hit something that does cash even if that's the very original publisher. So I, I think this gets us out of the, of all the sort of corner cases on that one. Okay, cause I'm trying to understand what's like the principle between that and, like, subscribe where you do not get anything except for future. Which is, like, the very like. I mean, the more okay. Fair. Fair. So the reason we wanted to keep that one in was if you're trying to join the live edge to sort of, like, minimize the, you know, not have an extra round trip time in the very common use case of like join me now based for some loose definition now. Oak, hay, Yeah. Yield my place into Cube. Do Martin. Martin Duke, Google. So I would argue this this makes it simpler, what matters, which is the application API. When I implemented MQT, an MQT layer, I wasn't gonna, store stuff in there. And so I already had this distinction where"
  },
  {
    "startTime": "00:46:00",
    "text": "Like, if I get a subscribe that starts in the past, I have to go ask the application to provide all this other data, but I'm also, like, looking for new data and passing that so there was this kind of So I had, like, sort of have that API. This guy really makes in the spectrum, I think, is better. Even from the client side, yes, like the internal MQMFG TMS becomes a little more complicated because you're sending, like, 2 or 3 messages. But the application API can still be give me this range. Right? You can still say I want 10 to Brevor. And that's decomposed in the messages in M OTT, but in the application, it's still very, very simple. So, that's one of the one of the appeals I see here. X, x, x, x, x, x, x, x, Thanks. Look again? Yeah. I just wanna say I I think Will and I should really could give it like a presentation on, like, HLS and dash and what the current problems are. I think I like that there's at least a previous, it sounds like just talking in the chat, there is a a previous group that's cashed. But there's just, like, I I don't wanna have group sizes even be known up front, for example. Like, the fact that you have to know 2 second groups, or 4 second groups is one of the main problems with HLS dash today. But at the same time, like, I I just I want I want to be careful here, Luke. There's nothing in this proposal that you that the relays, that anything in mock knows anything about the size of the video group. So Well, one of your slides said that they the player would know ahead of time what the site is so they can then apps request the absolute Okay. That's probably a mistake of my slides. Let's just jump back to second then because I probably didn't mean to write that. I I think we were implying that often the group sizes would be large enough relative to the stuff. I mean, If you need to back up, I think it's about 3 slides. I would just, like, for example, to have, like, be able to do stuff, like, have, a new group on a scene cut or something. So maybe a group could be a second long. And I think that kinda breaks the the the last proposal because I also need a jitter buffer large enough for that. I think kind of the biggest point. Like, if you're gonna let let one group in the past, like, why not let n in the past? And that's kinda where we went."
  },
  {
    "startTime": "00:48:02",
    "text": "Okay. So so, yeah, it was it was this slide effectively. So, so I I just wanna be clear. I don't think there's any need for, for the, for the mock or relay level to know anything about the size of the video group size, the scene cut for, like, you know, like, small group size was one of the things I was thinking about. I, I think it should work for that. I'm glad to sort of work through those sort of cases and make sure it does. And I also don't think that you need to handle the object You know, when you with the cash, anytime a relay receives an object. It doesn't matter where it came from. It drops it in the cache. Anytime it's looking for stuff that can look in the cash. I I don't think it should I don't think there should be, like, separate caches for anything or anything complicated about managing any of that. So I think a bunch of this think what we're proposing in May, we just need to get this down to a very specific PR. Is pretty close to, I think, what you're thinking about. But, it definitely does remove some of the some of the things you're thinking Yeah. I I just think it dumps a lot of complexity on the player. And that's just why I don't like it. Okay. Peter. Can you hear me? We can. Great. So I'm just wondering what happens if there are very large groups like there typically are for real time. Applications, And if we say that the relay should cash the last in the current and someone comes along and says, okay, I want the last or even just the current, and it's you know, 10 minutes long, it's not very useful for video, So Would we have some mechanism like a TTL from The client the publisher to say, Cash this, but After a while, don't bother anymore. Yes. The the the the TTLs would still override that should we have there. I didn't have that on slide. That would be a really great clarifying point that I hope makes it to the minutes, and we'll fix it. So"
  },
  {
    "startTime": "00:50:01",
    "text": "any TTLs on the objects, or other things that tell you to discard them out of the cash for whatever reasons, take priority over this the should we have that says you should cast the current and last object. And I totally agree with you, though, if not, Peter. Okay. That makes sense. Thanks. Thank you. So I guess the question to the group at this point, is there anybody who would object to taking the next step on this, which would be the very specific PR. This is in heading in such a bad direction that we shouldn't put the effort in to do that part part. Okay. Luke jumped in the queue. Okay. I'll unlock so Luke can answer. Yeah. I I would like a chance to do another proposal as well. Either, you know, write a PR or or next person, please note in our room. Okay. It sounds like we will get PR that influences and Luke will either comment on that or if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, if it, If it needs an alternative, he'll create an alternative. So Okay. So, as a follow-up, the PR will be available tomorrow and we already a slot tomorrow for subscribed fetch follow-up. Hi. Suite Google. I have one clarifying question. Is there any issue with this proposal that's, like, Like an issue, like, like, this does not work. For some, like, really severe case? Because it it'd be great to know, like, If there's something like fatal flaw with this, So there's a lot of stuff in the chat that points out that between this and priorities, and we don't have priorities sorted. I agree with that. So, I it's kinda hard to know whether that's a fatal flaw or merely mildly maimed we get the priority stuff sorted? My comment, a lot of these things are quite related. And so, like, for example, I'd like to talk more about, hopefully, later about subscribe update to, like,"
  },
  {
    "startTime": "00:52:01",
    "text": "until you know what subscribe is, it's hard to talk about subscribe. Like, At some point, we might have to go in a direction And then resolve other adjacent things, and then fix things up. But but if but if there's something critical that we know now, that's a huge problem that we should address. Let me know as the PR author Okay. you And let me that if could review the the just say the chat. There's some things in there that I think would be useful to to help you craft that PR between now and the next one. I have Luke in queue. And then, Jenna, Jenna, why aren't you getting in the queue? I am. This is the virtual you. Luke is before Yeah. I would I would just say it like there's a lot of stuff about CTL and prioritization and stream mapping what Alan brought up, that it kind of become, tricky to deal with, especially with fetch. And I I I do feel like we're gonna run into those. So I I do wanna talk about those more and figure out what we actually want out of the protocol and maybe ways we can do today and then see if that meshes with fetch made the proposal has to change because because These stream groups don't matter. You know, exactly. Because stuff stuff stuff doesn't firework. Thanks, Luke. Shauna, then Suhas, and then I see Colin, trying to enter the queue. And then I think we're gonna cut at the end of of Colin to to move on to our next question. So, John, Jenna and god fastly. Two comments. 1, I don't see anything on the chat. That that really is debilitating has debilitating issues. Sure there are unresolved issues. That's my second point. We have to move forward on this, I think, to be able to make sense of the issues. I think there are general issues on prioritization and other things. Which are very meaty issues to get 2, and I would love for us to get to them and spend more time on those. Personally, And I think that'd be good for the group as well. So I think we can always Always reconsider things. Nothing is done, done in a working group. Right? We know this. But,"
  },
  {
    "startTime": "00:54:01",
    "text": "if you can move forward at least and figure out why this breaks something in the future that would be wonderful. So I look forward to the PR and discussion on it. Okay. Suhas? I agree with Jenna here. We did we did the same thing with subscribe locations. We we had, proposals and and and we were not sure about if it worked or not. We gave 2 to 3 intents to implement it, and we came back to saying that, no, it does not work. As we expected it to work. So we're at a point where there's something that seems promising Yeah. We might not have all the answers, but, this is the point we need to kind of make a decision on, so let's as we did multiple times in this group, and if if the solves a problem. And I agree with the loop that we need to think about the detail and stream mapping, I I did spend some time on it. It's I don't see it is blocking We we I'm happy to discuss at some point, but, at point in time, this looks like we need to kind of move forward and not slow down the working progress right now. Colin. Colin James. I would I mean, I think that priorities are, are a big topic. Obviously, we've talked, we've spent a lot of time talking about them. We didn't come to converge a bunch more to do with that. I think we have to implement and collect data. It's really hard to implement without having this stuff sorted out first. I really would not want to hold up making a decision on this to fig until we figure out our priorities thing. I think we should make a decision on this do our priority stuff. And our priority stuff may be may reveal the decision we made here was wrong. Fine with that. But I I think that we just need to to pin some stuff down and keep making good progress on that, and and we need to do that. CTLs and stream stream orderings might be a a little bit easier than priority, but I can't how to do those without doing priorities at the same time because they're deeply those 2 are so tied to get so I I I I really favor, running code effectively on some of the stuff. Okay. So it looks like tomorrow, what we will get is a PR that"
  },
  {
    "startTime": "00:56:00",
    "text": "represents sort of a more concrete version of the the slides. And the authors will review the chat, see what the issues were, and see if they can put into the PR know, maybe it's just to do's. Know, that says in the PR to do include reflection on Xry that that may be the right way given where we are right now. A but, reviewing the chat on the discussion there would be very helpful. So we don't have to have the same discussion again tomorrow with the PR. So now from an agenda perspective, we are going back in time, slightly, Originally, before subscribing fast, we're gonna do a quick review of the updates and draft 3, Ian. You can answer that question. You asked about There were no Well, mentioned that he had serious concerns in the app, and that caught up Thank you. Can you pop up the slides? Uh-uh. So, I'd say this update is both in some ways incremental, but also really cleans up, a number of things. Yes. You can tell, we're in Bridge, Vegas. If you didn't already know, you can look up what that is online. Is a colloquial nickname for where we are. Next slide. Yeah. But but draft 3, A lot of it is tightening up things that were unclear before. The previous draft introduced the ability to subscribe to, you know, these relative ranges, absolute ranges and a whole number of other things that now now we're kind of rehashing, that was a huge chunk of functionality to add and a big change. And so some of this is is serving that up. In terms of the total number of open issues, it's not inordinately high? Obviously, more issues will be filed as time goes on. But certainly the number is trending down in a way that's"
  },
  {
    "startTime": "00:58:02",
    "text": "am cautiously optimistic about a few need a PR, some of those might be ambiguous. Some of those might be straightforward. But, yeah, nonetheless, I think the draft is heading in a good direction. Excellent. In terms of kind of really substantial updates, in particular, ones that are wire format breaking. We added the largest group and the largest object ID to subscribe. Okay. Which is kind of relevant to this conversation. So now, when you subscribe, you will know what the the largest current group and object are. We changed it from date of gram preferred, which allowed you to send things over datagrams or individual streams if Datograms did not fit over the MTU. We're not supported. Whatever reason. Datagram only. Folks seem to like this better. We we also require data gaps to be scored on that slide, but relevant to that. So, like, this all kind of But, web transport already requires Deepgrams to be supported. So They fact that this is probably not a big change for for almost anyone. And then reset were merged because they're awfully similar. And we didn't want more messages. Again, We allowed the final group object to be known and subscribed. Done. So that way when the publisher and to subscription for whatever reason. It'll actually tell you kind of what you need to wait for and what the last object in group will be. And we also added announce cancel. Which is sort of parallel to the ability to, cancel out a subscription. Some. Next slide. Number of clarifications. Yes. Objects are identical if they have the exact same sequence of identifiers, I think We clarified what enrollment, which was somewhat ambiguous before. So now it's clear. Can be a public or sure a subscriber or both"
  },
  {
    "startTime": "01:00:00",
    "text": "And you indicate that during the setup process, Trap namespace is basically an opaque blob that is matched exactly There's no kind of more clever matching there. We try to clear for what what expires does and subscribe. That's certainly an area I think we probably are gonna wanna refine in the future. But at least now it's kind of clear is an advisory field that says Hey. This might expire at this time based on what I know right now, I'm not guaranteeing it last that long. I'm not guaranteeing. I won't allow it to last longer, so on and so forth. But, like, you might have to re subscribe around this point. Yes. For current data grounds. And your subscription fails, you cannot send objects for it. Again, it seems pretty obvious. It failed. You shouldn't send something to court. But now we know for sure. So, next slide. Okay. Areas of future focus. Subscribe, which is now the past presentation. Is is a big one at the moment. We've talked or alluded to prioritization, TTL, things like that. I'm kind of buckling these all under transmission. Which is know, given I have stuff to send, what do I send first? At what point do I give up on sending it? Entire category of problems. Are a few details about the object model. That I think we wanna refine more. I'll talk about probably 1 or 2 of those later. I think the core object model at this point is is reasonably good and how it maps on the streams. But there are some issues like knowing when things end, knowing why there's a gap, what does the gap mean? And in the p further off in the future, I think, we will probably wanna revisit the handshake a bit questions about whether you know, other side can initiate it. There's questions about extensions no one's ever really written an extension because this is so new. It's not even kind of close to a v 1. But at some point, we need to make sure that extensions are possible."
  },
  {
    "startTime": "01:02:00",
    "text": "On and so forth. Yeah. Kind of a Any questions, comments, Anything I missed? I did try to go over all the PRs and issues that were landed since Prague. Oh, yeah. For folks who didn't attend the interim and didn't this is the difference between draft and draft 3, but there was a pretty significant difference between draft 1 and draft 2, which we covered in our interim. So, if you're finding yourself a little lost, you may wanna go back and check out the Yeah. those minutes or look at those deltas. Some some of these did happen I think Oh, I guess, oh, you're right. Something happened between the stream now, the the the stream now, automotive map increase was introduced to Graph 2 Okay. And Okay. that was after prog I apologize. Okay. Yes. The interprets slides would be helpful, in that case. Jenna, John, I'm very fastly in the queue this time. I just wanted to understand in transmission and what to send it through. Do you have, like, the idea of condition control and various things in there as well in encapsulated inside of that. Or is that separate? When it's mission control, I mean, like, you know, I'm not talking about How when I'm talking about source Relay client, that kind of contingency control. Initially, my intent is to focus on one core question, which is I have stuff to send. Where stuff is more than one thing. What do I send first? Yeah. And at what we keep talking about TTLs. We keep talking about dropping. We keep talking about reliability, At what point do I decide? I'm not gonna send it anymore. And we don't have good answers to either of those questions moment. Fair enough. That's what I meant. What you wanna send is accompanied with What do you not send? So Right. Yes. So, like, just it's it's it's"
  },
  {
    "startTime": "01:04:02",
    "text": "It's as simple as that at its core, but obviously, like, the detail is better. Lucas. Hello, Lucas here. Just on the the extensions thing, like, Oh, I would just wonder if you could elaborate a bit more like, the benefit of people who aren't tracking more closely specifically. Like, I think it's fine if there aren't extensions right now, and we don't need to create a dummy extension, but, like, What are the extension points of mock? Truns, port. Are they clearly defined? Or There are parameters in the setup message. So it's similar to settings in, you know, SP 3, but, but a bit So so just ignore them if you don't understand them. Like, is that the kind of level of text we're thinking of in the future or it something we don't need to worry about right now? One kinda trying to understand hope I believe it is something we do not need to worry about right now. But think we will want to Ideally, we would have an example extension you know, ready. Obviously, not like for an RC, but, like, ready to go and kind of using the mechanism before we publish the draft just to make sure, like, exactly work. Would be my thought. Have you considered a greasing extension? I certainly have. I don't think we've done it yet. But that's a great that would be a great issue to file to remind us not to forget. Okay. Cool. Thank you. Probably should just close the queue before I showed up. Just But briefly, even if we, like, botched the extensions, we also have the versions So, If all else fails, like, there's that. And if that doesn't work, we have ALPN. That's now. Yeah. Tell to me. Alright. Here."
  },
  {
    "startTime": "01:06:01",
    "text": "No. That's does that work? Hello? Yes. That's the wrong size. Isn't it? Oh, that's it. We found it. Okay. Thank you very much. Okay. So the next thing on the agenda is will Talking about the post adoption changes to the catalog draft. I actually didn't see Will in the participant list, though. It's kind of a odd time of day for him. 2 AM. Well and we know he wasn't coming in person, but he's on the agenda The two things, next And he made slugs very early on. So Okay. So we're gonna call an audible here. The next person that isn't will Moe is you with low overhead container? If he doesn't show up, I can do the I log signs after if you want, Okay. We're calling from that too. Okay. So this is the, low overhead container or, WebCodex, media format. Mhmm. Next slide, please. 3. And so a quick overview of what it is. It's, an alternative to CMAF so for people who are not necessarily doing a VOD or or streaming from, from CMF based containers. This is a lower overhead alternative for that. Particularly for something like audio. It's based on WebCodex. It's kind of a missed no more because it's really not that related to webcast. It's just that it wants to be at the lowest possible overhead basically the elementary stream of the of the codec itself. And Web codecs has already done some, some work to define that"
  },
  {
    "startTime": "01:08:00",
    "text": "and package that up. So we're basically just reusing that And then it also has the bindings to the catalog. So the catalog textual descriptions have some fields, that depend on what the streaming format is and the this new version of the draft that specifies those. And by a little overhead, we mean low wire overhead. So less data on the wire. Not a lot of extra encapsulation over the raw codec. And also less application overhead. So less runtime, you're interfacing with a primitive like WebCodex, Next slide. So what are the problems with Sumaf? Why can't we standardized on CMAF The main problem is, for use cases where the media itself is small. CMAF is a lot of overhead. It's over a 100 bytes, and it could actually be much, much larger than that. Depending on if a lot of optional boxes are also present. So for something small like audio, it would more than double or triple the the bit rate for an audio stream. There's also a lot of complexity with CMAF. There's a lot of rules about the boxes hierarchy and what could be nested in what So if you're not an expert in in MP 4 boxes, CMAF is not a lot of fun. There's also some complexity in how, The Adams in CMF are are defined. You can have, you know, chunks fragment segments all these different things that don't really directly map to frames. Whereas in WebCodex, it's very clear what a frame is they go to chunks are our frames And so At some point, a media application has to deal with frames to forward them on to their decoders and renderers. And so luck natively takes on frames, not different types of atoms, not sub frames, not super frames, but just directly frames. To"
  },
  {
    "startTime": "01:10:01",
    "text": "And there's also, you know, work in CMAF to find those spring boundaries and with luck you already have the frame boundaries in a simpler way. You don't have to parse deep into the the CMF containers to understand where the frame boundaries are. And like I said, every app every media application has to find those frame boundaries order to pass the those frames onto their decoders and renderers So That's that's one of the advantages of using this format Next slide. Okay. So the main The main thing here is that we're trying to map directly to what comes out of WebCodex. So if you're using WebCodex, there's a thing called encoded audio and video chunks. And there's an internal data field inside of that encoded audio and video chunk. That encoded data that internal data is basically the elementary bit stream. Whatever the code specifies, if it's, you know, 264 or 5, or AAC or OPUS the the raw elementary midstream of the codec is what is in the internal data of the chunk. And that's what we're using directly in lock as the payload. So the log payload maps directly to the raw elementary stream internal data of a web codec chunk. And we're not redefining all of the codex that exist we're not mapping anything onto what can be allowed or what what shouldn't be allowed. We're using the web codex codec registry directly. Anything that's registered through WebCodex would would be usable by this container. It's also usable without WebCodex. Like I mentioned, WebCodex is just for convenience. Because it provides uh-uh, a registry of the different codex that that are in use."
  },
  {
    "startTime": "01:12:02",
    "text": "And, what those codex elementary streams look like and what minimal mappings you have to do like video parameter sets and things like that. The minimal mappings you have to do for those codecs. So you could reuse all of those things outside of WebCodex. You could do this in a standalone application. Again, it would just be the raw elementary stream without the web codex wrappers. Without the extra fields beyond the encoded video and audio chunks. What Goodix provides. Next slide. So the wire format is very simple. So you have every mock object has a header and then a payload. So the mock object payload for this container is also broken up into a a a payload header and then the actual payload. So the lock header is a payload header inside of the mock object payload. And then there's the log payload. The log payload itself is just the raw elementary stream. So that's the internal data of a web codex, chunk. And encoded, audio or video frame. And then the log header is metadata. And some of that metadata, we may decide if middle, if relays, need to be able to access that, we may need to migrate some of that metadata over to the mock object header. Because we're assuming that all the object payloads are gonna be, likely to be in into an encrypted or a DRM, or in in some way inaccessible for the relays so If those fields are important for relay operation, then we we Mandy to consider moving some of them to the mock object header. There's an INA registry in the spec, for all of these header fields. And there's 2 common ones. A time stamp and, sequence. The sequence we may be able to eliminate, by"
  },
  {
    "startTime": "01:14:01",
    "text": "mapping on to the mock level object and group IDs. It's not as easy as it sounds, but there's a new spec now for secure objects that hopefully will make that a little bit simpler. Because the the the number spaces for object IDs and and and, group IDs is is not well defined yet. So, so, directly concatenating them is not is not quite as easy. But we think that that's that's the right direction. And so that only leaves time stamp is the only common field common object header field. And then there's specific fields for, for video and for audio. For video, there's frame marking flags, identify layers, And for audio, there's things like audio levels to to be able to do, things like switching without decoding Next slide. So the updates in this version, the largest update, if you if you do a direct diff, it's a huge update. That's because we removed the catalog. Version 2 had the full, mock catalog specified in there. We moved that off into a separate draft. So that's the common catalog that we'll be discussing about. After this. That's the largest of the of the diffs. We now bind to that common catalog using what's called a lock streaming format, That's format type 2. 1 is is type 1 is a CMAF now. Type 2 is locked. That's a typo. It should be LLC. And there's also this packaging format that's defined in the common catalog and we use lock packaging format for all of these, all these media types. And there's bindings, for the base fields, and the optional extensions. So The next line will give you details about that. Then finally, for NN encryption, we replaced, the text around s frame"
  },
  {
    "startTime": "01:16:03",
    "text": "with the references to newer design using MLS a new draft called secure objects. Next slide. So there's these are the details of what the what the video and audio optional and base fields are. So we added the mappings. These are catalog bindings. Temporal spatial IDs Independencies that's for doing things like scalable video. A a render group, which is really a time alignment or in CMF parlance, things like switching sets, ABR switching sets. And there's also selection parameters. Selection parameters are basically like a quality profile So things like the codec the frame rate, the bit rate, width height, for video. For audio, we also have their intergroup or time alignment, and also the selection parameters. And for audio, the selection parameters are again, the codec, the bit rate, but then also the sample rate, general config, and language. Next slide. So the open issues, A lot of them are the same as last time. Except for one new one. There's a question about whether we should separate the packaging container format from the mock streaming format It's a little confusing because this was a new concept introduced the common catalog, of having both streaming formats and packaging formats. And, I wish Will was here to to talk about his view of the of that distinction, but I think the intent is that a packaging format, could be used outside of mock. So you could package up the media in some way and use it with some other transport. Whereas a streaming format is a binding itself to mock. So a streaming format has the semantics of objects and groups and stream mappings, you know, how you map those objects and groups onto, quick streams or data grams. So the mock"
  },
  {
    "startTime": "01:18:03",
    "text": "level bindings is supposed to be the mock streaming format. And anything that's independent of that, you could consider packaging, format. So that's still an open issue that we would need to separate this draft into just a container format that doesn't know about mock and then a mock binding streaming format. So we can do that in a subsequent update. There's still also these, other open issues from last time from 117 video parameter sets, whether there should be in band or whether there should be some provision to have them, signaled in some other way, like as a group header or a track header, or even in the catalog itself, So CMF has a net segments, for doing this. In real time streaming cases, we never have separate in it segments. We get them in band inside of inside of the stream with the iframe that that they're corresponding to. So we need to resolve that. Like I mentioned, some fields may migrate to the object header. Maybe able to eliminate the sequence, by using the mock object header directly, the group ID, and the object ID And then do we need things like, common feet common header fields like the time stamp do those ever need to be visible to the relays? And if they do, then those need to be migrated to the Object header also. My contact had her. And right now, we specify a, content protection scheme using MLS and secure objects. Should we actually specify that in this, or should we just have a generic, you know, support any generic contact protection scheme whether it's, you know, DRM based or whether it's MLS or Secure objects based should should disrupt nuts talk about any of that. And just leave it. You know, leave it open for arbitrary. Extensions. Slide. Presented slide. That's next it. Questions."
  },
  {
    "startTime": "01:20:03",
    "text": "Questions or comments? So I suspect Will is not still online because he was the main one that had questions and comments on the list is I don't see him now. I've I've reached out to him a couple from my Colin. I mean, I was just gonna say that Oops. Oh, yeah. This mic's on. This scene, you know, this, when, when you think about what's here, yeah, sure. There's some open issues on this, the the basics of it is incredibly simple, very close to what we have in WebRTC, both in optional hair primers, you can throw in the other stuff. And I just think that this is, you know, close enough to move forward with as a working group draft, even you know, these questions will resolve slowly over time. So I would like to see us start moving this one into the working group some point in the sooner rather than later. Suwaz? Thanks, Moe, for the presentation. From the from 3 auto implementation today, they support some form of lock, that kind of shows that this is something promising on it, and we need to kind of see how to make it to the next step. And and with respect to, what should be in the lock header versus what should be in the mock header One of the goals for the mock from the very beginning has been to relates not to be less to be more media agnostic. Not to learn about, different kinds of media that can go that just makes really, implementation like you complicated at some point, we we need to kinda be careful and think about, you know, what kind of things are very specific to video versus what's something more generic and then consider if it's supposed to move in in the marketer. And on the last question about should the support arbit recording protection schemes. I I my slight preference would be to define a default one that way someone using lock wants to build something, they would have, a place to go look for it other than that, this heading in the positive direction."
  },
  {
    "startTime": "01:22:03",
    "text": "Look, So as somebody who had to deal with MP 4 a lot, because I support CMAF, for some reason. We can need a simpler container. So I I do support, you know, making your own container, basically. I will say I would like to see it decoupled a little bit from, mock transport. Like, I it's okay that if this summer doesn't sequenced numbers or whatever, because I'd like to be able to, like, serialize these to disk or something, and I don't wanna have a separate, lock on disk versus lock over the network format. But, At the same time, if that's lower overhead, I'm all for it. Yeah. Keep it up. I think this is good. So that's, both Will and Luke talking about splitting this up into a streaming format versus a packaging container. Yeah. Is there anybody that thinks that we should not Everybody thinks that You a mock should have this 1 mock working group just to find only. I can't get on the queue. Sorry. me. Victor said I I was going to ask what this splitting up here means because What what are the things that would go to the box trimming format? What are the things that would go to the log streaming format if you split them up. Okay. So, mock streaming format would basically be anything that references mock object IDs or group IDs. Or, stream mode mapping you know, object per group or object per you know, a stream per group or or track stream or things like that. So those mock level bindings, would define the streaming format. Anything that doesn't depend on any of those would be the packaging format. I would not try to split this up because even if you split this up, you would still need to bring them back in. Like,"
  },
  {
    "startTime": "01:24:02",
    "text": "The, like, if he wants to take an mock stream and, like, you want to make it. And on this container, you can't straightforwardly do that because you're missing, like, say, information into catalogs that's needed to decode it, etcetera. So any things that where we, like, attempt to represent mock on this, we would need some kind of formats. It looks like Gladys merge all of those. So, I I would not be concerned too much at this point. I might have different opinion and comments if I reads the draft more carefully. So I'll go to that. Come on. I mean, I'd I I am fine with us going and doing like, Hey, here's how it gets stored on disk or whatever. I'm not mean, maybe I'd have to see the format and the streaming what it exactly meant when it was all split But the only thing that I've wouldn't want us to do, and I don't think anyone's proposing this, but is that somehow our on the wire format gets bigger because we're trying to make it match the on disk format and the on disk format needed things like object IDs and group IDs. I wouldn't wanna see us duplicate information existed. At the Machatter level. Down here just because it matched the disc. So not only anyone's proposing that, but Like, I like this design for the on the wire. And if the draft also specified, like, an on the disk, thing, format or as well that was slightly different for some reason. Well, it would be slightly different. For, for a variety of reasons and slightly larger. I mean, that's, that's, that seems fine to me. That's kind of my view too is that if you're gonna Persist things. Just persist the mock level stuff too. Okay. I've cut the queue after Kero. Kettle. Map it. Just observation, We kind of have experience with doing this because Russia was originally, like, click, click, what you're proposing, one of the challenges is, like, all the tooling"
  },
  {
    "startTime": "01:26:03",
    "text": "Doesn't work, obviously. So and you have to as the sooner it's become a standard, the sooner the tools are actually there, and yeah, storing is, like, we're always gonna store things in and before. So we're not gonna store things they're likely more because just better, and, we're gonna have to translate between those. Back and forth. Yep. Yep. I to agree. So being able stream mock on the wire, but store it as an mp4 would be a useful library. Okay. So I think gonna close that topic. You're comfortable talking to the catalogs smite. Fool's not around. Yeah. We can I haven't seen him before, but We didn't collaborate on them, but we collaborated on the draft updates? Just on LLC, I heard a lot of support in the room for this is good. We wanna do it. We want mock to do this. Do we know what the next step is here. Yeah. We we can't, adopt it if they're gonna split it. Right? So if it goes in two documents, We can't do the adoption call until we've seen this split and the working group says, yeah. Okay. We now get how this still works together with the split document. So I think the thing would be, go ahead and split it. And then bring it back to the working group, and then we can adopt after that. Okay. So the decision is split. Only heard Victor objective splitting Just like, I I I thought we were gonna still have one. I thought split still meant one draft. Just just separate these as 2 concepts in the same draft. I mean, we don't need 50 RFCs work. That's true. I mean, draft wise, we could we could have one draft. The way it's just talking about it split it into 2 drafts. So if it's gonna be in I was just confused then. The the the currency map stuff is split into 2 drafts. There is a are 2 different drafts for the CMF Streaming format and the Luca, maybe help me. What's the other one called? Packaging format is not called packaging format. It's called something else. Okay. So, chairs will work with you to"
  },
  {
    "startTime": "01:28:01",
    "text": "to determine whether it's one draft or 2, but go ahead and split it mentally into other one one one draft that has 2 sections which are clearly splitting the 2 different things that are happening there. Or split it into two drafts, and then we'll work out with the Okay. The things. option thing is after after you've done one of those 2 Okay. Given that you didn't develop the slides. And one of our other things here is to go through transport I think we'll go ahead to the transport issues. And if the transport issues run low will pick up something from from tomorrow because we already had confirmation that We have the slides for the low overhead encryption if the transport issues don't take us the full so, Ian, this brings you back up and transport issues. Some Yep. Jet service. Okay. I'm sitting by my, like, all caps thing, like, the slides have to be in the day before before I leave my flight. That's still the party line in this working group. Those slides will be presented. But are you an enthusiast about his optimism? Yeah. I'm a your slides in the day before enthusiasts. get Wow at a so nothing has come through yet. Have you sent it? Yeah. So, the conversation earlier was motivating"
  },
  {
    "startTime": "01:30:01",
    "text": "because I had slides and I reordered them. Based on the conversation before I book, and other things. So Yeah. Sorry. Okay. Yeah. No problem. I'm not gonna be able to upload and you get them that I currently have to do. I just shared the screen. Yeah. So I wanna start with one I can start walking through. But right now, there are a number of issues about not necessarily being clear when a group ends or when a track ends, So when a track ends, one can indicate it by a a subscribe, done, Say, basically, you're not gonna get any more data. But that's a control kind of signal. Not an in bed signal. For the object model and the forwarding preference, we kinda decided that we wanna explicit signal whenever possible. And we want, like, an actual indication of you know, this object goes on the stream. This group goes on the stream. Track goes on the screen. And so Yes. And so there's kind of an open question of we want an explicit signal for 1 or both potentially both There's an example PR out But as much as I think, this is feedback from the group about, like, We we've kind of been heading in the explicit signal direction. It seems where we would like to keep people generally agree with that direction? Or Do we think this is a problem that doesn't need to be solved? I think Alan is someone who's hit this before as an individual. I don't know if you wanna comment think we did it in the queue first. Yeah. And the queues lock. Oh, okay. I should have a button on the line. Sure. Realized it was a Q ready. Okay. You're fine. Yeah. I to You said just wanted clarify. Controlstreams can't be explicit. Isn't that pretty explicit?"
  },
  {
    "startTime": "01:32:02",
    "text": "We trying to say that it has to be in the the data layer. I think it's what I heard a few people say. Yes. It's sorry. The control message is in the control stream. It is explicit. It is very clear. But it's not in the data layer. That that's where I was making the decision. So clearly, like, that message is very clear. Like, it's over. That's the end of the track. But other in other spots, we've kind of decided we'd like putting in today to litter better. At So per calendar. Yeah. I I I don't think we've talked about the data layer, before. I just wanna say that we we talked about explicit Okay. Cool. Yeah. So as an individual, I think, we'd we'd we'd Do you wanna have an end of An explicit end of group signal. Right now, it's I think there's actually even the draft. It may just say, like, to do figure out how these things end. And you can just sort of You can currently do it when the quick stream ends, but I think there have been other use cases expressed where people like, want to know, like, this was this was really the end of the group. Not just this dream ended possibly because my relay is, you know, I'm I'm shutting down the connection or some other reason the stream is ending, but, like, You know, there's really the end here. I think that is explicitly is useful. On subscribe done, I'm I had a need to think about it more whether that's It seems they get at least sort of Get it mostly done, get subscribed on right now. To to to, sorry, to mark the end of a track. Because they're tracking the signals right now. Yep. That's good. That And Because a is explicit. that's fair. then But I agree. The end of stream is an unreliable signal And for purposes of caching and such, you don't want, like, one cash to cash things one way and another cache means entirely differently. So I I think that's what Suraj. I I think they're two dimensions here. I don't is that, explicit or is implicit? Suhas can speak up a little bit."
  },
  {
    "startTime": "01:34:00",
    "text": "Okay. Is it better now? Much better. Thank you. Okay. Thank you. So there are 2 different dimensions here. One is want an explicit signal versus implicit signal or do you want an an another dimension is that is it on the control lane versus the data path. I think expresses signal always is useful. Because you don't know exactly what's happening. And on the control path versus data path, I would prefer anything that talks about data to be on a data path because, if you're implementing something at the closer to the hardware layer, you don't have to switch to some process and figure out what's happening. I can I can I can work at the line speed? That would be my preference to have, x split, and also on data path. Thanks. Uh-uh. I'm assuming Collins next. Up, So, Yeah. Plus, we want explicit. We want a a data path because of the timing issues as well as things. So I said, But I also think that just It's the group, like, you can see many ways to do the end of the track. But the end of the group is the one that just really bushes it here. And once and I think that we'll probably decide to do how Once we decide how to do the group, we'll probably decide to do the track roughly the same way. Yep. Mozanati plus want to explicit and in the data plan or an in an object area. From experience with RTP, this has always been a problem. You know, having even we had some things that were explicit, but they were ill defined, like the marker bit, was always a problem, and we had to define extensions and and and things in order to make that reliable and And, you know, being able to know the, the end of something is very important. Waiting for the next thing adds latency. I don't think that's ever acceptable for a protocol that's focused on low latency. Thanks. Okay. Awesome. Oh, we have more people. Because, Christian and then the"
  },
  {
    "startTime": "01:36:04",
    "text": "Yeah. We we absolutely need an explicit signal And I understand most point that the the ROCI call thing to do is to have something like a thin bit on the on the last subject in a group, The problem I see He said, it would be fairly frequent That a group is cut short. Because, for example, we do the mapping of one group that's trim and we we set this to him And if a group is cut short, you're not going to receive that last bit The the way I solve that, when I was doing a prototype, is to have a a property on the 1st objective index group saying, hey, The previous group was supposed to have so many entries. That's not necessarily ideal. But you you you have to consider the case where especially in the kiss of group. There's been a reset of the stream Add you want to know how much you have lost exactly in particular for cash management and things of that nature. Yep. Thanks, Christian. Look. Look. Yeah. I mentioned in the chat, but I would like a a signal when a group is dropped like cut short, which falls very similar to also this is its known length or just known final size. So I think we should have an explicit message will say the problem with the data layer is it's lossy by nature. I mean, even with Christian's proposal, if you lose two groups in a row, you you you you you just lose information about the first one. So I would I would I know people don't like control messages. But I'd want something reliable. I want when somebody saying this group is gone group 5 ended with 3. I I cut it off early, but it should have been 30. Try fetching again later. Some and I think it should be a control message. Yes. Yeah. That does lead into another"
  },
  {
    "startTime": "01:38:02",
    "text": "issue, which is, yeah, like, how do you know why you didn't get a certain object. But, but, hopefully, we can maybe we can working to that tomorrow if we have a extra So thanks. We have showing team that it's left in this session and we thought we might he want to use his up to another 5 to 10 minutes. Yeah. Okay. That's fine. Okay. Wonderful. Next slide. So this is, you know, the issue that we all love to talk about Cool. or maybe we don't but it's come up enough today that I thought it would be worth kind of rediscussing it. And we do have some slowly more specific proposals now. I think maybe then we have in the past. So There are a number of transmission issues. I think there's, like, 7 of them. Luke recently wrote up a zolt to do, I believe, the first three that I'm listing down the bottom bottom the current draft leaves this very, very unresolved. It's it it it it So you know, at some point, we need to do something about this. It's clearly a to do, basically, But the core issue is right now, there's really no instruction as a relay or cash as to what you should send versus anything else. Nor is there, despite it being intended to be a potentially, unreliable video transmission protocol and media transmission protocol, there's no advice whatsoever about when to drop anything. Or when do you stop sending anything? So those are fairly big, like, functional holes, I think. Particularly in the the latter one seems Quit. Quit. Quite unfortunate. And so, okay, Alan? I'm I'm gonna be lazy and not run over there, but speaking as an individual. So I I think prioritization And then you mentioned dropping at the end. And and I think in my head, those 2 things are kind of different. Right? Like, when you when when there's a when you have a queue of things to send, you can make it a priority queue. Zip, zip, zip, zip, zip, zip, zip, zip and then there's What do you do? Like, no queue is infinite."
  },
  {
    "startTime": "01:40:01",
    "text": "What do you do in your queues too big? Yes. And Sometimes, like, we have not defined the draft and say one it's okay to drop. So I don't know if we wanna have that as part of the do we prioritize things? I am if you follow the chat, you see a lot of people talking about, is it a publisher signal that it's a subscriber signal? Is it both? How does that really merge it? How many dimensions are there? Is it per track, per object, per group? So, like, there's all those things, which is just about how to manage the queue. And then there's the separate thing, which is what do we do in the queues I I agree. Thank you for thank you for keeping me on on task, and that's exactly what this subscribe, slides intended to cover, and there is are the slides that we get to them that talk about TL very briefly. And we that would be, I think a better time to talk about what to drop say that TTL is the only mechanism is a mechanism we've discussed. Yeah, so if we can focus on kind of the what to send assume a machine with an unlimited amount of memory that you can buffer anything you want what would you send, maybe for the purpose of this conversation No. This is Natty. I started a draft on priorities, I think three three meetings ago, and, made some headway. And then hit some hard hard walls. This is not that simple of a, of problem. I don't think it's gonna be a few lines or a few sections of the mock teedraft. I think, having its own dedicated draft to deal with these issues because there's not gonna be one prescriptive thing that we can say this is the normative behavior of how you should prioritize things because different applications have different needs. That's what I started trying to enumerate. Some of the things that Luke wants to do for some use cases, don't match up with what other people wanna do for other use cases. I think it's important to first layout how those use cases work prioritization wise. And then what are the mechanisms achieve that. And then how those mechanisms interact with each other, how they interact with other prioritization mechanisms because, ultimately, It's not just about what this mock layer does. It's about does this actually make something get delivered"
  },
  {
    "startTime": "01:42:02",
    "text": "And so that means you also look at things that are under you, look at quick under you, and look at what's under you at network layers. And so having all of those being considered is out of scope for just the MOGT section. I think it needs its own draft to talk about So a clarifying question from the chairs. You are still anticipating though that any MOC T mechanisms, that were implied by that draft would end up in a mock t draft. Right? Yes. There's some it would it would it would have some text would need to go into the mach t draft this Okay. As long as the MOC T draft tells you what you need to implement to have a conforming MOC T implementation. That what we need and having it split at this point so that the prioritization stuff was in a completely different draft would make some of what we just talked about Unsubscribed fetch behavior very difficult to for the use cases and the implications. That's all cool, but I think any protocol mechanisms that you derive from that, still need to go back into Machtee. Yes. I can reprioritize that prioritization draft, especially the sections that would go back into Maki itself. Yeah. Yeah. Yeah. Hello. This meeting. One comment. I agree. It's not don't think this is a trivial issue at all. But what we we don't have anything in the draft day factor. I mean, I could write a PR to just nuke the current text, then it would be equally functional. And so I guess I'm trying to get feedback about, like, do we want to add any of these specific proposals that have been discussed the past from the group. And that's, but I agree that, like, it's I think what Ted said about well, yeah, I was not thinking any of the specific proposals work in general for everybody's use cases worked for A certain defined use case. And so I think, try to revive what was done before and put it either in this issue. Or could it be easier it? for Yeah. Yeah. No. Definitely. That would be very helpful. Superior sheets, but post on enable or create a new one."
  },
  {
    "startTime": "01:44:00",
    "text": "We have one gift. Luke, Lucas Banks. Yeah. Moe, if you can bring up some use cases and, like, add some specifics that would be be helpful because I think I'm I've been the biggest proponent of, like, publisher chooses priority and kind of just encodes the priority almost like with the media. I'm doing a complete, like, like, 180 right here and saying subscribers in charge, because I think that actually handles use cases it it means that somebody can be watching and having a small window and request a different priority than somebody with a big window, or it it starts actually solving a lot of these issues we're talking about. The subscriber in charge. So I I think this at least is better in the car draft? I don't think it's perfect. I think there is a one wart about what relay is supposed to do? Other than that, though, I'm I'm I think it's better. Thanks. Hey. She inserted this conversation. I didn't put in the slides, but There is some kind of time pressure to do something I would argue. Because any type of client driven ABR probably need something vaguely functional here. Allow you to switch from like a lower resolution to higher resolution and vice versa. And so, like, doing something would be helpful even if it's not perfect. Thanks. Colleges. I mean, I agree with what you just said. The whole draft. the whole thing is probably useless without prior It at some level. Right? Okay. I mean, really, if we get down to but This is a really complicated topic. It is very data driven and use case driven. And we need to bring all those together. And what the chairs had decided a while back was we were not gonna discuss it for a while. I certainly don't wanna go adding these in today or whatever. I don't think these are the right way to do But I think that that's not really we need to meta up level here. I was just What's the right way to come to good decisions and designs about this and agreement on this"
  },
  {
    "startTime": "01:46:01",
    "text": "I think that probably we're gonna need to have, like, a full intern where we do nothing but but bring You know, I mean, we're what we said before is we need implementations. We now have implementations implement a bunch of these different schemes. We can see how they work. We can compare them to a each other, understand what the problems really are, discuss what people did, discuss what work, look at the requirements, look at this. I think that this needs, you know, About 20 hours to make progress on it. Then we'll we'll get things. I know it'll be very hard to get to anything before that. So my proposal would be all of these things that fall into the category of now, And, again, I split with Alan the same way. There's one thing which is 66 the the only thing a relay can ever really decide is What object do I send next? And there's also the issue of what objects do I discard. The which objects we discard we might be able to make progress with on less time than this maybe, maybe not. But though, which ones to send next? I think that's a very I I think that that the only way we'll come to agreement is a huge block of time. Okay. Thanks. So yes. I I I plus one to Colin. We we had quite a few discussion. It's it's not that we are doc talk this one. There's huge mailing list discussions on send order to Priority center versus receiver. We have we have a lot of discussion and as a group, we decided falls on it, for the exact same reasons. And, like, for example, my implementation does priorities, on on send on sender based and it works for our use And I can see why case. something like a fetch requires because if you don't have delivery order, you need a different way to say probably we'll think about it. But at the way the the the the pre the proposal has been designed today will not work some of these cases that I'm considering, for example. So I will not be comfortable getting this until you have the separate discussion on it. Thanks. Lucas. Hello, Lucas. So based on my experiences of HTTP and and quick and 3, but I don't wanna go into all of that and whatever. Like,"
  },
  {
    "startTime": "01:48:03",
    "text": "Ultimately, the relay always has to decide what to send. Right? It's the one stuck in this awkward position of middle of not really being the the thing that has to render anything or the thing that's producing anything. It's really tricky, and and it has to determine this anyway regardless of what signals we might side to to allow for the client or the server appreciate John's point that we wanna keep things simple. Like, in my experience, and it's kinda echo. So what Moe and Colin said, like, there's different kinds of use cases that need to be supported. And what I learned to the the HP priorities processes, you think you've described every possible permutation of what might go wrong, and you wanna be very descriptive, but you can't. You need to accommodate things. Need to accommodate the fact that there's other kinds of signals that aren't explicit that I really would want to use such as operational experience that they know there's always a certain kind of client that says something and it's lying. Because that's just how they are. So, think there's where this has to be done. I don't know if it has to be done right now. I think it's gonna take time, think even as we progress, the drafts, through, like, IETF last call. People will keep figuring out things we didn't consider on without adding more and more texts. So trying to be 2, lean right now on that and trying to hide the complex and shift it to implementations won't help us. But we we we need data. Really. That's what's otherwise with this, No. No. I I want his thing I was gonna say. Yeah, we need data. Yep. Thanks. John. Jana Yagar, I obviously agree with the fact that we need data. But, the thing I would say is that 6 two things. 1st, first, several of us have worked on priorities in many different spaces, and we've been burned badly by it. And we wanna do it ever again. But Here we are. And I say let's embrace this, and that's my second point. I think it's much more important here than it was in HTTP."
  },
  {
    "startTime": "01:50:01",
    "text": "It's much more relevant. To the actual performance of of your your thing. And the goal here is not to necessarily figure out what the right priorities are. The question is to figure out what the right primitives are again Right? And then let people go play with it. Because that can help you again, gather the right data. So my recommendation here would be or my suggestion to the chairs is if again, like, create the conversation here while we are here, at the IETF sort of a lot of room for require use cases, any data requirements to be presented and discussions to happen now. And then move it into the interim after that. That's an ask of the chairs. Yep. responded. Yeah. So, I think I had some people probably an interim focused on this is is probably in the the plans for the working group, and we'll discuss that. I I think tomorrow a little bit. I would say that One valuable thing people might talk about over beverages or brakes is What are the primitives you need to get the data you need? Right? Because if you don't have anything in the draft, don't have anything to imp interoperate around getting the data, That's going to help you figure out what each one of these client server relay need to do is gonna be difficult. So if over the the bricks and and beverages, you can think about What What's gonna enable you to get the data? Not just from your own implementation, but from interoperation that, I think, would make a huge step forward and mean that whenever we do have an interim. It's not just talking about talking about it, but actually making real decisions So, I think That'd be enormously helpful. Yeah. Yep. Okay. So we have 9 minutes to go. Have a choice of either doing more on this or leaping forward to tomorrow and doing the lightweight encryption for mock."
  },
  {
    "startTime": "01:52:02",
    "text": "Through more things. you wanna talk through more things where it Do already happened? I'm with doing lightweight encryption. I I would like some more time to, like, talk to folks about a few things and Okay. Maybe, like, a a run through would end up leading to a more productive conversation and this and other things. Okay. So, we'll switch then to the lightweight encryption Colin that to you. And 10, 8. Correctly, but I don't see the slides for this. I you told me the worst slides, but I don't see They're worse. Are they are they pending approval? Don't think so. Secure object. Oh, maybe I'm looking for the rest. Oh, day. sorry. They're on the second I submitted them the second day, not the first day. Okay. So I can't I can't reach them yet. That's why I do everything for every day. I have to go and get them out of the second day, resubmit them into it. Can you just, share them? No. Maybe? Give me a chance. I'm just gonna add that Ted grabbed the mic from me and said the thing about priorities. That was the same thing I was gonna say because we are just a one mind up here. Yeah. What it would I wanted to we missing some places where we need to be able to put some experimental signals so kind of interoperable implementations with solely gathering that priority data. Play out. Okay. I mean, well, point out there's 2 very specific proposals in the draft that have been there for a year ago, and people could deliver some of the experimental data from those. Those are only publisher side signals, and there's been some do we need subscriber set? Do we need a place for there to hold scrubbersize signals. It'd be really great to get some data on how those publisher side signals work. I I just wanna quickly say that I I did have"
  },
  {
    "startTime": "01:54:02",
    "text": "send order in production for a while, and it it does work. At least for the HLS state dash use case. But the only day I got I don't have So maybe you you approved it or something? If I get them on the screen, you know, the screen share for money. Well, if you if you set them up on a screen, you can screen share them directly. We can grant you the right disclosure. Oh, right. We're gonna just be there right for the snack right. That's getting really appealing by the moment. Yeah. Okay. 6 minutes ago. Okay. So instead of doing this, let's actually leap forward to the question of the interim and and ask people if If you're here today, either online or there. Whether you'd be able to dedicate a couple of, like, full 2 days a discussion of prioritization and an interim between now and, the Vancouver IETF, or are we looking at this because the data issues to be after Vancouver. And so I'm I'm gonna run a show of hands tool because why not? That says Before Vancouver, say yes if if you think before Vancouver say no if you think needs to be after Vancouver. Yep. So, yes, is you you think it's ready before Vancouver? No. Things It's not ready before Vancouver and no opinion is the 3rd choice, which means you don't know, but you like pressing buttons"
  },
  {
    "startTime": "01:56:13",
    "text": "I would like to press Yeah. I like pressing buttons might actually win. But I'll notice out of the 69 people here, less than half have actually Press any button. So there's I mean, for me, I couldn't figure out which button to press because I'm unsure if we're gonna have the data that we need to to present in the time before Vancouver And I'm kinda tend I kinda my gut says maybe not, which is why I wanna press no, but so There are lots of votes for yes. I don't wanna stand the way of progress. Okay. So I think we've concluded that the show of hands tool is not gonna help us make decision. So, always useful data, you know, it turns out I this week so let let's actually do that. We'll we'll try and get people to meet over beverages and breaks to Figuero. What prioritization experiments they can run or data they can get And then from those discussions, bring them back to the chairs, and and We'll discuss at that point. The scheduling question of of of of when this would actually happen? And the two people in queue. That's Jana and Victor, and Martin is not in Cuba. Standing there. It might be an AD thing. Janna, Jenna Ingram. First, it seems to me like there are a lot of people who do want to have the discussion. I mean, to me, that was a lot of consensus that we should have it if you were looking for that. But that's I mean, I do I the the the question that I I ask is what specific data are we talking about here? Data is a very big word."
  },
  {
    "startTime": "01:58:03",
    "text": "And it's not clear to me exactly what we're looking for to to decide whether to have the discussion or not. I would rather have the discussion with whatever data people can bring, and then figure out what are the data would be more useful. If people have it, it's unless somebody says, I've got this magical thing that's gonna happen in June. And therefore, we have to wait until Vancouver. I just don't know why we'll wait. Okay, Victor. Yeah. I'm I'm kinda really surprised, but a show of hands. I'm Really excited to see from all of those 17 people, the data that they have, because I've been working on that for quite a while and, I'm not sure I would be able to produce it even for Vancouver itself, not even in the interim time frame. But to clarify, I am actively working in this, but, Martin? Yeah. I I mean, I would like to dispute that that show pan's was was ambiguous. Like, I thought we had a bunch of people who seemed really excited something. Nope. Very few people who thought it was a terrible idea and a bunch of people like me who really don't know how to start on this whole priority thing. And and and And, somebody's got an idea that's great, but, Up I mean, so I agree that there's very there little opposition. There's so many four people who were pretty convinced that we wouldn't have enough data It's pretty evenly split between yes and no opinion which we defined as it's not clear whether we're ready. So I I think delaying it to the end of the week so that people can have side conversations while we're or while we're here. And then the chair is making the call at the end of the week. Seems sensible enough that's okay. Yeah. There's certainly no hurry. I mean, we can do it after we can declare this right. Yeah. Yeah. I think people have those side conversations of what data they can get by an interim and how that's gonna help. Because I think the use cases are gonna be"
  },
  {
    "startTime": "02:00:00",
    "text": "that we could definitely get before an interim but data based on them especially if you want to get something that says, hey. The client says this. My relay does this. The the upstream says that, and here's how it resulted to kinda go to Lucas's point, that can be complicated. And we could end up with a prior to prioritization scheme that works fine For the client's perspective, but it's, like, an incredible burden on a relay. If we don't have data that says what the relay side of this has to deal with. So figuring out the data is I think a good first step. Okay. It is the close of today's meeting. We have another meeting tomorrow. I do an Oh, love is that Yeah. Awesome. Yeah. I was just gonna quickly second Ted's point with use cases love to talk about the use cases prioritization before anything data or decision based That's all Okay? Thanks. So, we're at the break. Remember we have a a meeting tomorrow, and please do a take advantage of both this breaks and all of the other break to chat with the other folks interested in ammo queue. To see about how we can make further progress. Thanks. kind of thing. It's just like a weird Good. It's not that crazy. Thank you very much. This is a I think this is You guys ended the Thursday in Friday before Yeah. I just Saturday before Vancouver, my wife's cousin is getting married and you I mean"
  }
]
