[
  {
    "startTime": "00:00:10",
    "text": "good afternoon it\u0027s time it this is the net comp working group meeting if you\u0027re in the wrong room this is a good time to exit it\u0027s a no twelve statement anything you say or discuss in the working groups has to follow the guidelines stated in the note well so while you are speaking and on the might make sure that you do state your name clearly enough for people to know who you are and for people who are taking notes of course speak into the mic the blue sheets have been handed out make sure that you have entered your name JavaScript we do need a JavaScript default JavaScript adei so does anybody have Java installed under computers yeah all right thanks rychelle there is a link to the etherpad love people to comment in either pad and we can take that as minutes so status of folk group items since London we have a bunch of drafts actually ok so starting with zero touch it\u0027s already passed last call it\u0027s right now reading on Shepards write-up that\u0027s me do the write-up for zero touch the Netcom frisk on client-server suite of droughts are kind of work in progress the yank push suite address which we I guess we\u0027ll also discuss today are also work in progress the nmda suite of drafts and that\u0027s include 78 95 biz and in the Netcom press conf are already in ic publication queue and UDP pub channel is still work in progress anything else you want is the agenda for today for chartered items we have Eric and Alex talking about the FTP updates "
  },
  {
    "startTime": "00:03:11",
    "text": "to yank push and their related drafts followed by Ken that he\u0027ll talk about the status of client server drops and issues they\u0027re in and the last item on the chatted item is about you to be based publication chance that will be followed by nan chattered items and we have a few of those I won\u0027t necessarily go through the names but just one modification a lot is not here to present his so Rob Walton will be presenting instead of okay so with that we can get started and we have Eric doing some implementation stuff i speakers introduced into the group in and let him talk about the last two heroes all right alex is currently on a plane out here honey oh sorry now it\u0027s is currently on a plane he\u0027s gonna be here tonight but he\u0027s you\u0027ve seen his messages or comments on the on the list I\u0027ll be trying to do my best to be a good update from us and from what\u0027s going on in the in the list let\u0027s go on now we\u0027ve been in working group last call and started a little while ago for the three drafts that we\u0027re trying to push as the first set from the overall suite of drafts that includes a custom subscription to event streams the yang data store subscriptions and the Netcom support the session here is going to be talking about a couple of the other of the drafts that are not yet ready for for completion that\u0027s the rest comp stuff as well as the notification headers and bundles that\u0027s also part of this suite of drafts Walker is going to be talking about the EP stuff a little bit later and there\u0027s also a bunch of other items including igor\u0027s work that goes into this whole bundle of stuff but all a lot of the items are dependent on the first three drafts or the first two drafts at least for getting the base infrastructure for subscriptions nailed down reposed and that\u0027s what we\u0027ve been trying to accomplish with a lot of the mails that you\u0027ve seen on the mailing list now to get some context we did start on the stuff about night and 2814 across I Taurus and net Kampf in the time since we started there\u0027s been some parallel industry work going specifically with OSI to limit read yang and Gianna my and the other efforts have progressed and the real pressure in this point at this point is to complete the work so that we\u0027re able to provide something the industry so that the implementations don\u0027t go all their paths because we weren\u0027t able to close and that\u0027s one of things we have to recognize that there is a a window of relevance ballasts have a message just I guess started last week "
  },
  {
    "startTime": "00:06:12",
    "text": "yang pushed now trying to say that there is a window for closing some of these specs if we one hit relevance for a subset of the drafts there are new drafts over in the in the yang push side such as the Comey stuff that Hank is talking about which maybe does have a longer time window for relevance but there\u0027s still desire to get the basic basic infrastructure going so this other drafts can build upon it terms of changes with working group coalesce so far there have been a number of comments real heads-up and thanks to to Martin and Kent for doing a lot of the heavy the comments here there\u0027s been a lot of good interactions things that have been changed as we\u0027ve moved receiver address I know there\u0027s been some comments back and forth for a number of people oh that\u0027s appropriate but I think we did settle a on on removing address from the common model and putting all the transport specific parameters in the transport draft we added a very small update for replay previous event time to make the lost discovery easier for a new subscription started for configured subscriptions we did some minor renaming of event counters desi became an optional feature at last working group and there\u0027s another wording tricks there\u0027s one open mechanism which I\u0027m hoping to talk about next slide and that is do we have support for configured subscriptions and replay and we\u0027ll be talking about that one on our next slide we\u0027re hoping to get an answer for for that here the basic issue is this for configured subscriptions there is a need to figure out when that subscription started because it continues to reboot what do you do do you do it at the reboot time do you figure it at the time when the transport session comes up and in terms of the apps that I\u0027ve been seeing a lot of them are dealing with security really if they want replay they want to replay from the point where the boot is going and the thread we\u0027ve had is really do we really need it configured subscription capability what do we do if we don\u0027t have that capability in here so at least for some places our classes of applications which do need a start point which is nailed down a particular time the only time we can nail down with configured really as the is the is the boot time so without any you know so let\u0027s take a look and close on feedback here if we want to do this or if we just want to remove configured subscriptions for replay out so the two options if you\u0027re following the list is do we support replay for configured subscriptions that\u0027s in the current draft or do we not support configured replay and this does have the advantage of having one last feature but there\u0027s a lot of downsides to the in terms of delaying of processing doing a new dynamic subscription to pull the features from the beginning of the log there is requirements on the receiver that must be supported and also importantly if you have four or five receivers if you\u0027re trying to get the same set of events there\u0027s no way to time it so the events start from the same period so I guess the first question to ask you guys see if we can get feedback and hopefully "
  },
  {
    "startTime": "00:09:13",
    "text": "close this one way another is an option determined whether we support configured replay or whether we don\u0027t and either way it\u0027s fine some of us prefer option one but I don\u0027t know how you want to do the vote or just do it that way but let\u0027s start out with that particular topic so first off is everyone clear about what the issue is we have another slide little some options or no this is okay yeah okay so just a recap sorry I just this is Hank just like clarifying question um there is a replay feature for streams already for notifications they have a history so in theory the the mechanics to do some kind of replay are oddly in place they\u0027re not applied to the data store they are available for the stream option correct this is for the stream option this is for the stream option do we have replay on a configured subscription for a stream but as I I\u0027m new to this event so um there is a kind of history we play already in there somewhere right you have to create a dynamic subscription in order to get it and even then how do you know when to start the dynamic subscription oh okay that would be one is it started boot bottom one has you have a bunch of features and when you boot up you have to create lots of dynamic subscriptions in order to do replays from the client yeah then okay then and I\u0027m pretty sure what I know what I want now yes okay well as the generics on actually in our practice the major point of free play is not reboot of the network node but the loss of network connection and that loss of network connection would be individual to each of the receivers so it would become a bit complicated so I I like option 2 so that\u0027s a good lead-in if I understand if a lost connection would require another subscription started notification right it could you would write and currently it is the case that the client would have to do a dynamic the draft says the client should do a dynamic description to fill in any gaps as correct so already there\u0027s this a function or a requirement for clients to do that so this is just a special case of when the box is rebooted and it\u0027s starting as configured descriptions do we ask the clients to do a dynamic subscription then to fill in the gaps or do we just automatically start sending in all the logs that have been a creative sense to do time agreed so that\u0027s the the basic issue is either you started with the boot or you go ahead and record request the receiver\u0027s to create a dynamic description how many of there are at boot time well which come in at the same time okay so let\u0027s just give a show of hands for these two options so of all those in favor of option number one raise your hand please oh okay and then all those in favor of option two please register again it\u0027s author\u0027s choice I guess "
  },
  {
    "startTime": "00:12:18",
    "text": "alright option one I mean it just closes it it provides a feature alright from there yang push they\u0027re really only been minor review comments based on this so there\u0027s not really much work at all to be reporting on that so the so the working group last call for gangwish as far as you know there the comments are closed alright so the more interesting draft comes down to the Netcom event notifications in other words the transport draft for net comp we\u0027ve had a number of wording updates we\u0027ve changed some examples but the most interesting discussion since last go-around was a proposed yang augmentation for call home to to the ITF net comp server yang drafts which we\u0027ll be hearing about later now the question of when to do that augmentation is relevant here as we know we need some you know yang push now type stuff do we wait for the for the configured subscription support in order to close one or more of the drafts and so the real question that is the unresolved question that is the the big one to hopefully close the set of drafts out is the question of do we progress only the dynamic subscription requirements through last call or whole and then hold off for a biz once the Netcom server yang supports or do we just finish our current slides the drafts or do we go ahead and refactor all the work back through the original drafts of the yang push and configured subscriptions two totally separate contribute configured subscriptions there that\u0027s the big question for the group and so the question that I\u0027m trying to expose here is that the need for a transport draft or net cough does close the question needed now of do we support the current version of net confident notifications or variation where the net cough event notifications just supports configured subscription sorry dynamic subscriptions so that\u0027s the main issue I\u0027m gonna try to open the issues up on the next slide and that\u0027ll be the next book so yang push now thread how do we get to closure there\u0027s really three options the first option is the three current drafts provide dynamic and configured together we can be done I mean as you\u0027re gonna point it out on the thread it\u0027s better to have 80% than 120% the authors definitely believe that you know the four years of work that we\u0027ve done so far get us to a reasonable and implementable set of features and it\u0027s matching as best as we could to the Charter of having both configured subscriptions and dynamic together with support for different transports so that\u0027s the authors preferred option there\u0027s an option to which is dynamic and configured subscriptions together which includes the current subscribed "
  },
  {
    "startTime": "00:15:18",
    "text": "notification a Yank push without changes but also then an update of net comp notifications that just supports dynamic subscriptions there\u0027s a thread with Kent and I where we divided up what that would actually mean and there\u0027s an open question of is it you know is it a support of this viable now as well as support of enhancements to Netcom notif when ITF Netcom server completes so there you know it\u0027s not a really big change to have a net count only dynamic subscription draft the authors believe that that would be a fairly minimal time delta and it would be okay to make the kind of changes that we had tret chat tracked with the kenta a few weeks ago the last question is do we hold configured subscriptions off after dynamic subscribed notifications and yang push we authors and you might have seen it now because comment really do not believe that is the right path mostly because the yang model and the documents are so intertwined after four years of work that it would be extremely difficult to tease apart these elements and and it would require refactoring the yang model and and all all the text in those first drafts so based on that and based on the fact that we\u0027re at the very end we strongly recommend against that and probably would be looking for different authors who\u0027d be willing to complete the work if we are willing to go down the step of a3 just because just because we just believe it\u0027s at the market time in fact out of clothes so the last I think things we have to hear now is if people have a choice of the first one which is done the second one which is can we make a change with just a transport draft supporting the dynamic or the last one where somebody wants to go ahead and do the work of building a a set of drafts which just support dynamic but again a clarifying question I\u0027m Hank and I just looked it up so the milestone says September 18 for a start of working group last call so is this dependent on being are going to ask all completed that could be a long time and this has minimal data and and the milestone does not end it looks encouraging and with respect to minimal time data yes Mahesh and I modified the milestones recently our thinking was that that September milestone would be for the a3 up surprised to hear it might take longer the idea is - it could take less time if you know if we do the a one option so I know the full address perspective it looks kind of done but still there\u0027s things in flux and especially with the notice and you know there\u0027s still discussions and there may be a dependency on the client server drafts which could actually push out when you know it could become RFC\u0027s so I don\u0027t know so there\u0027s a Chancery question "
  },
  {
    "startTime": "00:18:19",
    "text": "September was thinking a three but it it\u0027s try not to hold us to that exactly it\u0027s we need to do the right work and it\u0027s going to take as long as it takes and I think a three would require new authors so a three would require it somebody to go ahead and raise their hand and do it so a two so there was a comment about it whether or not it\u0027s viable and I do want to sort of touch on that because I\u0027m not sure if we if we can actually do a two if I understand it correctly the idea would be that the SUBSCRIBE notifications yang would have config through nodes you could configure a subscription you configure a list of receivers and then when you get down to a receiver all you would have is its name there\u0027s no actual like configuring if it\u0027s in that copper rest column for you know what IP address what port number or what security parameters nothing it\u0027s just just that so it\u0027s really not confined what are you configuring exactly where\u0027s the interoperability to it if you were to try to have no you know what\u0027s the protocol so I think I think a to leak I can understand from implementation it could be done but from a no standards perspective I\u0027m not sure how the interoperable I do question if a2 is viable does anybody I think I can give an example of where they\u0027re certainly vendor implementations that talk about other types of transports so if you want to have a single subscription model and use a vendor Augmented transport node then it makes it quite direct to have the basic receiver with a vendor augmentations for other transports so there are values and having the name for use for implementations beyond the IDF certain thing on Jeopardy please so what do you think probably to divert wood for um okay so back to again the goal of this is to try to get something to RFC status faster a one it says done but I think that against there could be dependencies that would drag it out into when it would get to RFC status until you know potentially you know later right so but if a3 is I mean here\u0027s the authors are suggesting that they\u0027re gonna walk away then that\u0027s not gonna get done faster unless someone wants to raise her hand and try to do a three is anybody willing to pick up the pen for doing a three option III no hands raising so then a three is not gonna be faster right so an eight - I don\u0027t think is viable and all we\u0027re left with is a one so there\u0027s no need to do although it\u0027s fine but it will take longer be aware understood okay all right next hum or the next question is do we progress "
  },
  {
    "startTime": "00:21:21",
    "text": "subscribe notifications in yang push together I don\u0027t know if we still need this hum we can still ask about it because I thought that the there might have been some closure off this offline or do we still want to have I there may have been a misunderstanding and Hank told me that he didn\u0027t actually yeah he didn\u0027t actually mean to suggest that we could do yang push as a separate so it doesn\u0027t actually improve it doesn\u0027t make things go faster either does it I don\u0027t think it does though okay yeah no I don\u0027t think we need to deal with him on that alright which passes us back to the rest comp not\u0027ve so pass that off to Rashad it\u0027ll update us where they are there hi my name is Rashad Rahman I\u0027m going to give you an update on the restaurant transport draft so here you see the changes from revision for to revision six one of the first set of changes was error mechanisms to match the embedded restaurant mechanisms that I believe is section 3.3 in the latest draft the document was also restructured if you\u0027re a bit if you do it if but you know for K no sex there\u0027s quite quite a bit of restructuring Yankee to model was added for HTTP specific parameters that I believe is the URI for the subscription and the examples were changed and the examples which are in the restaurant transport dock now mirror the ones in the net can\u0027t transport draft upcoming changes for rep seven there\u0027s been discussions on the list regarding using a leaf ref for the for call home to the restaurant server so that\u0027s that\u0027s your draft I believe that\u0027s a dependency and I don\u0027t believe there is anything else which is committed for the next revision for now ending discussions the last bullet says when last call actually should not be one last call should most likely be what is needed to go to working group last call so I think the fact that well yes so that\u0027s a question to the chairs and and to the room I mean I don\u0027t know how much attention people have paid to that specific job because I know the three others have been getting way more love there are a couple of interesting questions that were raised in the last week starting up another thread you can you can look for them but that\u0027s who thinks things are needed for example how do we get the rest comp call home in do we actually have a linkage for for direct connection without having to call home from the from the publisher to the receiver so there\u0027s one or two tech questions once we can resolve them then we\u0027re ready but if between us we can come up with a list of open questions that need to be resolved "
  },
  {
    "startTime": "00:24:21",
    "text": "and happy to socialize them on the list so that\u0027s a discussion whether to use ssee or call home or not what\u0027s your I think the issue is the call home do you want a direct connection or do you want to go back to something else to inject a question a connection back and that was in these point on do we just go ahead and call home and drive a dynamic subscription back so I don\u0027t think that\u0027s nailed down and that still has to be worked through on the list okay so I put into the list a couple times I think that the note of drafts might need we might need more of them right and so so and some of these comes her to the neck huh transport as well but I mean there\u0027s a notion of is the server going to send the messages using that comp as a client or as a tech op server using call home same for restaurant and and or maybe just hhtv to you to write or you know and I know HB 2 is part of the rest cough but I think it could be its own thing at its own protocol because it could definitely I don\u0027t think that the net comp has the same issues that rest comp does because in net comp there\u0027s only the net comp client has to be the originator in terms of the HTTP to subscriptions just like G RPC often the client server is always unidirectional so the idea of the client being the publisher for HB 2 does make it different than if something\u0027s being originated from the rest comp side so the interplay of client-server flopping back and forth for the different roles is something that\u0027s been out there for a while but I don\u0027t think we\u0027ve had sufficient working group review of all the implications there one good implication that we have to nail down is sse sse2 for HP 1.1 and that\u0027s what andy has right now with with the rest comp and the other authors have the rest comp draft however you don\u0027t really need SSE with HTTP 2 because the way it works and how do we go ahead and deal with a legacy support do we just have legacy support of SSE for dynamic subscriptions what do we do about configured those are some of the scope elements that have been sitting there for a while but never really got completed by the group I\u0027m not sure if I understood what you\u0027re saying about restaurant client-server I understood that there was a lot of concerns about what like when a cop how there\u0027s a hello exchange it\u0027d be unusual for or just a server to start pushing messages without some sort of RPC to kick him off so I think there was some is that what you\u0027re talking about um I don\u0027t think that actually is the case on and them on the http/2 side there\u0027s plenty of times they you can just stream the other other side because you have the need to do a a push and have to get a response back that your push is working there is a means with configured subscriptions to do effectively in okay that it\u0027s ready to receive information before you push the updates it\u0027s in the draft but we can talk about it further the the real question is how do we link the existing "
  },
  {
    "startTime": "00:27:22",
    "text": "client-server model for publisher push for where there\u0027s no rest comp involved into a receiver side that can signal back that I guess I\u0027m ready to receive this info and there\u0027s a simple modeling for there for how it works now and we\u0027ve got to make sure that we link in what you\u0027ve built in the rest cough model with the handling of the certificates and the rest of this and that\u0027s really the key isn\u0027t that we have interaction model but it matches cleanly to the stuff that you\u0027re trying to do with the with the the credentials for for the security parameters so I mean meth absurd the not\u0027ve traps are going to go quickly I mean once we sort of nailed down this strategy that we\u0027re applying for trying to you\u0027re talking about the three drops I\u0027m talking no you\u0027re talking about the rest cough yeah no distress but I\u0027m trying in general the note of drafts are going to go quickly they\u0027re going to follow a pattern there\u0027s a sort of a template and they\u0027re all gonna argument into these subscribe notifications model and do something so so you know if you\u0027re bringing in here says ITF SQL Server I said without B of call home but you know there could be another draft which is using IETF Prescott client right so it\u0027s basically also pushing using rest cough but as a client and so I you know are those will be two different nodes of strategies they\u0027d be and in likewise to give you the same thing with Mecca um so Mike you know going back to sort of Eric\u0027s previous conversation with the options a 1 a 2 a 3 you know the question is with a 2 I said I didn\u0027t think is viable right and so you\u0027re in that list of receiver so you\u0027re trying to configure a receiver and all there is a name like should there be for instance a choice mandatory truth like you actually have to pick something like the server may support a number of different notice transports and they\u0027re all auditing the model and when you\u0027re configuring this configuring the subscription you have to pick one that\u0027s so that there\u0027s and then and then this sort of the following question is there a mandatory to implement transport currently there\u0027s no notion of there being a minute or two internet transport so so you know it what a support is going to be is it going to be a cop is gonna be restaurant is going to be something else do we s se for instance like in general I think that you know rest confident and net comp or independent and if you have chosen one transport you\u0027ve chosen the transport so a mandatory to implement really to me is a choice of the transport model underneath if you chosen one then it works in terms of the net comp draft I do think that from my perspective no more changes are needed we want to augment in the the call home and that\u0027s ready but I do see that as in a fairly good place but I do agree that the rest comp and other other models other transports will need their own draft like you\u0027re like you\u0027re saying yes "
  },
  {
    "startTime": "00:30:25",
    "text": "so that\u0027s the next draft no change so that\u0027s very good I could have tuned I\u0027ll be presenting the client server so drafts so just very quickly we adopted the crypto types and trust anchor drafts we did not unadopted keystore draft all drafts have been updated and submitted has a as a set but we do have some open issues issues lingering which will be going over right now I just also here\u0027s the relationship between all the different drafts I\u0027m not going to spend any more time on this but we can go back to the slide if necessary okay so the first issue is should we keep trust anchors separate from key stores so again originally we just had ITF key store which had both the keys and the trust anchors and but then we created trust anchors as a separate draft in an attempt to get rid of key store but we wanted up keeping key store in the end and yet trust anchors remain separate so the question is now do we actually keep them separate or bring them together trade offs of keeping them separate provides more applicable names so key storage s stores keys and provides some modularity for instance the drafts can be updated independently but bringing together would be one less module to deal with so the options are one and two keeping separate or as they are or bringing together so I just very quickly raising hands right so oh sorry I\u0027ve calming it yes so this is my TC TC G at the trusted computing group hat on em terminology and the trusted computing group differentiates between work of trust and shielded vocation which is basically the store and the key that the anchor sorry so they they they deliberately divided those terms and did not tell them call them a shielded secret but would be both for example but it\u0027s about a sheeted location about the capabilities of you of trust provides so maybe this is the same separation here also but there\u0027s precedents for the division or the PI I don\u0027t I guess that rules for option one unless someone objects okay option 1 keep the module separate show fans ID all right anybody for option number 2 okay that\u0027s option number okay next keep the local key store keys so there\u0027s a grouping and in the grouping uh there\u0027s a choice called local or key store which came from wanting to have application specific keys blush this was your common where you know keys that are not shared for any other purpose and the choice statement accurately configures single use keys but it makes for rather "
  },
  {
    "startTime": "00:33:25",
    "text": "busy models if you looked at them they kind of busy looking in ultra but when I when you made that comment this is what I thought would make sense but it occurred to me after the fact that an alternative could have been to instead have all the keys in the key store and just let the application the operator deal with ensuring that some keys are only used one so they\u0027re not referenced more than once so do we stick with option one as it is having this construct local or keys for choice or eliminate the local option and just have these in the key store and let the operator deal with any comments before we Rob Wilson Cisco so what is your preference they\u0027ve all these issues is useful understand as an author what you have a linear or if you don\u0027t care either way I I probably just keep the current less work but I don\u0027t care well I\u0027m Sonia Ericsson I foresee also an option that you just put an e if feature also on the local branch and then you can choose that my implementation is always a central key store that actual okay so the next slide is actually touching on that I\u0027m not sure if it\u0027s possible blush to do that and the next site goes into that perhaps we should the next slide then okay then come lash yes we can come back to this one okay so assuming we do the local and key store choice we keep it how to disable the support for the local choice this is what balázs was just saying so we could already there is a feature called a key store implemented and you know so for those who don\u0027t want to implement key store they don\u0027t have to they could just have all the keys be local and so we could have if defined not key store implemented which then would do it but that would be a global on/off switch right so whether or not the server implements key store it\u0027s it\u0027s a global selection it wouldn\u0027t be per use of the grouping so you couldn\u0027t have some keys be in the key store and other keys not the case where just one or the other option 2 is really the same as out from one but instead of doing the not key store implemented you create something called local key supported or something like that but it\u0027s again it\u0027s a global on/off switch it\u0027s not per use we could do nothing to these grouping definitions and let the downstream modules augment in their own if feature statements so that would be a per use switch which is good but the immediate use of these of these would be the SSH and TLS client server drafts because those drafts are using these groupings and then those drafts would want to augment an lea feature so what which what feature are they augmenting in and and it looks almost like a global selection at that point and then option forward we don\u0027t attempt to disable a local choice at all just it\u0027s always "
  },
  {
    "startTime": "00:36:25",
    "text": "available and so it\u0027s not what you want but so that\u0027s the rationale behind why and for this one night a to Rob\u0027s point I do have a preference I think option 4 is probably the better we don\u0027t try to limit it but you think sorry I would be happy with to one or two actually but even if you take one or two yeah you can not or you can support or not support the action rather than three and then you still have you can end up with options for they just have their feature accordingly okay so the global switch be okay yeah simple easy it is it easy is easy all right so then back to the previous slide I guess that means we do want to keep the local or keystore choice construct that would be option one and then for this slide we can add an a not keystore implemented if featured statement one do you want one or two okay to the market suppose I would like to because it\u0027s really what I want to say I don\u0027t like I don\u0027t want local keys that\u0027s that that\u0027s my feature okay alright next should some of key stores groupings be moved to crypto types so at the top of the slide you see that there\u0027s five groupings listed that are not key store specific and then there are three groupings that are key store specific and actually by their namesake you can see that these are the ones that have a leaf or f2 key store so they you know they depend on the existence the key store so the this one is for those five groupings that aren\u0027t key store specific should we just move them into the crypto types module you know you would think it\u0027s it be definitely would want to do that but I think it\u0027s a little bit unusual to put groupings in two types modules if you look at gang types or I am ax types you don\u0027t really have groupings in them so it might be just a little bit unusual from that perspective also note these groupings the ones with asterisks is they actually have an inline notification statement so again it\u0027s a little bit more than what you normally have in a types module so so one option option one is to move these five groupings into a crypto types module and then option two is to keep them in the keys work anybody have any preferences for these okay this one I think I might take two lists actually because there\u0027s probably some like maybe Apple we try to look at it\u0027s more well it\u0027ll make more sense okay next should algorithm identities be moved from the SSH TLS common modules to the crypto text module this one\u0027s "
  },
  {
    "startTime": "00:39:26",
    "text": "actually there\u0027s a we don\u0027t have any solutions for this currently so it\u0027s kind of a open discussion the uses for these identities are to define algorithms and their key definitions you know whether they\u0027re you know it doesn\u0027t matter if they\u0027re local or in the key store to constrain the allowed key algorithm types so as to conform to some security policy so for instance when you\u0027re doing a handshake you know a TLS handshake they\u0027re a subset of the protocols are being advertised just not all of them so you know how the identities were used as well also to specify a preference for certain key types in order that\u0027s what I said the problem is that there we have three sets of identities right so there\u0027s identities that are being defined at SSA Jeff cessation layer also the TLS layer and then and then finally at the key key store layer we have to have them the key store layer right so you\u0027re creating a key what algorithm was the key trading so RSA is the elliptical curve curve first key length you know all that it\u0027s it has to be there because you\u0027re creating a key but then you\u0027re using that key at the protocol layer and then there\u0027s you know almost a different set of identities and then how do we bring them together so I haven\u0027t in a discussion with Frank huawei who\u0027s into crypto and also Gary Wu from Cisco so hopefully you know they can help us resolve some of this but as well you know this is an open issue I don\u0027t have any proposed solutions that we can discuss but if anyone has does anyone there\u0027s anyone familiar with these identities used for keys and things of that I mean if anyone is interested in this topic we could use some help okay that one\u0027s going to list for sure next add a periodic feature enabling the initiating the the initiating peer to optionally support periodic connections so this is in the client server drafts and you know when the when making the connection whether you\u0027re acting as a client or call home it doesn\u0027t really matter it\u0027s you know are you having a persistent connection or is it more of a periodic connection so I think you know pretty standard is to have persistent connections right I mean everyone has the default it\u0027s the easier thing to do harder is to code for periodic connections but they\u0027re better in a way they\u0027re using less resources and they\u0027re actually more secure so there\u0027s there\u0027s benefits so the trade-offs would be it seems that periodic connections are not commonly implemented a feature would primarily be to accommodate that market market trend right just dealing with reality in a way periodic connections are incredibly useful but but by not having a feature we might not the end just industry into supporting them much more right so do we add the periodic feature and say that you know peak the periodicity "
  },
  {
    "startTime": "00:42:28",
    "text": "may be implemented or we don\u0027t add it and then it must be implemented comments Rob Wilson Cisco I would prefer option one and let the industry decide and I see some other heads nodding to that so I think often one\u0027s good thank you next and last I think adds support for TCP keeper lives so there was a discussion with the folks from the BBF who are interested in in this the Netcom restaurant client-server models currently support configuring keeper lives but those keeper lives are assumed to be happening at the trip to a layer level right so SSH based keep Elias or TLS level keeper lives it turns out that TLS keeper lives aren\u0027t well supported in TLS libraries so open open SSL doesn\u0027t implement them currently in fact they were implementing them but then they because they had a security issue they are trying to take it out and there\u0027s a discussion there\u0027s a budding IETF statement I think some of you saw it that says that when using a crypto transport the aliveness checks should not occur via the underlying clear text protocol right that actually it introduces a problem with sorts so there\u0027s that should not right but in that but here\u0027s the configuration model so what should the configuration model do question 1 do nothing and only support crypt at a level keep your lives or do something to also support TCP keep lives okay so we\u0027ll just do question 1 before we go to question two any comments okay Tim Kari Nokia so we brought this up from the broadband forum and so they\u0027re looking at persistent connections that they need to keep that through firewalls and proxies they have to keep that up and right now they\u0027ve got to keep allies going for it what they need to have is a way of configuring that so they can through these persistent connections so that they can so they can manage those those keep allies both from the client to server server decline right the domains many of the domains that they have are in secured area some are not so if you don\u0027t do they have so they have to have keeper lives TLS doesn\u0027t work because of the support as noted so the option would be to do this here or do it up at the the net conf layer and by the way the net says that we do it at the rest comp layer right because it\u0027s at the protocol there "
  },
  {
    "startTime": "00:45:28",
    "text": "or you allow for both I know that there right now they they are planning on using these modules and even if they have to augment for the TCP keep lives they\u0027ll do that at their layer but they would prefer to see them in the original drafts even if it\u0027s featured out you know that you can do it as a mess so that\u0027s where they\u0027re at right now but they\u0027re looking for some guidance right well I\u0027m showing you lyrics on our management system people actually prefer that con flag will keep alive so I don\u0027t see that as important for us and we have some configurations for that which yeah it\u0027s a simple timer which could be included in the net clock server but my diet yeah we can do it without standards so again Tim Kerry so I again I don\u0027t think they care if it\u0027s at the protocol layer so long as it\u0027s at both protocol layers okay and it\u0027s both ways that we do this that you that you allow for these configurations and again you know they can just augment off the TCP key for lives in the short-term waiting for the drafts to show up that\u0027s necessary yeah and one follow-up regarding the implementations like open SSL implementing it part of the discussion we\u0027re having with the TLS 80s and the transport area abs is to have an ITF level statement that we can then take back to the open SSL community and say look you know here it is you guys really should support TLS level people lives and hopefully get that implemented but you know how quickly would that happen I may not be within your timeframe okay so okay again currently in the model models there is a keepalive right it\u0027s optionally configured and if you do configure it you know so that you know just like how often do you send people iOS how many failed responses what\u0027s the delay you know those kinds of parameters you know it distant for says keep lives it doesn\u0027t say you know SSH keep lives or TLS keep lives just says keep lives so it\u0027s kind of neutral as to what kind of keep keep lives it is so I don\u0027t really think it would be okay and I think we need to strengthen the interpretation right from the interoperability perspective would I mean if it\u0027s unclear now we probably need to make it clear that we\u0027re definitely talking about it being the Crippler layer deep lives but I think to your point and I\u0027m fearful of going ttq lives for their security risk but if you like the protocol level keep lives we might be able to add that and then that would resolve this issue as well yeah so I mean what we\u0027ve done management protocols forever right and every management protocol as it has a keep a lot of mechanism in place usually at the protocol level right so that\u0027s probably the preferred approach to do this you know from both ways but there\u0027s also I think when you "
  },
  {
    "startTime": "00:48:28",
    "text": "look at the draft there are some attributions you know just some Leafs that that probably are missing you know because you got the intervals and lo there\u0027s like two or three attributes that need to be placed in there you know again whether it\u0027s at the protocol would be preferred the tcp if they need up that they can they can augment it and right now that because of the time frame that it takes to get this stuff through ITF you know frankly they\u0027re gonna augment the thing and waiting for the drafts anyway right well okay so so my concern and by I\u0027m bringing this to working group is that I didn\u0027t I was concerned that we might try to configure something which is actually not recommended from an IT perspective but and I would be a TCP keeper lives but I think it\u0027s definitely recommended to do protocol level keep lives and we should actually add something so we have the the the configure whoever\u0027s doing the configuration can choose do they want triple level people to keep lives or do they want protocol level keep lives we do that and if you do that just make sure you feature them because put a feature in there such that you know the people that may very well be going along the world for TCP keep lives can use that and they don\u0027t have to have the baggage of the you know the application protocol keeper lives that go through there so there could be a time we\u0027re gonna so the problem is that there\u0027s gonna be a time where they\u0027re where they may very well have to tcp keeper lives in place right or or a protocol level keep alive in place that they\u0027re not going to want the one that\u0027s out of the standard so just make sure that some sort of a may on it right because they can feature okay so i think we can work with this and so we don\u0027t really need to look at option the second part and i think this is great thank you hello everyone my own I\u0027m going down from Holly yes this draft is about the udp-based publishing channel and last night ITF oh we not do the petition because we not they\u0027re not not so many discussed in the Middle East at the time we discussed some issues and comments in the merest Anna we updated the draft and because there\u0027s not to plantation so many times so we reintroduce augment China for the UDP here for unity publishing in channel 2 we asked TCP for like overnight confer address count for all or the IPC and here data collector we were soft now country suffer a lot of TCP connection from many line cards "
  },
  {
    "startTime": "00:51:28",
    "text": "encrypted on different devices for the distributed diversities and has no connection data needs to be maintained so UDP incubation can be easily implemented by the hardware some like cement chip chips which will further improve the performance and because I was a lightweight so you DB incapacitation high frequency and better-trained see the performance can be achieved which is important the photo stream telemetry and and a new udp-based publication channel we have promoted here which a facility distributed at each collection mechanism like for directly populate push data from the line class on many devices to a collector and the support multiple encoding including binary and all for Jason yeah and adapting to the subscriber notification and a young push and enable some option for the its its inability here is the transporter mechanism at this time we updated in to the draft and here how to main McNeil way the dynamic subscription and a configured subscription here we have two euro for collector and publisher and for the dynamic like the subscriber notifications first establishes a subscription then after the confirm replied to the subscription the instant indications from Marty Lanka\u0027s by the UDP and the collector king modified the subscription by the control channel to the publisher after success modified successor the publisher was the updated the future and maybe some new subscription and send it and it came deleted from the character to the publisher to delete the subscriptions and the multi-line Karla we were terminated subscription this is the for the dynamic a subscription and the folder configure solution simile there is a cap Latini exchange for the wealth Sportage and if the bishop buys accomplishing edit configure to configure the subscription then the publisher will send the notification by the composition itself yeah here for the transports transport for the mace for the UDP channel for the Lear this time it is a security layer for with the TT RS who was UDP and the 40gr so it provided "
  },
  {
    "startTime": "00:54:29",
    "text": "a reusable security and authentication function over UDP and for the message header here is some important information before the this arising the notification like that encoding encoding method for TPP COBOL maybe some others and the photo may generate RT for the line casts and a photo sequence number and where\u0027s the support of implementation and some other options for its instability and a for the no to a message it included a notification header as defining another traffic current draft of owners messages which just no alcohol introduced and encoded with the content here is the diplomates of the duty publishing channel message header it had it included for the washing for the header ocean and a photo flag like some options for the liability fermentation and for the encoding type lines and a message and generate RT to max of which source comes from and for the may study and some other options yeah you know the binary encoding drafts there were set of comments that is the GPB or encoding trivial or do we need to document something around that and please and the Beermen stated that is not trivial and we do need some documentation around that if you want to use it you mean for another documented to how do you encode yang defined data in GPB i died near known expert but Andy was very strong that there needs to be a discussion on that okay okay any comments I have a comment Kent as a contributor so it seems like for configured descriptions it seems like maybe we should have a note of truth right like it would it would actually be a like a note of UDP note of something like this and it would augment then to the receivers list just like a right have you looked into for configured subscriptions yeah argumentum Eric subscribe notification strap yeah yeah well in the current draft there is no yang module so I was thinking that maybe there should be a yang module here that\u0027s augmenting and you plan to happen yeah you plan that again yeah so if you can go up a couple of slides yeah go to the diagram okay for next up we were elemental yahia were augmented as a same "
  },
  {
    "startTime": "00:57:31",
    "text": "model and added a OTC confusing and a for security consideration another yeah for other consider and address all so go back to your header idea Tim Kari Nokia just real quick questioning and I\u0027m just wondering because I was sitting in on Comey right yeah what you have here I see what you have here smells and looks a lot like co-op hey Mike my question is why do we need another format header format ahead of oh me too I think I just opposed the content content well you have a message ID of urges and flags right or is that the UDP header that\u0027s up there or what what do you have that unique you mean for the message ID what\u0027s they use either for my study the coding type there\u0027s no there\u0027s only I think only for the contain decoding here the head only max how to encode as a continent fitting content itself not the header the header will be plain text I think no right the question then is asking is how is it unique or different from the coop draft have you looked at the coop draft maybe not deeply for the maybe our locator deeply unearthing this chuckling for the cobalt itself so my point is is they\u0027ve already gone through this problem you know when you start talking about replay you talk about fragmentation and you talk about acknowledgments you talk about all that stuff that you have with a protocol and and now we\u0027re doing this with the UDP piece right and then we\u0027ve already said and guess what we\u0027re gonna use DTLS right am I going I\u0027m not saying use co-op as a protocol but I\u0027m wondering what is what is necessary that of the fly yeah they haven\u0027t thought about or that we haven\u0027t thought about that they\u0027ve already thought about with that co-op header right and because I look at the coop header and I\u0027ve seen there\u0027s some things that are distinctly missing all right and that that\u0027s all I\u0027m just saying is that I\u0027m not saying implement Komi or co-op I\u0027m saying that header has got things there for reasons it\u0027s got extensions it\u0027s got the whole bit that that you want to do and it\u0027s doing it in a very concise fashion right but to me it would seem like it would be something that maybe you want to make consistent right at least for protocol analyzers for protocol implementers that type of stuff okay hi yeah this is Hank speaking as an IT director um there\u0027s not only the coop RFC there are a lot of "
  },
  {
    "startTime": "01:00:31",
    "text": "extensions to it so some things haven\u0027t been addressed in the core co-op draft of course in Carmen Coronado and and so there are things like reliable transport via WebSockets DTS as a TLS and then something and there\u0027s also like like observing resources having basically a subscription there\u0027s also resilience there\u0027s also finding a home using coop that\u0027s basically unlearning mind so I think there are a lot of puzzle pieces that are already there and what I would like to know what the gap is that was just been talking about so if there\u0027s actually a gap where do we fill it in it will fit here what if the video we incubate something and then core or is its own that comes specific that is it is natural intuitive to do it here so what I would really like to see is the gap which I\u0027m actually really unaware of so there might be a lot of gaps but you have to have to look at all the building blocks and core and in what you want to achieve so your requirements and solutions here and then see what what\u0027s the differences and having done that I think we can make a real good decision here and I don\u0027t think that takes a lot maybe it just takes a lot of people from here talking to core people yeah maybe we can check after meeting and there maybe we have a discuss with you yeah I think course today yeah also yeah the next meeting yeah yeah I\u0027m doing slides right another and so can\u0027t as a contributor sort of add on to Tim and Hanks comments um you know so we have these client-server drafts and I\u0027m thinking you know that complaint server and rest compliance over I think that we might want to have a co-op client server someday right and and if there were a co-op client server then there would be I think almost by definition of co-op notif draft right and that co-op note of draft would no augment into the SUBSCRIBE notifications tree as well so if you wanted to do a dynamic subscription the client would start a co-op connection to the co-op server and basically do subscribe notifications over co-op which would give you the UDP and DPOs all that or if they want configured subscriptions they could configure that as well so so sort of I\u0027m I\u0027m I know we we adopted this draft what I\u0027m actually questioning if this is the right approach should we instead be actually just using co-op and have co-op client server drafts and co-op notif and go that route instead I\u0027m opening up the room and I see Tim walking to microphone so the director that I "
  },
  {
    "startTime": "01:03:33",
    "text": "I think he\u0027s got the right approach to if you want to go down that path do some analysis because there\u0027s a lot of extensions and some overhead with coop even with Comey stuff that they\u0027re doing right I was just noting the same they solved many of these problems and core right you know for co-op that you may be missing some things right so I think the analysis is before you go off that off that ledge do some analysis to make sure that you\u0027re not getting more than what you want to try to do because he\u0027s used in UDP here for streaming telemetry pro things for the primary purposes saying I don\u0027t know that one might be a bigger leaf because there\u0027s a lot of stuff that goes around co-op right okay so I but certainly the the protocol header in those fields that might be missing it may very well lead to what you\u0027re saying I\u0027m just saying don\u0027t don\u0027t make that decision without the analysis sort of one more fun alone comment um a lot of what this draft is about is allowing the notification so we sent it from the line cards themselves you know so they don\u0027t have to go to the routing engine for instance to get sent how is it how is that configured like it what like if you were to like do a dynamics description how do you say that you want it to come from with line cards versus from the routing engine or or if you\u0027re doing configured subscription how do you configure that I think for the subscription for the collector that\u0027s me for the client for the subscriber these are not depending whether hello Madeline card right just a configure I need I needed your push to some receiver it was a target and it\u0027s a system itself we decided whether whether distributed that Madeline had a st. Midas\u0027s yeah so that reason support I think for whether Madeline has or not is decided by our city the server itself so for the client I know another can state so that that works for UDP and I can but I\u0027m just thinking if we were to do and not that I recommend it but if we were to have the individual line card still in a tcp-based you know like Netcom 4s cough then they would have to be more aware because there\u0027s actually sessions and you know I know yeah multiple sessions then yeah so they\u0027d have to be more aware I\u0027m just thinking that I mean in Eric and all of your subscribe notifications work it\u0027s always been the assumption that there\u0027s just all the even notifications are being funneled into the routing engine and then you know like that so it seems like we need to do something to a flag to say something to help support the multi linkers yeah Anna for my Frank as we have another chapter yes okay Libby next yes yeah yeah he is for the yeah horse "
  },
  {
    "startTime": "01:06:33",
    "text": "subscribe to multi-stream ordinator now is the fall was not drafted we now is for genes that discussed for the use kiss enough for this draft i think is the from the beginning is separated from the UDP telemetry yes which is castle Erica and Andy and some other guys yeah we think maybe for this the scenario maybe we can define it another draft to discuss further comment and say yeah here for the use kiss of pasta with begin with the use kiss I think you seem for a large amount of data collection from devices with main distributor architecture design hardware design with the main border and a nine class and maybe exiting country existing solution consider only when happy Sawa is studying the main board which is a team performance the board and Erica for the collector when data are forwarded ur to the main board yeah countries Russia only one connection is there so Marty long harder we are sent to the main borders in sender to the character so there may be a bottleneck and the further request our distributed collection mechanism which came the directory push data from the line cards to a collector like the rest come just mentioned yeah for the used is to for here some some key Caesar for the ulti collector keynote a subscriber accepted directly from a Latinos so subscriber data from the maybe for the bottle rotor as in body rotor distributes a substring to the nose the Audi nose stream data to the collector through a border rotors in the collector a same substrate data exists and here is a initially is ruching overview we define the role of the ruching for character publisher for collectors there as though it may be usual as for subscriber and a receiver here like diagram yeah and a publisher they have two roles for master and a cinta because Aaron Marcus James under for for substance server and the components are in Sawa like in the diagram and now issue the being worker is a full sovereignty composition to keep check out resources and associate publisher and a make decision on that composes decomposing the calaboose exertion into multiple components absorption and for publication composition to compose a component and application into one because the sauce maybe from multi stream and some supreme elements some IRA costs related to the subscription accommodation and a component in a subscription and for the notifications the owner subscription States changes each component a sub solution maintains "
  },
  {
    "startTime": "01:09:35",
    "text": "its own substance States and is responsible for sending is owing away notifications and some other potential issues such as a synchronization and so the discovery may be net may be security yeah that is water we are working on okay yeah so my H speaking is a contributor so if you if I look at the two use cases that you have yeah you have a case where you have single box which is acting as a proxy which is use case to order and you have the other case where it\u0027s it\u0027s really the bottleneck right so and the individual line cards are sending them or means this is the connection right right so you have one case where one is a proxy in the other case it\u0027s not a proxy the line cards are sending it directly so the question I have is to the common that Kent made is when you\u0027re making a subscription notification is it for sending it through the proxy or is it through individual line cards how is that how do you resolve that I mean what kind of subscription notification would you be sending you mean for this for for this use Kies tool for either one other cases yeah I think it was this is to use this not only be not seen for use kiss one for maybe the notifications maybe the size or the traffic is a well big so in this case the force used is one maybe the main board over up upon the neck but for the hour T as we know maybe there\u0027s a not fiction not so many so different scenarios no but that\u0027s notification but how about the configuration request itself for configuration I think for for the client to subscriber it are not concerned whether it whether it is distributed or centralized a for the generator itself but they know the scenario whether the new scenario maybe they\u0027re the Mattie Mattie so smart generator so as for you to be publishing channel we have the generator D yeah so Anna for now we are discussing how to define the for configure complicate maybe when we configure the subscription they were is algebra publisher will require some parameter like a to notify the subscriber with a Haywood multi lanka\u0027s or not maybe zero gives somewhat general nuclear list of ordinary Tati yet to notify the client I "
  },
  {
    "startTime": "01:12:36",
    "text": "have the multi generates a sauce or not yeah just a support for use case one I definitely think this is valuable work and it\u0027s been stuff that a number of vendors have been talking about for a year so whenever you\u0027re ready to push for adoption not certainly say yes I don\u0027t know if now\u0027s the time we\u0027re not but it\u0027s certainly useful work in terms of the configuration versus when where the messages come off we have done a mapping in the past of each individual state change notification and configuration and it does Maps cleanly onto the lines from the subscribed notification draft so you are able to identify which flows go on which connection and I can work with with him in order to expose that to people as extra information okay okay so for use case one I isn\u0027t that what their previous draft the the adopted drop a UDP pub channel you said when you\u0027re doing that presentation that it be systems choice to just send it through the LAN card so seems like use case one is already solved with that traps you means that beauty channel so so disease the piece right yeah I think maybe how was the main main it\u0027s not it yeah it\u0027s already it\u0027s already resolves in that other driver yeah I think maybe the main means none is covered up yeah but here maybe the multitude maybe a different view okay yeah all right so I think I think this proposals really just for use case number two right now hello middle Hana from Nokia I want to just to ask because those two use cases seems to be quite different from each other I still don\u0027t understand why do you want to push them in one draft and you say for this common between them yeah this is I think I mean before the there have seen those those a kiss not seem so butter for they have some similar cooling solution maybe formats it generates a mighty sauce legacies yeah I think we can discuss affirmative yeah yeah I think you might want to consider both the points that this person from Nokia made and previous comment with respect what Kent made is isn\u0027t this if this has already solved in your UDP pops had kept up channel draft you may want to actually keep the UDP butchered to deal with the distributed sending of notifications and just pick this draft just to the for the use case - yeah we were discussed we have already put a meeting in a meeting - thank you meeting to discuss about this channel from Huawei and this we use this to a use "
  },
  {
    "startTime": "01:15:37",
    "text": "cases to introduce a more general distributed data crafting framework and for this framework atom we can also use TCP based channel we can use you to be based channel wherever so here this is the framework but for the previous chapter we focus on the UTP base the publication channel that\u0027s the difference I think let\u0027s take this to the list is that okay yeah and you\u0027re next all right I will talk about binary encoding just a quick recap from the London ITF there were a couple of questions on what is it going to be encoding our assertion is that it\u0027s simpler to do one switch to a new encoding format and do it for all the operations that would of course include not not just edit gate but but get data and notifications and the secondary question to that was whether we needed to do it just for push notifications or were there other operations that could benefit so in the case of periodic gets off even I get data or get could benefit from a binary encoded format but the bigger question is we want to play between different encodings for different operations or do we just switch to one encoding and use it for all the operations just to lay it out there the other question on the list was is this also relevant for restaurants and the question there is I think Andy responded saying there is already a content type header in HTTP that can be used to specify the encoding format so maybe the minimum thing that we could agree in this working group is what are the encoding formats we are going to support and register them in a registry in IDF and reskin could use those so specifically to the issues related to the draft question there was a bit of debate in London whether it should improve the message layer or should not be authors after discussing with Andy and couple of others seem to believe that there is a way to switch to a new encoding right after a hello and that would then include not only yang data "
  },
  {
    "startTime": "01:18:39",
    "text": "also the message layer on issue number one which is support for notifications if we were to go with that notion that we switch to a new encoding right after hello any form of notification whatever this workgroup finally agrees not only on 52 77 but the newer format would then could benefit from using the new encoding that is already negotiated on the session on issue number three we had initially indicated in 0-0 draft that we might have to indicate actual start of the new encoding but again after discussing with Andy and a couple of other authors we believe that we don\u0027t really need an explicit activate operation that the server will send an unordered list of encoding the client will indicate its preference with an ordered list and whichever is the first match is what is going to be picked for the encoding so this is more a question of are there\u0027s encoding formats going to be registered so both protocols know which other supported encoding formats I guess it\u0027s a non-issue in sense that yes we can put it in the registry for the list of encoding we want supported next steps are since there is still discussion or was discussion at least coming into this meeting regarding push notifications once that debate is kind of settled we can resolve any issues as far as encoding are concerned that it\u0027s configured or dynamic and then ask for this draft for workgroup adoption questions all right check no questions okay blush yes from Erickson I am presenting the trout that you have might have seen last time as well which is a kind of cut off from the anguish efforts to make it smaller and faster so just to recap we recognize that even though the publisher may say that he supports unchanged notification for some reasons them it might not support on change notification for every data node every bit of the model typical cases would be because it\u0027s just not implemented it takes time and effort to "
  },
  {
    "startTime": "01:21:40",
    "text": "implement especially if you fact need to fetch it from different parts of the hardware or maybe you say that you won\u0027t implement it because it not that\u0027s changing so fast that it is unreasonable and things are too much load to implement it or you might just not have the manpower to do all the implementation in other cases you might be limited even though the implementation there is there you might still not be able to send on change notifications because you have resource limitations like some hardware card is not locked in or you might share common yang model for big nodes and for constant constraint small nodes and they might have different capabilities so practically even if I say my nose supports unchanged notifications there\u0027s no guarantee that any individual single data nodes will really sound notifications and that\u0027s a problem so cool of this draft is to document which specific data nodes will stand on change notifications which data moves will not and we want some form of documentation about this and this documentation needs to be available both online during the life of the node and but also in design time or implementation time because you want to do an OSS integration you want to depend on what\u0027s what will be coming out of node so you want this information early and for that reason the proposal is to define a yang model that would document which they will send and or do not send their own change notifications and then I use the yang instance data draft to document that early in implementation time and then you can do the or OSS integration or the OSS development accordingly okay what changed since the last time I presented this based on the comments from Martin your clone the yang data model was simplified it\u0027s no longer an augmentation to the ITF young library because then connecting it to the different yang will use individual it would be complicated it\u0027s not the augmenting subscribe notifications either because that doesn\u0027t have a single route which is good to augment sets standalone model it contains default values so if your note supports on change notification for everything then you have to support just two leaves don\u0027t change defaults and then you are finished if you have that say some sounds special in cases then you can specify that individually but "
  },
  {
    "startTime": "01:24:42",
    "text": "because the unchanged capability is inherited down the containment model we believe there will be only few leaves to individual leaves needed this is the new model it\u0027s not a big it\u0027s read-only should be set by the system itself and this is just an example of how this would look like in an instance data file again there\u0027s a wrapper around it and then it\u0027s quite simple there are some open issues should we model the unchanged notifications capability separately for at the nmda data stores and yurgin a beer don\u0027t argue strongly for that sir you can shouldn\u0027t bother argue strongly for that on the other hand I don\u0027t see the use case why this would be needed if someone could tell that then it would be nice and the names in the multi rent model are too long but that\u0027s a separate small issue yes they should be made shorter and I think I would like to request adoption by the work group Italy we received quite a bit of support from the last year ITF methinks someone received some comments and support on the mailing list and the one objected really and the problem that we really must know if the font changes notifications are coming or not this problem maybe is not a good answer any questions Mobile San Cisco so looking at the economy the way they do this I think they had an option for subscriptions or telemetry data where the device itself can choose to send the data as quickly as possible so rather than be it\u0027s either it can do and change the scripture to a cart it can actually choose what rate for example so you had cobbler counters maybe it returns of every five seconds every 10 seconds so I wondered whether in addition to has been yes or no it might useful to have some way of saying what that rate is a that\u0027s too complicated to do because that might be I mean this just as useful is you\u0027ll only get counted every ten seconds I think they\u0027re really the basic problem will be is it really implemented what is for that specific note data don\u0027t I think that would be a much more common problem and yeah if you look at this meaningless small changes which is one more reason it was not my use gaelic - that\u0027s one more reason why not implemented this case you will say okay but if it changes fast if the change is bigger than whatever so it gets complicated fast and Smart Filters might solve some of these "
  },
  {
    "startTime": "01:27:44",
    "text": "issues which was proposed earlier that I sounded but only if if I don\u0027t know it\u0027s a pastor threshold or even if the change is faster than whatever I think Smart Filters is a better way to go for such more sophisticated gazes or another option could be to actually have a string that gets returned so we can return and then the device could say just provide extra information as to what that granularity can be so doesn\u0027t help an automated device if it does help the user was looking at it they can say okay finally goes data every 10 seconds I think you already have something similar in the negotiations for yank push well you could say that okay I refuse one second but I propose 10 seconds for them wouldn\u0027t that be redoing that work in some way maybe I mean I think I even config one is it just you say it does its frequency as it can so you need the device to choose but I see that the main point is that is it implemented or not really or so I Tim Kerry Nokia I wanted to be asked about the nmda support the on change per data store right so I know in other organizations we do have to differentiate whether it\u0027s an operational data store for certain elements particularly like it be enabled right you know where you configure it to enabled versus disabled administrative Lea right but then you have the operational status that can flap back and forth right now might wander and all change event for the administrative element of it right of that enable but not the operational element and so is that what you\u0027re asking about because they would be the same element just different stores I\u0027m coming partly from the ITU 3gpp background where you most commonly have an administrative state and the operational state has two separate leaves right and that\u0027s so now now we\u0027ve now Eve right yeah well actually I don\u0027t think it\u0027s the leaf that would be an operational be enabled I mean it would it would still be operationally enabled I mean the point is that we have attributes least nodes right that enable it is an example right work and go enable disabled right and it just what they did is they grouped it together in a single leaf right and the data store is what provides the the semantics around it and some semantics that we care about like if whether it\u0027s administratively changed do it on change for that right but you don\u0027t care about necessarily the operational status of it for example from the running right because it\u0027s flapping back and forth there right and you just don\u0027t you got too much perturbation there and so I\u0027m just saying that we\u0027ve seen those types of things and other management protocols "
  },
  {
    "startTime": "01:30:46",
    "text": "where that where they wanted to turn it on for one and not on the other day on chains right particularly the active this is an active notification mechanism and so I was wondering if that was the scenario that you were asking about right if people would sing let\u0027s say if you think that this is important that you configure that and you want to know when it but that was a that was a scenario that you were requesting right that was yes because I\u0027ve seen management systems depending upon who the consumer is management systems care about one and not about the other then what less so I would like to come back to the comment from the rate and then Rob that cetera I think that you want to keep it simple the drafts of a single problem which is you know I would like to have one change on all my objects in my router practically it won\u0027t happen for various reasons just knowing if it\u0027s support or not it solves a great issue and going into the rate and frequency of what you said it\u0027s too complex already put that mean that you oh you don\u0027t want the power datastore either I was paying attention to that comment sorry support networks so why this is not in the young push model it was in the yank push model it was taken out in a previous ITF where people wanted to simplify their and move it to its own draft so I always had it in the previous yank push model people wanted a bit separate this is a integrated part of the push right so if I fly something I need to know the status but if you\u0027re thinking about how it work yes to be pushed fast I am happy with the current situation okay any other comments before we take poll on whether we want the school to have to be adopted as a workgroup item okay if know how many people have actually read this draft okay a few how many would support it being adopted as a workgroup I\u0027ll okay okay quite a quite a few more anybody who would object to it being "
  },
  {
    "startTime": "01:33:47",
    "text": "adopted as a workgroup item okay I I guess then we will take this to the mailing list hello everyone my name is Tim I want to introduce this topic empty a base event and this topic actually has been discussed in the last idea meeting actually we have to open you we discussed actually one is about how the event we propose in this job the relative you the young especially unchanging unfortunate the second is what change is needed that you support an MBA so after last idea meeting we worked out whether with my colleague or rocky and I try to resolve this open issue we seem actually have potential open overlapping with young pussy so we actually proposed to replace the original event with we put in the chapter with an empty a paid beta validation event and another open issue actually we did actually pakka with the origin also the OP c64 78 medical co-pays event document and whether we should actually make a piece for the obviously 74-64 70 actually and he actually if a battery sink actually is better to keep a medical based event at as VR and we should define new event a specific to the MDA so also we responsible to Tim Kelly from Nokia the comments actually we sink right now the data store parameter only affect the net call for configure change events before as a event actually there\u0027s no such data store parameter so resolve these two open issue and we update this job and actually we write the post reaction and introduction and replace the original event way poster with the new event and empty a data validation so this is a use case for the an empty data validation we think actually there\u0027s quite background activity from the time the congregation has been complete committee into the running and to the time when the congregation is applied from intend to the operational so in some cases actually you may actually some contribution cannot be applied with "
  },
  {
    "startTime": "01:36:47",
    "text": "operational because some miss results of validation failure so in such cases some for client naturally the amount to know well what is the validation result what is the failure reason so one typical use case is the way you have validation have partial failure so you need to know how many object are really affected so this is what we propose for the solution actually we define a new event now call me when especially to the MD actually this event will be generated by the server who support young based the protocol actually to detect the event that take place during the time period as we mentioned about actually there is actually we call the event and say the change of the data validation and we think these are coming opinion that they need to be specific to the Nanticoke but also can be applied to the restaurant and other young face the protocol Apogee RPC and we think we should inherently the the management session parameter from original medical pace event after actually also we can actually allow the client to get access these events through various different separate sub screeching mechanism and so this is the example the empty data validation actually we can actually carry not only the management session parameter such as user name session ID source host but also we can actually include some validation result like a validation event and validation results actually we support a success failure and a partial failure in case of the failure of partial failure we released actually a set of the obstacles that are being affected so we think actually we resolve to open usual resisted in the NASA meeting and this job actually has not been stable will act recall a requester working with you covered option for these jobs that\u0027s it can\u0027t as a contributor so I mean this is interesting right but where where we have the configuration it\u0027s gone to running and then intended but it whether it\u0027s applied is the question and the its applicability or it could be flapping you know someone could pull a line card or gonna be different reasons for why it\u0027s not been applied so these notifications this is a way to provide visibility to the application as to how much of the configuration or which parts of the configuration have not been applied and so this would happen asynchronously you have you also thought about some sort of synchronous way to collect this information as well right "
  },
  {
    "startTime": "01:39:47",
    "text": "now we haven\u0027t thought about it by the weekend consent oh yeah seems like an important problem solve Jason\u0027s turn Nokia apologize I haven\u0027t read the draft but just keying on what Kemp said is this about determining that a data store became invalid hence the word validation or is this a notification saying hey something didn\u0027t get applied because the word validation yeah in this made me think that some set of config is no longer valid but what you\u0027re describing us and the example seemed to imply hey this leaf didn\u0027t get applied yeah my understanding is the latter yes over the ladder I\u0027m not sure validations the right term it seems like a misnomer yeah maybe the notification I called like something to do if someone in da term applied or didn\u0027t apply or something like that yeah good point so again I think it\u0027s an important problem to solve probably would want to have some synchronous way of determining what parts have been applied as well I mean there\u0027s a datastore diff right so if you do the diff between applied and operational maybe that\u0027s another way of determining what hasn\u0027t been applied so who who in the room thinks this is an important problem to solve raise your hand please interesting you know so then so Robert DiCicco so the reason I not put my hand up is because I think you can get seen same information by having a subscription notification on the configuration they\u0027d store all the applied datastore and then you can monitor the applied configuration through notification back to what your configure putting in is so you can completely circle using notification mechanisms asynchronously so you would still have to do a diff I guess between the dual notifications I think you would continuously monitor the state operation static device and you continuously rationalize that against the configuration you were putting in so naturally on a per data node level you would be rationalizing whether or not that particular variations apply it rather than querying or not saying it\u0027s a notification is a bad thing it\u0027s not quite sure whether it\u0027s necessary or not I think it\u0027s okay I think one of us in that way we can see that actually we we did concede actually there\u0027s a lot of data you need in monitoring so to really organize this actually we only when you failure of partial failure will actually include a affected object so we did actually more of these in a younger model and it may be that the failure case is more interesting to say yes first and but the other issue there is some luck it can be hard on some systems to actually be able to provide this your systems asynchronous in terms of how things have been propagated through the "
  },
  {
    "startTime": "01:42:47",
    "text": "system you may not easily know if the states have enriched why they were successfully or as a failure depend on how it\u0027s implemented yeah do how do you know so if I could step in so how would you know when intended it has finished applying all the changes to operation when do you decide there was a fault and therefore didn\u0027t get applied or he\u0027s still waiting for the system to go through and actually apply the changes I think I was sir I didn\u0027t know these right how the server I shouldn\u0027t know these and Jason sooner like if a line cards not plugged in it doesn\u0027t get applied so do you call that an error like sometimes it\u0027s hard to determine if something didn\u0027t get applied because I\u0027m error or versus just the requirements aren\u0027t there for the config to be able to be applied like it\u0027s not like we talked about the classic example of when you configure an interface but the line cards not plugged in then that\u0027s not applied that\u0027s not an error right we don\u0027t want to consider that in there sure it\u0027s a difference between applied and intended but with this thing call it an error I assume we cover these because of some case actually you may miss it results I think it\u0027s that\u0027s of what you gave the use case actually so I think it depends on the user than the configuration in there you will know whether or not they\u0027re doing pre conflict and hence whether or not it\u0027s an error so they\u0027re not doing pre-configure they may expected to work and not fail but if they are doing pretty config and Union and system was hot so I think the client using what you\u0027re talking about where it has a continuous view of the difference between applied and intended it could determine that over this case is bad but we\u0027re talking about a notification here sent by the server where the server decides that the case is that yeah okay maybe one more comment so when we try to just assume from modern Linux so when we try to apply text or changes because like hundred of years so the failures hundred few years the state will be saved somewhere must be right but I don\u0027t have any place to save those states I think this is another define a query the server we\u0027re pushing another patient to the client client can actually locally say this kind of failure results I don\u0027t know central one single RPC took out all the failures so we\u0027ve got the notification one by one hundred notifications on may bundling together got ten notifications thence after the "
  },
  {
    "startTime": "01:45:49",
    "text": "client who deal with them so the normal notification will cover that why do we have separate RPC to query the failure you which a number not vision you think you can be used i I think that is actually not a PC not because a new episode is kind of notification right is a generic notification just like a medical base event actually it\u0027s kind of general purpose modification so sorry if you\u0027re really running out of time on this so I would suggest that maybe you take the discussion to the mailing list and we can then revisit the question of adoption all right you have five minutes for the second version yeah another chapter is about the factory factory default setting capability for red scarf and I think it also applied to the neck hole and that goal actually is allow the restaurant line at you you know configure the unity powered device with precomputing stated you\u0027re in the mega for example they were attached bootstrapping process and also you can restore the conflation into the priests computer initiate stated during the the server restart or server federic arrow process so we motivation to do this actually we see a lot of limitation for the medical and a reskin flow for example when an account actually we have delete the config but they only actually can return the device to the factory before the setting it only applied to the startup but don\u0027t apply to the wronging for the config copy configure operating actually you can use that operation actually to copy when they distort you another datastore but without a factory beta star as a salsa you cannot return the target video store in to the factory default setting so also there are some limitation for the rest comm similar reason actually equal rest can be implemented in the device that has nano for server support actually you may consider to use a copy configure you may actually face a similar issue actually you copy won\u0027t be destroyed into another paper store but without the factory data so you cannot return the tacky data soy into the the pre-computer initial State so another case actually if the rest camp is implement in a device that doesn\u0027t have an account support so the rest count client can actually be the nmda datastore aware actually he can use HTTP "
  },
  {
    "startTime": "01:48:51",
    "text": "buta measured as specified by obviously 8840 and but the HTTP put measure can only actually replace in high in contents with some configures it\u0027s splitting here we give the example you cannot actually you know copy one people story - not another datastore use this kind of a duty we put so this is solution we propose that we propose to define the factory data store this factory store can initialize longing into the factory before setting actually if you only have the wrong name but you will have a wrong and stop both actually you can actually initialize powerful stop and running into the pre-configured initial State in some case that you really need service Sparta and so you so we here we want to upon out actually there\u0027s some consistent usual for example you want to initialize the Romney into the factory but at the same time there\u0027s another operation like a at a config actually also at accountant so I alter the contents of their running they may actually immediately update it to the estaba so they work also the inconsistency between the stop and Ronnie can you quickly wrap up so we define these data store actually as a read-only data store actually and we need also we need to document the factory with the medical restaurant operation may be restarted or Beijing together but we actually face some Evo we document this kind of behavior we also need to address that you open issue why is actually do we need the support is a new operation like a faculty priest or there\u0027s some discussion on the list actually some more people favor actually using existing and Coruscant operation maybe also need to consider we start off with operation but we also have some argument to define the new operation actually we see actually an imitation over the press conf operation also we need to support the general purpose operation so you may need to define this kind of general purpose operation applied not only net call but also read calm and as a young basic photos and in some cases you need to serve early star in some cases you Tony nurse every style for you have operation you have restarted Jaime that you indicator whether rich star is needed so so that\u0027s that\u0027s another case actually also in the manage to it discusses the difference between the system restart and reboot actually we think system restart actually the difference between system restart and every structure is for sitting Rizal you need to restart the whole system not only me to the Netcom but we started just that "
  },
  {
    "startTime": "01:51:53",
    "text": "you restarted the server so that\u0027s a period difference and the report is similar to the system we started so the pricing actually was we believe actually existing raskolnikov is sufficient and whether we need to define restart or vision so we single the general cream and actually to define a factory data store and allow it device to evaluate and but it says mix opening whether we need to define new operation that\u0027s that\u0027s it sorry we have to cut the presentation and move we have only eight minutes left for the last presentation is Robertson I\u0027m presenting on behalf of Lada because he misses flight so I\u0027m not an author on this draft but I have reviewed it and I\u0027ve provided constant length so I\u0027ll do a lot of justice so first of all what\u0027s his draft about really it\u0027s called a transaction draft by the way I think he\u0027s introducing private candidate data store so that you can have a candidate they distort that is tied to your session and he\u0027s done in terms of rest comp here but you could also apply this to Nick off as well so the moment in terms of what neck off defiance finds a candidate store but it\u0027s been big us on this but it\u0027s may see basically regarded as being a shared Canada date store and use locking to control it what\u0027s being proposed here is a bit different you have a candidate datastore which is calling somewhere remember I\u0027ve come to call something a staging I think and in doing that your particular session you can write data to that make multiple updates and it some point you can commit there in the data and as he says its enhancement to 80/40 and tastes like a capacity and in MDA compliance that\u0027s was written some work there so in terms of his implementation he\u0027s using intended as the converging point between where these new candidate private candidate data comes into I think that\u0027s my opinion pretty mistake and you can read intended as being running so actually that\u0027s the point where you\u0027d commit this configuration to there\u0027s no discussion on that on the ADA so I think he\u0027s agreed that he would change that so I\u0027ll keep discussing terms of intended but everywhere you see intended you could probably assume that\u0027s going to be running in term resolve the other thing that he\u0027s draft talks about is reusing the same existing slash data path this sort of unified view you have in restaurant I think there\u0027s some questions as to whether that\u0027s the right approach from not but it\u0027s thirty valid and it allows it to work with pre ending pre nmda service but there\u0027s also another way of doing it which would be to expose a stage and data store directly as the nmda version of restaurant supports so in terms of the "
  },
  {
    "startTime": "01:54:53",
    "text": "operations have been added in here your client you get a state one of these stage and data stores you write data to it and then when you decide to you can then commit it updates here it says intended I think that\u0027s running and he\u0027s also defines a reset operation which then reset staging back to a current copy of intended or running I\u0027d like to do that I think probably you also want to go to diff what\u0027s in staging against attended running and we\u0027d use the same diff operation that other people really proposed and the last thing I think that\u0027d probably be useful would be to be able to update staging to get a fresh copy against intended so you keep your changes you merge it in with what\u0027s currently and intended as well and so it requires here the intended is always valid that\u0027s the same thing applies to running as well so in his current draft he hasn\u0027t defined a merge procedure he\u0027s if that undefined because different use cases I suspect that something that would have to be specified as disguise for it is my opinion in terms of compatibility this is where he\u0027s saying in terms of using staging effectively there\u0027d be no change to the user by using the existing slash data path you and how many changes I suspect that you might have to have some some ago she ation first to know this is going on and beforehand yeah so I think there\u0027s some tweaks maybe here naming issues so some discussion as to whether it should be called staging or Canada if this new data store I would support calling it something different because I think it\u0027s valid potentially to expose candidate through dress conf it\u0027s giving it a new name is better there\u0027s been disguise discussion the alias between whether it should be intended or running as I\u0027ve just mentioned I think that would change to the updating running I think that\u0027s okay and then okay fine here\u0027s some examples they got running code in terms of his jet confrontation written in Python 3 so there\u0027s running counter to be sorted here really I think this is an interesting problem though do we try and solve this in the working group do we actually have this idea of private candidate dates tours so I think that\u0027s to me is the most useful question that maybe it\u0027s worth asking the room is this is the sort of thing a good idea so in Greek yeah so I personally as a country would agree that it\u0027s a problem but trying to solve but I let\u0027s all the working group to see the interest in do they think that the sabbatic problem that we should be solving so fans raise your hand if you think this is an interesting problem solve okay I\u0027ve commanded and if you don\u0027t think this is a important problem to solve raise your hand well okay one hand I feel like "
  },
  {
    "startTime": "01:57:54",
    "text": "important carbon to salt but the whether you\u0027re the separated style melted itself carnival yeah as a contributor I also think this is an important problem solve in fact I think it\u0027s a very important problem so this is the key this difference between rest cough and net cough right the reason why rest cough hasn\u0027t been able to eclipse neck off yet is because the lack of transactions and support for things like confirmed commit if this brings that in then it would make rest cough an equal player in the protocol space so I highly suppose yeah but I also think that the implementation of individual candidate data stores has been pretty much left undefined some have chosen to implement it as a private candidate others had done a locking mechanism to try to use candidate so maybe some specifications around what is a candidate datastore and whether it\u0027s staging is that it is for would be helpful to solve so so one last call it only counts a point to this is I know that some operators say this is not required and their justification is that you you can generate the entire change set in your clients and then just send it down as an atomic operation and hence you don\u0027t need this much a persistent behavior but that\u0027s this one operators view okay so I think we should confirm this adoption poll on the list no yeah okay thanks for presenting for let up and that\u0027s a wrap we kind of thing we one minute to spare so enjoy your rest of your afternoon Oh blue sheets somebody has the second pair of blue sheets "
  }
]