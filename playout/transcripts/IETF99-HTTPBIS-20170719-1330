[
  {
    "startTime": "00:00:50",
    "text": "so folks this is the htdp working group if you\u0027re not here for the htdp working group please leave in an orderly fashion we\u0027re just about to send the blue sheets around Thank You Barry you anticipate our needs as always excuse me so some preliminaries this is the note well statement this is the intellectual property terms which we participate in the IETF under which is very important it\u0027s one of the primary functions of a standards body is to give you well known terms for intellectual property and antitrust so please if you\u0027re not familiar with this you can use your favorite search engine for IETF note well but you do need to be aware of this it affects your contributions here another bit of policy which unfortunately doesn\u0027t get quite as much attention we strive to have a harassment free environment here there is policy on this which is in the reference to RFC\u0027s and we have an Ombuds team so if you feel you are being harassed or you come across a situation that causes you concern you can contact these kind people at the bottom either personally that\u0027s why we have there or using the email address or you can talk to the chairs if you\u0027d like we take that very seriously as well so the blue sheets are going around please sign them we need a scribe for this session do we have any volunteers come on Marie I saw you out oh yo yo thank you you\u0027re a kind gentleman can you handle the job or relay or should we get some octopus I gotcha ever you got the jabber okay you\u0027ve got the chipper our agenda we have two sessions in this first session we\u0027re gonna go over our active drafts and then we are going to go over a few bits of proposed work that has been discussed if we have time at the end we have a presentation on secondary certificates any discussion of this sessions agenda just to give you a preview the next session is exclusively about quicken HTTP so we can hold all those discussions till then okay all right so let\u0027s go ahead and start our first discussion is of RFC 62 65 this which is the cookie spec and we have the editor of that spec here Mike hello I\u0027m Mike West and I have been working on the RFC 265 this draft I have a brief update "
  },
  {
    "startTime": "00:03:53",
    "text": "for you all today basically boils down to two things thing one I am slow and thing too I have questions before we get to details of the draft I want to talk a little bit about the code that we have running out in the wild based on some of the drafts that are going into this revision of the cookie Draft after a long ramp up to an increasing number of users and stable chrome rolled out the restrictions on the secure attributes and I think chrome 56 at the end of January of this year that led to a short-lived surge of bug reports from people who are now being a affected by this that weren\u0027t affected before that has basically trailed off at this point and I think it\u0027s something that we\u0027re going to keep in place firefox shipped the same restrictions in Firefox 52 in March of this year as far as I know they\u0027re also planning on keeping this research and in place I haven\u0027t heard anything from either Apple or Microsoft about their implementations but this is certainly something that is affecting large numbers of users and servers today and I think it\u0027s something that we\u0027re actually going to be able to ship and keep in place the second thing our cookie prefixes so there are two prefixes to find the Medoc a double underscore is secure and double underscore host based on the chrome chip these last year Firefox shipped these last year as well based on the metrics that we have in chrome the secure prefix sees practically no usage I think there was something like 16,000 set cookie headers that we saw over the last month whereas the post prefix sees also not a lot of usage but something like 0.005 percent of the set cookie headers that we see carry a host prefix and I know of at least two see a session fixation attacks inside of Google that this is actively prevented so it is pretty useful it\u0027s something that I\u0027m happy that we\u0027re shipping again I haven\u0027t heard anything from either Apple or Microsoft but Firefox and Chrome are both shipping implementations today seems like cookies shipped in chrome 51 last year Mozilla folks were also working on an implementation it looks like that implementation is stalled but it still seems like there\u0027s interest in that implementation from Mozilla again I haven\u0027t heard from either Apple or Microsoft but we\u0027re hopeful that this kind of thing seems to have a lot of popularity with developers we see something like 0.01% of site cookie headers have already adopted this which is actually larger than I would have expected given that it\u0027s only implemented in one browser and that it provides enough protection that developers seem interested in the defending themselves against CSRF using this attribute so with those implementations in minds let\u0027s to the draft that is cleverly up on the screen in front of you right now long story short I\u0027m just slow I missed the draft deadline for this IETF I have a draft on my local computer "
  },
  {
    "startTime": "00:06:55",
    "text": "that has all three of these specifications stuffed into it that I\u0027ll upload as soon as those restrictions are lifted so that you can actually take a look at it and give some feedback on it one area in which comments would be particularly helpful it regards the layering between the cookie specification and the fetch and HTML specifications that are currently being worked on in the what\u0027s up ug standards body in particular same site needs a couple of me has more understanding of HTML and a fetch then I think it probably should have for this document but it\u0027s not entirely clear to me what documents the IETF actually wants to reference and to what extent the IETF document can pull in concepts specifically from fetching from HTML that have a lot to do with web browsers but don\u0027t have a lot to do with clients like curl so figuring out exactly what that layering should look like and providing a clean entry point to those other specifications is something that I\u0027d love to get y\u0027all\u0027s feedback on I can imagine pulling things out of the same site portion of the spec and putting them into HTML putting them into fetch and then providing a set mechanism of some sort that would set the header based upon a set of attributes they\u0027re passed in I can also imagine using the request concept from fetch directly in the cookie specification order to read that kind of data ourselves but getting feedback for me all about what that layering should look like would be super helpful the last thing I would note is that martin thompson put together a draft last year that was adopted by the group i forget what the name of it was eat cookies or he\u0027s non-secure cookies or omnomnom it\u0027s not entirely clear but the the basic idea is that we should treat cookies that are delivered over HTTP in a different way than we treat cookies that are delivered over HTTP given the amount of adoption of HTTP over the last year and a half I think it\u0027s probably time to revisit that specification more actively and start exploring what that space might look like this goes to the point of defending against pervasive monitoring and also encouraging advertisers and others who embed their party contents to migrate to TLS in order to allow the first birth migrates to TLS as well so I think that\u0027s an interesting spec I think it\u0027s something that we should look at I don\u0027t think chrome would implement it as is but I do think that there are some subtle changes and minor directional changes that we can make to it that would make it pretty appealing both for Chrome and hopefully for other vendors as well yeah so I\u0027m on Thompson the point of that draft is really to establish a set of principles by which you might set policy and so the policy that chrome implements if they start going down this path will be necessarily a subset of the things that are described in the document and over time we might see that change and that\u0027s "
  },
  {
    "startTime": "00:09:55",
    "text": "one of the risks that we have with writing documents like this is that this is the this touches on policy space and we need to allow for the fact that the environment changes over time and as Mike points out it has changed to the point where this has become interesting in the future it may change to the point that we can actually make a more definitive statement about it but for the for this intervening time we have to think about allowing user agents the ability to set policies and providing some sort of guidelines and a framework for doing that and I think that\u0027s the intent of the draft and I\u0027m very happy to talk about what those policies might look like or what guidance we might provide regarding that yeah so folks puzzled I\u0027m just curious if Mike you wanted something more definitive or or if you agree with that standard I do agree with that statement I think the direction of the document that you wrote is the right one and I think that what we need to do collectively is figure out ways to get to that without having sincere negative side effects on the ecosystem and I think we can do that that\u0027s all I got so if you have any questions or feedback about cookies great I would be happy to have them so just from my standpoint and I don\u0027t know if I\u0027m wearing a hat or not personally I\u0027m willing to try referencing the what working group document I think it is going to require some talking to people and thinking and we\u0027ll see how it goes but I\u0027m willing to try that makes sense to me I can basically see two paths one is that we reference that document when we use its concepts directly the other is that we provide an entry point to that document with a lot of boolean\u0027s and parameters that get past it and allow the embedder of cookies whether it be a user agent or whether it be curl or whether it be something else decide what the what the meaning of those terms is I would be I\u0027m kind of unhappy about doing that because I think this document should define the terms in a way that is interoperable but putting those definitions into HTML or into batch is also viable okay cool thanks folks all right the next up is expect CT I believe so Emily Oh full screen my old friend okay hello I\u0027m gonna give a quick update on expect CT um the main thing is the next slide which is that we\u0027re getting ready to ship an implementation in chrome this will be branching very soon it goes it\u0027s going out with chrome 61 which goes to stable in September if you are a site "
  },
  {
    "startTime": "00:12:57",
    "text": "operator who\u0027s interested in using expect CT now would be a good time to start thinking about that it would be great to have some sites using it as chrome goes into beta so that we can you know figure out if there are problems figure out how it\u0027s working etc before it hits stable okay so I wanted to give a quick update on some of the open issues and well hopefully neither of these are open still but we\u0027ll see so one of them is fairly minor I updated the reporting format to handle both svt\u0027s in both 696 two and six nine six two bits format so it specifies how clients supporting either of these versions of CT can report their at cts the night the next open issue is cores this is not we discussed this on the list a little bit this isn\u0027t really the isn\u0027t really that relevant to the ITF except that it affects implementers of this spec so I wanted to just talk about it a little bit your slicer in front of you Emily okay so the issue here is that um expect CT reports like many other types of reporting that that browsers implement arguably fall under cores restrictions that prevent web content from triggering arbitrary requests to two servers that don\u0027t expect those requests there are various hacks that we unsatisfying solutions that we discussed on the list one of them was to just bite the bullet and send pre flights for expect CT reports this is not a hack on the face of it but it turns into a little bit of a hack because of implementation concerns we can take reports and stuff them into a request that does not need to be preflighted according to cores or we can just knowingly violate cores those are our options right now um what I have ended up doing in the draft right now is just leaving it up to the client to decide what makes sense obviously does it make sense for you know non browser client to send pre flights and browsers can also reasonably disagree on whether they think that these requests are our subject to preflight and crumb what we\u0027re doing is we are sending pre flights right now but my plan is to go take this up with the fetch spec and see if we can carve out some kind of exception that makes sense for reporting requests because the fact is that there are a number of reporting requests reporting requests right now and other kind of browser generated requests that violate Korres and will continue to do "
  },
  {
    "startTime": "00:15:57",
    "text": "so for the foreseeable future so that is where I think things have settled I\u0027m curious to hear whether people whether people agree with that but other than that if those if those issues are resolved I\u0027d like to see if we\u0027re ready for working group last call because I don\u0027t have any other open issues or plans to make changes right now hi Nick Sullivan CloudFlare just a quick question about expect CT can the report URL be on the same host name as the event that triggered it this would sort of avoid your core\u0027s issue and it would be easy for us something like Loffler to deploy widely if that was possible I don\u0027t think the draft says anything about it right now but I think I think the chrome implementation does not allow them to be on the same host name same as for pinning because of looping possibilities so so Martin Thompson I don\u0027t know that we ever really got to the end of this one I think there was a lot of talking but we never really came to any conclusion on other thing and I would like to reach some sort of conclusion can you explain to me why it\u0027s not possible but the origin of the response that contained the expect CT header in the origin of the pre-flight it\u0027s possible but incorrect I mean that\u0027s the that\u0027s not what the origin had her is the origin header is the the contexts that initiated the request so yes so who generated in this case it\u0027s the it\u0027s the entity that generated the URI by the thing that controls the the URI that goes in that request is really what matters in this context is the attacker if anyone\u0027s the attacker no I mean if evil calm has a sub resource includes a sub resource from victim calm its victim calm that has to opt in to receiving that request from evil calm so it\u0027s the evil calm origin that needs to go in the origin header okay maybe maybe this is not the time to talk that through I don\u0027t know if that\u0027s correct because they the expects et header comes from the victim yes yes but the but evil.com is initiating the requests yes our who initiates the request in this in this context doesn\u0027t actually matter because victim calm is the only one who has any control over their expects et oh "
  },
  {
    "startTime": "00:18:58",
    "text": "well the other issues that it doesn\u0027t you\u0027re saying if victim calm chooses to serve expects et than they are opting into their incidents but the report URI can be arbitrary so that\u0027s what that\u0027s why you need the origin feel that I mean as as Nick suggested if you weren\u0027t going cross-origin for this if if victim calm didn\u0027t want to send their reports to CT reporting calm then that and they would have and they were and we doesn\u0027t like the system such that they were the only ones that could receive it that would not be a cross-origin request in that sense because the victim calm is receiving reports at victim calm and it\u0027s it\u0027s the one setting the the thing and it\u0027s not a cross-origin request I think the your modeling of this as the thing that initiates the request that then that the HTTP request that then causes the certificate validation to occur as being the triggering our agenda is incorrect I think you need to perceive this as the thing that sets the policy and sets the reporting your I as the one that actually initiated the request yeah and then it\u0027s different and I think we might have been talking past each other when we\u0027re talking on this just is literally impossible because we have this context and I didn\u0027t understand that that\u0027s what you were thinking about I see because to me it was obvious that the person making the request is the one that sets the expectation to think about that a little bit more but I think I yeah and with that Mike okay you think about that some more and say and decide whether or not you you think that the the carve out the cause is still necessary because the kabbala cause is problematic um I I suspect I will end up thinking that the carve out records is still necessary for other reasons but this may be the wrong place to be having that discussion ultimately being the fetch back as the as the venue yeah that sort of thing you guys decided but we can offer some advice I don\u0027t know if we can get honor involved in this conversation any more than we have but that\u0027s really what it yeah and and by the way after after thinking about it a little bit more I don\u0027t actually think the null origin is that big of a hack like it doesn\u0027t it\u0027s fine perspex as far as I can tell and it is safe as far as I can tell in the sense that it does require the server to opt in and like you know and unless the report collection server is an internet server I think it\u0027s fine but but I see what you\u0027re saying yeah so that so the alternative here that that still ends up with two requests is for the person setting the expects a T to set up a resource for reporting on their own site and they they you never have across a that\u0027s never across origin requests from this perspective and then you don\u0027t have a have a pre-flight if they do want to "
  },
  {
    "startTime": "00:22:00",
    "text": "use an external service they can use one of our wonderful redirects and we\u0027ll we\u0027ll post across to the external service that\u0027s that\u0027s possible right so there\u0027s a number of different ways that this particular cat can be skinned and I think we can we should talk faster so it seems like the conclusion is to leave that issue open for a little bit more time yeah though I mean another way one could read that is that I mean the draft doesn\u0027t really say anything in particular right now it says that if the client is supposed to be sending Korres the client should send Korres so I\u0027m not sure that any of these yeah so - Martin Thompson I would like to see at least a plan for for a solution whether it be here or in some other document know if if it is entirely appropriate for this document to say basically nothing about cause then that\u0027s fine but I don\u0027t want to ship this thing and then find out that the conclusion of the discussion on the fetch spec is that this document had had to do something I we don\u0027t need to ship it in screaming hurry do we do we have a specific issue about this open on a third spec yep it\u0027s a fetch pick and the fax back yep I think did you work alone um I don\u0027t think there\u0027s one specific to expect CT if there\u0027s one about OCSP which is the whole other because it seems like ona and sleevee and a few other folks need to be consulted so i I\u0027d say so yeah let\u0027s let\u0027s talk to those guys and then hi there this is this is important to them so it should be difficult to get their time so hopefully you know okay any other questions or comments for Emily all right thank you all right thank you so is Paul Henning with us silence alright so the next item on our agenda is about the header a common structure draft mark is going to do is best phk imitation and consumptive let that\u0027s quite a bar I don\u0027t think we have a lot to talk about here there hasn\u0027t been a lot of activity on this spec what there has been is confusion about the scope of the specification in that I think people think that this spec is for different things and my understanding from the discussion that led us into adopting this spec and indeed the discussion about jfv which was its predecessor was that we were most interested in something that would improve the experience for people authoring new headers so that there were "
  },
  {
    "startTime": "00:25:00",
    "text": "less pitfalls facing them and they had something they could rely upon and also to make headers more reliable to parse there are some secondary goals in terms of making headers more efficient or allowing alternative encodings of headers but those were not our primary goals in doing this work and so I guess from my perspective I\u0027m interested in what people think about if I\u0027ve got those goals right and if so whether we\u0027re still on track for meeting those does anybody have any strong opinions or even weak opinions about that Julie and I see you out there hi I\u0027m Mike West as someone who is minting headers I liked JSON a lot more I think JSON from a web developer perspective has tooling everywhere in every language is very easy to use is well understood by developers who are going to be setting headers and reading headers and that seems to me to be a strong argument in favor of something that reuses things that developers know about today thank you Julian says on jabber we\u0027re not making progress that\u0027s the main issue and I\u0027m willing to get the Jason\u0027s back out as a non-working groupers back right my response that is I would ask for a little bit of Julian\u0027s patience in that if we can come to a solution as a working group it would be nice to have one way to do this instead of two but let\u0027s let\u0027s maybe give it a little more time Michael for me to echo you\u0027re on the air well what\u0027s up pressing the button okay so I would agree with the goals as you stated them I would say that from discussion with our dev team we really really don\u0027t want to be including a JSON parser that low in the sack if we have to we will but I\u0027d prefer we not go that route and I like this draft a lot better more in that direction but again making progress is not there\u0027s the issue so Mike I guess again speaking personally I look at this draft and I have a hard time getting from it to I think where we need to be you know it doesn\u0027t talk about parsing error handling the author experience any of that and it does seem complex you know personally I\u0027m tempted to try and write a draft to you know offer another approach do you think that this draft that we have now is is you know 50% of the way there 80% is its eligible I "
  },
  {
    "startTime": "00:28:02",
    "text": "suspected it is salvageable I agree with you that there are probably some pieces missing and it would be interesting to see a draft or a full request but trust to fill those in okay I might talk to Paul Henning and I think we need to huddle yeah yeah my quest again one thing I would note about the JSON parser is that I understand that putting a JSON parser into the net stack seemed strange and difficult one nice thing about JSON is that because we have implementations and because those implementations are exposed to the web they\u0027ve been very well fuzzed and we have a very good understanding of the security properties associated with them given that I even I don\u0027t have that much trepidation about using the existing JSON parsers in places where they aren\u0027t currently used because again I think they\u0027ve been very well fuzzed I\u0027d love to hear from Daniel Steinberg but I don\u0027t think he\u0027s about is he I am opposed to using Jason since even in the most popular JSON process we found in compatibilities that result in different interpretations and since it\u0027s about headers and miss interpretations or disagreement between how a for example a floating number would be implement interpreted might result in a security issue so I\u0027m strictly opposed to using Jason and I favored using this HTTP had a common structure as a basis so Martin Thompson won I sort of caution against getting too much into the what we would prefer to do a or b no I think we\u0027ve actually heard a lot of those comments before about Julian\u0027s draft and about this draft I think part of the problem with the current draft is that it it originally came from a place where it was being a little more aspirational in its goals and a lot of that legacy remains in the document and maybe it can be salvaged but I would I would like to see those goals articulated first and that would be that would be worthy of yeah conclusion as well yeah right and I think one thing we can do we started the discussion on the list about these goals we probably need to finish that and get consensus on them I don\u0027t know that we\u0027re in a place to get that consensus right here and now because we need to articulate them a bit better but let\u0027s go ahead and do that and then see where we sit perhaps right anything else in this one not for me okay cuz you know cache digest yes "
  },
  {
    "startTime": "00:31:05",
    "text": "screens right let me just find the presentation hi so let me explain about the changes that has been made to the cash next draft so there has been three changes and well the first let\u0027s talk about the last one and this intended status has been changed to experimental as we discussed in Chicago since a browsers likely to have support for cash dices in the news feed future and on instead we\u0027ve added definition for the cash Liars header and considering I\u0027m going to experiment so the cash that is headed is emulation of the cash digest http/2 house frame which is not as optimal as using a frame but it kind of works and it\u0027s already being implemented in apache h2o and also there is a node module called chastised immutable and there are some small scale deployments now that already have this being activated and the header looks like this and it\u0027s basically a base64 form of the digest value and some flags so it\u0027s really one-to-one matching between the frame definition and the header so next please and we also have a new feature that is actually an HTTP to setting that allows the server to tell the client whether it supports cash values and the issue with we thought that it existed but since Justin just needs to be setting 0 RTD there was no way to let the server to notify the client whether it wants to be chances not however we\u0027ve noticed that since the else one points very full handshakes let\u0027s the server speak first using the zero zero point 5 RTG data we cannot fire from the server to the client that if it wants to see a cash status before clients has the chance to say me I need it so this takes advantage of the approach on the other hand 0.5 RTG is only a very available in for handshake so for the zero our duty resumption the client needs to remember the remember if the server supports a cache digest and have that information associated it\u0027s at your session cache and well while that might sound complicated my understanding that terrorists tax would have that kind of a support that kind of association I mean associating extra data to station "
  },
  {
    "startTime": "00:34:05",
    "text": "cash since that that is also a requirement in quick so we have that we have this API and we hope their browsers once they decide to support cache stylist can use this thing so this so these are all the changes so the question is what the next step is maybe we could go through right and and and so that\u0027s the the I guess the question is that we\u0027ve been letting this draft hangin around for a little while to see if a browser would implement it and and we don\u0027t seem to have anyone prioritizing it you know in a native browser implementation although as Kazuo mentioned we do have some header implementations and so if if we don\u0027t get any information about that I think it makes sense to take it to last call and go as experimental pkg hi this is Gigi I apologize that I have not read the draft does the are you expecting for the client to remember this for the duration of the resumption ticket of the TLS resumption ticket earth so that that\u0027s the explicit duration that you want that to be cached ah you mean the accept cash digest header will be remembered for the duration of the session ticket of the session to get okay on the other hand the cache state is more stable oh I mean the thing right but this particular header is synced in it\u0027s it\u0027s retained specifically alongside the presumption state yes okay so does anyone have any any comment about going ahead to working group last call with this does any browser vendor went to shout no no I\u0027m going to implement that right we did have some interest but we didn\u0027t have a commitment so Oh Mike I wish I could be doing SH and doing the shouting that I\u0027m going to implement this but I think we\u0027re still in the same state of interested in that but don\u0027t have any immediate plans for it we want to see how it goes could you remind me though what is the size particularly when you base64 it we\u0027re kind of sighs do you need four acceptable false positive rates sorry what\u0027s what size do you typically see with the header version when you base64 it what to represent a reasonable cash with a reasonable false positive rate yes I understand that you know we don\u0027t have we only have very small size deployments at the moment so loads our numbers quite small like how everybody\u0027s going to save it mm-hm hundred bytes "
  },
  {
    "startTime": "00:37:07",
    "text": "Mike firfer but for the very limited deployments we have now yes when you use the header I see something like the serviceworker cache answer you\u0027re choosing what you store in it rather than doing it full HD right so for a lot skill site a lot especially with that I catch that his frame would typically be one that rings a bell I think that\u0027s what I came up with yeah and you know it kind of blows due to base64 and it will have some impact on the HP compressor it however the size is likely we might be less than half of the HVAC C so hopefully we can live with some hon Thompson you said less than half the h-back state how big are you actually making these things I didn\u0027t think it was that I didn\u0027t think they were that big yeah and where people are advertising pretty large h-back tables now after realizing that the default is fairly really small so I\u0027m not I think part of the problem here is that this is an experiment backed up behind what is effectively another experiment and the success of server push on the whole doesn\u0027t hinge on this but it it is still in question I think some people would disagree with that I think some people see this as necessary to make the server push successful and I know that that\u0027s a contentious topic but some people have stated that sure but a lot of the problem this solves some of the problem with server push but not all the problems that we\u0027ve discussion at some length up in other venues but to the extent that it fixes the problem it is it is also equally encumbered by the other problems that that are attached to so proportion and until we understand more we we can\u0027t really say whether or not this is the right solution and that\u0027s why I think we should publish it as it experimental and just though it\u0027s been sitting here it hasn\u0027t changed in some ridiculously long time now there are implementations out there let\u0027s see how the experiment runs right and explicitly say this is an experiment to determine whether or not we can fix heavy push but the one thing we were kind of waiting for was that a whole discussion of golden compressed sets versus cuckoo filters but that seems to us without more data we can\u0027t really make a decision there otherwise so we decided just to stick with how it is so in jabber llansteffan oats that size depends on the probability you want to achieve which mic agrees with either bread lossy Google Chrome just to answer the question of what our status is we\u0027re interested in this but it\u0027s not prioritized the biggest problem we see is it\u0027s quite hard "
  },
  {
    "startTime": "00:40:08",
    "text": "to implement within our current cash implementation so and we\u0027re not sure that this is the right solution to server pushes problems so if this doesn\u0027t have a high probability of being required we don\u0027t want to put the investment in to rewrite our whole cache to support it that makes sense Gemma and Gugu just came up to Jen Iyengar Google I just came up here to can you hear me now yes yes to say that I agree with Martin in that this seems like an experimental proposal unless there\u0027s any other way to do this that\u0027s that\u0027s the way I would publish it as experimental right thank you and I think the worst case is is that if a browser gets interested but discovers that this isn\u0027t the right approach we burn a frame type and have cache digest 2 or whatever it is but it\u0027s still worth publishing I think it\u0027s a bit we\u0027ll never have again mark what about the bits we will think of other bits yes thank you thank you so mark I have a friendly I have a request for an agenda Bash can we at least move the origin frame a little later we have someone in another in another room doing a presentation who would like to be here for this certainly sir that puts us at random access in live content we\u0027ll find out if dar shockers paying attention or he thought he had another 10 minutes and you checked in a PowerPoint presentation I checked in when I was sent bad Patrick oh yeah hold on let\u0027s see if I can make this work that\u0027s a shit of really quick and we don\u0027t even need the presentation ok I can go we\u0027re getting there I can\u0027t guarantee the fonts will be exactly the same that\u0027s all right so I\u0027m just gonna I\u0027m here to just give a quick a bid on the random access live draft that\u0027s right so I think at the last working group we actually had requested comments or feedback from from the working group we haven\u0027t received any specific concerns or comments I\u0027m assuming people have probably read it and no problems at all our people haven\u0027t read it but then the other feedback that we had received was to actually just try out you know the protocol of the idea and make sure that it actually works with caches or intermediaries and doesn\u0027t have any problems with that so next slide on that note so we are actually just working on kind of building a test framework so we have our client and server sort of ready we are you are hoping to finish this by before this IETF but we are a little bit behind so we\u0027ll still finish this and send out our observations of results or hope is that the answer is there are no issues with caches and intermediaries but we want to verify the hypothesis and "
  },
  {
    "startTime": "00:43:10",
    "text": "that\u0027s pretty much it next slide so any questions and I guess the question to the working group would be we is it a good time to issue a last call keeping it open pending over results or should we wait once that\u0027s the question of who\u0027s read the draft raise your hand if you\u0027ve read the draft live access and random sorry random access and live content okay succeed can I help yes I would observe that that you know we can do a last call fairly quickly and so if you know what if you were to bring the data either you know on the lists in next month or two or in Singapore Wieck additional last call and have a two week period and then yeah soft glass call if you like I mean we are sort of right now asking for any concerns which is very similar question through a lens called indeed in right so I would say if you\u0027ve got an active experiment I\u0027d prefer to see it finish and then we can do you know just a two-week call maybe yeah we\u0027re hoping you\u0027re doing before Singapore so okay sounds good right thank you look forward hearing about it 8gb replays just keep going on um we can do that sure so replays this is Martin ah oh wow that\u0027s right all right so one of the things we\u0027ve been doing in TLS is this is zero I\u0027ll teach a theme that has everyone in a flap and one of the things that that document requires of us is to explain how it is that you use your protocol with zero ITT before you actually start using it full disclosure we may have deployed this already without any of the measures that are in this dart in this document but such as the nature of the pre-release channels that has been deployed on that I think we\u0027ve probably claimed that you know there\u0027s an experiment out there right now it just happens to be sort of rather large next slide please so I\u0027m the primary risk here is that zero ITT lights the client make requests but the TLS handshake isn\u0027t done as a consequence there\u0027s no fresh state from the server mixed in to this and the request can effectively be replayed now TLS mandates that you do some Antibes replay stuff and they\u0027re imperfect what "
  },
  {
    "startTime": "00:46:10",
    "text": "can I say next so this is what the draft does and says it says that the TLS connection is modeled as a single stream there was a lot of debate about this in in Telos as to whether you would have separate compartments for the early data and the other stuff and you were somehow have some sort of clear delineation between the two of them practically speaking that doesn\u0027t work for HTTP I\u0027m not sure that works for many TCP based protocols it may work for things that use that data ground protocols but we\u0027re not done with DTLS ones for you just yet and then the document contains advice some basic guidance on what to send in zero RTT and on the receiving end what you might want to do with it and how you would deal with it on that end and then there\u0027s some discussion that we had in a workshop about intermediaries and we realized that we\u0027ve really nice if we had a couple mechanisms from intermediaries and we defined some of those next place so the advice for clients we recommend safe methods in the document there\u0027s some sort of hand waving with shoots and maize and whatnot that allows for other things in the browser context different policies will prevail depending on your attitude and what these things the other thing is that we we actually mandate an automatic retry of the request if the zero ITT is rejected and we talk about the fact that you might decide not to send a request anyway but in the general case if you made the request in zero ITT and zero RCT is rejected then you will make the request again that would be the default operation unless someone has used one of the new methods that we\u0027re providing to cancel the request in the meantime I think that\u0027s probably the only out that we have one that it\u0027s important to recognize this enables an attack and the draft explains that but it\u0027s it\u0027s a 1:1 kind of one time only it\u0027s it\u0027s it\u0027s a visible thing and we are being very careful to distinguish between the effects of retries from the rific at the effects of replays and the distinction here is that a retry is something that the client does with full knowledge of what\u0027s going on a replay or something in an attacker does with the packets on the network and this is language that\u0027s being used in tailless as well next advice to the server\u0027s here first thing is please consider whether you want to enable zero ICT at all and this is something that TLS does not necessarily enable by default you have to turn it on we have some advice on that one and then it says whatever you do before the handshake completes that\u0027s the risky stuff and the assertion in the draft and the model that we have sort of adopted "
  },
  {
    "startTime": "00:49:12",
    "text": "for this not formally verified disclaimer is that if servers always deferred processing of a given request until after the handshake group completes then they will only ever see that request once that\u0027s a that\u0027s an assertion I\u0027m like I said not sure about that and so the recommendation following on from that is that if you\u0027re not sure whether something is safe wait and so this has some performance downsides but the consequence of this is that when you get these messages you have some have some certainty and the performance downsides aren\u0027t it doesn\u0027t completely eliminate the performance gains from zero ITT the opportunity cost of having this slot is not completely wasted so you you can send all the bytes and then the bytes are ready on the server ready for processing and you can even do some basic parsing as long as that parsing is sort of content agnostics side-effect free and all the sorts of things we\u0027ve talked about so there are still some benefits to having the data arrive without actually doing anything about it we talked about that as well next place intermediaries with the interesting discussion so an intermediary really can\u0027t decide what\u0027s safe just based on the knowledge they have typically so what we recommend here is that an intermediary marks the requests that arrive in before the handshake completes with a new header field and that header field signals to upstream servers that the request may or may not be safe as a result of something that happened further downstream on the path and that origin server can reject those requests if it thinks that they\u0027re unsafe or it can defer processing on them or do what whatever other things that might want to do deferring processing at the origin is difficult because it doesn\u0027t know when the hantai completes and doesn\u0027t know whether that that signal doesn\u0027t arrive so the here is that the header field is only really used by intermediaries if a request arrives in zero huh tt you know that the person sending it would have included this header is basically implicitly present by default and that allows us to sort of not worry too much about annotating every single request that we ever sent and saves a little bit space the reject mechanism allows the server to force non zero RCT requests in the unsafe cases it means if the server is unwilling to accept the risk of a replay it can tell the client hey this is not cool try again there\u0027s a risk here again that "
  },
  {
    "startTime": "00:52:14",
    "text": "if this processing is not consistent you get you\u0027ve created a side channel so there\u0027s a little bit of advice about what to do in that circumstance as well and the important point here that we had some discussion between the author authors of the draft for quite some time is that the combination of these two mechanisms requires coordination between an intermediary who enables zero RTT and the servers that sit behind them because if these annotations are not understood by the server\u0027s in the back then the server\u0027s in the back will not know to be it will not be able to reject things appropriately and so the message arrives its marked with early data by the intermediary who supports this draft and implements it and and deploy zero RTT but the back-end server doesn\u0027t even know to look at the early data header and so it processes the message without knowledge of the this risks that it has taken and so that could be exploited in some fairly nasty ways we don\u0027t really know any way to avoid this particular problem I mean once the request is being forwarded then it\u0027s being forwarded and there\u0027s some things we can do that I think this is probably the best solution without making the request completely incomprehensible so we could we could rot13 the entire request if they came in early data and put the old I had a field up front I suppose that would be on we could do some some serious damage to the protocol if we wanted to do to make this possible mandatory but I think this is a reasonable compromise is that all I have no more just a small clarification which I think follows from what you just said this isn\u0027t really for all intermediaries it\u0027s just for gateways yes specifically use the word gateway and the term there because I don\u0027t see this being useful in the forward proxy case because the forward proxy enables the it\u0027s quite convenient you know the client connects with zero ITT it sends a request to the forward proxy like you\u0027re gonna do that anyway but since the forward proxy and the forward proxy annotates in this way but it\u0027s got no idea that the server\u0027s are going to be able to accept this you understand the new header field and I think there\u0027s if I remember there\u0027s still advice in there that if you\u0027re configured to use a proxy you don\u0027t use your RTT correct oh you can use zero ICT because you\u0027re gonna connect yeah right so that\u0027s right you can do whatever you want it\u0027s yeah right I don\u0027t think anyone uses for proxies without this oh yeah so for xx is one of our we have this design pattern that with we\u0027re started to use a lot more often which is an explicit permission to retry something and improves reliability no end importantly here it\u0027s it\u0027s an automatic retry and no matter what the request is this means that clients can "
  },
  {
    "startTime": "00:55:14",
    "text": "be more confident in attempting zero RTT because any server that accepts zero RTT will understand this will reject something if the server blaze it say so if the client thinks it\u0027s safe then they can attempt the zero ITT there was a risk with out these mechanisms that the clients would not do this because if they don\u0027t know that the server\u0027s were able to understand this particularly in those intermediate ated cases where you have the CD ends involved you know the reverse proxy the the gateways and so it becomes a mutual thing both sides have to agree that it\u0027s safe to do this to know each other before anything happens next example so you can see in the example you make the zero RTT request its annotated by the gateway with the new header field the server goes eh not not for me right now and sends back a too early status code and then the client waits for the handshake to complete then we try some request pretty straightforward that\u0027s all I have okay Victor is waiting very patiently the question so one thing which kind of feels weird about this design is that we don\u0027t actually have a standardized mechanism to communicate a between gateway and server whether it\u0027s a connection was secure or not as far as I\u0027m aware so Oh early data feels a little bit weird in this context because it\u0027s like well you don\u0027t have early data you don\u0027t know whether it was actually secure or not so so Victor in the in this in this scenario typically the the origin server is completely usually pretty well aware of the fact that they\u0027ve employed a CDN or have a load balancer sitting in front of them I\u0027m not sure whether I why you have this specific concern as a result of this I mean is it just an observation it\u0027s mostly an observation that just feels weird well another thing to feel weird yeah welcome to http especially with CD ends it\u0027s about it\u0027s about anger so if I\u0027m understanding this correctly the clients don\u0027t send their early header but this is meant for only intermediates it\u0027s implicit in the case when you put something you know a data the that the purpose of it is to signal that something on a previous hop happened so as for example as a browser if I\u0027m sending a request server early data then is it valid for me to actually include this early data header but because I would be really useful since without that I didn\u0027t is that whatever the the intermediate proxy has to have a separate API to "
  },
  {
    "startTime": "00:58:14",
    "text": "receiver Lydia to know that this data came over early data because it\u0027s a single stream like you said and so there\u0027s a number of reasons sergeant ones I mentioned and one of the more important reasons is that it is often very difficult when you\u0027re constructing a message and putting it on the wire knowing what the status of the the wire is when the message hits the wire and so this way allows the clients to send the same message twice and and avoids accidentally annotating things that are either the handshake is yeah I think that equal same argument to be made about like receiving data as well and some data as between the half there are two tiered stuff so I\u0027ve assumed that like a reasonable thing would be if I have at least some data on this request sterilized of a zero ITT I would include this early data header and that would help terminating proxies not need to have the separate API first evening so RTT data if they want to do something more fancy they can you don\u0027t need a separate API how the the draft sort of explains this that the terms under which we we mark things is is the handshake complete that is the marker that we\u0027re looking for and it\u0027s a very simple marker to get and every every stack that I\u0027m aware of has has a very clear delineation you have a point in time at which the handshake is considered complete and a point where you may may be uncertain but it\u0027s I\u0027m gonna cut in I don\u0027t know we\u0027ve got 20 minutes left and other things to discuss the focus here should be on whether there\u0027s interest in adopting the document not on the details please as a solo developer who has already shaped a gateway that suppose you are Tiki I love to have this document for my eyes early and even before working group adoption I love to have that 4x X code space piloting the sick number so that we can implement it we had some debate about the number was less that\u0027s already a teapot Nick yet Nick Sullivan I like this I support this draft I think it\u0027s really good the only question I had was how are you going to deal with interactions with TLS intercepting proxies it\u0027s the wild wild west out there then nothing I can do about it this is dkg so the decision on the server side of when to send the 4xx is I think the least understood part of this the part of this that I understand the least yes I think the semantics that we want for that are you as a server must know the complete architecture of your entire operation and you must be able to identify as an origin server the set of requests that are not permissible to be sent in that that would be damaging if "
  },
  {
    "startTime": "01:01:17",
    "text": "they were redoing and so when it said you\u0027re effectively saying sort of permission to retry what you\u0027re actually saying is there\u0027s no way that if this thing was replayed somewhere else we\u0027re not sick it\u0027s attempting to read this as the semantics are ok I receive this but for whatever reason I I\u0027m not gonna handle it therefore it\u0027s safe to go ahead and retry which is distinct from saying the request that you sent is not something that should have been in zero rgt in the first place you see what I\u0027m saying but we don\u0027t want to do is we don\u0027t want to we don\u0027t want the origin server to be like okay I received this I\u0027m not gonna process it because it could have been replayed therefore it\u0027s okay to go ahead and retry there\u0027s there\u0027s two slightly different meanings there yeah and it would be really bad if we gave origin servers the wrong guidance yeah and so this is actually the critical guidance and that\u0027s the part that I I\u0027m not confident you know so pkg what it were close is that something that you think would stop us adopting it or something that we could discuss and perhaps no I think it\u0027s something that if we\u0027re good I think I\u0027d opting it is reasonable I see the I see the if we\u0027re gonna have zero RTT I see the need for this but but yeah okay so full disclosure so along with Martin and Willy I\u0027m a co-author on the doc so determining consensus for this lies in Patrick\u0027s capable hands so we\u0027re gonna seek consensus from the working group do a couple hums on whether or not we\u0027re interested in adoption of this document I guess first can you hum if you have read this document if you favor the working group oh we got one on jabber there got to do both if you favor the working group are adopting the document that\u0027s been presented here would you hum now and if you oppose the working group docking the document we\u0027ve discussed here hum now okay that sounds like strong consensus perhaps unanimity well this reflects at least three or four adopting hums on jabber five they keep growing so thank you Thank You Martin Thank You Nikki mark I think we should backtrack and reward it Martin is the person who you were concerned about now with us I thought that might be the case I think we should give that party because that\u0027s active work Randy so let\u0027s talk about origin um do I need to update my classes are now authenticated there we go I just need to pull it over they\u0027ll be a second you go ahead and get a pen oh sure they were really good more chair slides than not personal slides so is there anything to discuss on origin other than the active discussion on the "
  },
  {
    "startTime": "01:04:17",
    "text": "mammals as one of the author\u0027s I do not believe they\u0027re primarily errs there is some discussion that has been going on regarding a few things that Lucas brought up and if you want you know Mike time to address those I think that\u0027s fine but the primary issue in the document has been this clause other than that we are I think fairly close to wrapping up the origin frame extension so the clause reads clients must not consult the Dinah\u0027s to establish the connections authority for a new requests this is in reference obviously to origins that were in the origin frame and it of course also involves the normal certificate checks from 7540 that are referenced elsewhere in the text this clause you know it\u0027s clearly not yet reached working group consensus there are a couple different schools of thought on this so if you want to move to the next slide I think there is consensus that the existing DNS provision in 7540 is a weak second factor involved and you know establishing a connection there is however disagreement in the group about you know just how valuable of a factor that that is and so the discussion has been leading the chairs to ask you know this question here is the substitution of a different more performance and privacy friendly second factor or factors you know into the origin extension you know a path forward with that if mark which I can make any comment says you know co-author of that document not that slide so I mean from my perspective I\u0027m looking you know has an editor I\u0027m an editor on that document as well for a way forward on it and and as I commented on list in the last day or two you know historically we haven\u0027t specified the exact spec stack of specifications that you use when you\u0027re verifying about a new certificate for htdp that has resided elsewhere the IETF defines a selection of those mechanisms but we don\u0027t say in HTP itself you must do this this this or this and so it seems like we should think about that before we go and specify specific mechanisms here but from what I\u0027ve seen there does seem to be support for saying in a slightly more vague fashion you need some sort of second factor beyond just their certificate itself and and and it could be that mechanisms that we typically use to validate those certificates could also be used as that second factor to have more confidence in it but I\u0027m still looking as an editor for input from the working group on exactly how we want to go back to that mm-hmm comments from the floor yeah so so Martin Thompson I think the this Falls kind of into the territory of what "
  },
  {
    "startTime": "01:07:21",
    "text": "what does a client do to decide that a given server is acceptable for a given name and there is there are some commonality there but there\u0027s also quite a bit of wiggle room our certificate transparency policies diverse and the way that we validate certificates is in some cases a little bit different and we have different trust anchors in some cases and so the idea that we mandate a single thing is I think the point on which we\u0027ve actually sort of gotten wrapped around the axle in this discussion and I that the the right advice here is that we we acknowledge the possibility that DNS is important and that we\u0027re potentially taking that away recognize that the privacy benefits of doing so are significant and then say that and a client or user agent can make its own decisions about what policy it wants to apply in determining whether or not a given request can be made to this particular server and I think that is it\u0027s kind of weaseling in a sense because we\u0027re just sort of pumping the can down the road a little bit but with a lot of these things I think the the normalization comes with time as we get more experience with the policies I do think that there is value in having the must not DNS statement in here and retaining that because I don\u0027t want servers to be in a position where they can\u0027t rely on this mechanism for particular properties and that property that I care about here is not making additional DNS queries and certainly in the in the current environment making those DNS queries expo certain information to to others that I would rather not have exposed so um just to respond to that I get a little uncomfortable when you talk about servers relying on that property because that\u0027s not a design property that we have and it\u0027s possible for you know in error handling in transients conditions for a connection to close or foreign or you know an origin to be popped onto a new connection and all the sudden it is exposed to the network and if your piano and not being exposed to the network that that it seems like it\u0027s a much higher bar than we\u0027ve currently designed a floor it is you probably also need some kind of an acknowledgement yeah Eric right so what happens when you send this origin frame doing an existing client nothing right so it\u0027s already the case that you cannot rely on this property right and similarly any client which decided to it didn\u0027t like the origin the frame would then be made these DNS requests so as far as I can "
  },
  {
    "startTime": "01:10:22",
    "text": "tell regrettably you know I mean regrettably this is a best-effort kind of situation unless we\u0027re gonna create some a mess we\u0027re going unless we\u0027re gonna grate some indication for the client that says I promise to speak origin and I promise not to do DNS or cross those are evidences that would be a new kind of interlocking we have not previously but we could put in an acknowledgment like essentially yeah I mean we could put a thing where the client said and right you would think with a client could it could you say that those are my semantics it\u0027s not in touch I guess the question then becomes is how would how would we actually expect the server behave differently under those circumstances given that presumably the situation at hand is the client is gonna attempted you reference those URLs and if the client like you know refuses Jeff I mean like the server\u0027s not gonna send you some content which causes external linking because then because you said screw you I don\u0027t like origin I mean I I guess I guess I understand like I mean I agree agreed the desire a property to conceal the DNS requests I just don\u0027t understand how like how is this so we\u0027re gonna dependent that property even if it could so I agree that I don\u0027t this is dkg I also don\u0027t see how without some additional mechanism and I\u0027m not even sure what the mechanism would be that we can make this a must although I agreed that it would be nice to make it a must this statement of the problem that\u0027s on the screen right here I think is problematic because it says existing DNS provision but it\u0027s really doing about existing DNS over the local network provision there are multiple ways to get DNS data and I think if we\u0027re gonna frame the problem like this we should be clear that we\u0027re talking about the network path being the additional week second factor not the fact of DNS data period so for example I could have some additional out-of-band channel that gives me DNS information or I could have an in band general that gives me DNS information not to bring this working group to the question though but the you know it\u0027s not about DNS / data it\u0027s about what came over the local model oh no the provision of 7540 is about data we\u0027ve got two remote people waiting let\u0027s do one or two of those no sure of course Yoshiko Google sorry we\u0027re on Mike\u0027s on or about people yes I\u0027m like hey so I\u0027m going to echo the concerns that I don\u0027t really want to see this as a must not because and you have existing clients that are that already have coalescing logic and I don\u0027t think that this should depart from that substantially if we want to say that it\u0027s a clients may do other things may omit the check and have some guidance as to what you might look for before you make that decision I think that\u0027s probably a smarter path I also will repeat what I said in the jabber that "
  },
  {
    "startTime": "01:13:23",
    "text": "we\u0027re also later today doing an adoption call for a draft that says the exact opposite the client must still do DNS so we need to reconcile this one way or the other in both graphs thanks Mike go ahead ekor oh yeah so um I I guess two things first is um um I don\u0027t I think partially right the the we second factor is the go deep on the network path that is allegedly associated with the DNS and that will be a weak second factor even if the DNS were entirely trustworthy mainly say you got that over DNS SEC like the issue is is the the issue is the if I thought the factors are way if all the network between you and the website right so the the is attending to give you is even if we trusted yes entirely is not being routed some entirely third location which is not associated with it with the origin you care about um the that the second thing I was going to note is that we actually can take three postures one posture is the one that\u0027s in this traffic nobody likes very much the other is to sort of kind of encourage people to do some other second factor and not say what that really is but say there ought to be one and the third is to say we take no position or are hostile so that you have a second factor that we spoke you can so I think like I mean this is sort of a very weaselly kind of text um I think it might be better simply to document exactly what the assumptions are and say implement we\u0027d lead off the implementations decide how to behave I don\u0027t know so not place requirements around them just document possibilities yeah I mean I mean I mean my sense was that that may the people on the mailing list resisted the ID you should not do a second check and um and so if we\u0027re gonna say is that means me saying don\u0027t do a second check to be problematic by their hand I sense their people um you know in a sense there were people all in the discussion who thought a second check was silly and then I\u0027m like that makes me operate enthusiastic about recommending a second check especially when there appear to be 84 second checks with extremely different security properties no okay Victor so if was there is one saying which my experience with browsers and socket poles has taught me is that normally so they cannot promise you that they will handle requests in certain way they will try to handle it optimal way but God knows how it will they actually handled so I do not believe that from perspective of user agents this is actually a viable strategy the assumption of not having DNS queries is viable so I do i side with occurs that which would document "
  },
  {
    "startTime": "01:16:23",
    "text": "that there might be a second factor required by user agent and documents clearly what happens when the user agent declines that second factor and whether it declines its explicitly or implicitly but leaves the specific policy after browsers thanks Victor the cheek or a Google so I would rather see as the site what should be the second factor especially since some of the considerate options would require changes to the format of origin frame for example if you wanna staple DNS SEC response and send it inside of jean-frank that\u0027s part of the draft and it cannot be like hand wave it and say like trying to do whatever then Schwartz I agree with that I it does seem like having a you even just a relatively open-ended extension field in in origin to be able to figure this out later it would be nice let\u0027s hear from Eric no audio working here yes yeah I think the one of the things that worries me is trying to well I appreciate the desire to have a pride can do someone\u0027s for privacy reasons trying to have something that\u0027s not explicitly designed for privacy it\u0027s just kind of a a piece of an overall privacy story seems like it could do more harm than good and it may make sense to take the design of a a privacy specific thing and look at what are all the pieces needed together and treat that as a separate draft and have the origin frame itself just go back to not changing the existing behavior because because prior to origin frame the there already are constraints on what sort of coalescing is needed in that era allowed and that DNS needs to be checked so the the most conservative thing to do would be forge and frame to not relax that requirement and then for us to look back separately at building a better and more comprehensive story on how we might want to real relaxed the DNS requirements in a way that that can be that does does it could unbuild up a comprehensive privacy story some of them Thompson I just wanted to push back against the suggestion that we that we hold this one because we might want to make some changes to the origin frame I think the if we do want to make some if we do want to say do some DNS SEC record pinning and we would find a way to do that virtually orthogonal to the to all of this and I just keep coming back to the "
  },
  {
    "startTime": "01:19:25",
    "text": "the notion that this is really kind of this DNS requirement is really a policy decision that we made by accident I think more than anything else and that we\u0027re relying on it so thoroughly is it\u0027s kind of sad but we kind of got it\u0027s like one of those ossification things we we ended up here by accident now we\u0027re now we find that we can\u0027t remove it and I don\u0027t know what it just makes me sad that that\u0027s where we\u0027re at I would rather leave this completely for the time being and loans and things maybe before we actually commit to something okay so I think the chairs will have to huddle and sort of you reread the minutes here but thank you all for the comments ad Adam wrote are you still the room are okay well based on that we\u0027re going to do the discussion of BCP 56 bits next and hopefully we\u0027ll talk about HC Beecher as time allows in our next session we\u0027ll try and carve out a little space for that but we appreciate out of making time to be here for this okay if I can get to it all right so um this is another proposal for a document that I\u0027ve been working on the background for a little while called BCP 56 bits and the original BCP 56 was on the use of HTTP a substrate so basically how do we use you know HTTP well when we use it with other protocols that are defined inside the IETF and it was done this is from the data tracker as you can see in 2002 2002 it had just a couple of drafts from from Keith Moore and and was published way back then and this is the abstract which I finally recently somewhat amusing it turns out we we now have a lot of interest and quite widespread interest in using HTTP as a substrate for other application level protocols I have a cron job on one of my boxes that emails me and Patrick every couple of weeks now and and lists all of the ITF documents in working groups that reference HTTP and this is the current run of that tool there are lots of people you know using HTTP different ways and this doesn\u0027t actually list them all there are new working groups blowing up all the time it\u0027s saying oh yeah we\u0027ll use HTTP for that and and I don\u0027t have time to review them all and give them advice Julien I\u0027m sure doesn\u0027t have time to review all the header fields that they create he is our bottleneck for header field "
  },
  {
    "startTime": "01:22:26",
    "text": "syntax as well as other things of course it\u0027s it\u0027s the there\u0027s a lot going on we\u0027re seeing an explosion of this not just in the outer world but but in the IETF specifically and in the outer world it\u0027s happening as well you know HTTP api\u0027s are used for everything including cat gifs and the problem that I see or maybe problems too strong but one of the issues is that people design a an API for their own server to deploy to serve cat gifts via API and they don\u0027t think about the implications of taking that API design for one HTTP server and scaling it out to multiple HTTP servers multiple implantation with different versions and different extensions and the coordination problem that that entails it\u0027s it requires a different kind of protocol but they\u0027re still using the techniques that they\u0027ve learned deploying their single implementation and deployment API on the other hand you know the it\u0027s very easy for an effort to give this kind of guidance to turn into a bit of a crusade to to say thou shalt be restful and and I really want to avoid that that minefield I want to have advice that is useful to people based upon the experience we have as a community for using HTTP as a substrate and so that is the the line I\u0027m trying to walk and it\u0027s very embryonic right now that\u0027s the line I\u0027m trying to walk in this document it\u0027s it\u0027s very bare-bones right now but I think the question I have for the working group as an editor of that document is are we interested in in in starting work up in this area again the the hallway chats I\u0027ve had personally are that people recognize its way past overdue for for revising this advice because the world has moved on considerably since 2000 and 2001 in terms of how we use HTTP and so I wanted some feedback as to whether people are interested in working on this and giving feedback I\u0027ve already had a lot of feedback during this meeting that I\u0027ve started incorporating the document there\u0027s certainly a lot more work to do but I\u0027m very interested in doing this if only to save us the time and the effort of scaling you out to individual reviews all the time Jonathan the Jedi and God I think yeah I think that it makes complete sense to consider the things that you would need to do to make HTTP a good substrate if that\u0027s part of the goal of such of this document and I think it\u0027s absolutely appropriate in particular when something becomes a substrate which HTTP has it ends up picking things into it which people don\u0027t realize that you don\u0027t scale widely to large numbers of applications latency is one of those things when there\u0027s a tiny bit of latency that\u0027s baked into the substrate things that build on top of it end up havin deeper and deeper latency that\u0027s not a good thing to have so being able to document all of that stuff is "
  },
  {
    "startTime": "01:25:26",
    "text": "very useful at the same time I wonder if this is the community that would be in a position to do that what I mean by that is the people who are actually using HTTP as a substrate are likely to be folks who don\u0027t care about exactly what is going on underneath but are more likely to simply grab a library which they can use to talk easily to the other side and use the surface of it and use HTTP without necessary caring about exactly what\u0027s going on underneath my wrist but I think that\u0027s true for folks outside the ITF but we still have folks come here who want to use HTTP as the protocol and JE map is an excellent example of that we spent some time with Jay map this week talking about their use of the protocol and for me that was an exciting thing to do because we learned that they had requirements that we weren\u0027t meeting and so now we can start to think about how we could possibly meet those requirements and also we can give them at the same time we can give them some guidance of where they are able to use existing things in HTTP we can guide them to make sure that they\u0027re not breaking other stuff or that they\u0027re using it well so I think you know certainly there are folks in this working group who this may be too high layer for more to semantics for but there are also a lot of people in this working group I believe who have a lot to say about this and have the right experience to do it yeah I should probably change what I said you\u0027re right of course and I I guess I was thinking that there are people who are not in the room who you may want to invite into the room to talk about how it\u0027s being used sure that\u0027s a perhaps a slightly different point than what I made earlier as part of the goal also do document issues that are mean this is going to be a BCB I don\u0027t know the data are in the document but certainly if we encounter things that you know are too gnarly to put in there I would like to resolve them some somehow yes well Google line after atom separate document whatever yeah not until some like like the the general goals and particularly the way that you stated them we\u0027re going to push back a bit against what what Jonah said here one of the core things that I think this document kind of needs to say if if not directly but but sort of at least cover is that HTTP is not a dumb transport protocol right it\u0027s an application protocol and the consequences of that are what the document explores in great depth and that\u0027s valuable to the extent that HTTP serves the needs of people we should make it better suit those needs but I\u0027m not interested in having the discussion about how you might use it for a multiplexing protocol or as a substrate for tunneling and various other things over the top I think that\u0027s just one of the one of the ways in which it has been abused and I think we can talk about things like eventsource and various other things where they "
  },
  {
    "startTime": "01:28:26",
    "text": "basically treat it as a transport protocol right and it is kind of ill-suited to that I will just add to that Jonah every time you call HTTP a transport protocol Roy fielding knows and he will find you so it\u0027s transfer Ferg in the end it\u0027s not Adam Roche I wanted to end up here mostly because of all the example of J map is interesting they\u0027re they\u0027re kind of you know a motorcycle with you know relatively small crowd falling behind it we have a freight train called 5g that has already said that they\u0027re looking at HTTP for their you know working between their services they\u0027re basically breaking their monolithic service it down into what looked to me like micro services and they\u0027ve already strongly signaled that they\u0027re likely to want some changes here right so we should definitely have some guidance in place for them before that happens I think that\u0027s probably a lot more motivating than the current ongoing efforts inside the ITF Alexei Alexei as an area director I review lots of documents that try to use HTTP so I can\u0027t quite understand you as as an area director I review quite a lot of documents to try to use HTTP so having a single point where you know partially as a checklist partially where to send people you know go fix these things now would be very useful for me thank you until I clear I\u0027m very excited if you can actually do this job right I have not at all attached to the current form of the document I think it probably needs to change quite a bit so we were we\u0027re out of time we cut the line down sorry and we are out of time in the session so we will do another revision before he does that okay never mind I think yeah yeah all right thank you everyone we\u0027ll see you back here hopefully a 3:24 mostly quick and HTTP but well if we can we\u0027re gonna sneak in HTTP terrific time as well and Julian called it Trey and his slides it\u0027s turf I looked it up it does I like this this yes I do it\u0027s not in their budget "
  }
]